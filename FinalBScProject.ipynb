{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from datasets import Dataset\n",
        "import time\n",
        "\n",
        "import transformers\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, BertTokenizerFast\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data.dataset import ConcatDataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "iA747vMj9Iq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analytics"
      ],
      "metadata": {
        "id": "w8M6IlRzm3Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "concatenated_df = pd.read_csv('chunked_new.csv')\n",
        "\n",
        "del concatenated_df['Unnamed: 0']\n",
        "concatenated_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mZTuf5Lvm2eS",
        "outputId": "7e95bd6b-afd3-469e-ac97-ee76d32ea79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown\n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown\n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown\n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown\n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown\n",
              "...                                                 ...          ...\n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown\n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown\n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown\n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown\n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown\n",
              "\n",
              "[4374 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17eafddf-7960-4bb0-ac16-9f71ac260979\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17eafddf-7960-4bb0-ac16-9f71ac260979')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17eafddf-7960-4bb0-ac16-9f71ac260979 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17eafddf-7960-4bb0-ac16-9f71ac260979');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6985a9e8-1632-49bd-a57e-9dc841b0bb94\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6985a9e8-1632-49bd-a57e-9dc841b0bb94')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6985a9e8-1632-49bd-a57e-9dc841b0bb94 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9ac61dec-7051-424d-883a-c7dc5e7ed124\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('concatenated_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ac61dec-7051-424d-883a-c7dc5e7ed124 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('concatenated_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "concatenated_df['tokens'] = concatenated_df['LogContent'].apply(lambda x : tokenizer.encode(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDDd3N5lm648",
        "outputId": "14b9a90a-b2a1-4e4f-fd91-b04c19cd0efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_df['token_numbers'] = concatenated_df['tokens'].apply(lambda x : len(x))"
      ],
      "metadata": {
        "id": "34UMVvC5nwV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rGmtMwz_qIdR",
        "outputId": "ecdb94a0-c7eb-4467-9142-edff4c1a4810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  \\\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown   \n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown   \n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown   \n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown   \n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown   \n",
              "...                                                 ...          ...   \n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown   \n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown   \n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown   \n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown   \n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown   \n",
              "\n",
              "                                                 tokens  token_numbers  \n",
              "0     [101, 12046, 2015, 2475, 1012, 17727, 2140, 10...            510  \n",
              "1     [101, 1012, 4949, 10230, 2243, 1024, 1006, 266...            510  \n",
              "2     [101, 1001, 1001, 1047, 1024, 24888, 14117, 21...            512  \n",
              "3     [101, 1024, 24888, 14117, 2102, 1027, 5824, 26...            510  \n",
              "4     [101, 1001, 1001, 4229, 2620, 1006, 11502, 275...            421  \n",
              "...                                                 ...            ...  \n",
              "4369  [101, 4949, 10230, 2243, 1024, 1006, 26640, 10...            510  \n",
              "4370  [101, 24888, 14117, 2102, 1027, 16065, 14142, ...            510  \n",
              "4371  [101, 1001, 1001, 1056, 1027, 16785, 2575, 177...            512  \n",
              "4372  [101, 1001, 1001, 1018, 1006, 6146, 17914, 238...            512  \n",
              "4373  [101, 1001, 1001, 1047, 1024, 24888, 14117, 21...            232  \n",
              "\n",
              "[4374 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03cd8d1f-9ded-4523-aadd-e101535ba5d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>tokens</th>\n",
              "      <th>token_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 12046, 2015, 2475, 1012, 17727, 2140, 10...</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1012, 4949, 10230, 2243, 1024, 1006, 266...</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1001, 1001, 1047, 1024, 24888, 14117, 21...</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1024, 24888, 14117, 2102, 1027, 5824, 26...</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1001, 1001, 4229, 2620, 1006, 11502, 275...</td>\n",
              "      <td>421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 4949, 10230, 2243, 1024, 1006, 26640, 10...</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 24888, 14117, 2102, 1027, 16065, 14142, ...</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1001, 1001, 1056, 1027, 16785, 2575, 177...</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1001, 1001, 1018, 1006, 6146, 17914, 238...</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[101, 1001, 1001, 1047, 1024, 24888, 14117, 21...</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03cd8d1f-9ded-4523-aadd-e101535ba5d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03cd8d1f-9ded-4523-aadd-e101535ba5d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03cd8d1f-9ded-4523-aadd-e101535ba5d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13baa7c9-3bd1-41af-8645-936fdf0c706e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13baa7c9-3bd1-41af-8645-936fdf0c706e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13baa7c9-3bd1-41af-8645-936fdf0c706e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f4ca610b-ef52-4990-8ebb-c9d7fbbd6f86\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('concatenated_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f4ca610b-ef52-4990-8ebb-c9d7fbbd6f86 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('concatenated_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_df.to_csv('forAnalysis_cunked.csv')"
      ],
      "metadata": {
        "id": "lcZvAtPLpSDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4DcAT3AfaWn"
      },
      "source": [
        "# Start The Pre Processing Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NKjY1U7lXJh"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftmClNnlir2k"
      },
      "outputs": [],
      "source": [
        "Filter_time = data\n",
        "# Filter_time['LogContent'] = Filter_time['LogContent'].str.replace(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3} ', '')\n",
        "Filter_time['LogContent'] = Filter_time['LogContent'].apply(lambda x: re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}', '', x))\n",
        "# Display the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7V0rFe8mne_"
      },
      "outputs": [],
      "source": [
        "# Filter_time['LogContent'] = Filter_time['LogContent'].apply(lambda x: re.sub(r'INFO', '', x))\n",
        "# Filter_time['LogContent'] = Filter_time['LogContent'].apply(lambda x: re.sub(r'org.apache.hadoop.', '', x))\n",
        "Filter_time['LogContent'] = Filter_time['LogContent'].apply(lambda x: re.sub(r'\\[main\\]', '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzRFponpmtqH",
        "outputId": "1d4d937c-ffd3-480d-da8a-583cb2254e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5140"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['LogContent'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "iGB7L2Zkkt0W",
        "outputId": "b013c03e-2a52-4a4d-9642-6ddd71a87b20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"   metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\\n   metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system started\\n   mapred.YarnChild: Executing with tokens:\\n   mapred.YarnChild: Kind: mapreduce.job, Service: job_1445144423722_0022, Ident: (mapreduce.security.token.JobTokenIdentifier@6ace4625)\\n   mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\\n   mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445144423722_0022\\n   conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\\n   yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\\n   mapred.Task:  Using ResourceCalculatorProcessTree : yarn.util.WindowsBasedProcessTree@3c367995\\n   mapred.MapTask: Processing split: hdfs://msra-sa-41:9000/pageinput2.txt:1207959552+48562176\\n   mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\\n   mapred.MapTask: mapreduce.task.io.sort.mb: 100\\n   mapred.MapTask: soft limit at 83886080\\n   mapred.MapTask: bufstart = 0; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 26214396; length = 6553600\\n   mapred.MapTask: Map output collector class = mapred.MapTask$MapOutputBuffer\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 0; bufend = 48193401; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 26214396(104857584); kvend = 17291232(69164928); length = 8923165/6553600\\n   mapred.MapTask: (EQUATOR) 57262153 kvi 14315532(57262128)\\n  [SpillThread] mapred.MapTask: Finished spill 0\\n   mapred.MapTask: (RESET) equator 57262153 kv 14315532(57262128) kvi 12120076(48480304)\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 57262153; bufend = 658166; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 14315532(57262128); kvend = 5407424(21629696); length = 8908109/6553600\\n   mapred.MapTask: (EQUATOR) 9726918 kvi 2431724(9726896)\\n  [SpillThread] mapred.MapTask: Finished spill 1\\n   mapred.MapTask: (RESET) equator 9726918 kv 2431724(9726896) kvi 228516(914064)\\n   mapred.MapTask: Starting flush of map output\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 9726918; bufend = 49084664; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 2431724(9726896); kvend = 21376588(85506352); length = 7269537/6553600\\n   mapred.MapTask: Finished spill 2\\n   mapred.Merger: Merging 3 sorted segments\\n   mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 105653983 bytes\\n   mapred.Task: Task:attempt_1445144423722_0022_m_000009_0 is done. And is in the process of committing\\n   mapred.Task: Task 'attempt_1445144423722_0022_m_000009_0' done.\\n   metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\\n\""
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Filter_time['LogContent'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIkb9rfnjdeE"
      },
      "outputs": [],
      "source": [
        "Filter_time.to_csv(\"check.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWL0hJN9ibzr"
      },
      "source": [
        "# Pre Processing Phase 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVt6v7v5Vhpp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a9bb87ab-560e-45ba-94cd-76308924d600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "3       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "4       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "..                                                 ...                   ...\n",
              "753     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "754     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "755     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "756     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "757     mapreduce.v2.app.MRAppMaster: Created MRApp...           MachineDown\n",
              "\n",
              "[758 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aeb3932-8cfb-4dd5-bbe6-dc220776def9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>mapreduce.v2.app.MRAppMaster: Created MRApp...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aeb3932-8cfb-4dd5-bbe6-dc220776def9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3aeb3932-8cfb-4dd5-bbe6-dc220776def9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3aeb3932-8cfb-4dd5-bbe6-dc220776def9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd3f9bf9-3380-4815-a019-99c11d8b45dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd3f9bf9-3380-4815-a019-99c11d8b45dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd3f9bf9-3380-4815-a019-99c11d8b45dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d77ca05a-2a58-44ec-bbd9-d7818ca4541e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_process')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d77ca05a-2a58-44ec-bbd9-d7818ca4541e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_process');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#1st time LangChain\n",
        "data_process = pd.read_csv(\"check.csv\")\n",
        "del data_process['Unnamed: 0.1']\n",
        "del data_process['Unnamed: 0']\n",
        "del data_process['FileName']\n",
        "data_process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd time LangChain\n",
        "df_1 = pd.read_csv('dataset.csv')\n",
        "df_2 = pd.read_csv('largerLogs.csv')\n",
        "data_process = pd.concat([df_1, df_2], ignore_index=True)\n",
        "del data_process['Unnamed: 0']\n",
        "del data_process['num_words']\n",
        "del data_process['labels']\n",
        "data_process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WXDnHNoXOdpK",
        "outputId": "98f06da8-448e-4272-8175-2b2a362c2670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "2       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "3       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "..                                                 ...                   ...\n",
              "621     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "622     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "623     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "624     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "625     mapreduce.v2.app.MRAppMaster: Created MRApp...           MachineDown\n",
              "\n",
              "[626 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16d42c4d-c05d-4c3f-b42f-835d5ddd9856\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>mapreduce.v2.app.MRAppMaster: Created MRApp...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>626 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16d42c4d-c05d-4c3f-b42f-835d5ddd9856')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16d42c4d-c05d-4c3f-b42f-835d5ddd9856 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16d42c4d-c05d-4c3f-b42f-835d5ddd9856');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cb5932f-cff2-42a3-b114-1e7980adb685\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cb5932f-cff2-42a3-b114-1e7980adb685')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cb5932f-cff2-42a3-b114-1e7980adb685 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_08d9864b-c8e8-4438-aebf-5367ef8d7289\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_process')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_08d9864b-c8e8-4438-aebf-5367ef8d7289 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_process');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_process['num_words'] = data_process['LogContent'].apply(lambda x: len(x.split()))\n",
        "data_process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Z4fWHhKINtL3",
        "outputId": "76525f75-9769-42d0-e7d4-2a2620d3e99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "..                                                 ...                   ...   \n",
              "753     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "754     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "755     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "756     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "757     mapreduce.v2.app.MRAppMaster: Created MRApp...           MachineDown   \n",
              "\n",
              "     num_words  \n",
              "0          270  \n",
              "1          464  \n",
              "2          449  \n",
              "3          254  \n",
              "4          382  \n",
              "..         ...  \n",
              "753        256  \n",
              "754        298  \n",
              "755        464  \n",
              "756        214  \n",
              "757       4678  \n",
              "\n",
              "[758 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8afa29af-657d-434c-8ae7-4e3ed3e639d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>mapreduce.v2.app.MRAppMaster: Created MRApp...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>4678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8afa29af-657d-434c-8ae7-4e3ed3e639d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8afa29af-657d-434c-8ae7-4e3ed3e639d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8afa29af-657d-434c-8ae7-4e3ed3e639d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d92cb30-c435-47a5-a8bb-d35a4bd2388b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d92cb30-c435-47a5-a8bb-d35a4bd2388b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d92cb30-c435-47a5-a8bb-d35a4bd2388b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c00e9a39-2211-43e4-9592-6009b92e4130\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_process')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c00e9a39-2211-43e4-9592-6009b92e4130 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_process');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = data_process[data_process['num_words']>512]\n",
        "# tmp.to_csv('largerLogs.csv')\n",
        "tmp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7Xeiy-olN1IX",
        "outputId": "487f4370-a6f0-4358-99aa-27f5af4f9bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "10      metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "11      metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "16      metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "28      metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "29      metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "..                                                 ...                   ...   \n",
              "710     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "718     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "728     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "741     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "757     mapreduce.v2.app.MRAppMaster: Created MRApp...           MachineDown   \n",
              "\n",
              "     num_words  \n",
              "10        1212  \n",
              "11         960  \n",
              "16         979  \n",
              "28         945  \n",
              "29         945  \n",
              "..         ...  \n",
              "710       1074  \n",
              "718        720  \n",
              "728        997  \n",
              "741        832  \n",
              "757       4678  \n",
              "\n",
              "[99 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b110f56-503e-4d8a-a1a7-4ea82bcb8fb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>1074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>mapreduce.v2.app.MRAppMaster: Created MRApp...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>4678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b110f56-503e-4d8a-a1a7-4ea82bcb8fb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b110f56-503e-4d8a-a1a7-4ea82bcb8fb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b110f56-503e-4d8a-a1a7-4ea82bcb8fb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-801abacc-0689-4d1e-842f-09b4ac99aaa2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-801abacc-0689-4d1e-842f-09b4ac99aaa2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-801abacc-0689-4d1e-842f-09b4ac99aaa2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_52ba9401-0ffa-4e9c-9039-92329bb0995f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tmp')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_52ba9401-0ffa-4e9c-9039-92329bb0995f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tmp');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Iy9FXrBnWh6w",
        "outputId": "a347a142-1b44-4963-a010-ad6a3c87d98f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"   metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\\n   metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system started\\n   mapred.YarnChild: Executing with tokens:\\n   mapred.YarnChild: Kind: mapreduce.job, Service: job_1445144423722_0022, Ident: (mapreduce.security.token.JobTokenIdentifier@6ace4625)\\n   mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\\n   mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445144423722_0022\\n   conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\\n   yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\\n   mapred.Task:  Using ResourceCalculatorProcessTree : yarn.util.WindowsBasedProcessTree@3c367995\\n   mapred.MapTask: Processing split: hdfs://msra-sa-41:9000/pageinput2.txt:1207959552+48562176\\n   mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\\n   mapred.MapTask: mapreduce.task.io.sort.mb: 100\\n   mapred.MapTask: soft limit at 83886080\\n   mapred.MapTask: bufstart = 0; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 26214396; length = 6553600\\n   mapred.MapTask: Map output collector class = mapred.MapTask$MapOutputBuffer\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 0; bufend = 48193401; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 26214396(104857584); kvend = 17291232(69164928); length = 8923165/6553600\\n   mapred.MapTask: (EQUATOR) 57262153 kvi 14315532(57262128)\\n  [SpillThread] mapred.MapTask: Finished spill 0\\n   mapred.MapTask: (RESET) equator 57262153 kv 14315532(57262128) kvi 12120076(48480304)\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 57262153; bufend = 658166; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 14315532(57262128); kvend = 5407424(21629696); length = 8908109/6553600\\n   mapred.MapTask: (EQUATOR) 9726918 kvi 2431724(9726896)\\n  [SpillThread] mapred.MapTask: Finished spill 1\\n   mapred.MapTask: (RESET) equator 9726918 kv 2431724(9726896) kvi 228516(914064)\\n   mapred.MapTask: Starting flush of map output\\n   mapred.MapTask: Spilling map output\\n   mapred.MapTask: bufstart = 9726918; bufend = 49084664; bufvoid = 104857600\\n   mapred.MapTask: kvstart = 2431724(9726896); kvend = 21376588(85506352); length = 7269537/6553600\\n   mapred.MapTask: Finished spill 2\\n   mapred.Merger: Merging 3 sorted segments\\n   mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 105653983 bytes\\n   mapred.Task: Task:attempt_1445144423722_0022_m_000009_0 is done. And is in the process of committing\\n   mapred.Task: Task 'attempt_1445144423722_0022_m_000009_0' done.\\n   metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\\n   metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#test\n",
        "data_process['LogContent'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At22Ewmxbt6c"
      },
      "outputs": [],
      "source": [
        "# tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased', add_prefix_space=True)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh2B2NxGc4C8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331d2ab1-af62-41da-bbf5-b0cb2a1da5b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "encoded_input = tokenizer(text, return_tensors='tf', add_special_tokens=False)\n",
        "encoded_input.input_ids.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aEHwYsvy-OK",
        "outputId": "fb174f70-69ac-436b-efec-b8d470a31f05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'want',\n",
              " 'to',\n",
              " 'know',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'token',\n",
              " '##s',\n",
              " 'in',\n",
              " 'this',\n",
              " 'sentence',\n",
              " '!',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "text = \"I want to know the number of tokens in this sentence!!!\"\n",
        "tokenized_input = tokenizer.tokenize(text)\n",
        "len(tokenized_input)\n",
        "tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RDM6Rs_fCY7",
        "outputId": "24a84da1-06d6-4d56-ccc6-e3947e3a6bbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'i',\n",
              " 'want',\n",
              " 'to',\n",
              " 'know',\n",
              " 'the',\n",
              " 'number',\n",
              " 'of',\n",
              " 'token',\n",
              " '##s',\n",
              " 'in',\n",
              " 'this',\n",
              " 'sentence',\n",
              " '!',\n",
              " '!',\n",
              " '!',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "encoding = tokenizer.encode(text)\n",
        "tokenizer.convert_ids_to_tokens(encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhSzDKeOffr6",
        "outputId": "94b3b4b8-02c6-44f8-f6e6-20e621c65f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "data_process['tokens'] = data_process['LogContent'].apply(lambda x: tokenizer.convert_ids_to_tokens(tokenizer.encode(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChain"
      ],
      "metadata": {
        "id": "SOg7jNMXmiN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKr7plAeJU_7",
        "outputId": "6ecf12a7-c0af-4f91-a2b7-4d9a8202012f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
            "  Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=50, chunk_overlap=10)"
      ],
      "metadata": {
        "id": "FEsXhQkNJV7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "\n",
        "text_splitter = SpacyTextSplitter(chunk_size=1200)"
      ],
      "metadata": {
        "id": "uU5k5TTeMOLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text = data_process['LogContent'][0]\n",
        "texts = text_splitter.split_text(Text)\n",
        "# print(len(str(texts[3])))\n",
        "# print(texts[1])\n",
        "# print(texts[2])\n",
        "# print(texts[8])\n",
        "type(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baPQVhQbJXDG",
        "outputId": "f98a3e2b-0c33-40fc-b8af-3fe7465ff1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in texts:\n",
        "  t = tokenizer.convert_ids_to_tokens(tokenizer.encode(item))\n",
        "  print(len(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "aus75Ff6MotV",
        "outputId": "3168ac5d-7f5b-4304-c56b-4019b6457319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-469242c13abc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_process['TextChunks'] = data_process['LogContent'].apply(lambda x: text_splitter.split_text(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F81pY2AEPHNW",
        "outputId": "68a113f8-b2b5-489c-b0e1-910313fde61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_process.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nCneREqLPg7A",
        "outputId": "94453e90-664e-4670-c9f7-32f53a0c6ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          LogContent             RootCause  \\\n",
              "0     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "1     metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "3     metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "4     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "                                          TextChunks  \n",
              "0  [metrics2.impl.\\n\\nMetricsConfig: loaded prope...  \n",
              "1  [metrics2.impl.\\n\\nMetricsConfig: loaded prope...  \n",
              "2  [metrics2.impl.\\n\\nMetricsConfig: loaded prope...  \n",
              "3  [metrics2.impl.\\n\\nMetricsConfig: loaded prope...  \n",
              "4  [metrics2.impl.\\n\\nMetricsConfig: loaded prope...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c51c0068-0467-4846-a8c0-6d4c5b2ac029\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>TextChunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[metrics2.impl.\\n\\nMetricsConfig: loaded prope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>[metrics2.impl.\\n\\nMetricsConfig: loaded prope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[metrics2.impl.\\n\\nMetricsConfig: loaded prope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>[metrics2.impl.\\n\\nMetricsConfig: loaded prope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>[metrics2.impl.\\n\\nMetricsConfig: loaded prope...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c51c0068-0467-4846-a8c0-6d4c5b2ac029')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c51c0068-0467-4846-a8c0-6d4c5b2ac029 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c51c0068-0467-4846-a8c0-6d4c5b2ac029');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03c964f5-c8fa-48aa-8e2e-a2dc95f36f02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03c964f5-c8fa-48aa-8e2e-a2dc95f36f02')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03c964f5-c8fa-48aa-8e2e-a2dc95f36f02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs = pd.DataFrame(columns=['LogContent', 'RootCause'])\n",
        "tmp = []\n",
        "for index, row in data_process.iterrows():\n",
        "    root_cause = row['RootCause']\n",
        "    log_chunks = row['TextChunks']\n",
        "\n",
        "    # Create a DataFrame for the current row\n",
        "    df = pd.DataFrame({'LogContent': log_chunks, 'RootCause': [root_cause] * len(log_chunks)})\n",
        "\n",
        "    # Append to the list\n",
        "    tmp.append(df)\n",
        "\n",
        "# Concatenate the list of DataFrames into a single DataFrame\n",
        "chunked_logs = pd.concat(tmp, ignore_index=True)\n",
        "\n",
        "# Reorder the columns\n",
        "chunked_logs = chunked_logs[['LogContent', 'RootCause']]"
      ],
      "metadata": {
        "id": "3Hf77sVpQIQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply tokenizer.convert_ids_to_tokens and calculate the length of tokens\n",
        "chunked_logs['token_numbers'] = chunked_logs['LogContent'].apply(lambda x: len(tokenizer.convert_ids_to_tokens(tokenizer.encode(x))))"
      ],
      "metadata": {
        "id": "P_LgL0EsSoV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs[chunked_logs['token_numbers']>512]\n",
        "# chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "tX6k-DfDQIw5",
        "outputId": "9dd31495-1667-4816-faa0-233fe676b865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  \\\n",
              "3165  JobHistoryEventHandler:\\n\\nStopping JobHistory...  MachineDown   \n",
              "\n",
              "      token_numbers  \n",
              "3165            513  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d06335f-9143-4cb4-8115-830136c52b03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>token_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3165</th>\n",
              "      <td>JobHistoryEventHandler:\\n\\nStopping JobHistory...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d06335f-9143-4cb4-8115-830136c52b03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d06335f-9143-4cb4-8115-830136c52b03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d06335f-9143-4cb4-8115-830136c52b03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = chunked_logs[chunked_logs['token_numbers']<=512]\n",
        "# final_df.to_csv('forClassify_2.csv')\n",
        "final_df.to_csv('chunked_dataset.csv')"
      ],
      "metadata": {
        "id": "hbE8IVfrTWyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_HDcBnbuX9"
      },
      "source": [
        "# **Splitter**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('forClassify_1.csv')\n",
        "df_2 = pd.read_csv('largerLogs.csv')\n",
        "del df['Unnamed: 0.2']\n",
        "del df['Unnamed: 0.1']\n",
        "del df['Unnamed: 0']\n",
        "del df['tokens']\n",
        "del df['FileName']\n",
        "del df_2['Unnamed: 0']\n",
        "del df_2['num_words']\n",
        "concatenated_df = pd.concat([df, df_2], ignore_index=True)\n",
        "concatenated_df\n",
        "labels = concatenated_df['RootCause'].unique().tolist()\n",
        "labels = [s.strip() for s in labels ]\n",
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}\n",
        "concatenated_df[\"labels\"]=concatenated_df.RootCause.map(lambda x: label2id[x.strip()])\n",
        "NUM_LABELS\n",
        "concatenated_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nHRzruwnLkVG",
        "outputId": "90c39727-f4ec-4d62-eaa0-6ce1bbf55cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "..                                                 ...                   ...   \n",
              "753     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "754     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "755     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "756     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "757     mapreduce.v2.app.MRAppMaster: Created MRApp...           MachineDown   \n",
              "\n",
              "     labels  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "..      ...  \n",
              "753       2  \n",
              "754       2  \n",
              "755       2  \n",
              "756       2  \n",
              "757       2  \n",
              "\n",
              "[758 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcc9284c-5eba-42a0-84c0-03fb18863e63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>mapreduce.v2.app.MRAppMaster: Created MRApp...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcc9284c-5eba-42a0-84c0-03fb18863e63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcc9284c-5eba-42a0-84c0-03fb18863e63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcc9284c-5eba-42a0-84c0-03fb18863e63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd4e6e11-c805-474d-bfbc-20744e7b22d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd4e6e11-c805-474d-bfbc-20744e7b22d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd4e6e11-c805-474d-bfbc-20744e7b22d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e7bcda1-74b7-467b-a2d7-e23c5f6605e0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('concatenated_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e7bcda1-74b7-467b-a2d7-e23c5f6605e0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('concatenated_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into draft and evaluation datasets (80-20 split)\n",
        "draft, evaluation = train_test_split(concatenated_df, test_size=0.2, random_state=45, shuffle=True)\n",
        "draft = draft.reset_index(drop=True)\n",
        "evaluation = evaluation.reset_index(drop=True)\n",
        "draft['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO1AZ2eNMD5Z",
        "outputId": "8d59f330-ad41-4d87-fe28-3ea4b2beb6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    396\n",
              "1    108\n",
              "0    102\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVVsTvuzM_my",
        "outputId": "2d63e56c-52c3-4752-965b-cc1df31d1edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    94\n",
              "1    33\n",
              "0    25\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del evaluation['labels']\n",
        "del draft['labels']"
      ],
      "metadata": {
        "id": "7fsNdyhnBsCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation.to_csv('evaluation.csv')\n",
        "draft.to_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "KGi2HJeIMXOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Rsr9qEzGUO"
      },
      "source": [
        "# FROM JUPYTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8lyeMSX2zZSQ",
        "outputId": "215aa291-95bb-4bcd-e8bb-0690c6fb56c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent             RootCause\n",
              "0     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection\n",
              "1     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  NetworkDisconnection\n",
              "2     MapTask: (EQUATOR) 9726918\\n\\nkvi 2431724(9726...  NetworkDisconnection\n",
              "3     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection\n",
              "4     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  NetworkDisconnection\n",
              "...                                                 ...                   ...\n",
              "4858  [Thread-78] mapreduce.v2.app.MRAppMaster: We a...           MachineDown\n",
              "4859  CompletedMaps:10 CompletedReds:1\\n\\nContAlloc:...           MachineDown\n",
              "4860  JobHistoryEventHandler:\\n\\nCopied to done loca...           MachineDown\n",
              "4861  JobHistoryEventHandler:\\n\\nMoved tmp to done: ...           MachineDown\n",
              "4862  RMContainerAllocator: Final Stats: PendingReds...           MachineDown\n",
              "\n",
              "[4863 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc8d3208-bfeb-45e0-ae11-dad26fd31d15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MapTask: (EQUATOR) 9726918\\n\\nkvi 2431724(9726...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4858</th>\n",
              "      <td>[Thread-78] mapreduce.v2.app.MRAppMaster: We a...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>CompletedMaps:10 CompletedReds:1\\n\\nContAlloc:...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4860</th>\n",
              "      <td>JobHistoryEventHandler:\\n\\nCopied to done loca...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4861</th>\n",
              "      <td>JobHistoryEventHandler:\\n\\nMoved tmp to done: ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4862</th>\n",
              "      <td>RMContainerAllocator: Final Stats: PendingReds...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4863 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc8d3208-bfeb-45e0-ae11-dad26fd31d15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc8d3208-bfeb-45e0-ae11-dad26fd31d15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc8d3208-bfeb-45e0-ae11-dad26fd31d15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8dc3f750-5b5c-4013-ab76-4a175fa12bc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dc3f750-5b5c-4013-ab76-4a175fa12bc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8dc3f750-5b5c-4013-ab76-4a175fa12bc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "df = pd.read_csv('forClassify_2.csv')\n",
        "# df = pd.read_csv('forClassify_1.csv')\n",
        "# df.columns\n",
        "# del df['Unnamed: 0.2']\n",
        "# del df['Unnamed: 0.1']\n",
        "del df['Unnamed: 0']\n",
        "# del df['tokens']\n",
        "# del df['FileName']\n",
        "del df['token_numbers']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['token_numbers'] >= 400]\n",
        "del df['token_numbers']\n",
        "df = df.reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "ym7Kw7GIf5B7",
        "outputId": "75b1fa3e-3159-4f41-e53c-803b23c0089c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'token_numbers'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0827cd01034a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_numbers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_numbers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'token_numbers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m6gscTxzj21",
        "outputId": "18e94dc8-5e41-460f-ee81-18b75e41802e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NetworkDisconnection': 0, 'DiskFull': 1, 'MachineDown': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "labels = df['RootCause'].unique().tolist()\n",
        "labels = [s.strip() for s in labels ]\n",
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}\n",
        "df[\"labels\"]=df.RootCause.map(lambda x: label2id[x.strip()])\n",
        "NUM_LABELS\n",
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXMwajhtzp_z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "5835f4a7d9d3468ebe0a23d9cf90b24b",
            "b10c08db91e34912b6155338b3c2d960",
            "2211e3911de04ef5b5ac00fdc33b2cba",
            "8cc54a2811e443839ed27f6d7a419185",
            "6c3dfece449049f781557df694bcaf13",
            "972350f425854a1a9208b7a7fdde484d",
            "f35386668fc749c1b3337457716623ec",
            "5881c279608a4afdbf0987eb1c903a49",
            "1379cbe4276c4ab89dfd3a7731a0d190",
            "c1935e4edf4d49ffa6e63d188219c386",
            "3b800dc0386b478f8d959d41f48d0d14",
            "1bd575fab1aa4835bec842eacee78334",
            "025ef785e0e44632a460c7c6378194c4",
            "cea12ba71d4447358c12b74557eeba22",
            "d061cfb0d2714c10b4e94e43e86660fa",
            "e6a94f9b541a420688a1707d7b53180e",
            "16fc1340460641b6a2aed5e46d31c576",
            "43f3699cfbde4abc835218a9e9f3f27f",
            "cc865a32fdb247b28729e20a42d76905",
            "dc7ab87384c845e98af5d301ed6bd010",
            "6bcf295ccc584ef7afd59bd1556380bb",
            "0c77992ab848410fabd7c9b14d2b422b",
            "7a462a79fe924da7bbb2145701052797",
            "3aa75dd4b68b456a9f84e21a9f9be8d8",
            "26b7cae120d34413962f8d3d0a2bcd1d",
            "eaba901aa37145669788e686add50b28",
            "f4ae8fde7cb04eec81a5644d4d5e1d60",
            "eb68d4d36adb43f9bc9bdaaf817d05b8",
            "a0062d3167844758accb4b7de17e9ddb",
            "14921e3b440147d7b150d84533e9250b",
            "370db093b0eb4e0db8d90c74609eb348",
            "0bf7c07f06bc4ab0a09a3a60b4b6f4b1",
            "55b2da98fa394d5a937f379e8a54c008",
            "29b1a659c4b4454192ea0275589d9fa4",
            "5538efd5bd9242d28832235a368793de",
            "2ea1a474636248f5869638ee933be005",
            "a07ab1b37ef745599446e20b8dcbc8c6",
            "733b5ac09d3346e485c8f2a94c1efea2",
            "9d7d9f51081749789ba6eea5e86dccb8",
            "cb41004d4bc34b76b2f5ae9abd9f0eee",
            "56afec1cc4d54e998f8a6f738cb7a5d8",
            "135e893871564eceb039174c9ff2917c",
            "408c9ce8995f4b79a5be34ab83380f5c",
            "eabf0925d7874fb08b71aedd322ef28e"
          ]
        },
        "outputId": "6ec1cf65-ee12-405c-ec3a-8b80b7f52ad4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5835f4a7d9d3468ebe0a23d9cf90b24b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd575fab1aa4835bec842eacee78334"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a462a79fe924da7bbb2145701052797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29b1a659c4b4454192ea0275589d9fa4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-large-uncased\", max_length=512)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtGrxL5nzwrb"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "#         self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "#         item['labels'] = torch.tensor(self.labels[idx])  # Convert label to tensor if not already\n",
        "#         return item\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RAW datasplit**"
      ],
      "metadata": {
        "id": "x_DIr2BxkF3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ8g_T2gz0SZ"
      },
      "outputs": [],
      "source": [
        "# Tokenize the LogContent and convert labels to IDs using CustomDataset\n",
        "# train_dataset = CustomDataset(texts=list(df['LogContent']), labels=[label2id[label] for label in df['RootCause']], tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "# Tokenize the LogContent and convert labels to IDs using CustomDataset\n",
        "train_dataset = CustomDataset(texts=list(df['LogContent']), labels=df['labels'], tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3WzWtL-z3N3"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNYvaAV9z7oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f00c2b-f1ea-43ed-ce63-306f3a7a92a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "487"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj8TJE2M0F8K",
        "outputId": "e7fbfa14-e787-4423-a499-f4f987d0097d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCYKWMQNKAWO"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17myd1SK0LvX",
        "outputId": "88587ec7-04a8-4e1b-a889-a144c17836ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Batch 1/66, Loss: 1.0857, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 2/66, Loss: 0.6184, Time: 0.81 seconds\n",
            "Epoch 1/4, Batch 3/66, Loss: 0.4269, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 4/66, Loss: 1.0671, Time: 0.81 seconds\n",
            "Epoch 1/4, Batch 5/66, Loss: 1.5483, Time: 0.81 seconds\n",
            "Epoch 1/4, Batch 6/66, Loss: 1.1265, Time: 0.81 seconds\n",
            "Epoch 1/4, Batch 7/66, Loss: 0.7454, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 8/66, Loss: 0.4829, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 9/66, Loss: 0.8772, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 10/66, Loss: 1.3706, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 11/66, Loss: 0.5985, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 12/66, Loss: 1.0739, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 13/66, Loss: 1.3496, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 14/66, Loss: 1.1021, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 15/66, Loss: 0.7665, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 16/66, Loss: 0.8412, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 17/66, Loss: 0.5336, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 18/66, Loss: 0.9461, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 19/66, Loss: 0.7434, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 20/66, Loss: 0.7756, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 21/66, Loss: 1.0484, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 22/66, Loss: 0.8143, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 23/66, Loss: 0.4088, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 24/66, Loss: 0.9939, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 25/66, Loss: 0.9172, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 26/66, Loss: 1.4927, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 27/66, Loss: 0.7475, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 28/66, Loss: 0.3617, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 29/66, Loss: 0.7868, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 30/66, Loss: 1.0543, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 31/66, Loss: 1.1716, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 32/66, Loss: 1.1587, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 33/66, Loss: 1.0854, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 34/66, Loss: 1.0834, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 35/66, Loss: 0.7231, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 36/66, Loss: 1.1358, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 37/66, Loss: 1.0501, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 38/66, Loss: 0.7422, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 39/66, Loss: 0.9729, Time: 0.90 seconds\n",
            "Epoch 1/4, Batch 40/66, Loss: 0.8150, Time: 0.90 seconds\n",
            "Epoch 1/4, Batch 41/66, Loss: 0.7832, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 42/66, Loss: 1.0608, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 43/66, Loss: 0.9811, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 44/66, Loss: 1.0359, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 45/66, Loss: 1.2302, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 46/66, Loss: 0.6391, Time: 0.89 seconds\n",
            "Epoch 1/4, Batch 47/66, Loss: 1.0107, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 48/66, Loss: 0.8371, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 49/66, Loss: 0.5041, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 50/66, Loss: 0.9577, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 51/66, Loss: 0.8209, Time: 0.88 seconds\n",
            "Epoch 1/4, Batch 52/66, Loss: 0.8544, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 53/66, Loss: 0.3932, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 54/66, Loss: 0.6201, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 55/66, Loss: 0.9643, Time: 0.87 seconds\n",
            "Epoch 1/4, Batch 56/66, Loss: 1.0938, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 57/66, Loss: 1.0084, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 58/66, Loss: 1.1897, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 59/66, Loss: 0.3152, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 60/66, Loss: 1.1641, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 61/66, Loss: 0.5415, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 62/66, Loss: 1.1887, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 63/66, Loss: 0.7313, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 64/66, Loss: 0.7392, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 65/66, Loss: 0.7286, Time: 0.85 seconds\n",
            "Epoch 1/4, Batch 66/66, Loss: 1.2565, Time: 0.76 seconds\n",
            "Epoch 1/4, Training Loss: 0.8984, Time: 56.94 seconds\n",
            "Validation Loss: 0.9624, Accuracy: 0.5985\n",
            "Epoch 2/4, Batch 1/66, Loss: 1.0681, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 2/66, Loss: 0.8980, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 3/66, Loss: 1.6408, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 4/66, Loss: 0.4434, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 5/66, Loss: 0.9551, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 6/66, Loss: 1.1693, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 7/66, Loss: 0.9143, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 8/66, Loss: 1.0807, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 9/66, Loss: 0.6895, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 10/66, Loss: 0.8189, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 11/66, Loss: 0.6770, Time: 0.82 seconds\n",
            "Epoch 2/4, Batch 12/66, Loss: 0.7403, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 13/66, Loss: 0.7721, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 14/66, Loss: 0.6016, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 15/66, Loss: 0.5932, Time: 0.82 seconds\n",
            "Epoch 2/4, Batch 16/66, Loss: 0.9273, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 17/66, Loss: 1.1451, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 18/66, Loss: 0.7559, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 19/66, Loss: 0.6707, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 20/66, Loss: 0.5503, Time: 0.82 seconds\n",
            "Epoch 2/4, Batch 21/66, Loss: 1.6319, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 22/66, Loss: 1.3646, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 23/66, Loss: 1.4418, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 24/66, Loss: 0.8933, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 25/66, Loss: 0.7944, Time: 0.82 seconds\n",
            "Epoch 2/4, Batch 26/66, Loss: 0.4768, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 27/66, Loss: 1.0129, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 28/66, Loss: 0.6054, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 29/66, Loss: 0.8121, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 30/66, Loss: 0.6210, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 31/66, Loss: 0.8663, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 32/66, Loss: 0.5677, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 33/66, Loss: 0.9482, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 34/66, Loss: 0.7596, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 35/66, Loss: 0.7461, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 36/66, Loss: 0.7430, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 37/66, Loss: 0.8857, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 38/66, Loss: 0.9038, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 39/66, Loss: 0.9524, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 40/66, Loss: 0.4912, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 41/66, Loss: 1.2167, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 42/66, Loss: 0.9847, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 43/66, Loss: 0.5436, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 44/66, Loss: 0.9104, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 45/66, Loss: 0.7638, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 46/66, Loss: 0.7680, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 47/66, Loss: 0.9427, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 48/66, Loss: 0.9627, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 49/66, Loss: 1.2592, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 50/66, Loss: 0.5510, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 51/66, Loss: 0.8939, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 52/66, Loss: 0.6847, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 53/66, Loss: 0.9140, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 54/66, Loss: 0.7792, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 55/66, Loss: 1.0905, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 56/66, Loss: 1.0161, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 57/66, Loss: 0.5934, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 58/66, Loss: 0.8681, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 59/66, Loss: 0.7071, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 60/66, Loss: 0.9463, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 61/66, Loss: 1.1229, Time: 0.86 seconds\n",
            "Epoch 2/4, Batch 62/66, Loss: 0.6113, Time: 0.86 seconds\n",
            "Epoch 2/4, Batch 63/66, Loss: 0.9210, Time: 0.86 seconds\n",
            "Epoch 2/4, Batch 64/66, Loss: 1.1181, Time: 0.86 seconds\n",
            "Epoch 2/4, Batch 65/66, Loss: 1.3415, Time: 0.86 seconds\n",
            "Epoch 2/4, Batch 66/66, Loss: 1.0282, Time: 0.77 seconds\n",
            "Epoch 2/4, Training Loss: 0.8813, Time: 55.25 seconds\n",
            "Validation Loss: 0.9552, Accuracy: 0.5985\n",
            "Epoch 3/4, Batch 1/66, Loss: 0.7943, Time: 0.87 seconds\n",
            "Epoch 3/4, Batch 2/66, Loss: 0.8231, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 3/66, Loss: 0.7620, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 4/66, Loss: 0.8713, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 5/66, Loss: 1.3767, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 6/66, Loss: 1.1816, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 7/66, Loss: 0.9399, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 8/66, Loss: 0.6702, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 9/66, Loss: 0.9257, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 10/66, Loss: 1.1178, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 11/66, Loss: 0.8200, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 12/66, Loss: 0.6317, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 13/66, Loss: 1.2222, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 14/66, Loss: 0.6844, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 15/66, Loss: 1.1129, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 16/66, Loss: 1.0909, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 17/66, Loss: 0.7745, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 18/66, Loss: 0.9761, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 19/66, Loss: 0.7705, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 20/66, Loss: 0.5711, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 21/66, Loss: 0.7341, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 22/66, Loss: 1.0420, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 23/66, Loss: 0.5570, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 24/66, Loss: 0.9291, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 25/66, Loss: 0.3820, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 26/66, Loss: 0.7039, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 27/66, Loss: 0.9986, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 28/66, Loss: 0.8591, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 29/66, Loss: 0.8501, Time: 0.86 seconds\n",
            "Epoch 3/4, Batch 30/66, Loss: 0.4985, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 31/66, Loss: 1.3127, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 32/66, Loss: 0.8989, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 33/66, Loss: 0.9829, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 34/66, Loss: 0.7125, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 35/66, Loss: 0.8967, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 36/66, Loss: 0.9426, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 37/66, Loss: 0.5532, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 38/66, Loss: 0.9807, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 39/66, Loss: 0.9458, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 40/66, Loss: 0.6425, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 41/66, Loss: 0.3592, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 42/66, Loss: 0.8402, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 43/66, Loss: 1.3019, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 44/66, Loss: 0.5307, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 45/66, Loss: 1.0666, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 46/66, Loss: 0.7812, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 47/66, Loss: 0.8200, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 48/66, Loss: 0.8040, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 49/66, Loss: 0.6565, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 50/66, Loss: 0.7166, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 51/66, Loss: 0.9350, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 52/66, Loss: 0.6171, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 53/66, Loss: 0.5695, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 54/66, Loss: 0.4661, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 55/66, Loss: 0.9814, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 56/66, Loss: 0.5889, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 57/66, Loss: 0.2650, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 58/66, Loss: 0.9187, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 59/66, Loss: 0.9189, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 60/66, Loss: 0.5656, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 61/66, Loss: 0.4172, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 62/66, Loss: 0.4274, Time: 0.85 seconds\n",
            "Epoch 3/4, Batch 63/66, Loss: 0.7074, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 64/66, Loss: 0.3309, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 65/66, Loss: 0.9533, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 66/66, Loss: 0.8917, Time: 0.76 seconds\n",
            "Epoch 3/4, Training Loss: 0.8026, Time: 56.30 seconds\n",
            "Validation Loss: 0.4442, Accuracy: 0.8030\n",
            "Epoch 4/4, Batch 1/66, Loss: 0.2706, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 2/66, Loss: 0.4128, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 3/66, Loss: 0.5041, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 4/66, Loss: 0.1277, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 5/66, Loss: 0.4824, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 6/66, Loss: 1.1539, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 7/66, Loss: 0.4465, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 8/66, Loss: 0.7276, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 9/66, Loss: 0.5642, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 10/66, Loss: 0.4244, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 11/66, Loss: 1.0631, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 12/66, Loss: 1.1056, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 13/66, Loss: 0.5737, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 14/66, Loss: 0.5981, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 15/66, Loss: 0.4851, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 16/66, Loss: 0.4988, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 17/66, Loss: 0.4275, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 18/66, Loss: 0.3482, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 19/66, Loss: 0.4234, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 20/66, Loss: 0.5093, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 21/66, Loss: 0.5558, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 22/66, Loss: 0.3214, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 23/66, Loss: 0.4842, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 24/66, Loss: 0.2980, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 25/66, Loss: 0.3923, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 26/66, Loss: 0.3190, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 27/66, Loss: 0.3508, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 28/66, Loss: 0.2655, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 29/66, Loss: 0.1672, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 30/66, Loss: 0.1659, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 31/66, Loss: 0.1756, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 32/66, Loss: 0.0859, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 33/66, Loss: 0.5062, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 34/66, Loss: 0.0986, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 35/66, Loss: 0.4874, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 36/66, Loss: 0.2873, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 37/66, Loss: 0.4558, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 38/66, Loss: 0.2231, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 39/66, Loss: 0.2035, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 40/66, Loss: 0.2156, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 41/66, Loss: 0.2692, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 42/66, Loss: 0.3266, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 43/66, Loss: 0.3055, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 44/66, Loss: 0.2341, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 45/66, Loss: 0.2027, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 46/66, Loss: 0.1502, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 47/66, Loss: 0.5610, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 48/66, Loss: 0.8003, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 49/66, Loss: 0.1950, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 50/66, Loss: 0.0903, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 51/66, Loss: 0.2900, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 52/66, Loss: 0.3094, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 53/66, Loss: 0.2585, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 54/66, Loss: 0.4410, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 55/66, Loss: 0.5307, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 56/66, Loss: 0.4080, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 57/66, Loss: 0.4786, Time: 0.86 seconds\n",
            "Epoch 4/4, Batch 58/66, Loss: 0.7510, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 59/66, Loss: 0.3941, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 60/66, Loss: 0.4338, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 61/66, Loss: 0.3667, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 62/66, Loss: 0.2031, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 63/66, Loss: 0.0218, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 64/66, Loss: 0.3713, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 65/66, Loss: 0.0208, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 66/66, Loss: 0.1990, Time: 0.77 seconds\n",
            "Epoch 4/4, Training Loss: 0.3912, Time: 56.15 seconds\n",
            "Validation Loss: 0.2295, Accuracy: 0.9545\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 4\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZH-wX1y3EYl"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"./trained_models/old_way\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3tZ21z4NgxJ"
      },
      "source": [
        "### Using class weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "M = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "M.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(M.parameters(), lr=5e-5)\n",
        "# loss_fn = torch.nn.CrossEntropyLoss()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvy7wuJRYY35",
        "outputId": "9546af5d-d749-4b90-df98-a51b175893cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crr0WLbhNgey",
        "outputId": "2302ae16-4d6c-4ea4-8f1d-b87f8f8e6e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 73 samples\n",
            "Class 1: 110 samples\n",
            "Class 2: 344 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ],
      "source": [
        "class_counts = [0, 0, 0]\n",
        "\n",
        "# Iterate over the training dataset to count samples for each class\n",
        "for sample in train_dataset:\n",
        "    label = sample['labels']  # Replace 'label' with the actual key used in your dataset\n",
        "    class_counts[label] += 1\n",
        "\n",
        "# Print the counts for each class\n",
        "for class_idx, count in enumerate(class_counts):\n",
        "    print(f\"Class {class_idx}: {count} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts7BbM1eNb9o"
      },
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "class_weights = torch.tensor([1.0 / 73.0, 1.0 / 110.0, 1.0 / 344.0], dtype=torch.float).to(device)\n",
        "\n",
        "# Define the loss function with class weights\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC3J-6_TNb1U",
        "outputId": "5fb2cfdc-3814-410c-8245-5ffc098cdf28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Batch 1/66, Loss: 0.8959, Time: 0.86 seconds\n",
            "Epoch 1/4, Batch 2/66, Loss: 1.2486, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 3/66, Loss: 1.1195, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 4/66, Loss: 1.2306, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 5/66, Loss: 1.1822, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 6/66, Loss: 1.2346, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 7/66, Loss: 1.2481, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 8/66, Loss: 1.1154, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 9/66, Loss: 0.9139, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 10/66, Loss: 0.8973, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 11/66, Loss: 1.4625, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 12/66, Loss: 1.3076, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 13/66, Loss: 0.8458, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 14/66, Loss: 1.2025, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 15/66, Loss: 1.3124, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 16/66, Loss: 1.4255, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 17/66, Loss: 0.8189, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 18/66, Loss: 1.0701, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 19/66, Loss: 1.1060, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 20/66, Loss: 1.2981, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 21/66, Loss: 1.0747, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 22/66, Loss: 1.1780, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 23/66, Loss: 1.0808, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 24/66, Loss: 1.2240, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 25/66, Loss: 1.1344, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 26/66, Loss: 1.3320, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 27/66, Loss: 1.2543, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 28/66, Loss: 1.0724, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 29/66, Loss: 1.1931, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 30/66, Loss: 1.3140, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 31/66, Loss: 1.2611, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 32/66, Loss: 1.2706, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 33/66, Loss: 1.1653, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 34/66, Loss: 1.1795, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 35/66, Loss: 1.1794, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 36/66, Loss: 1.1562, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 37/66, Loss: 0.8727, Time: 0.81 seconds\n",
            "Epoch 1/4, Batch 38/66, Loss: 1.2398, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 39/66, Loss: 1.1172, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 40/66, Loss: 1.1279, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 41/66, Loss: 1.0286, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 42/66, Loss: 1.0681, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 43/66, Loss: 1.1497, Time: 0.82 seconds\n",
            "Epoch 1/4, Batch 44/66, Loss: 1.1328, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 45/66, Loss: 1.0781, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 46/66, Loss: 1.2011, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 47/66, Loss: 1.1806, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 48/66, Loss: 1.2204, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 49/66, Loss: 0.9811, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 50/66, Loss: 1.0692, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 51/66, Loss: 1.1144, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 52/66, Loss: 0.8265, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 53/66, Loss: 1.4505, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 54/66, Loss: 1.0752, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 55/66, Loss: 1.0849, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 56/66, Loss: 1.1730, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 57/66, Loss: 1.1005, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 58/66, Loss: 1.2285, Time: 0.83 seconds\n",
            "Epoch 1/4, Batch 59/66, Loss: 1.2548, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 60/66, Loss: 1.2020, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 61/66, Loss: 1.0740, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 62/66, Loss: 1.0055, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 63/66, Loss: 1.1754, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 64/66, Loss: 1.1884, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 65/66, Loss: 1.1608, Time: 0.84 seconds\n",
            "Epoch 1/4, Batch 66/66, Loss: 1.2183, Time: 0.76 seconds\n",
            "Epoch 1/4, Training Loss: 1.1486, Time: 54.75 seconds\n",
            "Validation Loss: 1.0919, Accuracy: 0.6439\n",
            "Epoch 2/4, Batch 1/66, Loss: 1.1186, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 2/66, Loss: 1.1247, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 3/66, Loss: 1.0779, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 4/66, Loss: 0.9815, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 5/66, Loss: 1.1989, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 6/66, Loss: 0.9779, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 7/66, Loss: 1.1587, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 8/66, Loss: 1.1861, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 9/66, Loss: 1.1140, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 10/66, Loss: 1.2976, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 11/66, Loss: 1.1017, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 12/66, Loss: 0.8059, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 13/66, Loss: 1.2207, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 14/66, Loss: 1.0785, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 15/66, Loss: 1.3352, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 16/66, Loss: 1.1939, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 17/66, Loss: 1.1691, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 18/66, Loss: 0.9738, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 19/66, Loss: 1.2100, Time: 0.85 seconds\n",
            "Epoch 2/4, Batch 20/66, Loss: 0.9130, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 21/66, Loss: 1.1206, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 22/66, Loss: 1.0490, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 23/66, Loss: 0.8486, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 24/66, Loss: 1.3415, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 25/66, Loss: 1.1948, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 26/66, Loss: 1.3038, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 27/66, Loss: 1.1412, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 28/66, Loss: 1.0867, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 29/66, Loss: 1.1079, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 30/66, Loss: 1.2172, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 31/66, Loss: 1.1332, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 32/66, Loss: 1.1870, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 33/66, Loss: 1.1152, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 34/66, Loss: 1.1140, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 35/66, Loss: 1.1461, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 36/66, Loss: 1.0569, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 37/66, Loss: 1.2445, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 38/66, Loss: 1.1568, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 39/66, Loss: 1.1517, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 40/66, Loss: 0.9298, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 41/66, Loss: 0.9988, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 42/66, Loss: 1.2338, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 43/66, Loss: 1.3739, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 44/66, Loss: 1.0730, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 45/66, Loss: 1.0189, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 46/66, Loss: 1.0748, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 47/66, Loss: 1.2197, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 48/66, Loss: 1.2539, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 49/66, Loss: 1.0660, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 50/66, Loss: 1.0763, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 51/66, Loss: 1.0229, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 52/66, Loss: 1.1331, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 53/66, Loss: 1.1107, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 54/66, Loss: 1.0972, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 55/66, Loss: 1.1817, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 56/66, Loss: 1.1162, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 57/66, Loss: 1.1662, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 58/66, Loss: 1.1636, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 59/66, Loss: 0.9891, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 60/66, Loss: 1.0906, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 61/66, Loss: 1.0226, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 62/66, Loss: 1.1220, Time: 0.83 seconds\n",
            "Epoch 2/4, Batch 63/66, Loss: 1.2268, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 64/66, Loss: 0.9811, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 65/66, Loss: 1.0810, Time: 0.84 seconds\n",
            "Epoch 2/4, Batch 66/66, Loss: 0.9710, Time: 0.76 seconds\n",
            "Epoch 2/4, Training Loss: 1.1174, Time: 55.53 seconds\n",
            "Validation Loss: 1.1714, Accuracy: 0.1439\n",
            "Epoch 3/4, Batch 1/66, Loss: 1.0158, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 2/66, Loss: 1.1611, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 3/66, Loss: 1.0939, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 4/66, Loss: 1.1406, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 5/66, Loss: 1.2704, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 6/66, Loss: 1.1474, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 7/66, Loss: 1.0454, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 8/66, Loss: 1.0950, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 9/66, Loss: 1.0323, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 10/66, Loss: 1.1283, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 11/66, Loss: 1.1791, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 12/66, Loss: 1.2619, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 13/66, Loss: 1.0158, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 14/66, Loss: 1.1731, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 15/66, Loss: 1.0833, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 16/66, Loss: 1.0718, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 17/66, Loss: 1.0323, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 18/66, Loss: 1.0812, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 19/66, Loss: 0.8514, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 20/66, Loss: 1.3203, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 21/66, Loss: 1.1600, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 22/66, Loss: 1.1869, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 23/66, Loss: 0.9810, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 24/66, Loss: 1.3211, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 25/66, Loss: 1.2875, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 26/66, Loss: 1.3382, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 27/66, Loss: 1.0115, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 28/66, Loss: 0.7951, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 29/66, Loss: 1.0773, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 30/66, Loss: 1.0673, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 31/66, Loss: 1.1922, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 32/66, Loss: 1.1711, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 33/66, Loss: 1.1465, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 34/66, Loss: 1.1201, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 35/66, Loss: 0.9401, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 36/66, Loss: 1.2019, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 37/66, Loss: 1.2227, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 38/66, Loss: 1.1574, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 39/66, Loss: 1.1117, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 40/66, Loss: 1.1107, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 41/66, Loss: 1.2479, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 42/66, Loss: 1.1614, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 43/66, Loss: 1.1927, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 44/66, Loss: 1.0532, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 45/66, Loss: 1.1167, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 46/66, Loss: 1.0935, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 47/66, Loss: 1.1116, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 48/66, Loss: 1.1627, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 49/66, Loss: 1.1051, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 50/66, Loss: 1.0435, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 51/66, Loss: 1.0538, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 52/66, Loss: 1.1940, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 53/66, Loss: 1.1421, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 54/66, Loss: 1.1017, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 55/66, Loss: 1.1541, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 56/66, Loss: 1.2302, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 57/66, Loss: 1.2440, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 58/66, Loss: 1.0889, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 59/66, Loss: 1.0731, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 60/66, Loss: 1.1246, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 61/66, Loss: 1.1346, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 62/66, Loss: 1.1827, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 63/66, Loss: 1.1795, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 64/66, Loss: 1.0051, Time: 0.84 seconds\n",
            "Epoch 3/4, Batch 65/66, Loss: 1.0660, Time: 0.83 seconds\n",
            "Epoch 3/4, Batch 66/66, Loss: 1.0735, Time: 0.76 seconds\n",
            "Epoch 3/4, Training Loss: 1.1233, Time: 55.21 seconds\n",
            "Validation Loss: 1.0775, Accuracy: 0.6439\n",
            "Epoch 4/4, Batch 1/66, Loss: 1.0948, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 2/66, Loss: 1.0289, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 3/66, Loss: 1.1669, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 4/66, Loss: 1.1084, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 5/66, Loss: 1.2209, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 6/66, Loss: 1.0725, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 7/66, Loss: 1.0476, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 8/66, Loss: 0.9851, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 9/66, Loss: 1.1274, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 10/66, Loss: 1.0677, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 11/66, Loss: 0.9658, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 12/66, Loss: 1.2091, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 13/66, Loss: 1.2686, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 14/66, Loss: 1.1414, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 15/66, Loss: 1.0124, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 16/66, Loss: 1.1154, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 17/66, Loss: 1.0788, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 18/66, Loss: 1.1226, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 19/66, Loss: 1.0102, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 20/66, Loss: 1.1551, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 21/66, Loss: 1.2092, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 22/66, Loss: 1.2460, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 23/66, Loss: 1.1815, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 24/66, Loss: 1.2141, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 25/66, Loss: 1.1039, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 26/66, Loss: 1.1791, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 27/66, Loss: 1.0805, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 28/66, Loss: 1.0320, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 29/66, Loss: 1.2290, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 30/66, Loss: 1.2649, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 31/66, Loss: 1.1259, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 32/66, Loss: 1.1624, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 33/66, Loss: 1.0994, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 34/66, Loss: 1.1597, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 35/66, Loss: 1.1351, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 36/66, Loss: 1.0644, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 37/66, Loss: 1.1444, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 38/66, Loss: 1.1019, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 39/66, Loss: 1.0178, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 40/66, Loss: 1.1143, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 41/66, Loss: 1.1655, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 42/66, Loss: 1.1602, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 43/66, Loss: 1.1829, Time: 0.83 seconds\n",
            "Epoch 4/4, Batch 44/66, Loss: 1.0799, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 45/66, Loss: 1.0430, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 46/66, Loss: 0.9756, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 47/66, Loss: 1.1435, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 48/66, Loss: 1.0102, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 49/66, Loss: 1.1553, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 50/66, Loss: 1.1828, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 51/66, Loss: 1.1741, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 52/66, Loss: 1.1828, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 53/66, Loss: 1.1755, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 54/66, Loss: 1.1934, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 55/66, Loss: 1.0612, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 56/66, Loss: 1.0314, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 57/66, Loss: 1.0918, Time: 0.85 seconds\n",
            "Epoch 4/4, Batch 58/66, Loss: 1.1012, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 59/66, Loss: 1.0582, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 60/66, Loss: 1.1647, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 61/66, Loss: 1.0231, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 62/66, Loss: 1.0424, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 63/66, Loss: 1.0042, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 64/66, Loss: 1.0737, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 65/66, Loss: 1.1802, Time: 0.84 seconds\n",
            "Epoch 4/4, Batch 66/66, Loss: 1.2208, Time: 0.76 seconds\n",
            "Epoch 4/4, Training Loss: 1.1173, Time: 55.41 seconds\n",
            "Validation Loss: 1.1220, Accuracy: 0.6439\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 4\n",
        "for epoch in range(num_epochs):\n",
        "    M.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = M(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "    # Validation\n",
        "    M.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = M(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += loss_fn(outputs.logits, labels).item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"./trained_models/UsedClassWeights\")\n",
        "M.save_pretrained(\"./trained_models/tmp\")"
      ],
      "metadata": {
        "id": "BRs4QtFIalHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "0652a628-a4d9-466e-e256-dc1308140220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-635a582231b4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.save_pretrained(\"./trained_models/UsedClassWeights\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./trained_models/tmp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using over-sampling"
      ],
      "metadata": {
        "id": "cy-V-2s47_Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK3hxr7l8bbL",
        "outputId": "4e8a6ce3-5524-4dae-ee2f-e9aec3f3b49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Separate minority and majority classes\n",
        "minority_classes = ['NetworkDisconnection', 'DiskFull']\n",
        "minority_df = df[df['RootCause'].isin(minority_classes)]\n",
        "majority_df = df[~df['RootCause'].isin(minority_classes)]\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "train_minority, val_minority = train_test_split(minority_df, test_size=0.2, random_state=432)\n",
        "train_majority, val_majority = train_test_split(majority_df, test_size=0.2, random_state=432)\n",
        "\n",
        "# Combine minority and majority datasets for training\n",
        "train_df = pd.concat([train_minority, train_majority], ignore_index=True)\n",
        "\n",
        "# Apply oversampling to minority classes\n",
        "oversampler = RandomOverSampler(random_state=432)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(\n",
        "    train_df['LogContent'].values.reshape(-1, 1),\n",
        "    train_df['labels']\n",
        ")\n",
        "\n",
        "# Create a new DataFrame with oversampled data\n",
        "oversampled_df = pd.DataFrame({'LogContent': X_resampled.flatten(), 'labels': y_resampled})\n",
        "\n",
        "# Combine minority and majority datasets for validation\n",
        "val_df = pd.concat([val_minority, val_majority], ignore_index=True)"
      ],
      "metadata": {
        "id": "P-Esdolv-pdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Assuming 'oversampled_df' is your oversampled DataFrame\n",
        "class_counts = Counter(oversampled_df['labels'])\n",
        "\n",
        "# Print the counts for each class\n",
        "for class_idx, count in class_counts.items():\n",
        "    print(f\"Class {class_idx}: {count} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzei-_A-4kv",
        "outputId": "ee2c5865-f4d2-4b0b-ace7-08db64f5ca52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 343 samples\n",
            "Class 1: 343 samples\n",
            "Class 2: 343 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDataset(texts=list(oversampled_df['LogContent']), labels=oversampled_df['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDataset(texts=list(val_df['LogContent']), labels=val_df['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w87GgE3Y_489",
        "outputId": "4575acee-cf06-4711-d69a-b43831170537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "258"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzAnhgfINVwf",
        "outputId": "718e2fa3-ff44-4509-fdcb-f8b4d929cc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 4\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U19oYUscNcbk",
        "outputId": "326da178-d128-4d8c-f136-1b16bc3489cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Batch 1/258, Loss: 1.0671, Time: 0.49 seconds\n",
            "Epoch 1/4, Batch 2/258, Loss: 1.0458, Time: 0.40 seconds\n",
            "Epoch 1/4, Batch 3/258, Loss: 1.2766, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 4/258, Loss: 1.3021, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 5/258, Loss: 1.1273, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 6/258, Loss: 1.0619, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 7/258, Loss: 1.0128, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 8/258, Loss: 1.1526, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 9/258, Loss: 0.8608, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 10/258, Loss: 1.2940, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 11/258, Loss: 1.2056, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 12/258, Loss: 1.1798, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 13/258, Loss: 1.4408, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 14/258, Loss: 1.1107, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 15/258, Loss: 1.0637, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 16/258, Loss: 1.1903, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 17/258, Loss: 1.1359, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 18/258, Loss: 1.1377, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 19/258, Loss: 1.1379, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 20/258, Loss: 1.1166, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 21/258, Loss: 1.1862, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 22/258, Loss: 0.9322, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 23/258, Loss: 1.1841, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 24/258, Loss: 1.1082, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 25/258, Loss: 1.0101, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 26/258, Loss: 0.9120, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 27/258, Loss: 0.9961, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 28/258, Loss: 0.9469, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 29/258, Loss: 1.5540, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 30/258, Loss: 1.0122, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 31/258, Loss: 1.0857, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 32/258, Loss: 1.0654, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 33/258, Loss: 1.1877, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 34/258, Loss: 1.1094, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 35/258, Loss: 0.9571, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 36/258, Loss: 1.0666, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 37/258, Loss: 1.1017, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 38/258, Loss: 1.0717, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 39/258, Loss: 1.1431, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 40/258, Loss: 1.1588, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 41/258, Loss: 1.2427, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 42/258, Loss: 1.2779, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 43/258, Loss: 1.0199, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 44/258, Loss: 1.2128, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 45/258, Loss: 1.1777, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 46/258, Loss: 1.0774, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 47/258, Loss: 1.0223, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 48/258, Loss: 1.1678, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 49/258, Loss: 1.1653, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 50/258, Loss: 1.1200, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 51/258, Loss: 1.0670, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 52/258, Loss: 1.1204, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 53/258, Loss: 1.1345, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 54/258, Loss: 1.0447, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 55/258, Loss: 1.0321, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 56/258, Loss: 1.1276, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 57/258, Loss: 1.0239, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 58/258, Loss: 1.1782, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 59/258, Loss: 1.1948, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 60/258, Loss: 1.0597, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 61/258, Loss: 1.0380, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 62/258, Loss: 1.0674, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 63/258, Loss: 1.0860, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 64/258, Loss: 1.1022, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 65/258, Loss: 1.1503, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 66/258, Loss: 1.0560, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 67/258, Loss: 1.1433, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 68/258, Loss: 1.1484, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 69/258, Loss: 1.1018, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 70/258, Loss: 1.0899, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 71/258, Loss: 1.0908, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 72/258, Loss: 1.0269, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 73/258, Loss: 1.1771, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 74/258, Loss: 1.0355, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 75/258, Loss: 1.0449, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 76/258, Loss: 1.0980, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 77/258, Loss: 1.0341, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 78/258, Loss: 1.3858, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 79/258, Loss: 1.2312, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 80/258, Loss: 1.0894, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 81/258, Loss: 1.1028, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 82/258, Loss: 1.3741, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 83/258, Loss: 1.1034, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 84/258, Loss: 1.1650, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 85/258, Loss: 1.1242, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 86/258, Loss: 1.0723, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 87/258, Loss: 1.0502, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 88/258, Loss: 1.0514, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 89/258, Loss: 1.2139, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 90/258, Loss: 1.1654, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 91/258, Loss: 1.1543, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 92/258, Loss: 1.1307, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 93/258, Loss: 0.9972, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 94/258, Loss: 1.1956, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 95/258, Loss: 1.0703, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 96/258, Loss: 1.0777, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 97/258, Loss: 1.0456, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 98/258, Loss: 1.1260, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 99/258, Loss: 1.0974, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 100/258, Loss: 1.0277, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 101/258, Loss: 1.1014, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 102/258, Loss: 1.1852, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 103/258, Loss: 1.0125, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 104/258, Loss: 1.2328, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 105/258, Loss: 1.1962, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 106/258, Loss: 1.0866, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 107/258, Loss: 1.1060, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 108/258, Loss: 1.1092, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 109/258, Loss: 1.1732, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 110/258, Loss: 1.0446, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 111/258, Loss: 1.1839, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 112/258, Loss: 1.0630, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 113/258, Loss: 1.0542, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 114/258, Loss: 1.0303, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 115/258, Loss: 1.1067, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 116/258, Loss: 1.1751, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 117/258, Loss: 1.1610, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 118/258, Loss: 1.1705, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 119/258, Loss: 1.0545, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 120/258, Loss: 1.0657, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 121/258, Loss: 1.1128, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 122/258, Loss: 1.1107, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 123/258, Loss: 1.1550, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 124/258, Loss: 1.1628, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 125/258, Loss: 1.1777, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 126/258, Loss: 1.1233, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 127/258, Loss: 1.1188, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 128/258, Loss: 1.1231, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 129/258, Loss: 1.0540, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 130/258, Loss: 1.0671, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 131/258, Loss: 1.0476, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 132/258, Loss: 1.0732, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 133/258, Loss: 1.0722, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 134/258, Loss: 1.2038, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 135/258, Loss: 1.0768, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 136/258, Loss: 1.0562, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 137/258, Loss: 1.1724, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 138/258, Loss: 1.1594, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 139/258, Loss: 0.9266, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 140/258, Loss: 0.9037, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 141/258, Loss: 1.0588, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 142/258, Loss: 1.1645, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 143/258, Loss: 1.2077, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 144/258, Loss: 1.0340, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 145/258, Loss: 1.1009, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 146/258, Loss: 1.0775, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 147/258, Loss: 1.0651, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 148/258, Loss: 1.1856, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 149/258, Loss: 1.1960, Time: 0.40 seconds\n",
            "Epoch 1/4, Batch 150/258, Loss: 1.0964, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 151/258, Loss: 0.9696, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 152/258, Loss: 0.8569, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 153/258, Loss: 1.1743, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 154/258, Loss: 1.1063, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 155/258, Loss: 1.1672, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 156/258, Loss: 1.1869, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 157/258, Loss: 1.1607, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 158/258, Loss: 1.3189, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 159/258, Loss: 1.3007, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 160/258, Loss: 1.1556, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 161/258, Loss: 1.1818, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 162/258, Loss: 1.1068, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 163/258, Loss: 1.0356, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 164/258, Loss: 1.1108, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 165/258, Loss: 1.1845, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 166/258, Loss: 1.1156, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 167/258, Loss: 1.0317, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 168/258, Loss: 1.1023, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 169/258, Loss: 1.1178, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 170/258, Loss: 1.1487, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 171/258, Loss: 1.1852, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 172/258, Loss: 1.0701, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 173/258, Loss: 1.0224, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 174/258, Loss: 1.1700, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 175/258, Loss: 1.1469, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 176/258, Loss: 1.0989, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 177/258, Loss: 1.0538, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 178/258, Loss: 0.8972, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 179/258, Loss: 1.0587, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 180/258, Loss: 1.1841, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 181/258, Loss: 1.1817, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 182/258, Loss: 1.1469, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 183/258, Loss: 1.0434, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 184/258, Loss: 1.0232, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 185/258, Loss: 1.3225, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 186/258, Loss: 1.0734, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 187/258, Loss: 1.0544, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 188/258, Loss: 1.1554, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 189/258, Loss: 1.3863, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 190/258, Loss: 1.1403, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 191/258, Loss: 1.1808, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 192/258, Loss: 0.9896, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 193/258, Loss: 1.0177, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 194/258, Loss: 1.1141, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 195/258, Loss: 1.1874, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 196/258, Loss: 1.1650, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 197/258, Loss: 1.1522, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 198/258, Loss: 1.0244, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 199/258, Loss: 1.0885, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 200/258, Loss: 1.0733, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 201/258, Loss: 1.1914, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 202/258, Loss: 1.0028, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 203/258, Loss: 1.0728, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 204/258, Loss: 1.0197, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 205/258, Loss: 1.1149, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 206/258, Loss: 1.0956, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 207/258, Loss: 1.2285, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 208/258, Loss: 1.1741, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 209/258, Loss: 1.1419, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 210/258, Loss: 1.0861, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 211/258, Loss: 1.1395, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 212/258, Loss: 1.0824, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 213/258, Loss: 1.1385, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 214/258, Loss: 1.1385, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 215/258, Loss: 1.2849, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 216/258, Loss: 1.0311, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 217/258, Loss: 1.1019, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 218/258, Loss: 1.1332, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 219/258, Loss: 1.2250, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 220/258, Loss: 1.0358, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 221/258, Loss: 1.0638, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 222/258, Loss: 1.0509, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 223/258, Loss: 1.0929, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 224/258, Loss: 1.1336, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 225/258, Loss: 1.1106, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 226/258, Loss: 1.1431, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 227/258, Loss: 1.0615, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 228/258, Loss: 1.1048, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 229/258, Loss: 1.1384, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 230/258, Loss: 1.0713, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 231/258, Loss: 1.1716, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 232/258, Loss: 1.0270, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 233/258, Loss: 1.0395, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 234/258, Loss: 1.0539, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 235/258, Loss: 1.1636, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 236/258, Loss: 1.2188, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 237/258, Loss: 1.1516, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 238/258, Loss: 1.2715, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 239/258, Loss: 1.1705, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 240/258, Loss: 1.1558, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 241/258, Loss: 1.0707, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 242/258, Loss: 1.1203, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 243/258, Loss: 1.1643, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 244/258, Loss: 1.1782, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 245/258, Loss: 1.1163, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 246/258, Loss: 1.0677, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 247/258, Loss: 1.1008, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 248/258, Loss: 1.1055, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 249/258, Loss: 1.0894, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 250/258, Loss: 1.1374, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 251/258, Loss: 1.0496, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 252/258, Loss: 1.0530, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 253/258, Loss: 1.0829, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 254/258, Loss: 0.9333, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 255/258, Loss: 0.7948, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 256/258, Loss: 0.8699, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 257/258, Loss: 1.1499, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 258/258, Loss: 0.9977, Time: 0.13 seconds\n",
            "Epoch 1/4, Training Loss: 1.1123, Time: 108.10 seconds\n",
            "Validation Loss: 0.9579, Accuracy: 0.6515\n",
            "Epoch 2/4, Batch 1/258, Loss: 1.2143, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 2/258, Loss: 1.2279, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 3/258, Loss: 1.0591, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 4/258, Loss: 0.8624, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 5/258, Loss: 1.0723, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 6/258, Loss: 1.0097, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 7/258, Loss: 1.2579, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 8/258, Loss: 0.8094, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 9/258, Loss: 0.7315, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 10/258, Loss: 0.6845, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 11/258, Loss: 0.6592, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 12/258, Loss: 0.6591, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 13/258, Loss: 0.4507, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 14/258, Loss: 0.3531, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 15/258, Loss: 0.7829, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 16/258, Loss: 0.3596, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 17/258, Loss: 0.2686, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 18/258, Loss: 0.3898, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 19/258, Loss: 0.2065, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 20/258, Loss: 0.4476, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 21/258, Loss: 0.1905, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 22/258, Loss: 0.0692, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 23/258, Loss: 0.0976, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 24/258, Loss: 0.1682, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 25/258, Loss: 0.1496, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 26/258, Loss: 0.9616, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 27/258, Loss: 0.0997, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 28/258, Loss: 0.0688, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 29/258, Loss: 0.0431, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 30/258, Loss: 0.3439, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 31/258, Loss: 0.0574, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 32/258, Loss: 0.0506, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 33/258, Loss: 0.0775, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 34/258, Loss: 0.0455, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 35/258, Loss: 0.0410, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 36/258, Loss: 0.0440, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 37/258, Loss: 0.1117, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 38/258, Loss: 0.0488, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 39/258, Loss: 0.8006, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 40/258, Loss: 0.0485, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 41/258, Loss: 0.7242, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 42/258, Loss: 0.2723, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 43/258, Loss: 0.3611, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 44/258, Loss: 0.0838, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 45/258, Loss: 0.0715, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 46/258, Loss: 0.1476, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 47/258, Loss: 0.1322, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 48/258, Loss: 0.0341, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 49/258, Loss: 0.0810, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 50/258, Loss: 0.0429, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 51/258, Loss: 0.0226, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 52/258, Loss: 0.8396, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 53/258, Loss: 0.0467, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 54/258, Loss: 0.0404, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 55/258, Loss: 0.1282, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 56/258, Loss: 0.0367, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 57/258, Loss: 0.8235, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 58/258, Loss: 0.0285, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 59/258, Loss: 0.0431, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 60/258, Loss: 0.7063, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 61/258, Loss: 0.0325, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 62/258, Loss: 0.0583, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 63/258, Loss: 0.6048, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 64/258, Loss: 0.0828, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 65/258, Loss: 0.0939, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 66/258, Loss: 0.0631, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 67/258, Loss: 0.5086, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 68/258, Loss: 0.0866, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 69/258, Loss: 0.3910, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 70/258, Loss: 0.5437, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 71/258, Loss: 0.2435, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 72/258, Loss: 0.3221, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 73/258, Loss: 0.0096, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 74/258, Loss: 0.0806, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 75/258, Loss: 0.1742, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 76/258, Loss: 0.3747, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 77/258, Loss: 0.5781, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 78/258, Loss: 0.1201, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 79/258, Loss: 0.3501, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 80/258, Loss: 0.1711, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 81/258, Loss: 0.0607, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 82/258, Loss: 0.0196, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 83/258, Loss: 0.0369, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 84/258, Loss: 0.0816, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 85/258, Loss: 0.1396, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 86/258, Loss: 0.0386, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 87/258, Loss: 0.0443, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 88/258, Loss: 0.7300, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 89/258, Loss: 0.8530, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 90/258, Loss: 0.0642, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 91/258, Loss: 0.7756, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 92/258, Loss: 0.1791, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 93/258, Loss: 0.0189, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 94/258, Loss: 0.0574, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 95/258, Loss: 0.0297, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 96/258, Loss: 0.0243, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 97/258, Loss: 0.6655, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 98/258, Loss: 0.0198, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 99/258, Loss: 0.7177, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 100/258, Loss: 0.0577, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 101/258, Loss: 0.0689, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 102/258, Loss: 0.0818, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 103/258, Loss: 0.1139, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 104/258, Loss: 0.1167, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 105/258, Loss: 0.0383, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 106/258, Loss: 0.6074, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 107/258, Loss: 0.0898, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 108/258, Loss: 0.0411, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 109/258, Loss: 0.1792, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 110/258, Loss: 0.1242, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 111/258, Loss: 0.0067, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 112/258, Loss: 0.0378, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 113/258, Loss: 0.0094, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 114/258, Loss: 0.1011, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 115/258, Loss: 0.6468, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 116/258, Loss: 0.0370, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 117/258, Loss: 0.0330, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 118/258, Loss: 0.0363, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 119/258, Loss: 0.0950, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 120/258, Loss: 0.0280, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 121/258, Loss: 0.6581, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 122/258, Loss: 0.0047, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 123/258, Loss: 0.6742, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 124/258, Loss: 0.0294, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 125/258, Loss: 0.0719, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 126/258, Loss: 0.0307, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 127/258, Loss: 0.6156, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 128/258, Loss: 0.0501, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 129/258, Loss: 0.6392, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 130/258, Loss: 0.4811, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 131/258, Loss: 0.0635, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 132/258, Loss: 0.1545, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 133/258, Loss: 0.0866, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 134/258, Loss: 0.2905, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 135/258, Loss: 0.0062, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 136/258, Loss: 0.0041, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 137/258, Loss: 0.0055, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 138/258, Loss: 0.5500, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 139/258, Loss: 0.2382, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 140/258, Loss: 0.2087, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 141/258, Loss: 0.2320, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 142/258, Loss: 0.2682, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 143/258, Loss: 0.3402, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 144/258, Loss: 0.0572, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 145/258, Loss: 0.0497, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 146/258, Loss: 0.0655, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 147/258, Loss: 0.1427, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 148/258, Loss: 0.0534, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 149/258, Loss: 0.0468, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 150/258, Loss: 0.5141, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 151/258, Loss: 0.0646, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 152/258, Loss: 0.0282, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 153/258, Loss: 0.0566, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 154/258, Loss: 0.0278, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 155/258, Loss: 0.6145, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 156/258, Loss: 0.0489, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 157/258, Loss: 0.0461, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 158/258, Loss: 0.0760, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 159/258, Loss: 0.0799, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 160/258, Loss: 0.6953, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 161/258, Loss: 0.0217, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 162/258, Loss: 0.6931, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 163/258, Loss: 0.0045, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 164/258, Loss: 0.0279, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 165/258, Loss: 0.0528, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 166/258, Loss: 0.0285, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 167/258, Loss: 0.0699, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 168/258, Loss: 0.0808, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 169/258, Loss: 0.0252, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 170/258, Loss: 0.0849, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 171/258, Loss: 0.0047, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 172/258, Loss: 0.5703, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 173/258, Loss: 0.7073, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 174/258, Loss: 0.6234, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 175/258, Loss: 0.0582, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 176/258, Loss: 0.0991, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 177/258, Loss: 0.0034, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 178/258, Loss: 0.0738, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 179/258, Loss: 0.0834, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 180/258, Loss: 0.0752, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 181/258, Loss: 0.0637, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 182/258, Loss: 0.0363, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 183/258, Loss: 0.0031, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 184/258, Loss: 0.0400, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 185/258, Loss: 0.0266, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 186/258, Loss: 0.0402, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 187/258, Loss: 0.0288, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 188/258, Loss: 0.0051, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 189/258, Loss: 0.0037, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 190/258, Loss: 0.0293, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 191/258, Loss: 0.0026, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 192/258, Loss: 0.0511, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 193/258, Loss: 0.0775, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 194/258, Loss: 0.0498, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 195/258, Loss: 0.0213, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 196/258, Loss: 0.6688, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 197/258, Loss: 0.0242, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 198/258, Loss: 1.3714, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 199/258, Loss: 0.0241, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 200/258, Loss: 0.0230, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 201/258, Loss: 0.0277, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 202/258, Loss: 0.0728, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 203/258, Loss: 0.0350, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 204/258, Loss: 0.0325, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 205/258, Loss: 0.6600, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 206/258, Loss: 0.5306, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 207/258, Loss: 0.0026, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 208/258, Loss: 0.0036, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 209/258, Loss: 0.0765, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 210/258, Loss: 0.0425, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 211/258, Loss: 0.1149, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 212/258, Loss: 0.0015, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 213/258, Loss: 0.0502, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 214/258, Loss: 0.0574, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 215/258, Loss: 0.4639, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 216/258, Loss: 0.4137, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 217/258, Loss: 0.1091, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 218/258, Loss: 0.1591, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 219/258, Loss: 0.0563, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 220/258, Loss: 0.0622, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 221/258, Loss: 0.1317, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 222/258, Loss: 0.0040, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 223/258, Loss: 0.0445, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 224/258, Loss: 0.1082, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 225/258, Loss: 0.0471, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 226/258, Loss: 0.0810, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 227/258, Loss: 0.1811, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 228/258, Loss: 0.9965, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 229/258, Loss: 0.4717, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 230/258, Loss: 0.0568, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 231/258, Loss: 0.0899, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 232/258, Loss: 0.0379, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 233/258, Loss: 0.0438, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 234/258, Loss: 0.0027, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 235/258, Loss: 0.0047, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 236/258, Loss: 0.0023, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 237/258, Loss: 0.0859, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 238/258, Loss: 0.1964, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 239/258, Loss: 0.0020, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 240/258, Loss: 0.0019, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 241/258, Loss: 0.1314, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 242/258, Loss: 0.5040, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 243/258, Loss: 0.0635, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 244/258, Loss: 0.0724, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 245/258, Loss: 0.0221, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 246/258, Loss: 0.0560, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 247/258, Loss: 0.0770, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 248/258, Loss: 0.5791, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 249/258, Loss: 0.6941, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 250/258, Loss: 1.0506, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 251/258, Loss: 0.5651, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 252/258, Loss: 0.0035, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 253/258, Loss: 0.0027, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 254/258, Loss: 0.1016, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 255/258, Loss: 0.5081, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 256/258, Loss: 0.4306, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 257/258, Loss: 0.0960, Time: 0.41 seconds\n",
            "Epoch 2/4, Batch 258/258, Loss: 0.3024, Time: 0.13 seconds\n",
            "Epoch 2/4, Training Loss: 0.2320, Time: 107.28 seconds\n",
            "Validation Loss: 0.1605, Accuracy: 0.9242\n",
            "Epoch 3/4, Batch 1/258, Loss: 0.4201, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 2/258, Loss: 0.0704, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 3/258, Loss: 0.1711, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 4/258, Loss: 0.3505, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 5/258, Loss: 0.1481, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 6/258, Loss: 0.1776, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 7/258, Loss: 0.4311, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 8/258, Loss: 0.4807, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 9/258, Loss: 0.0899, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 10/258, Loss: 0.2464, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 11/258, Loss: 0.0776, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 12/258, Loss: 0.0673, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 13/258, Loss: 0.2458, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 14/258, Loss: 0.0028, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 15/258, Loss: 0.0470, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 16/258, Loss: 0.1136, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 17/258, Loss: 0.0035, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 18/258, Loss: 0.0831, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 19/258, Loss: 0.5212, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 20/258, Loss: 0.0700, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 21/258, Loss: 0.0314, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 22/258, Loss: 0.0037, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 23/258, Loss: 0.0263, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 24/258, Loss: 0.0509, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 25/258, Loss: 0.0489, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 26/258, Loss: 0.5466, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 27/258, Loss: 0.0620, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 28/258, Loss: 0.6233, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 29/258, Loss: 0.0281, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 30/258, Loss: 0.0557, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 31/258, Loss: 0.0918, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 32/258, Loss: 0.0892, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 33/258, Loss: 0.5848, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 34/258, Loss: 0.0317, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 35/258, Loss: 0.0037, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 36/258, Loss: 0.5816, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 37/258, Loss: 0.0035, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 38/258, Loss: 0.0365, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 39/258, Loss: 0.0020, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 40/258, Loss: 0.0409, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 41/258, Loss: 0.6118, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 42/258, Loss: 0.5488, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 43/258, Loss: 0.0448, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 44/258, Loss: 0.0028, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 45/258, Loss: 0.1325, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 46/258, Loss: 0.0590, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 47/258, Loss: 0.4937, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 48/258, Loss: 0.0712, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 49/258, Loss: 0.1422, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 50/258, Loss: 0.0622, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 51/258, Loss: 0.1399, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 52/258, Loss: 0.0615, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 53/258, Loss: 0.0019, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 54/258, Loss: 0.1403, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 55/258, Loss: 0.0428, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 56/258, Loss: 0.5259, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 57/258, Loss: 0.1176, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 58/258, Loss: 0.5889, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 59/258, Loss: 0.0613, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 60/258, Loss: 0.0040, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 61/258, Loss: 0.0675, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 62/258, Loss: 0.5499, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 63/258, Loss: 0.0944, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 64/258, Loss: 0.0626, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 65/258, Loss: 0.0020, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 66/258, Loss: 0.0025, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 67/258, Loss: 0.6706, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 68/258, Loss: 0.0645, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 69/258, Loss: 0.1232, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 70/258, Loss: 0.0016, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 71/258, Loss: 0.0354, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 72/258, Loss: 0.0687, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 73/258, Loss: 0.0432, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 74/258, Loss: 0.0022, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 75/258, Loss: 0.0940, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 76/258, Loss: 0.0021, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 77/258, Loss: 0.0600, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 78/258, Loss: 0.6632, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 79/258, Loss: 0.0570, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 80/258, Loss: 0.0581, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 81/258, Loss: 0.6068, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 82/258, Loss: 0.0304, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 83/258, Loss: 0.5571, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 84/258, Loss: 0.0244, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 85/258, Loss: 0.0022, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 86/258, Loss: 0.0381, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 87/258, Loss: 0.0773, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 88/258, Loss: 0.0339, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 89/258, Loss: 0.5819, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 90/258, Loss: 0.1092, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 91/258, Loss: 0.0374, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 92/258, Loss: 0.0433, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 93/258, Loss: 0.4905, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 94/258, Loss: 0.6224, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 95/258, Loss: 0.0851, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 96/258, Loss: 0.0687, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 97/258, Loss: 0.4112, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 98/258, Loss: 0.0021, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 99/258, Loss: 0.0493, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 100/258, Loss: 0.0435, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 101/258, Loss: 0.1256, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 102/258, Loss: 0.5616, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 103/258, Loss: 0.2124, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 104/258, Loss: 0.5601, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 105/258, Loss: 0.1492, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 106/258, Loss: 0.0026, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 107/258, Loss: 0.0675, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 108/258, Loss: 0.1250, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 109/258, Loss: 0.0542, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 110/258, Loss: 0.0022, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 111/258, Loss: 0.0531, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 112/258, Loss: 0.4517, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 113/258, Loss: 0.0030, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 114/258, Loss: 0.0759, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 115/258, Loss: 0.0426, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 116/258, Loss: 0.1543, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 117/258, Loss: 0.1004, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 118/258, Loss: 0.4041, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 119/258, Loss: 0.0819, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 120/258, Loss: 0.0026, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 121/258, Loss: 0.5995, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 122/258, Loss: 0.0588, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 123/258, Loss: 0.0423, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 124/258, Loss: 0.0951, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 125/258, Loss: 0.5576, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 126/258, Loss: 0.1070, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 127/258, Loss: 0.0387, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 128/258, Loss: 0.0027, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 129/258, Loss: 0.9970, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 130/258, Loss: 0.5262, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 131/258, Loss: 0.0317, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 132/258, Loss: 0.0538, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 133/258, Loss: 0.0945, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 134/258, Loss: 0.0024, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 135/258, Loss: 0.0574, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 136/258, Loss: 0.1099, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 137/258, Loss: 0.0533, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 138/258, Loss: 0.0499, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 139/258, Loss: 0.1581, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 140/258, Loss: 0.0540, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 141/258, Loss: 0.1867, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 142/258, Loss: 0.0878, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 143/258, Loss: 0.1184, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 144/258, Loss: 0.6422, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 145/258, Loss: 0.0394, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 146/258, Loss: 0.9949, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 147/258, Loss: 0.0015, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 148/258, Loss: 1.4624, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 149/258, Loss: 0.5192, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 150/258, Loss: 0.1474, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 151/258, Loss: 0.0564, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 152/258, Loss: 0.1622, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 153/258, Loss: 0.2148, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 154/258, Loss: 0.0760, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 155/258, Loss: 0.0692, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 156/258, Loss: 0.0600, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 157/258, Loss: 0.1317, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 158/258, Loss: 0.0657, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 159/258, Loss: 0.3440, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 160/258, Loss: 0.0981, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 161/258, Loss: 0.0454, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 162/258, Loss: 0.0799, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 163/258, Loss: 0.4735, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 164/258, Loss: 0.0590, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 165/258, Loss: 0.0563, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 166/258, Loss: 0.1873, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 167/258, Loss: 0.0973, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 168/258, Loss: 0.0018, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 169/258, Loss: 0.0484, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 170/258, Loss: 0.0420, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 171/258, Loss: 0.0981, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 172/258, Loss: 0.0356, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 173/258, Loss: 0.0376, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 174/258, Loss: 0.5576, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 175/258, Loss: 0.0796, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 176/258, Loss: 0.0388, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 177/258, Loss: 0.0028, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 178/258, Loss: 0.0019, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 179/258, Loss: 0.6202, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 180/258, Loss: 0.0689, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 181/258, Loss: 0.0959, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 182/258, Loss: 0.0868, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 183/258, Loss: 0.0345, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 184/258, Loss: 0.0591, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 185/258, Loss: 0.0490, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 186/258, Loss: 0.6493, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 187/258, Loss: 0.0009, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 188/258, Loss: 0.0682, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 189/258, Loss: 0.0220, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 190/258, Loss: 0.0535, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 191/258, Loss: 0.0551, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 192/258, Loss: 0.0626, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 193/258, Loss: 0.0009, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 194/258, Loss: 0.0461, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 195/258, Loss: 0.0349, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 196/258, Loss: 0.6782, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 197/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 198/258, Loss: 0.0216, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 199/258, Loss: 0.0226, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 200/258, Loss: 0.6759, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 201/258, Loss: 0.0676, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 202/258, Loss: 0.0426, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 203/258, Loss: 0.0593, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 204/258, Loss: 0.0649, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 205/258, Loss: 0.0659, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 206/258, Loss: 0.0589, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 207/258, Loss: 0.6553, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 208/258, Loss: 0.0495, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 209/258, Loss: 0.0410, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 210/258, Loss: 0.6231, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 211/258, Loss: 0.0205, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 212/258, Loss: 0.0427, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 213/258, Loss: 0.0544, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 214/258, Loss: 0.0211, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 215/258, Loss: 0.0255, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 216/258, Loss: 0.0227, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 217/258, Loss: 0.0499, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 218/258, Loss: 0.0714, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 219/258, Loss: 0.0218, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 220/258, Loss: 0.6716, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 221/258, Loss: 0.0395, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 222/258, Loss: 0.0194, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 223/258, Loss: 0.0287, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 224/258, Loss: 0.0484, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 225/258, Loss: 0.0236, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 226/258, Loss: 0.0262, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 227/258, Loss: 0.0269, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 228/258, Loss: 0.0398, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 229/258, Loss: 0.0223, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 230/258, Loss: 0.0239, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 231/258, Loss: 0.0331, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 232/258, Loss: 0.0380, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 233/258, Loss: 0.0012, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 234/258, Loss: 0.0350, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 235/258, Loss: 0.0147, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 236/258, Loss: 0.7053, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 237/258, Loss: 0.7149, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 238/258, Loss: 0.0012, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 239/258, Loss: 0.0354, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 240/258, Loss: 0.0011, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 241/258, Loss: 0.0214, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 242/258, Loss: 0.6111, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 243/258, Loss: 0.7805, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 244/258, Loss: 0.0477, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 245/258, Loss: 0.0542, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 246/258, Loss: 0.0262, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 247/258, Loss: 0.0228, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 248/258, Loss: 0.0020, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 249/258, Loss: 0.5010, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 250/258, Loss: 0.0321, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 251/258, Loss: 0.0716, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 252/258, Loss: 0.0362, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 253/258, Loss: 0.0512, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 254/258, Loss: 0.0448, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 255/258, Loss: 0.0051, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 256/258, Loss: 0.0906, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 257/258, Loss: 0.4759, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 258/258, Loss: 0.0033, Time: 0.13 seconds\n",
            "Epoch 3/4, Training Loss: 0.1647, Time: 107.17 seconds\n",
            "Validation Loss: 0.1748, Accuracy: 0.9242\n",
            "Epoch 4/4, Batch 1/258, Loss: 0.0391, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 2/258, Loss: 0.9532, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 3/258, Loss: 0.0016, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 4/258, Loss: 0.5205, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 5/258, Loss: 0.0649, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 6/258, Loss: 0.5505, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 7/258, Loss: 0.2464, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 8/258, Loss: 0.1765, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 9/258, Loss: 0.1404, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 10/258, Loss: 0.0773, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 11/258, Loss: 0.0681, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 12/258, Loss: 0.0594, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 13/258, Loss: 0.1233, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 14/258, Loss: 0.0551, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 15/258, Loss: 0.2021, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 16/258, Loss: 0.0020, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 17/258, Loss: 0.0816, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 18/258, Loss: 0.0418, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 19/258, Loss: 0.0017, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 20/258, Loss: 0.6528, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 21/258, Loss: 0.0026, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 22/258, Loss: 0.6217, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 23/258, Loss: 0.0932, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 24/258, Loss: 0.0317, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 25/258, Loss: 0.0969, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 26/258, Loss: 0.0465, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 27/258, Loss: 0.0667, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 28/258, Loss: 0.6232, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 29/258, Loss: 0.0021, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 30/258, Loss: 0.0571, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 31/258, Loss: 0.0469, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 32/258, Loss: 0.5603, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 33/258, Loss: 0.0373, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 34/258, Loss: 0.0876, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 35/258, Loss: 0.0856, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 36/258, Loss: 0.0553, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 37/258, Loss: 0.0840, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 38/258, Loss: 0.6319, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 39/258, Loss: 0.0266, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 40/258, Loss: 0.0546, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 41/258, Loss: 0.0886, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 42/258, Loss: 0.5905, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 43/258, Loss: 0.0266, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 44/258, Loss: 0.0748, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 45/258, Loss: 0.0572, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 46/258, Loss: 0.0339, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 47/258, Loss: 0.0494, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 48/258, Loss: 0.7036, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 49/258, Loss: 0.0291, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 50/258, Loss: 0.0804, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 51/258, Loss: 0.0325, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 52/258, Loss: 0.6410, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 53/258, Loss: 0.0227, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 54/258, Loss: 0.0241, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 55/258, Loss: 0.1019, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 56/258, Loss: 0.0370, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 57/258, Loss: 0.0546, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 58/258, Loss: 0.0210, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 59/258, Loss: 0.0909, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 60/258, Loss: 0.5802, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 61/258, Loss: 0.6292, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 62/258, Loss: 0.0274, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 63/258, Loss: 0.0364, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 64/258, Loss: 0.0574, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 65/258, Loss: 0.6511, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 66/258, Loss: 0.0016, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 67/258, Loss: 0.0409, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 68/258, Loss: 0.0264, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 69/258, Loss: 0.0776, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 70/258, Loss: 0.0283, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 71/258, Loss: 0.0291, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 72/258, Loss: 0.5802, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 73/258, Loss: 0.1514, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 74/258, Loss: 0.6077, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 75/258, Loss: 0.0406, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 76/258, Loss: 0.0636, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 77/258, Loss: 0.0020, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 78/258, Loss: 0.0764, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 79/258, Loss: 0.1172, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 80/258, Loss: 0.0329, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 81/258, Loss: 0.0935, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 82/258, Loss: 0.0331, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 83/258, Loss: 0.0714, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 84/258, Loss: 0.0577, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 85/258, Loss: 0.0714, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 86/258, Loss: 0.5737, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 87/258, Loss: 0.5031, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 88/258, Loss: 0.0604, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 89/258, Loss: 0.0414, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 90/258, Loss: 0.0307, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 91/258, Loss: 0.0340, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 92/258, Loss: 0.0268, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 93/258, Loss: 0.0387, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 94/258, Loss: 0.0804, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 95/258, Loss: 0.0234, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 96/258, Loss: 0.0847, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 97/258, Loss: 0.0532, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 98/258, Loss: 0.0287, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 99/258, Loss: 0.0218, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 100/258, Loss: 0.6910, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 101/258, Loss: 0.0013, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 102/258, Loss: 0.0411, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 103/258, Loss: 0.0497, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 104/258, Loss: 0.0198, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 105/258, Loss: 0.6847, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 106/258, Loss: 0.0230, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 107/258, Loss: 0.0218, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 108/258, Loss: 0.0766, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 109/258, Loss: 0.0289, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 110/258, Loss: 0.0775, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 111/258, Loss: 0.6305, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 112/258, Loss: 0.0489, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 113/258, Loss: 0.0255, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 114/258, Loss: 0.0602, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 115/258, Loss: 0.0546, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 116/258, Loss: 0.6337, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 117/258, Loss: 0.0307, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 118/258, Loss: 0.6328, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 119/258, Loss: 0.0277, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 120/258, Loss: 0.0262, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 121/258, Loss: 0.0276, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 122/258, Loss: 0.0620, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 123/258, Loss: 0.0572, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 124/258, Loss: 0.5714, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 125/258, Loss: 0.1089, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 126/258, Loss: 0.0009, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 127/258, Loss: 0.0010, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 128/258, Loss: 0.0671, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 129/258, Loss: 0.5845, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 130/258, Loss: 0.0777, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 131/258, Loss: 0.0763, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 132/258, Loss: 0.0809, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 133/258, Loss: 0.0335, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 134/258, Loss: 0.1064, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 135/258, Loss: 0.0851, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 136/258, Loss: 0.0013, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 137/258, Loss: 0.0419, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 138/258, Loss: 0.0022, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 139/258, Loss: 0.4957, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 140/258, Loss: 0.0906, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 141/258, Loss: 0.0362, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 142/258, Loss: 0.0223, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 143/258, Loss: 0.0191, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 144/258, Loss: 0.0298, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 145/258, Loss: 0.5616, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 146/258, Loss: 0.5165, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 147/258, Loss: 0.0352, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 148/258, Loss: 0.4849, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 149/258, Loss: 0.5152, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 150/258, Loss: 0.0390, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 151/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 152/258, Loss: 0.0820, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 153/258, Loss: 0.9317, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 154/258, Loss: 0.0991, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 155/258, Loss: 0.0548, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 156/258, Loss: 0.1324, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 157/258, Loss: 0.0010, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 158/258, Loss: 0.4347, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 159/258, Loss: 0.0017, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 160/258, Loss: 0.1741, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 161/258, Loss: 0.1540, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 162/258, Loss: 0.0867, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 163/258, Loss: 0.0618, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 164/258, Loss: 0.4152, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 165/258, Loss: 0.0014, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 166/258, Loss: 0.0005, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 167/258, Loss: 0.0027, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 168/258, Loss: 0.0015, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 169/258, Loss: 0.0703, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 170/258, Loss: 0.0012, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 171/258, Loss: 0.1821, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 172/258, Loss: 0.2144, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 173/258, Loss: 0.1191, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 174/258, Loss: 0.1280, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 175/258, Loss: 0.1124, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 176/258, Loss: 0.0551, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 177/258, Loss: 0.5582, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 178/258, Loss: 0.1208, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 179/258, Loss: 0.0392, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 180/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 181/258, Loss: 0.5456, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 182/258, Loss: 0.0015, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 183/258, Loss: 0.0268, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 184/258, Loss: 0.6064, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 185/258, Loss: 0.6167, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 186/258, Loss: 0.0016, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 187/258, Loss: 1.0537, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 188/258, Loss: 0.0334, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 189/258, Loss: 0.0013, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 190/258, Loss: 0.0310, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 191/258, Loss: 0.1108, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 192/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 193/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 194/258, Loss: 0.0427, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 195/258, Loss: 0.9107, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 196/258, Loss: 0.0823, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 197/258, Loss: 0.5134, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 198/258, Loss: 0.4885, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 199/258, Loss: 0.0663, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 200/258, Loss: 0.0564, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 201/258, Loss: 0.2694, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 202/258, Loss: 0.1559, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 203/258, Loss: 0.1518, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 204/258, Loss: 0.1661, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 205/258, Loss: 0.1166, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 206/258, Loss: 0.1110, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 207/258, Loss: 0.0012, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 208/258, Loss: 0.4544, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 209/258, Loss: 0.1360, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 210/258, Loss: 0.0320, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 211/258, Loss: 0.0559, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 212/258, Loss: 0.0008, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 213/258, Loss: 0.1165, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 214/258, Loss: 0.1385, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 215/258, Loss: 0.4649, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 216/258, Loss: 0.0648, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 217/258, Loss: 0.5460, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 218/258, Loss: 0.0301, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 219/258, Loss: 0.0361, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 220/258, Loss: 0.0004, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 221/258, Loss: 0.0416, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 222/258, Loss: 0.0770, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 223/258, Loss: 0.0756, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 224/258, Loss: 0.0243, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 225/258, Loss: 0.0326, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 226/258, Loss: 0.5765, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 227/258, Loss: 0.1054, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 228/258, Loss: 0.0479, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 229/258, Loss: 0.0683, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 230/258, Loss: 0.0541, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 231/258, Loss: 0.0394, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 232/258, Loss: 0.0529, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 233/258, Loss: 0.0013, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 234/258, Loss: 0.0426, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 235/258, Loss: 0.0227, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 236/258, Loss: 0.0005, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 237/258, Loss: 0.0270, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 238/258, Loss: 0.6731, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 239/258, Loss: 0.0454, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 240/258, Loss: 0.0323, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 241/258, Loss: 0.0175, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 242/258, Loss: 0.0156, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 243/258, Loss: 0.0208, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 244/258, Loss: 0.7070, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 245/258, Loss: 0.0013, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 246/258, Loss: 0.6600, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 247/258, Loss: 0.0649, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 248/258, Loss: 0.0200, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 249/258, Loss: 0.0213, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 250/258, Loss: 0.6864, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 251/258, Loss: 0.7036, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 252/258, Loss: 0.0221, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 253/258, Loss: 0.0284, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 254/258, Loss: 0.0659, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 255/258, Loss: 0.0411, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 256/258, Loss: 0.0330, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 257/258, Loss: 0.0621, Time: 0.41 seconds\n",
            "Epoch 4/4, Batch 258/258, Loss: 2.1923, Time: 0.13 seconds\n",
            "Epoch 4/4, Training Loss: 0.1725, Time: 107.21 seconds\n",
            "Validation Loss: 0.1755, Accuracy: 0.9242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/old_way_1\")"
      ],
      "metadata": {
        "id": "nxh8yI2LgpSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using under-sampling"
      ],
      "metadata": {
        "id": "JZ225ZsEZe59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "# Separate minority and majority classes\n",
        "majority_class = ['NetworkDisconnection', 'MachineDown']\n",
        "majority_df = df[df['RootCause'].isin(majority_class)]\n",
        "minority_df = df[~df['RootCause'].isin(majority_class)]\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "train_minority, val_minority = train_test_split(minority_df, test_size=0.2, random_state=412)\n",
        "train_majority, val_majority = train_test_split(majority_df, test_size=0.2, random_state=412)\n",
        "\n",
        "# Combine minority and majority datasets for training\n",
        "train_df = pd.concat([train_minority, train_majority], ignore_index=True)\n",
        "\n",
        "\n",
        "min_samples_per_class = min(train_df['RootCause'].value_counts())\n",
        "desired_samples = {0: min_samples_per_class, 1: min_samples_per_class, 2: min_samples_per_class}\n",
        "\n",
        "\n",
        "# Apply undersampling to majority class\n",
        "undersampler = RandomUnderSampler(sampling_strategy=desired_samples, random_state=412)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(\n",
        "    train_df['LogContent'].values.reshape(-1, 1),\n",
        "    train_df['labels']\n",
        ")\n",
        "\n",
        "# Create a new DataFrame with undersampled data\n",
        "undersampled_df = pd.DataFrame({'LogContent': X_resampled.flatten(), 'labels': y_resampled})\n",
        "\n",
        "# Combine minority and majority datasets for validation\n",
        "val_df = pd.concat([val_minority, val_majority], ignore_index=True)\n",
        "\n",
        "\n",
        "# Apply undersampling to VAL df\n",
        "\n",
        "min_samples_per_class = min(val_df['RootCause'].value_counts())\n",
        "desired_samples_val = {0: min_samples_per_class, 1: min_samples_per_class, 2: min_samples_per_class}\n",
        "\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy=desired_samples_val, random_state=412)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(\n",
        "    val_df['LogContent'].values.reshape(-1, 1),\n",
        "    val_df['labels']\n",
        ")\n",
        "\n",
        "# Create a new DataFrame with undersampled data\n",
        "val_df = pd.DataFrame({'LogContent': X_resampled.flatten(), 'labels': y_resampled})\n",
        "\n"
      ],
      "metadata": {
        "id": "LKAtFUzzZhiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "undersampled_df['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J57exui5Z_Uj",
        "outputId": "273cd975-7ec2-4618-acd5-bb8c99b67952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    80\n",
              "1    80\n",
              "2    80\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDataset(texts=list(undersampled_df['LogContent']), labels=undersampled_df['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDataset(texts=list(val_df['LogContent']), labels=val_df['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqiYSdBSaj3t",
        "outputId": "c58d1346-a8c3-4a20-e282-562ecc60fd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTAkDt2UO9s7",
        "outputId": "a051d440-dde0-44bb-80df-d9bb94509447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 4\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL_OFz7HO-96",
        "outputId": "25459bce-124c-4ce5-d92b-2349ee3d528b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Batch 1/60, Loss: 0.9407, Time: 0.46 seconds\n",
            "Epoch 1/4, Batch 2/60, Loss: 1.1940, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 3/60, Loss: 1.6561, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 4/60, Loss: 1.1386, Time: 0.41 seconds\n",
            "Epoch 1/4, Batch 5/60, Loss: 1.0190, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 6/60, Loss: 1.2034, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 7/60, Loss: 1.1201, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 8/60, Loss: 1.0635, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 9/60, Loss: 1.3102, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 10/60, Loss: 1.0991, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 11/60, Loss: 0.9371, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 12/60, Loss: 1.0779, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 13/60, Loss: 1.2841, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 14/60, Loss: 1.3493, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 15/60, Loss: 1.1029, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 16/60, Loss: 0.9751, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 17/60, Loss: 1.1627, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 18/60, Loss: 1.0339, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 19/60, Loss: 1.1707, Time: 0.42 seconds\n",
            "Epoch 1/4, Batch 20/60, Loss: 1.1311, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 21/60, Loss: 1.4072, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 22/60, Loss: 1.2068, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 23/60, Loss: 1.3686, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 24/60, Loss: 1.0473, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 25/60, Loss: 1.1912, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 26/60, Loss: 1.0521, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 27/60, Loss: 0.9998, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 28/60, Loss: 1.2581, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 29/60, Loss: 1.1056, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 30/60, Loss: 1.1299, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 31/60, Loss: 1.0783, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 32/60, Loss: 1.1216, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 33/60, Loss: 1.2747, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 34/60, Loss: 1.1288, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 35/60, Loss: 1.0763, Time: 0.43 seconds\n",
            "Epoch 1/4, Batch 36/60, Loss: 0.9799, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 37/60, Loss: 1.0511, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 38/60, Loss: 1.2292, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 39/60, Loss: 1.1219, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 40/60, Loss: 1.1265, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 41/60, Loss: 1.1103, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 42/60, Loss: 1.0718, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 43/60, Loss: 1.0688, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 44/60, Loss: 1.0679, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 45/60, Loss: 1.0141, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 46/60, Loss: 1.0050, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 47/60, Loss: 0.9502, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 48/60, Loss: 1.3309, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 49/60, Loss: 1.2115, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 50/60, Loss: 1.1371, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 51/60, Loss: 1.0849, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 52/60, Loss: 1.0477, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 53/60, Loss: 1.0198, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 54/60, Loss: 1.4376, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 55/60, Loss: 0.8641, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 56/60, Loss: 1.5856, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 57/60, Loss: 1.2845, Time: 0.44 seconds\n",
            "Epoch 1/4, Batch 58/60, Loss: 1.0666, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 59/60, Loss: 0.9927, Time: 0.45 seconds\n",
            "Epoch 1/4, Batch 60/60, Loss: 1.1619, Time: 0.45 seconds\n",
            "Epoch 1/4, Training Loss: 1.1406, Time: 26.31 seconds\n",
            "Validation Loss: 1.1134, Accuracy: 0.3333\n",
            "Epoch 2/4, Batch 1/60, Loss: 1.0617, Time: 0.45 seconds\n",
            "Epoch 2/4, Batch 2/60, Loss: 1.1186, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 3/60, Loss: 1.1432, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 4/60, Loss: 1.2542, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 5/60, Loss: 1.0821, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 6/60, Loss: 1.2528, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 7/60, Loss: 1.2133, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 8/60, Loss: 0.9153, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 9/60, Loss: 1.2089, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 10/60, Loss: 1.0748, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 11/60, Loss: 1.0188, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 12/60, Loss: 0.9855, Time: 0.44 seconds\n",
            "Epoch 2/4, Batch 13/60, Loss: 1.0645, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 14/60, Loss: 1.1540, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 15/60, Loss: 1.1710, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 16/60, Loss: 1.1748, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 17/60, Loss: 1.1824, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 18/60, Loss: 1.1208, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 19/60, Loss: 1.1066, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 20/60, Loss: 1.1009, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 21/60, Loss: 1.2135, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 22/60, Loss: 1.0512, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 23/60, Loss: 1.0517, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 24/60, Loss: 1.1572, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 25/60, Loss: 1.2415, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 26/60, Loss: 1.1288, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 27/60, Loss: 1.1493, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 28/60, Loss: 1.0715, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 29/60, Loss: 1.1769, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 30/60, Loss: 0.9721, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 31/60, Loss: 1.0217, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 32/60, Loss: 1.4820, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 33/60, Loss: 0.9864, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 34/60, Loss: 1.3577, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 35/60, Loss: 1.1752, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 36/60, Loss: 1.1498, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 37/60, Loss: 1.1677, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 38/60, Loss: 1.1461, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 39/60, Loss: 1.2492, Time: 0.43 seconds\n",
            "Epoch 2/4, Batch 40/60, Loss: 1.1172, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 41/60, Loss: 1.0137, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 42/60, Loss: 1.1898, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 43/60, Loss: 1.1650, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 44/60, Loss: 1.1687, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 45/60, Loss: 1.0862, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 46/60, Loss: 1.0202, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 47/60, Loss: 0.9631, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 48/60, Loss: 1.2941, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 49/60, Loss: 1.0495, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 50/60, Loss: 1.2376, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 51/60, Loss: 1.3049, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 52/60, Loss: 1.1246, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 53/60, Loss: 1.1739, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 54/60, Loss: 1.1552, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 55/60, Loss: 1.0988, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 56/60, Loss: 1.0743, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 57/60, Loss: 0.9949, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 58/60, Loss: 1.2185, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 59/60, Loss: 1.1503, Time: 0.42 seconds\n",
            "Epoch 2/4, Batch 60/60, Loss: 1.1866, Time: 0.42 seconds\n",
            "Epoch 2/4, Training Loss: 1.1357, Time: 25.78 seconds\n",
            "Validation Loss: 1.1394, Accuracy: 0.3333\n",
            "Epoch 3/4, Batch 1/60, Loss: 1.1098, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 2/60, Loss: 1.1500, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 3/60, Loss: 1.2765, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 4/60, Loss: 1.1096, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 5/60, Loss: 0.9820, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 6/60, Loss: 1.2602, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 7/60, Loss: 1.0018, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 8/60, Loss: 1.3438, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 9/60, Loss: 1.1744, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 10/60, Loss: 1.2225, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 11/60, Loss: 1.0934, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 12/60, Loss: 1.3002, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 13/60, Loss: 1.1808, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 14/60, Loss: 1.0961, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 15/60, Loss: 1.0624, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 16/60, Loss: 1.1677, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 17/60, Loss: 1.2652, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 18/60, Loss: 1.1664, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 19/60, Loss: 1.0785, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 20/60, Loss: 1.0598, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 21/60, Loss: 1.0779, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 22/60, Loss: 1.2578, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 23/60, Loss: 1.1393, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 24/60, Loss: 1.0842, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 25/60, Loss: 1.1539, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 26/60, Loss: 1.0989, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 27/60, Loss: 1.1821, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 28/60, Loss: 0.9852, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 29/60, Loss: 1.2002, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 30/60, Loss: 1.0249, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 31/60, Loss: 1.2198, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 32/60, Loss: 1.3169, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 33/60, Loss: 1.1621, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 34/60, Loss: 1.1300, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 35/60, Loss: 1.0970, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 36/60, Loss: 1.1957, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 37/60, Loss: 1.0980, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 38/60, Loss: 1.0975, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 39/60, Loss: 1.1162, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 40/60, Loss: 1.1670, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 41/60, Loss: 1.1220, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 42/60, Loss: 1.2115, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 43/60, Loss: 1.1266, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 44/60, Loss: 1.0874, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 45/60, Loss: 1.0490, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 46/60, Loss: 0.9568, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 47/60, Loss: 1.2222, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 48/60, Loss: 1.1374, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 49/60, Loss: 1.0491, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 50/60, Loss: 1.1244, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 51/60, Loss: 1.1211, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 52/60, Loss: 1.1103, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 53/60, Loss: 1.0491, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 54/60, Loss: 1.1286, Time: 0.43 seconds\n",
            "Epoch 3/4, Batch 55/60, Loss: 1.0929, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 56/60, Loss: 1.0984, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 57/60, Loss: 1.1046, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 58/60, Loss: 1.1559, Time: 0.41 seconds\n",
            "Epoch 3/4, Batch 59/60, Loss: 1.1014, Time: 0.42 seconds\n",
            "Epoch 3/4, Batch 60/60, Loss: 1.0513, Time: 0.42 seconds\n",
            "Epoch 3/4, Training Loss: 1.1334, Time: 25.18 seconds\n",
            "Validation Loss: 1.0991, Accuracy: 0.3333\n",
            "Epoch 4/4, Batch 1/60, Loss: 1.1548, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 2/60, Loss: 1.0280, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 3/60, Loss: 1.0652, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 4/60, Loss: 1.1855, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 5/60, Loss: 1.1328, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 6/60, Loss: 1.0739, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 7/60, Loss: 1.2660, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 8/60, Loss: 1.0923, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 9/60, Loss: 0.8926, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 10/60, Loss: 1.0040, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 11/60, Loss: 1.1028, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 12/60, Loss: 1.1185, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 13/60, Loss: 0.9864, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 14/60, Loss: 1.2360, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 15/60, Loss: 0.9910, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 16/60, Loss: 1.2785, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 17/60, Loss: 1.1427, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 18/60, Loss: 0.9923, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 19/60, Loss: 0.8927, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 20/60, Loss: 1.3371, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 21/60, Loss: 1.3131, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 22/60, Loss: 1.0950, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 23/60, Loss: 1.2497, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 24/60, Loss: 1.3503, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 25/60, Loss: 0.9571, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 26/60, Loss: 1.0931, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 27/60, Loss: 1.2370, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 28/60, Loss: 1.0958, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 29/60, Loss: 1.1670, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 30/60, Loss: 1.0438, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 31/60, Loss: 1.0614, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 32/60, Loss: 1.0795, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 33/60, Loss: 1.0244, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 34/60, Loss: 1.1811, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 35/60, Loss: 1.0421, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 36/60, Loss: 1.1649, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 37/60, Loss: 1.1350, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 38/60, Loss: 0.9873, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 39/60, Loss: 1.0843, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 40/60, Loss: 1.1697, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 41/60, Loss: 1.1793, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 42/60, Loss: 1.3360, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 43/60, Loss: 1.2562, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 44/60, Loss: 1.2205, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 45/60, Loss: 1.1759, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 46/60, Loss: 0.9668, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 47/60, Loss: 1.0539, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 48/60, Loss: 1.0624, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 49/60, Loss: 1.0092, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 50/60, Loss: 1.1504, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 51/60, Loss: 1.1349, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 52/60, Loss: 1.1186, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 53/60, Loss: 1.0975, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 54/60, Loss: 1.1415, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 55/60, Loss: 1.0391, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 56/60, Loss: 1.0470, Time: 0.42 seconds\n",
            "Epoch 4/4, Batch 57/60, Loss: 1.0982, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 58/60, Loss: 1.1021, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 59/60, Loss: 1.3278, Time: 0.43 seconds\n",
            "Epoch 4/4, Batch 60/60, Loss: 0.9773, Time: 0.42 seconds\n",
            "Epoch 4/4, Training Loss: 1.1167, Time: 25.52 seconds\n",
            "Validation Loss: 1.1072, Accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvCNJg7ZBNSE"
      },
      "source": [
        "## Using trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgy_IXcM8q7V",
        "outputId": "a6b7e1e1-c6cc-4822-a3f7-79bb5b2343d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Load the trained model\n",
        "# model_path = \"./trained_models/Batch_8_BERT_Base_acc75\"\n",
        "# model_path = \"./trained_models/UsedClassWeights\"\n",
        "# model_path = \"./trained_models/old_way\"\n",
        "model_path = \"./trained_models/semi_supervised/third_semi_unbalanced\"\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf_HUkzBBlXk"
      },
      "source": [
        "### PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMJavoQJBQkm",
        "outputId": "ac2a34e4-c498-4138-9e29-a79fec52b481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 2, Confidence: 0.6677\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "def predict(text, model, tokenizer, device):\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n",
        "    outputs = model(**inputs)\n",
        "    probs = outputs.logits.softmax(dim=1)\n",
        "    predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs[0][predicted_class].item()\n",
        "\n",
        "# Example usage\n",
        "# text_to_predict = \"Your input text here.\"\n",
        "text_to_predict = pseudo_labeled['LogContent'][3000]\n",
        "predicted_class, confidence = predict(text_to_predict, loaded_model, tokenizer, device)\n",
        "print(f\"Predicted Class: {predicted_class}, Confidence: {confidence:.4f}\")\n",
        "\n",
        "print(pseudo_labeled['labels'][3000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekT6u37-Bo94",
        "outputId": "0196e974-b9dc-47e6-b3ef-d66dfa452cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-33f4ade4f096>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.58      0.73       177\n",
            "           1       0.63      0.48      0.55       156\n",
            "           2       0.80      0.94      0.87       640\n",
            "\n",
            "    accuracy                           0.80       973\n",
            "   macro avg       0.80      0.67      0.71       973\n",
            "weighted avg       0.81      0.80      0.79       973\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loaded_model.eval()\n",
        "# model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = loaded_model(input_ids, attention_mask=attention_mask)\n",
        "        # outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufugSJbzB_d7",
        "outputId": "d31af9c4-89f9-4cdc-b653-97716f083949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n",
            "   metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n",
            "   metrics2.impl.MetricsSystemImpl: MapTask metrics system started\n",
            "   mapred.YarnChild: Executing with tokens:\n",
            "   mapred.YarnChild: Kind: mapreduce.job, Service: job_1445144423722_0022, Ident: (mapreduce.security.token.JobTokenIdentifier@6ace4625)\n",
            "   mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\n",
            "   mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445144423722_0022\n",
            "   conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "   yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
            "   mapred.Task:  Using ResourceCalculatorProcessTree : yarn.util.WindowsBasedProcessTree@3c367995\n",
            "   mapred.MapTask: Processing split: hdfs://msra-sa-41:9000/pageinput2.txt:1207959552+48562176\n",
            "   mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "   mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "   mapred.MapTask: soft limit at 83886080\n",
            "   mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "   mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "   mapred.MapTask: Map output collector class = mapred.MapTask$MapOutputBuffer\n",
            "   mapred.MapTask: Spilling map output\n",
            "   mapred.MapTask: bufstart = 0; bufend = 48193401; bufvoid = 104857600\n",
            "   mapred.MapTask: kvstart = 26214396(104857584); kvend = 17291232(69164928); length = 8923165/6553600\n",
            "   mapred.MapTask: (EQUATOR) 57262153 kvi 14315532(57262128)\n",
            "  [SpillThread] mapred.MapTask: Finished spill 0\n",
            "   mapred.MapTask: (RESET) equator 57262153 kv 14315532(57262128) kvi 12120076(48480304)\n",
            "   mapred.MapTask: Spilling map output\n",
            "   mapred.MapTask: bufstart = 57262153; bufend = 658166; bufvoid = 104857600\n",
            "   mapred.MapTask: kvstart = 14315532(57262128); kvend = 5407424(21629696); length = 8908109/6553600\n",
            "   mapred.MapTask: (EQUATOR) 9726918 kvi 2431724(9726896)\n",
            "  [SpillThread] mapred.MapTask: Finished spill 1\n",
            "   mapred.MapTask: (RESET) equator 9726918 kv 2431724(9726896) kvi 228516(914064)\n",
            "   mapred.MapTask: Starting flush of map output\n",
            "   mapred.MapTask: Spilling map output\n",
            "   mapred.MapTask: bufstart = 9726918; bufend = 49084664; bufvoid = 104857600\n",
            "   mapred.MapTask: kvstart = 2431724(9726896); kvend = 21376588(85506352); length = 7269537/6553600\n",
            "   mapred.MapTask: Finished spill 2\n",
            "   mapred.Merger: Merging 3 sorted segments\n",
            "   mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 105653983 bytes\n",
            "   mapred.Task: Task:attempt_1445144423722_0022_m_000009_0 is done. And is in the process of committing\n",
            "   mapred.Task: Task 'attempt_1445144423722_0022_m_000009_0' done.\n",
            "   metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\n",
            "   metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\n",
            "   metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming df is your DataFrame\n",
        "logs_with_label_0 = df[df['labels'] == 0]\n",
        "\n",
        "# Display LogContents where label is 0\n",
        "print(logs_with_label_0['LogContent'][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi Supervised"
      ],
      "metadata": {
        "id": "pdgkqJx55Zxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4BmlbjZ5aoP"
      },
      "outputs": [],
      "source": [
        "chunked = pd.read_csv('forClassify_2.csv')\n",
        "original = pd.read_csv('forClassify_1.csv')\n",
        "# df.columns\n",
        "del original['Unnamed: 0.2']\n",
        "del original['Unnamed: 0.1']\n",
        "del original['Unnamed: 0']\n",
        "del original['tokens']\n",
        "del original['FileName']\n",
        "del chunked['token_numbers']\n",
        "del chunked['Unnamed: 0']\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6kyzXZwMzwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cb482c08-bddc-49eb-b331-3d3f1cd20912"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent             RootCause  \\\n",
              "0     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection   \n",
              "1     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  NetworkDisconnection   \n",
              "2     MapTask: (EQUATOR) 9726918\\n\\nkvi 2431724(9726...  NetworkDisconnection   \n",
              "3     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection   \n",
              "4     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  NetworkDisconnection   \n",
              "...                                                 ...                   ...   \n",
              "5517     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "5518     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "5519     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "5520     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "5521     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "      labels  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "5517       2  \n",
              "5518       2  \n",
              "5519       2  \n",
              "5520       2  \n",
              "5521       2  \n",
              "\n",
              "[5522 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c519df24-e2e7-443f-83d6-b2fc5cca7d11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MapTask: (EQUATOR) 9726918\\n\\nkvi 2431724(9726...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5517</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5518</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5519</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5520</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5521</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5522 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c519df24-e2e7-443f-83d6-b2fc5cca7d11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c519df24-e2e7-443f-83d6-b2fc5cca7d11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c519df24-e2e7-443f-83d6-b2fc5cca7d11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-009bef4b-ec98-4bf0-9797-7a866a14f158\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-009bef4b-ec98-4bf0-9797-7a866a14f158')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-009bef4b-ec98-4bf0-9797-7a866a14f158 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e95a3c11-133b-4cdd-83ef-8d3920fee6ab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e95a3c11-133b-4cdd-83ef-8d3920fee6ab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.concat([chunked, original], ignore_index=True)\n",
        "labels = df['RootCause'].unique().tolist()\n",
        "labels = [s.strip() for s in labels ]\n",
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}\n",
        "df[\"labels\"]=df.RootCause.map(lambda x: label2id[x.strip()])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into labeled and unlabeled datasets (80-20 split)\n",
        "labeled, unlabeled = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
        "labeled = labeled.reset_index(drop=True)\n",
        "unlabeled = unlabeled.reset_index(drop=True)\n",
        "labeled['labels'].value_counts()\n",
        "# labeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SDEJlexR8AH",
        "outputId": "ae2bf2ff-2cd5-47d1-de6b-4ab0c8148338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2938\n",
              "0     775\n",
              "1     704\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_dataset = CustomDataset(texts=list(labeled['LogContent']), labels=labeled['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader for labeled dataset\n",
        "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "-alTFAmA53f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCRCPmeo8ndV",
        "outputId": "9813b945-56d5-4473-9caa-c57c97433330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming labeled_train_dataloader is your DataLoader for labeled training data\n",
        "\n",
        "# Fine-tuning loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the labeled training DataLoader\n",
        "    for batch_idx, batch in enumerate(labeled_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        print(f\"Batch {batch_idx + 1}/{len(labeled_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(labeled_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(labeled_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMtzz9l98t2j",
        "outputId": "341b3f0d-1044-4806-b062-9d95ec5134f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-33f4ade4f096>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 1/277, Loss: 1.5977, Time: 1.40 seconds\n",
            "Batch 2/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 2/277, Loss: 1.0071, Time: 1.33 seconds\n",
            "Batch 3/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 3/277, Loss: 0.9736, Time: 1.35 seconds\n",
            "Batch 4/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 4/277, Loss: 0.9710, Time: 1.35 seconds\n",
            "Batch 5/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 5/277, Loss: 0.8982, Time: 1.35 seconds\n",
            "Batch 6/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 6/277, Loss: 1.1257, Time: 1.35 seconds\n",
            "Batch 7/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 1/2, Batch 7/277, Loss: 0.7823, Time: 1.35 seconds\n",
            "Batch 8/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/2, Batch 8/277, Loss: 0.9698, Time: 1.35 seconds\n",
            "Batch 9/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 9/277, Loss: 0.9372, Time: 1.35 seconds\n",
            "Batch 10/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 10/277, Loss: 0.9957, Time: 1.35 seconds\n",
            "Batch 11/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 11/277, Loss: 0.9899, Time: 1.36 seconds\n",
            "Batch 12/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 12/277, Loss: 0.8504, Time: 1.36 seconds\n",
            "Batch 13/277, Label Counts: {1: 5, 2: 11}\n",
            "Epoch 1/2, Batch 13/277, Loss: 0.9087, Time: 1.36 seconds\n",
            "Batch 14/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 14/277, Loss: 0.7605, Time: 1.36 seconds\n",
            "Batch 15/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 15/277, Loss: 0.8564, Time: 1.37 seconds\n",
            "Batch 16/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 16/277, Loss: 0.6572, Time: 1.36 seconds\n",
            "Batch 17/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 17/277, Loss: 0.7296, Time: 1.37 seconds\n",
            "Batch 18/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 18/277, Loss: 0.7532, Time: 1.38 seconds\n",
            "Batch 19/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 19/277, Loss: 0.4841, Time: 1.37 seconds\n",
            "Batch 20/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 20/277, Loss: 0.4652, Time: 1.37 seconds\n",
            "Batch 21/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 21/277, Loss: 0.7083, Time: 1.37 seconds\n",
            "Batch 22/277, Label Counts: {2: 16}\n",
            "Epoch 1/2, Batch 22/277, Loss: 0.3426, Time: 1.39 seconds\n",
            "Batch 23/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/2, Batch 23/277, Loss: 1.2730, Time: 1.38 seconds\n",
            "Batch 24/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/2, Batch 24/277, Loss: 1.1833, Time: 1.39 seconds\n",
            "Batch 25/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 25/277, Loss: 0.7540, Time: 1.40 seconds\n",
            "Batch 26/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 26/277, Loss: 0.7620, Time: 1.39 seconds\n",
            "Batch 27/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 27/277, Loss: 1.0052, Time: 1.39 seconds\n",
            "Batch 28/277, Label Counts: {0: 1, 1: 6, 2: 9}\n",
            "Epoch 1/2, Batch 28/277, Loss: 0.9352, Time: 1.39 seconds\n",
            "Batch 29/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 29/277, Loss: 0.7830, Time: 1.40 seconds\n",
            "Batch 30/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 30/277, Loss: 0.7366, Time: 1.41 seconds\n",
            "Batch 31/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 31/277, Loss: 0.6089, Time: 1.41 seconds\n",
            "Batch 32/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 32/277, Loss: 0.8456, Time: 1.39 seconds\n",
            "Batch 33/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 33/277, Loss: 0.8539, Time: 1.41 seconds\n",
            "Batch 34/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 34/277, Loss: 0.9667, Time: 1.42 seconds\n",
            "Batch 35/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 35/277, Loss: 0.7857, Time: 1.40 seconds\n",
            "Batch 36/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 36/277, Loss: 0.8572, Time: 1.40 seconds\n",
            "Batch 37/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/2, Batch 37/277, Loss: 1.2739, Time: 1.39 seconds\n",
            "Batch 38/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 38/277, Loss: 0.9085, Time: 1.40 seconds\n",
            "Batch 39/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 39/277, Loss: 0.7588, Time: 1.40 seconds\n",
            "Batch 40/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 40/277, Loss: 0.6373, Time: 1.42 seconds\n",
            "Batch 41/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/2, Batch 41/277, Loss: 1.0662, Time: 1.41 seconds\n",
            "Batch 42/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 42/277, Loss: 0.7649, Time: 1.42 seconds\n",
            "Batch 43/277, Label Counts: {1: 1, 2: 15}\n",
            "Epoch 1/2, Batch 43/277, Loss: 0.5236, Time: 1.41 seconds\n",
            "Batch 44/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 44/277, Loss: 0.6674, Time: 1.42 seconds\n",
            "Batch 45/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 45/277, Loss: 0.7513, Time: 1.42 seconds\n",
            "Batch 46/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 46/277, Loss: 0.6493, Time: 1.43 seconds\n",
            "Batch 47/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 47/277, Loss: 1.1040, Time: 1.43 seconds\n",
            "Batch 48/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 48/277, Loss: 1.2246, Time: 1.43 seconds\n",
            "Batch 49/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 49/277, Loss: 1.0125, Time: 1.43 seconds\n",
            "Batch 50/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 50/277, Loss: 0.7362, Time: 1.43 seconds\n",
            "Batch 51/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 51/277, Loss: 0.8267, Time: 1.43 seconds\n",
            "Batch 52/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 52/277, Loss: 0.7708, Time: 1.43 seconds\n",
            "Batch 53/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 53/277, Loss: 0.8806, Time: 1.44 seconds\n",
            "Batch 54/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 54/277, Loss: 0.9247, Time: 1.44 seconds\n",
            "Batch 55/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 55/277, Loss: 0.9460, Time: 1.44 seconds\n",
            "Batch 56/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 56/277, Loss: 0.8514, Time: 1.44 seconds\n",
            "Batch 57/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 57/277, Loss: 0.9159, Time: 1.45 seconds\n",
            "Batch 58/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 58/277, Loss: 0.9442, Time: 1.45 seconds\n",
            "Batch 59/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 59/277, Loss: 1.0087, Time: 1.44 seconds\n",
            "Batch 60/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 60/277, Loss: 1.0065, Time: 1.45 seconds\n",
            "Batch 61/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 61/277, Loss: 0.9026, Time: 1.45 seconds\n",
            "Batch 62/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 62/277, Loss: 0.9140, Time: 1.46 seconds\n",
            "Batch 63/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 1/2, Batch 63/277, Loss: 0.7573, Time: 1.47 seconds\n",
            "Batch 64/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 64/277, Loss: 0.9730, Time: 1.47 seconds\n",
            "Batch 65/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 65/277, Loss: 0.8922, Time: 1.47 seconds\n",
            "Batch 66/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 66/277, Loss: 0.8627, Time: 1.49 seconds\n",
            "Batch 67/277, Label Counts: {2: 16}\n",
            "Epoch 1/2, Batch 67/277, Loss: 0.5028, Time: 1.50 seconds\n",
            "Batch 68/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 68/277, Loss: 0.8437, Time: 1.50 seconds\n",
            "Batch 69/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 69/277, Loss: 0.7386, Time: 1.50 seconds\n",
            "Batch 70/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 70/277, Loss: 0.8555, Time: 1.53 seconds\n",
            "Batch 71/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 71/277, Loss: 1.0656, Time: 1.49 seconds\n",
            "Batch 72/277, Label Counts: {1: 4, 2: 12}\n",
            "Epoch 1/2, Batch 72/277, Loss: 0.8052, Time: 1.50 seconds\n",
            "Batch 73/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 73/277, Loss: 0.8864, Time: 1.49 seconds\n",
            "Batch 74/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 74/277, Loss: 0.9141, Time: 1.52 seconds\n",
            "Batch 75/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 75/277, Loss: 0.6437, Time: 1.52 seconds\n",
            "Batch 76/277, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/2, Batch 76/277, Loss: 1.2986, Time: 1.50 seconds\n",
            "Batch 77/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 77/277, Loss: 1.0924, Time: 1.53 seconds\n",
            "Batch 78/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 78/277, Loss: 0.8100, Time: 1.53 seconds\n",
            "Batch 79/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 79/277, Loss: 0.9379, Time: 1.56 seconds\n",
            "Batch 80/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 80/277, Loss: 0.6506, Time: 1.54 seconds\n",
            "Batch 81/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 81/277, Loss: 0.8449, Time: 1.56 seconds\n",
            "Batch 82/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 82/277, Loss: 0.6756, Time: 1.56 seconds\n",
            "Batch 83/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 83/277, Loss: 0.8961, Time: 1.59 seconds\n",
            "Batch 84/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 84/277, Loss: 0.9324, Time: 1.58 seconds\n",
            "Batch 85/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/2, Batch 85/277, Loss: 1.0741, Time: 1.58 seconds\n",
            "Batch 86/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 86/277, Loss: 1.0573, Time: 1.57 seconds\n",
            "Batch 87/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 87/277, Loss: 0.6561, Time: 1.59 seconds\n",
            "Batch 88/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 88/277, Loss: 0.7042, Time: 1.60 seconds\n",
            "Batch 89/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 89/277, Loss: 0.6697, Time: 1.60 seconds\n",
            "Batch 90/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 90/277, Loss: 1.0861, Time: 1.60 seconds\n",
            "Batch 91/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 91/277, Loss: 0.9151, Time: 1.60 seconds\n",
            "Batch 92/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 92/277, Loss: 0.8741, Time: 1.59 seconds\n",
            "Batch 93/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 93/277, Loss: 0.6301, Time: 1.59 seconds\n",
            "Batch 94/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 94/277, Loss: 0.8980, Time: 1.60 seconds\n",
            "Batch 95/277, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/2, Batch 95/277, Loss: 1.0972, Time: 1.59 seconds\n",
            "Batch 96/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 1/2, Batch 96/277, Loss: 0.6857, Time: 1.57 seconds\n",
            "Batch 97/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 97/277, Loss: 0.5388, Time: 1.55 seconds\n",
            "Batch 98/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/2, Batch 98/277, Loss: 1.1230, Time: 1.58 seconds\n",
            "Batch 99/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 99/277, Loss: 0.9502, Time: 1.56 seconds\n",
            "Batch 100/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 100/277, Loss: 0.7175, Time: 1.56 seconds\n",
            "Batch 101/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 101/277, Loss: 0.7505, Time: 1.53 seconds\n",
            "Batch 102/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 102/277, Loss: 0.9304, Time: 1.55 seconds\n",
            "Batch 103/277, Label Counts: {0: 1, 1: 6, 2: 9}\n",
            "Epoch 1/2, Batch 103/277, Loss: 1.0099, Time: 1.54 seconds\n",
            "Batch 104/277, Label Counts: {1: 2, 2: 14}\n",
            "Epoch 1/2, Batch 104/277, Loss: 0.5935, Time: 1.55 seconds\n",
            "Batch 105/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 105/277, Loss: 1.0101, Time: 1.52 seconds\n",
            "Batch 106/277, Label Counts: {0: 7, 2: 9}\n",
            "Epoch 1/2, Batch 106/277, Loss: 1.0010, Time: 1.53 seconds\n",
            "Batch 107/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 107/277, Loss: 0.7894, Time: 1.53 seconds\n",
            "Batch 108/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 108/277, Loss: 1.0239, Time: 1.52 seconds\n",
            "Batch 109/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 109/277, Loss: 0.7452, Time: 1.53 seconds\n",
            "Batch 110/277, Label Counts: {0: 2, 2: 14}\n",
            "Epoch 1/2, Batch 110/277, Loss: 0.5826, Time: 1.53 seconds\n",
            "Batch 111/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 111/277, Loss: 0.7771, Time: 1.51 seconds\n",
            "Batch 112/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 112/277, Loss: 0.9506, Time: 1.52 seconds\n",
            "Batch 113/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 113/277, Loss: 0.9033, Time: 1.49 seconds\n",
            "Batch 114/277, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/2, Batch 114/277, Loss: 1.2379, Time: 1.50 seconds\n",
            "Batch 115/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 115/277, Loss: 0.7210, Time: 1.51 seconds\n",
            "Batch 116/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 116/277, Loss: 0.6875, Time: 1.50 seconds\n",
            "Batch 117/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 117/277, Loss: 0.7990, Time: 1.50 seconds\n",
            "Batch 118/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 118/277, Loss: 0.7131, Time: 1.51 seconds\n",
            "Batch 119/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 119/277, Loss: 0.7914, Time: 1.51 seconds\n",
            "Batch 120/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 1/2, Batch 120/277, Loss: 0.8014, Time: 1.52 seconds\n",
            "Batch 121/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 121/277, Loss: 0.7833, Time: 1.49 seconds\n",
            "Batch 122/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 122/277, Loss: 1.1438, Time: 1.52 seconds\n",
            "Batch 123/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 123/277, Loss: 0.6947, Time: 1.51 seconds\n",
            "Batch 124/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 124/277, Loss: 0.7825, Time: 1.50 seconds\n",
            "Batch 125/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/2, Batch 125/277, Loss: 1.1070, Time: 1.53 seconds\n",
            "Batch 126/277, Label Counts: {0: 5, 2: 11}\n",
            "Epoch 1/2, Batch 126/277, Loss: 0.7990, Time: 1.53 seconds\n",
            "Batch 127/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 1/2, Batch 127/277, Loss: 0.8610, Time: 1.52 seconds\n",
            "Batch 128/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 128/277, Loss: 0.7290, Time: 1.54 seconds\n",
            "Batch 129/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 129/277, Loss: 0.7970, Time: 1.51 seconds\n",
            "Batch 130/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 130/277, Loss: 0.6972, Time: 1.53 seconds\n",
            "Batch 131/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 131/277, Loss: 0.4365, Time: 1.52 seconds\n",
            "Batch 132/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 132/277, Loss: 0.7598, Time: 1.53 seconds\n",
            "Batch 133/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 133/277, Loss: 0.8807, Time: 1.52 seconds\n",
            "Batch 134/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 134/277, Loss: 1.0199, Time: 1.53 seconds\n",
            "Batch 135/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 135/277, Loss: 1.0007, Time: 1.53 seconds\n",
            "Batch 136/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 136/277, Loss: 0.8250, Time: 1.54 seconds\n",
            "Batch 137/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/2, Batch 137/277, Loss: 1.0353, Time: 1.54 seconds\n",
            "Batch 138/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 138/277, Loss: 0.9742, Time: 1.54 seconds\n",
            "Batch 139/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 139/277, Loss: 0.8766, Time: 1.52 seconds\n",
            "Batch 140/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 140/277, Loss: 0.8059, Time: 1.55 seconds\n",
            "Batch 141/277, Label Counts: {0: 6, 2: 10}\n",
            "Epoch 1/2, Batch 141/277, Loss: 0.8349, Time: 1.55 seconds\n",
            "Batch 142/277, Label Counts: {1: 4, 2: 12}\n",
            "Epoch 1/2, Batch 142/277, Loss: 0.7528, Time: 1.56 seconds\n",
            "Batch 143/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 143/277, Loss: 0.8731, Time: 1.57 seconds\n",
            "Batch 144/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 144/277, Loss: 0.7097, Time: 1.55 seconds\n",
            "Batch 145/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 145/277, Loss: 0.7213, Time: 1.55 seconds\n",
            "Batch 146/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 146/277, Loss: 0.6010, Time: 1.55 seconds\n",
            "Batch 147/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 147/277, Loss: 0.9022, Time: 1.56 seconds\n",
            "Batch 148/277, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 1/2, Batch 148/277, Loss: 1.3649, Time: 1.53 seconds\n",
            "Batch 149/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/2, Batch 149/277, Loss: 1.2430, Time: 1.54 seconds\n",
            "Batch 150/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 150/277, Loss: 0.7798, Time: 1.55 seconds\n",
            "Batch 151/277, Label Counts: {1: 4, 2: 12}\n",
            "Epoch 1/2, Batch 151/277, Loss: 0.7255, Time: 1.56 seconds\n",
            "Batch 152/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/2, Batch 152/277, Loss: 0.9134, Time: 1.54 seconds\n",
            "Batch 153/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/2, Batch 153/277, Loss: 1.0219, Time: 1.55 seconds\n",
            "Batch 154/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 154/277, Loss: 0.7710, Time: 1.54 seconds\n",
            "Batch 155/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 155/277, Loss: 0.8118, Time: 1.54 seconds\n",
            "Batch 156/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 156/277, Loss: 0.7246, Time: 1.56 seconds\n",
            "Batch 157/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/2, Batch 157/277, Loss: 0.9374, Time: 1.54 seconds\n",
            "Batch 158/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 158/277, Loss: 0.7680, Time: 1.51 seconds\n",
            "Batch 159/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 159/277, Loss: 0.7137, Time: 1.55 seconds\n",
            "Batch 160/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 160/277, Loss: 0.4987, Time: 1.53 seconds\n",
            "Batch 161/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 161/277, Loss: 0.8144, Time: 1.53 seconds\n",
            "Batch 162/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 162/277, Loss: 0.7040, Time: 1.52 seconds\n",
            "Batch 163/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 163/277, Loss: 0.7039, Time: 1.55 seconds\n",
            "Batch 164/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 164/277, Loss: 0.6783, Time: 1.53 seconds\n",
            "Batch 165/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 165/277, Loss: 0.5121, Time: 1.53 seconds\n",
            "Batch 166/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 166/277, Loss: 0.5898, Time: 1.54 seconds\n",
            "Batch 167/277, Label Counts: {0: 5, 2: 11}\n",
            "Epoch 1/2, Batch 167/277, Loss: 0.8949, Time: 1.54 seconds\n",
            "Batch 168/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 168/277, Loss: 0.6530, Time: 1.54 seconds\n",
            "Batch 169/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 169/277, Loss: 0.8702, Time: 1.51 seconds\n",
            "Batch 170/277, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/2, Batch 170/277, Loss: 1.1634, Time: 1.54 seconds\n",
            "Batch 171/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/2, Batch 171/277, Loss: 1.0410, Time: 1.53 seconds\n",
            "Batch 172/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 172/277, Loss: 0.8755, Time: 1.53 seconds\n",
            "Batch 173/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/2, Batch 173/277, Loss: 1.0732, Time: 1.53 seconds\n",
            "Batch 174/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 174/277, Loss: 0.9890, Time: 1.52 seconds\n",
            "Batch 175/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 175/277, Loss: 0.7865, Time: 1.52 seconds\n",
            "Batch 176/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 176/277, Loss: 0.9901, Time: 1.53 seconds\n",
            "Batch 177/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 177/277, Loss: 0.7947, Time: 1.52 seconds\n",
            "Batch 178/277, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/2, Batch 178/277, Loss: 1.0501, Time: 1.53 seconds\n",
            "Batch 179/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 179/277, Loss: 0.5795, Time: 1.52 seconds\n",
            "Batch 180/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 180/277, Loss: 0.7323, Time: 1.51 seconds\n",
            "Batch 181/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/2, Batch 181/277, Loss: 1.0486, Time: 1.52 seconds\n",
            "Batch 182/277, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/2, Batch 182/277, Loss: 1.0505, Time: 1.54 seconds\n",
            "Batch 183/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 183/277, Loss: 0.5343, Time: 1.52 seconds\n",
            "Batch 184/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 184/277, Loss: 0.7984, Time: 1.55 seconds\n",
            "Batch 185/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 185/277, Loss: 0.6587, Time: 1.55 seconds\n",
            "Batch 186/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 186/277, Loss: 0.6627, Time: 1.53 seconds\n",
            "Batch 187/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 187/277, Loss: 0.7775, Time: 1.52 seconds\n",
            "Batch 188/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 188/277, Loss: 0.5284, Time: 1.55 seconds\n",
            "Batch 189/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 189/277, Loss: 0.6168, Time: 1.51 seconds\n",
            "Batch 190/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 190/277, Loss: 0.5625, Time: 1.54 seconds\n",
            "Batch 191/277, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 1/2, Batch 191/277, Loss: 0.9292, Time: 1.51 seconds\n",
            "Batch 192/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 192/277, Loss: 0.4619, Time: 1.53 seconds\n",
            "Batch 193/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/2, Batch 193/277, Loss: 1.1040, Time: 1.53 seconds\n",
            "Batch 194/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 194/277, Loss: 0.7002, Time: 1.54 seconds\n",
            "Batch 195/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 195/277, Loss: 0.8123, Time: 1.56 seconds\n",
            "Batch 196/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 196/277, Loss: 0.4288, Time: 1.54 seconds\n",
            "Batch 197/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 197/277, Loss: 0.8773, Time: 1.52 seconds\n",
            "Batch 198/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 198/277, Loss: 0.4986, Time: 1.54 seconds\n",
            "Batch 199/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 199/277, Loss: 0.8398, Time: 1.51 seconds\n",
            "Batch 200/277, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/2, Batch 200/277, Loss: 1.0835, Time: 1.54 seconds\n",
            "Batch 201/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 201/277, Loss: 0.7812, Time: 1.53 seconds\n",
            "Batch 202/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 202/277, Loss: 0.5804, Time: 1.52 seconds\n",
            "Batch 203/277, Label Counts: {0: 1, 2: 15}\n",
            "Epoch 1/2, Batch 203/277, Loss: 0.3708, Time: 1.55 seconds\n",
            "Batch 204/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 204/277, Loss: 0.8630, Time: 1.53 seconds\n",
            "Batch 205/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 205/277, Loss: 0.5878, Time: 1.54 seconds\n",
            "Batch 206/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 206/277, Loss: 0.4510, Time: 1.54 seconds\n",
            "Batch 207/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/2, Batch 207/277, Loss: 0.8613, Time: 1.53 seconds\n",
            "Batch 208/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 208/277, Loss: 0.5744, Time: 1.53 seconds\n",
            "Batch 209/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 209/277, Loss: 0.5461, Time: 1.54 seconds\n",
            "Batch 210/277, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/2, Batch 210/277, Loss: 0.9711, Time: 1.55 seconds\n",
            "Batch 211/277, Label Counts: {0: 6, 1: 1, 2: 9}\n",
            "Epoch 1/2, Batch 211/277, Loss: 0.5722, Time: 1.53 seconds\n",
            "Batch 212/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 212/277, Loss: 0.6616, Time: 1.55 seconds\n",
            "Batch 213/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/2, Batch 213/277, Loss: 0.6906, Time: 1.55 seconds\n",
            "Batch 214/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 214/277, Loss: 0.4515, Time: 1.53 seconds\n",
            "Batch 215/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 215/277, Loss: 0.6289, Time: 1.54 seconds\n",
            "Batch 216/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 216/277, Loss: 0.5827, Time: 1.54 seconds\n",
            "Batch 217/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 217/277, Loss: 0.3905, Time: 1.55 seconds\n",
            "Batch 218/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 218/277, Loss: 0.8614, Time: 1.54 seconds\n",
            "Batch 219/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 219/277, Loss: 0.6816, Time: 1.54 seconds\n",
            "Batch 220/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 220/277, Loss: 0.4921, Time: 1.53 seconds\n",
            "Batch 221/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 1/2, Batch 221/277, Loss: 0.5141, Time: 1.55 seconds\n",
            "Batch 222/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/2, Batch 222/277, Loss: 0.6905, Time: 1.54 seconds\n",
            "Batch 223/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 223/277, Loss: 0.6276, Time: 1.55 seconds\n",
            "Batch 224/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/2, Batch 224/277, Loss: 0.6528, Time: 1.53 seconds\n",
            "Batch 225/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/2, Batch 225/277, Loss: 0.9444, Time: 1.54 seconds\n",
            "Batch 226/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 226/277, Loss: 0.5000, Time: 1.54 seconds\n",
            "Batch 227/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 1/2, Batch 227/277, Loss: 0.4727, Time: 1.55 seconds\n",
            "Batch 228/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 228/277, Loss: 0.6788, Time: 1.54 seconds\n",
            "Batch 229/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/2, Batch 229/277, Loss: 0.6252, Time: 1.54 seconds\n",
            "Batch 230/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 230/277, Loss: 0.5529, Time: 1.55 seconds\n",
            "Batch 231/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 231/277, Loss: 0.6953, Time: 1.53 seconds\n",
            "Batch 232/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 232/277, Loss: 0.4639, Time: 1.55 seconds\n",
            "Batch 233/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 233/277, Loss: 0.3804, Time: 1.54 seconds\n",
            "Batch 234/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 234/277, Loss: 0.3035, Time: 1.55 seconds\n",
            "Batch 235/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 235/277, Loss: 0.4738, Time: 1.54 seconds\n",
            "Batch 236/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 236/277, Loss: 0.3565, Time: 1.55 seconds\n",
            "Batch 237/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 237/277, Loss: 0.3862, Time: 1.52 seconds\n",
            "Batch 238/277, Label Counts: {0: 6, 2: 10}\n",
            "Epoch 1/2, Batch 238/277, Loss: 0.7285, Time: 1.54 seconds\n",
            "Batch 239/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 239/277, Loss: 0.5557, Time: 1.55 seconds\n",
            "Batch 240/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 240/277, Loss: 0.4367, Time: 1.52 seconds\n",
            "Batch 241/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 241/277, Loss: 0.5944, Time: 1.52 seconds\n",
            "Batch 242/277, Label Counts: {1: 1, 2: 15}\n",
            "Epoch 1/2, Batch 242/277, Loss: 0.1894, Time: 1.53 seconds\n",
            "Batch 243/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 243/277, Loss: 0.7673, Time: 1.53 seconds\n",
            "Batch 244/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 1/2, Batch 244/277, Loss: 0.3119, Time: 1.53 seconds\n",
            "Batch 245/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 1/2, Batch 245/277, Loss: 0.2357, Time: 1.54 seconds\n",
            "Batch 246/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 246/277, Loss: 0.4416, Time: 1.53 seconds\n",
            "Batch 247/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/2, Batch 247/277, Loss: 0.4222, Time: 1.55 seconds\n",
            "Batch 248/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 248/277, Loss: 0.5179, Time: 1.55 seconds\n",
            "Batch 249/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 1/2, Batch 249/277, Loss: 0.6293, Time: 1.53 seconds\n",
            "Batch 250/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/2, Batch 250/277, Loss: 0.8023, Time: 1.54 seconds\n",
            "Batch 251/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/2, Batch 251/277, Loss: 1.0188, Time: 1.54 seconds\n",
            "Batch 252/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 252/277, Loss: 0.8316, Time: 1.55 seconds\n",
            "Batch 253/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/2, Batch 253/277, Loss: 0.7966, Time: 1.56 seconds\n",
            "Batch 254/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 254/277, Loss: 0.5968, Time: 1.54 seconds\n",
            "Batch 255/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 1/2, Batch 255/277, Loss: 0.5682, Time: 1.54 seconds\n",
            "Batch 256/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/2, Batch 256/277, Loss: 0.4546, Time: 1.56 seconds\n",
            "Batch 257/277, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/2, Batch 257/277, Loss: 0.7957, Time: 1.54 seconds\n",
            "Batch 258/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/2, Batch 258/277, Loss: 0.5142, Time: 1.54 seconds\n",
            "Batch 259/277, Label Counts: {1: 2, 2: 14}\n",
            "Epoch 1/2, Batch 259/277, Loss: 0.3103, Time: 1.54 seconds\n",
            "Batch 260/277, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 1/2, Batch 260/277, Loss: 0.5049, Time: 1.52 seconds\n",
            "Batch 261/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/2, Batch 261/277, Loss: 0.5554, Time: 1.55 seconds\n",
            "Batch 262/277, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/2, Batch 262/277, Loss: 0.6684, Time: 1.54 seconds\n",
            "Batch 263/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 263/277, Loss: 0.7401, Time: 1.56 seconds\n",
            "Batch 264/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 264/277, Loss: 0.3671, Time: 1.54 seconds\n",
            "Batch 265/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/2, Batch 265/277, Loss: 0.3526, Time: 1.53 seconds\n",
            "Batch 266/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 1/2, Batch 266/277, Loss: 0.7310, Time: 1.56 seconds\n",
            "Batch 267/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/2, Batch 267/277, Loss: 0.5778, Time: 1.54 seconds\n",
            "Batch 268/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 268/277, Loss: 0.4367, Time: 1.53 seconds\n",
            "Batch 269/277, Label Counts: {1: 4, 2: 12}\n",
            "Epoch 1/2, Batch 269/277, Loss: 0.4899, Time: 1.54 seconds\n",
            "Batch 270/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/2, Batch 270/277, Loss: 0.6665, Time: 1.55 seconds\n",
            "Batch 271/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 1/2, Batch 271/277, Loss: 0.3465, Time: 1.54 seconds\n",
            "Batch 272/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 1/2, Batch 272/277, Loss: 0.6179, Time: 1.52 seconds\n",
            "Batch 273/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 1/2, Batch 273/277, Loss: 0.3128, Time: 1.55 seconds\n",
            "Batch 274/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 1/2, Batch 274/277, Loss: 0.5592, Time: 1.54 seconds\n",
            "Batch 275/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/2, Batch 275/277, Loss: 0.9050, Time: 1.53 seconds\n",
            "Batch 276/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/2, Batch 276/277, Loss: 0.3492, Time: 1.55 seconds\n",
            "Batch 277/277, Label Counts: {2: 1}\n",
            "Epoch 1/2, Batch 277/277, Loss: 0.0079, Time: 0.13 seconds\n",
            "Epoch 1/2, Training Loss: 0.7662, Time: 416.39 seconds\n",
            "Batch 1/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 1/277, Loss: 0.6315, Time: 1.54 seconds\n",
            "Batch 2/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/2, Batch 2/277, Loss: 0.6297, Time: 1.56 seconds\n",
            "Batch 3/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 3/277, Loss: 0.4941, Time: 1.53 seconds\n",
            "Batch 4/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 4/277, Loss: 0.2943, Time: 1.55 seconds\n",
            "Batch 5/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/2, Batch 5/277, Loss: 0.5202, Time: 1.53 seconds\n",
            "Batch 6/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 6/277, Loss: 0.6020, Time: 1.53 seconds\n",
            "Batch 7/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 7/277, Loss: 0.2609, Time: 1.53 seconds\n",
            "Batch 8/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 8/277, Loss: 0.7933, Time: 1.55 seconds\n",
            "Batch 9/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 9/277, Loss: 0.3572, Time: 1.54 seconds\n",
            "Batch 10/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 10/277, Loss: 0.3510, Time: 1.55 seconds\n",
            "Batch 11/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 11/277, Loss: 0.3356, Time: 1.52 seconds\n",
            "Batch 12/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 12/277, Loss: 0.6342, Time: 1.53 seconds\n",
            "Batch 13/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 13/277, Loss: 0.5423, Time: 1.53 seconds\n",
            "Batch 14/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 14/277, Loss: 0.1837, Time: 1.53 seconds\n",
            "Batch 15/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 15/277, Loss: 0.8751, Time: 1.56 seconds\n",
            "Batch 16/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 16/277, Loss: 0.5262, Time: 1.55 seconds\n",
            "Batch 17/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 17/277, Loss: 0.5600, Time: 1.53 seconds\n",
            "Batch 18/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 2/2, Batch 18/277, Loss: 0.4103, Time: 1.52 seconds\n",
            "Batch 19/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 19/277, Loss: 0.5897, Time: 1.54 seconds\n",
            "Batch 20/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 20/277, Loss: 0.6871, Time: 1.52 seconds\n",
            "Batch 21/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 21/277, Loss: 0.3769, Time: 1.53 seconds\n",
            "Batch 22/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 22/277, Loss: 0.5513, Time: 1.55 seconds\n",
            "Batch 23/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 23/277, Loss: 0.6453, Time: 1.54 seconds\n",
            "Batch 24/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 24/277, Loss: 0.5683, Time: 1.55 seconds\n",
            "Batch 25/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 25/277, Loss: 0.4762, Time: 1.54 seconds\n",
            "Batch 26/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 2/2, Batch 26/277, Loss: 0.3634, Time: 1.54 seconds\n",
            "Batch 27/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 27/277, Loss: 0.6139, Time: 1.54 seconds\n",
            "Batch 28/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 28/277, Loss: 0.7322, Time: 1.54 seconds\n",
            "Batch 29/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/2, Batch 29/277, Loss: 0.5041, Time: 1.51 seconds\n",
            "Batch 30/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 30/277, Loss: 0.9547, Time: 1.54 seconds\n",
            "Batch 31/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 31/277, Loss: 0.5002, Time: 1.53 seconds\n",
            "Batch 32/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 32/277, Loss: 0.2742, Time: 1.53 seconds\n",
            "Batch 33/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 33/277, Loss: 0.4135, Time: 1.55 seconds\n",
            "Batch 34/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 2/2, Batch 34/277, Loss: 0.2180, Time: 1.52 seconds\n",
            "Batch 35/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 35/277, Loss: 0.5509, Time: 1.52 seconds\n",
            "Batch 36/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 36/277, Loss: 0.5398, Time: 1.55 seconds\n",
            "Batch 37/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 37/277, Loss: 0.5000, Time: 1.53 seconds\n",
            "Batch 38/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/2, Batch 38/277, Loss: 0.5421, Time: 1.53 seconds\n",
            "Batch 39/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 39/277, Loss: 0.6529, Time: 1.54 seconds\n",
            "Batch 40/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 40/277, Loss: 0.7968, Time: 1.54 seconds\n",
            "Batch 41/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 41/277, Loss: 0.4561, Time: 1.54 seconds\n",
            "Batch 42/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 42/277, Loss: 0.4672, Time: 1.52 seconds\n",
            "Batch 43/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 43/277, Loss: 0.7012, Time: 1.53 seconds\n",
            "Batch 44/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 44/277, Loss: 0.5422, Time: 1.54 seconds\n",
            "Batch 45/277, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/2, Batch 45/277, Loss: 0.3451, Time: 1.51 seconds\n",
            "Batch 46/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 46/277, Loss: 0.4043, Time: 1.54 seconds\n",
            "Batch 47/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 47/277, Loss: 0.8898, Time: 1.53 seconds\n",
            "Batch 48/277, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 2/2, Batch 48/277, Loss: 0.3788, Time: 1.52 seconds\n",
            "Batch 49/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 49/277, Loss: 0.2761, Time: 1.52 seconds\n",
            "Batch 50/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 50/277, Loss: 0.6232, Time: 1.53 seconds\n",
            "Batch 51/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 51/277, Loss: 0.5713, Time: 1.56 seconds\n",
            "Batch 52/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 52/277, Loss: 0.5769, Time: 1.52 seconds\n",
            "Batch 53/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 53/277, Loss: 0.3657, Time: 1.54 seconds\n",
            "Batch 54/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 54/277, Loss: 0.4876, Time: 1.54 seconds\n",
            "Batch 55/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/2, Batch 55/277, Loss: 0.5349, Time: 1.54 seconds\n",
            "Batch 56/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 56/277, Loss: 0.8358, Time: 1.53 seconds\n",
            "Batch 57/277, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 2/2, Batch 57/277, Loss: 0.4378, Time: 1.55 seconds\n",
            "Batch 58/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 58/277, Loss: 0.3361, Time: 1.50 seconds\n",
            "Batch 59/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 59/277, Loss: 0.5393, Time: 1.54 seconds\n",
            "Batch 60/277, Label Counts: {0: 6, 2: 10}\n",
            "Epoch 2/2, Batch 60/277, Loss: 0.5785, Time: 1.55 seconds\n",
            "Batch 61/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 61/277, Loss: 0.9418, Time: 1.53 seconds\n",
            "Batch 62/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 62/277, Loss: 0.5623, Time: 1.54 seconds\n",
            "Batch 63/277, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/2, Batch 63/277, Loss: 0.5657, Time: 1.53 seconds\n",
            "Batch 64/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 64/277, Loss: 1.0731, Time: 1.55 seconds\n",
            "Batch 65/277, Label Counts: {1: 5, 2: 11}\n",
            "Epoch 2/2, Batch 65/277, Loss: 0.5254, Time: 1.54 seconds\n",
            "Batch 66/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 66/277, Loss: 0.4854, Time: 1.54 seconds\n",
            "Batch 67/277, Label Counts: {1: 2, 2: 14}\n",
            "Epoch 2/2, Batch 67/277, Loss: 0.3717, Time: 1.52 seconds\n",
            "Batch 68/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 68/277, Loss: 0.4736, Time: 1.55 seconds\n",
            "Batch 69/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 69/277, Loss: 0.3488, Time: 1.52 seconds\n",
            "Batch 70/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 70/277, Loss: 0.2749, Time: 1.53 seconds\n",
            "Batch 71/277, Label Counts: {0: 6, 1: 1, 2: 9}\n",
            "Epoch 2/2, Batch 71/277, Loss: 0.3720, Time: 1.53 seconds\n",
            "Batch 72/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 72/277, Loss: 0.4755, Time: 1.55 seconds\n",
            "Batch 73/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 73/277, Loss: 0.2431, Time: 1.52 seconds\n",
            "Batch 74/277, Label Counts: {1: 1, 2: 15}\n",
            "Epoch 2/2, Batch 74/277, Loss: 0.2618, Time: 1.55 seconds\n",
            "Batch 75/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/2, Batch 75/277, Loss: 0.6423, Time: 1.53 seconds\n",
            "Batch 76/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 76/277, Loss: 0.4119, Time: 1.52 seconds\n",
            "Batch 77/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 77/277, Loss: 0.5237, Time: 1.53 seconds\n",
            "Batch 78/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 78/277, Loss: 0.3696, Time: 1.53 seconds\n",
            "Batch 79/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 79/277, Loss: 0.5959, Time: 1.52 seconds\n",
            "Batch 80/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 80/277, Loss: 0.3548, Time: 1.53 seconds\n",
            "Batch 81/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 81/277, Loss: 0.2652, Time: 1.51 seconds\n",
            "Batch 82/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 82/277, Loss: 0.4882, Time: 1.55 seconds\n",
            "Batch 83/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 83/277, Loss: 0.4091, Time: 1.52 seconds\n",
            "Batch 84/277, Label Counts: {1: 2, 2: 14}\n",
            "Epoch 2/2, Batch 84/277, Loss: 0.1390, Time: 1.52 seconds\n",
            "Batch 85/277, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 2/2, Batch 85/277, Loss: 0.9756, Time: 1.53 seconds\n",
            "Batch 86/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/2, Batch 86/277, Loss: 0.6225, Time: 1.54 seconds\n",
            "Batch 87/277, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/2, Batch 87/277, Loss: 0.4124, Time: 1.52 seconds\n",
            "Batch 88/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 88/277, Loss: 0.5657, Time: 1.54 seconds\n",
            "Batch 89/277, Label Counts: {0: 1, 1: 7, 2: 8}\n",
            "Epoch 2/2, Batch 89/277, Loss: 0.6649, Time: 1.55 seconds\n",
            "Batch 90/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 90/277, Loss: 0.3522, Time: 1.52 seconds\n",
            "Batch 91/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 91/277, Loss: 0.6212, Time: 1.51 seconds\n",
            "Batch 92/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 92/277, Loss: 0.5152, Time: 1.55 seconds\n",
            "Batch 93/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/2, Batch 93/277, Loss: 0.4526, Time: 1.53 seconds\n",
            "Batch 94/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 94/277, Loss: 0.2913, Time: 1.52 seconds\n",
            "Batch 95/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 95/277, Loss: 0.7600, Time: 1.53 seconds\n",
            "Batch 96/277, Label Counts: {1: 2, 2: 14}\n",
            "Epoch 2/2, Batch 96/277, Loss: 0.2882, Time: 1.53 seconds\n",
            "Batch 97/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 97/277, Loss: 0.3115, Time: 1.52 seconds\n",
            "Batch 98/277, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 2/2, Batch 98/277, Loss: 0.4417, Time: 1.53 seconds\n",
            "Batch 99/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 99/277, Loss: 0.5226, Time: 1.54 seconds\n",
            "Batch 100/277, Label Counts: {0: 2, 2: 14}\n",
            "Epoch 2/2, Batch 100/277, Loss: 0.2743, Time: 1.54 seconds\n",
            "Batch 101/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 101/277, Loss: 0.4747, Time: 1.53 seconds\n",
            "Batch 102/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 102/277, Loss: 0.4267, Time: 1.53 seconds\n",
            "Batch 103/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 103/277, Loss: 0.6126, Time: 1.53 seconds\n",
            "Batch 104/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 104/277, Loss: 0.2649, Time: 1.52 seconds\n",
            "Batch 105/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 105/277, Loss: 0.4861, Time: 1.52 seconds\n",
            "Batch 106/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 106/277, Loss: 0.6100, Time: 1.54 seconds\n",
            "Batch 107/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 107/277, Loss: 0.3868, Time: 1.53 seconds\n",
            "Batch 108/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 108/277, Loss: 0.4265, Time: 1.51 seconds\n",
            "Batch 109/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 2/2, Batch 109/277, Loss: 0.6483, Time: 1.54 seconds\n",
            "Batch 110/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 110/277, Loss: 0.6362, Time: 1.53 seconds\n",
            "Batch 111/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 111/277, Loss: 0.4583, Time: 1.52 seconds\n",
            "Batch 112/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 112/277, Loss: 0.5858, Time: 1.54 seconds\n",
            "Batch 113/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 113/277, Loss: 0.4535, Time: 1.53 seconds\n",
            "Batch 114/277, Label Counts: {1: 5, 2: 11}\n",
            "Epoch 2/2, Batch 114/277, Loss: 0.4675, Time: 1.53 seconds\n",
            "Batch 115/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 115/277, Loss: 0.5471, Time: 1.54 seconds\n",
            "Batch 116/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 2/2, Batch 116/277, Loss: 0.6616, Time: 1.53 seconds\n",
            "Batch 117/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 117/277, Loss: 0.7765, Time: 1.54 seconds\n",
            "Batch 118/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 118/277, Loss: 0.4043, Time: 1.53 seconds\n",
            "Batch 119/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 119/277, Loss: 0.3771, Time: 1.55 seconds\n",
            "Batch 120/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 120/277, Loss: 0.4267, Time: 1.54 seconds\n",
            "Batch 121/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 121/277, Loss: 0.3673, Time: 1.54 seconds\n",
            "Batch 122/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 122/277, Loss: 0.6994, Time: 1.54 seconds\n",
            "Batch 123/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 123/277, Loss: 0.8010, Time: 1.52 seconds\n",
            "Batch 124/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 124/277, Loss: 0.3807, Time: 1.54 seconds\n",
            "Batch 125/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 125/277, Loss: 0.5725, Time: 1.53 seconds\n",
            "Batch 126/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 126/277, Loss: 0.3092, Time: 1.52 seconds\n",
            "Batch 127/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 127/277, Loss: 0.7287, Time: 1.54 seconds\n",
            "Batch 128/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 2/2, Batch 128/277, Loss: 0.3425, Time: 1.54 seconds\n",
            "Batch 129/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 129/277, Loss: 0.2972, Time: 1.54 seconds\n",
            "Batch 130/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 130/277, Loss: 0.1580, Time: 1.53 seconds\n",
            "Batch 131/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 131/277, Loss: 0.3296, Time: 1.52 seconds\n",
            "Batch 132/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 132/277, Loss: 0.5017, Time: 1.52 seconds\n",
            "Batch 133/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 133/277, Loss: 0.4971, Time: 1.53 seconds\n",
            "Batch 134/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/2, Batch 134/277, Loss: 0.9042, Time: 1.53 seconds\n",
            "Batch 135/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 135/277, Loss: 0.4619, Time: 1.55 seconds\n",
            "Batch 136/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 136/277, Loss: 0.5133, Time: 1.51 seconds\n",
            "Batch 137/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 137/277, Loss: 0.6686, Time: 1.53 seconds\n",
            "Batch 138/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 138/277, Loss: 0.4558, Time: 1.55 seconds\n",
            "Batch 139/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 2/2, Batch 139/277, Loss: 0.3511, Time: 1.55 seconds\n",
            "Batch 140/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 2/2, Batch 140/277, Loss: 0.3595, Time: 1.53 seconds\n",
            "Batch 141/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 141/277, Loss: 0.4005, Time: 1.52 seconds\n",
            "Batch 142/277, Label Counts: {1: 5, 2: 11}\n",
            "Epoch 2/2, Batch 142/277, Loss: 0.2587, Time: 1.55 seconds\n",
            "Batch 143/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/2, Batch 143/277, Loss: 0.5734, Time: 1.54 seconds\n",
            "Batch 144/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 144/277, Loss: 0.9257, Time: 1.54 seconds\n",
            "Batch 145/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 145/277, Loss: 0.1511, Time: 1.54 seconds\n",
            "Batch 146/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 146/277, Loss: 0.5036, Time: 1.51 seconds\n",
            "Batch 147/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 147/277, Loss: 0.4780, Time: 1.53 seconds\n",
            "Batch 148/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 148/277, Loss: 0.5929, Time: 1.53 seconds\n",
            "Batch 149/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 2/2, Batch 149/277, Loss: 0.3682, Time: 1.53 seconds\n",
            "Batch 150/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 150/277, Loss: 0.5551, Time: 1.53 seconds\n",
            "Batch 151/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 151/277, Loss: 0.4391, Time: 1.54 seconds\n",
            "Batch 152/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 152/277, Loss: 0.5506, Time: 1.53 seconds\n",
            "Batch 153/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 2/2, Batch 153/277, Loss: 0.5923, Time: 1.53 seconds\n",
            "Batch 154/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 154/277, Loss: 0.3397, Time: 1.54 seconds\n",
            "Batch 155/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/2, Batch 155/277, Loss: 0.6965, Time: 1.53 seconds\n",
            "Batch 156/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 156/277, Loss: 0.3611, Time: 1.53 seconds\n",
            "Batch 157/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 157/277, Loss: 0.4537, Time: 1.55 seconds\n",
            "Batch 158/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 158/277, Loss: 0.4483, Time: 1.53 seconds\n",
            "Batch 159/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 159/277, Loss: 0.4079, Time: 1.53 seconds\n",
            "Batch 160/277, Label Counts: {0: 5, 2: 11}\n",
            "Epoch 2/2, Batch 160/277, Loss: 0.4200, Time: 1.52 seconds\n",
            "Batch 161/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 161/277, Loss: 0.7159, Time: 1.55 seconds\n",
            "Batch 162/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 162/277, Loss: 0.4278, Time: 1.52 seconds\n",
            "Batch 163/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/2, Batch 163/277, Loss: 0.7478, Time: 1.54 seconds\n",
            "Batch 164/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 164/277, Loss: 0.3493, Time: 1.56 seconds\n",
            "Batch 165/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 165/277, Loss: 0.4409, Time: 1.53 seconds\n",
            "Batch 166/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 166/277, Loss: 0.4130, Time: 1.53 seconds\n",
            "Batch 167/277, Label Counts: {0: 2, 2: 14}\n",
            "Epoch 2/2, Batch 167/277, Loss: 0.1740, Time: 1.52 seconds\n",
            "Batch 168/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 168/277, Loss: 0.6214, Time: 1.52 seconds\n",
            "Batch 169/277, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/2, Batch 169/277, Loss: 0.3577, Time: 1.54 seconds\n",
            "Batch 170/277, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/2, Batch 170/277, Loss: 0.4598, Time: 1.54 seconds\n",
            "Batch 171/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 171/277, Loss: 0.6073, Time: 1.55 seconds\n",
            "Batch 172/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/2, Batch 172/277, Loss: 0.5279, Time: 1.53 seconds\n",
            "Batch 173/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 173/277, Loss: 0.8797, Time: 1.56 seconds\n",
            "Batch 174/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 174/277, Loss: 0.2763, Time: 1.52 seconds\n",
            "Batch 175/277, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/2, Batch 175/277, Loss: 0.8260, Time: 1.53 seconds\n",
            "Batch 176/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 176/277, Loss: 0.5779, Time: 1.54 seconds\n",
            "Batch 177/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 2/2, Batch 177/277, Loss: 0.4102, Time: 1.53 seconds\n",
            "Batch 178/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/2, Batch 178/277, Loss: 0.6477, Time: 1.54 seconds\n",
            "Batch 179/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 2/2, Batch 179/277, Loss: 0.5078, Time: 1.52 seconds\n",
            "Batch 180/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 180/277, Loss: 0.4323, Time: 1.53 seconds\n",
            "Batch 181/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 181/277, Loss: 0.5036, Time: 1.55 seconds\n",
            "Batch 182/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 182/277, Loss: 0.5877, Time: 1.55 seconds\n",
            "Batch 183/277, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 2/2, Batch 183/277, Loss: 0.5482, Time: 1.54 seconds\n",
            "Batch 184/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/2, Batch 184/277, Loss: 0.7131, Time: 1.53 seconds\n",
            "Batch 185/277, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 2/2, Batch 185/277, Loss: 0.7687, Time: 1.54 seconds\n",
            "Batch 186/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 186/277, Loss: 0.3788, Time: 1.54 seconds\n",
            "Batch 187/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 187/277, Loss: 0.3465, Time: 1.54 seconds\n",
            "Batch 188/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 188/277, Loss: 0.4975, Time: 1.54 seconds\n",
            "Batch 189/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 189/277, Loss: 0.4985, Time: 1.54 seconds\n",
            "Batch 190/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 190/277, Loss: 0.3366, Time: 1.53 seconds\n",
            "Batch 191/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 191/277, Loss: 0.5061, Time: 1.55 seconds\n",
            "Batch 192/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 192/277, Loss: 0.5045, Time: 1.52 seconds\n",
            "Batch 193/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 193/277, Loss: 0.3266, Time: 1.53 seconds\n",
            "Batch 194/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 194/277, Loss: 0.0947, Time: 1.55 seconds\n",
            "Batch 195/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 195/277, Loss: 0.3805, Time: 1.52 seconds\n",
            "Batch 196/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 196/277, Loss: 0.4170, Time: 1.53 seconds\n",
            "Batch 197/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 197/277, Loss: 0.3765, Time: 1.54 seconds\n",
            "Batch 198/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/2, Batch 198/277, Loss: 0.3400, Time: 1.53 seconds\n",
            "Batch 199/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 199/277, Loss: 0.2511, Time: 1.55 seconds\n",
            "Batch 200/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 200/277, Loss: 0.4337, Time: 1.53 seconds\n",
            "Batch 201/277, Label Counts: {0: 6, 1: 1, 2: 9}\n",
            "Epoch 2/2, Batch 201/277, Loss: 0.7178, Time: 1.53 seconds\n",
            "Batch 202/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 202/277, Loss: 0.3446, Time: 1.56 seconds\n",
            "Batch 203/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 203/277, Loss: 0.3905, Time: 1.53 seconds\n",
            "Batch 204/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 204/277, Loss: 0.6471, Time: 1.55 seconds\n",
            "Batch 205/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 205/277, Loss: 0.3173, Time: 1.55 seconds\n",
            "Batch 206/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 206/277, Loss: 0.3762, Time: 1.54 seconds\n",
            "Batch 207/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 207/277, Loss: 0.2435, Time: 1.53 seconds\n",
            "Batch 208/277, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/2, Batch 208/277, Loss: 0.5728, Time: 1.54 seconds\n",
            "Batch 209/277, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 2/2, Batch 209/277, Loss: 0.5232, Time: 1.54 seconds\n",
            "Batch 210/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 210/277, Loss: 0.6804, Time: 1.55 seconds\n",
            "Batch 211/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 211/277, Loss: 0.5991, Time: 1.53 seconds\n",
            "Batch 212/277, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/2, Batch 212/277, Loss: 0.2403, Time: 1.53 seconds\n",
            "Batch 213/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 213/277, Loss: 0.5102, Time: 1.55 seconds\n",
            "Batch 214/277, Label Counts: {2: 16}\n",
            "Epoch 2/2, Batch 214/277, Loss: 0.2212, Time: 1.54 seconds\n",
            "Batch 215/277, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 2/2, Batch 215/277, Loss: 0.2379, Time: 1.53 seconds\n",
            "Batch 216/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 216/277, Loss: 0.1810, Time: 1.53 seconds\n",
            "Batch 217/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 217/277, Loss: 0.2796, Time: 1.53 seconds\n",
            "Batch 218/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 218/277, Loss: 0.5861, Time: 1.53 seconds\n",
            "Batch 219/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 219/277, Loss: 0.2604, Time: 1.55 seconds\n",
            "Batch 220/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 220/277, Loss: 0.5014, Time: 1.53 seconds\n",
            "Batch 221/277, Label Counts: {0: 1, 2: 15}\n",
            "Epoch 2/2, Batch 221/277, Loss: 0.1955, Time: 1.53 seconds\n",
            "Batch 222/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 222/277, Loss: 0.4378, Time: 1.53 seconds\n",
            "Batch 223/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 223/277, Loss: 0.6439, Time: 1.54 seconds\n",
            "Batch 224/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 224/277, Loss: 0.4504, Time: 1.56 seconds\n",
            "Batch 225/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 225/277, Loss: 0.4316, Time: 1.53 seconds\n",
            "Batch 226/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 226/277, Loss: 0.6350, Time: 1.55 seconds\n",
            "Batch 227/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 227/277, Loss: 0.5691, Time: 1.54 seconds\n",
            "Batch 228/277, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/2, Batch 228/277, Loss: 0.7801, Time: 1.54 seconds\n",
            "Batch 229/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 229/277, Loss: 0.3467, Time: 1.53 seconds\n",
            "Batch 230/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 230/277, Loss: 0.4591, Time: 1.52 seconds\n",
            "Batch 231/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 231/277, Loss: 0.2928, Time: 1.56 seconds\n",
            "Batch 232/277, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/2, Batch 232/277, Loss: 0.3454, Time: 1.53 seconds\n",
            "Batch 233/277, Label Counts: {1: 4, 2: 12}\n",
            "Epoch 2/2, Batch 233/277, Loss: 0.4018, Time: 1.53 seconds\n",
            "Batch 234/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 234/277, Loss: 0.9697, Time: 1.54 seconds\n",
            "Batch 235/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 235/277, Loss: 0.3069, Time: 1.54 seconds\n",
            "Batch 236/277, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/2, Batch 236/277, Loss: 0.4353, Time: 1.54 seconds\n",
            "Batch 237/277, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/2, Batch 237/277, Loss: 0.2556, Time: 1.55 seconds\n",
            "Batch 238/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 238/277, Loss: 0.3991, Time: 1.52 seconds\n",
            "Batch 239/277, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/2, Batch 239/277, Loss: 0.7292, Time: 1.51 seconds\n",
            "Batch 240/277, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/2, Batch 240/277, Loss: 0.3490, Time: 1.54 seconds\n",
            "Batch 241/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 241/277, Loss: 0.4591, Time: 1.53 seconds\n",
            "Batch 242/277, Label Counts: {0: 6, 1: 1, 2: 9}\n",
            "Epoch 2/2, Batch 242/277, Loss: 0.5739, Time: 1.53 seconds\n",
            "Batch 243/277, Label Counts: {0: 2, 1: 1, 2: 13}\n",
            "Epoch 2/2, Batch 243/277, Loss: 0.1532, Time: 1.53 seconds\n",
            "Batch 244/277, Label Counts: {1: 1, 2: 15}\n",
            "Epoch 2/2, Batch 244/277, Loss: 0.2841, Time: 1.55 seconds\n",
            "Batch 245/277, Label Counts: {0: 1, 1: 3, 2: 12}\n",
            "Epoch 2/2, Batch 245/277, Loss: 0.4111, Time: 1.53 seconds\n",
            "Batch 246/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 246/277, Loss: 0.2460, Time: 1.55 seconds\n",
            "Batch 247/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 247/277, Loss: 0.3784, Time: 1.55 seconds\n",
            "Batch 248/277, Label Counts: {0: 1, 1: 6, 2: 9}\n",
            "Epoch 2/2, Batch 248/277, Loss: 0.4075, Time: 1.52 seconds\n",
            "Batch 249/277, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/2, Batch 249/277, Loss: 0.2974, Time: 1.54 seconds\n",
            "Batch 250/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 250/277, Loss: 0.2292, Time: 1.53 seconds\n",
            "Batch 251/277, Label Counts: {0: 4, 2: 12}\n",
            "Epoch 2/2, Batch 251/277, Loss: 0.5833, Time: 1.55 seconds\n",
            "Batch 252/277, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/2, Batch 252/277, Loss: 0.5398, Time: 1.54 seconds\n",
            "Batch 253/277, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/2, Batch 253/277, Loss: 0.4170, Time: 1.53 seconds\n",
            "Batch 254/277, Label Counts: {1: 3, 2: 13}\n",
            "Epoch 2/2, Batch 254/277, Loss: 0.3108, Time: 1.55 seconds\n",
            "Batch 255/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 2/2, Batch 255/277, Loss: 0.1943, Time: 1.56 seconds\n",
            "Batch 256/277, Label Counts: {0: 1, 1: 1, 2: 14}\n",
            "Epoch 2/2, Batch 256/277, Loss: 0.5808, Time: 1.54 seconds\n",
            "Batch 257/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 257/277, Loss: 0.1519, Time: 1.54 seconds\n",
            "Batch 258/277, Label Counts: {0: 3, 2: 13}\n",
            "Epoch 2/2, Batch 258/277, Loss: 0.3087, Time: 1.53 seconds\n",
            "Batch 259/277, Label Counts: {0: 4, 1: 1, 2: 11}\n",
            "Epoch 2/2, Batch 259/277, Loss: 0.3032, Time: 1.53 seconds\n",
            "Batch 260/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 260/277, Loss: 0.5540, Time: 1.56 seconds\n",
            "Batch 261/277, Label Counts: {0: 5, 2: 11}\n",
            "Epoch 2/2, Batch 261/277, Loss: 0.5357, Time: 1.52 seconds\n",
            "Batch 262/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 262/277, Loss: 0.3594, Time: 1.54 seconds\n",
            "Batch 263/277, Label Counts: {0: 1, 2: 15}\n",
            "Epoch 2/2, Batch 263/277, Loss: 0.3515, Time: 1.54 seconds\n",
            "Batch 264/277, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 2/2, Batch 264/277, Loss: 0.4905, Time: 1.54 seconds\n",
            "Batch 265/277, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/2, Batch 265/277, Loss: 1.0218, Time: 1.54 seconds\n",
            "Batch 266/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 266/277, Loss: 0.6649, Time: 1.52 seconds\n",
            "Batch 267/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 267/277, Loss: 0.3673, Time: 1.55 seconds\n",
            "Batch 268/277, Label Counts: {0: 1, 1: 2, 2: 13}\n",
            "Epoch 2/2, Batch 268/277, Loss: 0.2719, Time: 1.55 seconds\n",
            "Batch 269/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 269/277, Loss: 0.3354, Time: 1.53 seconds\n",
            "Batch 270/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 270/277, Loss: 0.3925, Time: 1.54 seconds\n",
            "Batch 271/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 271/277, Loss: 0.2117, Time: 1.54 seconds\n",
            "Batch 272/277, Label Counts: {0: 2, 1: 2, 2: 12}\n",
            "Epoch 2/2, Batch 272/277, Loss: 0.2008, Time: 1.53 seconds\n",
            "Batch 273/277, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/2, Batch 273/277, Loss: 0.3015, Time: 1.55 seconds\n",
            "Batch 274/277, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 2/2, Batch 274/277, Loss: 0.3037, Time: 1.54 seconds\n",
            "Batch 275/277, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 2/2, Batch 275/277, Loss: 0.5929, Time: 1.55 seconds\n",
            "Batch 276/277, Label Counts: {0: 3, 1: 1, 2: 12}\n",
            "Epoch 2/2, Batch 276/277, Loss: 0.5108, Time: 1.54 seconds\n",
            "Batch 277/277, Label Counts: {2: 1}\n",
            "Epoch 2/2, Batch 277/277, Loss: 0.0024, Time: 0.13 seconds\n",
            "Epoch 2/2, Training Loss: 0.4743, Time: 424.56 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/semi_supervised/fine_tuned_3\")"
      ],
      "metadata": {
        "id": "opOmZDGJagFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd ..\n",
        "# %cd trained_models/semi_supervised\n",
        "# unlabeled.to_csv('unlabeled.csv')\n",
        "# labeled.to_csv('labeled.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhXDFZavYgMG",
        "outputId": "b53b005c-27fc-434a-88c8-582693ef2b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/MHA/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "IDRZ0paWgwxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict labels using the fine-tuned model"
      ],
      "metadata": {
        "id": "RMH_CGOH-670"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-biVGQ8PfOYy",
        "outputId": "3d7c52b1-df91-4c17-ede4-4e9dad8252ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  labels\n",
              "0     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  MachineDown       2\n",
              "1     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       2\n",
              "2     TaskAttemptListenerImpl: Progress of TaskAttem...  MachineDown       2\n",
              "3     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       2\n",
              "4     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       2\n",
              "...                                                 ...          ...     ...\n",
              "1100  MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  MachineDown       2\n",
              "1101  MapTask: Processing split: hdfs://msra-sa-41:9...  MachineDown       2\n",
              "1102  ShuffleSchedulerImpl: assigned 1 of 1 to MSRA-...  MachineDown       2\n",
              "1103  metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       2\n",
              "1104  MapTask: (EQUATOR) 9776658 kvi 2444160(9776640...  MachineDown       2\n",
              "\n",
              "[1105 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd044c43-4088-41be-ba91-068820bfaeff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TaskAttemptListenerImpl: Progress of TaskAttem...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>MapTask: Processing split: hdfs://msra-sa-41:9...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>ShuffleSchedulerImpl: assigned 1 of 1 to MSRA-...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>MapTask: (EQUATOR) 9776658 kvi 2444160(9776640...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1105 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd044c43-4088-41be-ba91-068820bfaeff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd044c43-4088-41be-ba91-068820bfaeff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd044c43-4088-41be-ba91-068820bfaeff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55cfa66e-e55c-4649-95cf-ce8a06cc4cf3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55cfa66e-e55c-4649-95cf-ce8a06cc4cf3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55cfa66e-e55c-4649-95cf-ce8a06cc4cf3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_72d705f7-56fc-4162-bd1f-ee8ced10c065\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unlabeled')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_72d705f7-56fc-4162-bd1f-ee8ced10c065 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('unlabeled');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model and unlabeled dataset if needed\n",
        "# model_path = \"./trained_models/old_way\"\n",
        "# model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# labeled = pd.read_csv('./trained_models/semi_supervised/labeled.csv')\n",
        "# unlabeled = pd.read_csv('./trained_models/semi_supervised/unlabeled.csv')\n",
        "\n",
        "# Move the model to the same device as the training\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Assuming 'unlabeled' is your unlabeled dataset\n",
        "batch_size = 8  # Adjust the batch size based on your available GPU memory\n",
        "\n",
        "# Tokenize the unlabeled texts\n",
        "unlabeled_texts = unlabeled['LogContent'].tolist()\n",
        "num_batches = int(np.ceil(len(unlabeled_texts) / batch_size))\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "# Make predictions batch-wise\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, len(unlabeled_texts))\n",
        "\n",
        "        batch_texts = unlabeled_texts[start_idx:end_idx]\n",
        "\n",
        "        # Tokenize the batch\n",
        "        batch_encodings = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "        batch_inputs = {key: val.to(device) for key, val in batch_encodings.items()}\n",
        "\n",
        "        # Make predictions for the batch\n",
        "        outputs = model(**batch_inputs)\n",
        "        batch_predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        predicted_labels.extend(batch_predictions.cpu().numpy())\n",
        "\n",
        "# Create a new dataframe with the original columns and the predicted labels\n",
        "predicted_df = pd.DataFrame({\n",
        "    'LogContent': unlabeled['LogContent'],\n",
        "    'RootCause': unlabeled['RootCause'],\n",
        "    'PredictedLabels': predicted_labels\n",
        "})\n",
        "\n",
        "predicted_df = predicted_df.rename(columns={'PredictedLabels': 'labels'})\n",
        "\n",
        "predicted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "97pwD1RsUpmZ",
        "outputId": "856d5668-ed65-4e62-f8cc-5fb4122a61f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  labels\n",
              "0     MapTask: Spilling map output\\n   mapred.\\n\\nMa...     DiskFull       2\n",
              "1     ContainerManagementProtocolProxy:\\n\\nOpening p...  MachineDown       2\n",
              "2     ShuffleSchedulerImpl: assigned 5 of 5 to MSRA-...  MachineDown       2\n",
              "3     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       1\n",
              "4     TaskAttemptImpl: TaskAttempt: [attempt_1445062...  MachineDown       2\n",
              "...                                                 ...          ...     ...\n",
              "1100  MapTask: (EQUATOR) 89325783 kvi 22331440(89325...  MachineDown       2\n",
              "1101  MapTask: (EQUATOR) 9764656 kvi 2441160(9764640...  MachineDown       2\n",
              "1102  metrics2.impl.\\n\\nMetricsConfig: loaded proper...     DiskFull       1\n",
              "1103  MergeManagerImpl: Merging 13 files, 2831866878...  MachineDown       0\n",
              "1104  ShuffleSchedulerImpl: Assigning 04DN8IQ.fareas...  MachineDown       2\n",
              "\n",
              "[1105 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13e6fbfa-154b-4847-abc2-5ed7237d74b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MapTask: Spilling map output\\n   mapred.\\n\\nMa...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ContainerManagementProtocolProxy:\\n\\nOpening p...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShuffleSchedulerImpl: assigned 5 of 5 to MSRA-...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TaskAttemptImpl: TaskAttempt: [attempt_1445062...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>MapTask: (EQUATOR) 89325783 kvi 22331440(89325...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>MapTask: (EQUATOR) 9764656 kvi 2441160(9764640...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103</th>\n",
              "      <td>MergeManagerImpl: Merging 13 files, 2831866878...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>ShuffleSchedulerImpl: Assigning 04DN8IQ.fareas...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1105 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13e6fbfa-154b-4847-abc2-5ed7237d74b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13e6fbfa-154b-4847-abc2-5ed7237d74b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13e6fbfa-154b-4847-abc2-5ed7237d74b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d405b56e-8f53-495f-bffa-e17f11df7f2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d405b56e-8f53-495f-bffa-e17f11df7f2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d405b56e-8f53-495f-bffa-e17f11df7f2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4y3_2jfhp2E",
        "outputId": "d41c0faf-9a88-4bd1-e9e8-dd9fb6c274de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    813\n",
              "1    156\n",
              "0    136\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTCOcVuNhYM0",
        "outputId": "faaabc97-d7e1-4403-b610-cabca1498e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    706\n",
              "0    214\n",
              "1    185\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_labeled = pd.concat([labeled, predicted_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "XTtJ8XPCe82P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_labeled['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9-iqOpCfGzS",
        "outputId": "d8b9d840-75f6-4331-e2d8-c63c3cedaee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3751\n",
              "0     911\n",
              "1     860\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation datasets (80-20 split)\n",
        "train, val = train_test_split(pseudo_labeled, test_size=0.2, random_state=42, shuffle=True)\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "CCL8k2NpfoAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDataset(texts=list(train['LogContent']), labels=train['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDataset(texts=list(val['LogContent']), labels=val['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML4gfCrJfcgD",
        "outputId": "67ae25fc-025b-49c7-c2db-86d772286260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "553"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Training loop without early stopping\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mJ1OXqeoBZ8H",
        "outputId": "990308ba-f506-4467-eec4-ef9b0a416f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-33f4ade4f096>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch 1/553, Loss: 0.3085, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 2/553, Loss: 0.3919, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 3/553, Loss: 0.3218, Time: 0.67 seconds\n",
            "Epoch 1/10, Batch 4/553, Loss: 0.4004, Time: 0.67 seconds\n",
            "Epoch 1/10, Batch 5/553, Loss: 0.5880, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 6/553, Loss: 0.8048, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 7/553, Loss: 0.2975, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 8/553, Loss: 0.3838, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 9/553, Loss: 0.4310, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 10/553, Loss: 0.5555, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 11/553, Loss: 0.4149, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 12/553, Loss: 0.3717, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 13/553, Loss: 0.3128, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 14/553, Loss: 0.2969, Time: 0.67 seconds\n",
            "Epoch 1/10, Batch 15/553, Loss: 0.4341, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 16/553, Loss: 0.5791, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 17/553, Loss: 0.1580, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 18/553, Loss: 0.2636, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 19/553, Loss: 0.3566, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 20/553, Loss: 0.4880, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 21/553, Loss: 0.2049, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 22/553, Loss: 0.6232, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 23/553, Loss: 0.5670, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 24/553, Loss: 0.7680, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 25/553, Loss: 0.3574, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 26/553, Loss: 0.1299, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 27/553, Loss: 0.4198, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 28/553, Loss: 0.7549, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 29/553, Loss: 0.7221, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 30/553, Loss: 0.4884, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 31/553, Loss: 0.2559, Time: 0.68 seconds\n",
            "Epoch 1/10, Batch 32/553, Loss: 0.7169, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 33/553, Loss: 0.3994, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 34/553, Loss: 0.5640, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 35/553, Loss: 0.3467, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 36/553, Loss: 0.1927, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 37/553, Loss: 0.4196, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 38/553, Loss: 0.2301, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 39/553, Loss: 0.3687, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 40/553, Loss: 0.9610, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 41/553, Loss: 0.1258, Time: 0.69 seconds\n",
            "Epoch 1/10, Batch 42/553, Loss: 0.3106, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 43/553, Loss: 0.1727, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 44/553, Loss: 0.7747, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 45/553, Loss: 0.4588, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 46/553, Loss: 0.3444, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 47/553, Loss: 0.5365, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 48/553, Loss: 0.2474, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 49/553, Loss: 0.7259, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 50/553, Loss: 0.0965, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 51/553, Loss: 0.4019, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 52/553, Loss: 0.5634, Time: 0.70 seconds\n",
            "Epoch 1/10, Batch 53/553, Loss: 0.3218, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 54/553, Loss: 0.4929, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 55/553, Loss: 0.4195, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 56/553, Loss: 0.1689, Time: 0.71 seconds\n",
            "Epoch 1/10, Batch 57/553, Loss: 0.4986, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 58/553, Loss: 0.3793, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 59/553, Loss: 0.1994, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 60/553, Loss: 0.0961, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 61/553, Loss: 0.0965, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 62/553, Loss: 0.9291, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 63/553, Loss: 0.2953, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 64/553, Loss: 0.3975, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 65/553, Loss: 0.1452, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 66/553, Loss: 0.4003, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 67/553, Loss: 0.3629, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 68/553, Loss: 0.3472, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 69/553, Loss: 0.1681, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 70/553, Loss: 0.5303, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 71/553, Loss: 0.4256, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 72/553, Loss: 0.6669, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 73/553, Loss: 0.5433, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 74/553, Loss: 0.2099, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 75/553, Loss: 0.7269, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 76/553, Loss: 0.2048, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 77/553, Loss: 0.2485, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 78/553, Loss: 0.5793, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 79/553, Loss: 0.3787, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 80/553, Loss: 0.4531, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 81/553, Loss: 0.1963, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 82/553, Loss: 0.0925, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 83/553, Loss: 0.1611, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 84/553, Loss: 0.0511, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 85/553, Loss: 0.4036, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 86/553, Loss: 0.7987, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 87/553, Loss: 0.6681, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 88/553, Loss: 0.6478, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 89/553, Loss: 0.3000, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 90/553, Loss: 0.4434, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 91/553, Loss: 0.8299, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 92/553, Loss: 0.3531, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 93/553, Loss: 0.3996, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 94/553, Loss: 0.6780, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 95/553, Loss: 0.6592, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 96/553, Loss: 0.3909, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 97/553, Loss: 0.5279, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 98/553, Loss: 0.5791, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 99/553, Loss: 0.2649, Time: 0.72 seconds\n",
            "Epoch 1/10, Batch 100/553, Loss: 0.7472, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 101/553, Loss: 0.3355, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 102/553, Loss: 0.8829, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 103/553, Loss: 0.3935, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 104/553, Loss: 0.2896, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 105/553, Loss: 0.3978, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 106/553, Loss: 0.3437, Time: 0.73 seconds\n",
            "Epoch 1/10, Batch 107/553, Loss: 0.4014, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 108/553, Loss: 0.3722, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 109/553, Loss: 0.5814, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 110/553, Loss: 0.5325, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 111/553, Loss: 0.3923, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 112/553, Loss: 0.3372, Time: 0.74 seconds\n",
            "Epoch 1/10, Batch 113/553, Loss: 0.2461, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 114/553, Loss: 0.4962, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 115/553, Loss: 0.6571, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 116/553, Loss: 0.4915, Time: 0.75 seconds\n",
            "Epoch 1/10, Batch 117/553, Loss: 0.1143, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 118/553, Loss: 1.1369, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 119/553, Loss: 0.2234, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 120/553, Loss: 0.0886, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 121/553, Loss: 0.1357, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 122/553, Loss: 0.9399, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 123/553, Loss: 0.3906, Time: 0.77 seconds\n",
            "Epoch 1/10, Batch 124/553, Loss: 0.1494, Time: 0.77 seconds\n",
            "Epoch 1/10, Batch 125/553, Loss: 0.1032, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 126/553, Loss: 0.0660, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 127/553, Loss: 0.3926, Time: 0.78 seconds\n",
            "Epoch 1/10, Batch 128/553, Loss: 0.1879, Time: 0.76 seconds\n",
            "Epoch 1/10, Batch 129/553, Loss: 0.6089, Time: 0.78 seconds\n",
            "Epoch 1/10, Batch 130/553, Loss: 0.4992, Time: 0.78 seconds\n",
            "Epoch 1/10, Batch 131/553, Loss: 0.5076, Time: 0.76 seconds\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-0cc64585b072>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mbatch_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop with early stopping\n",
        "\n",
        "# Set the initial best validation loss to a large value\n",
        "best_val_loss = float('inf')\n",
        "best_model_state_dict = model.state_dict()\n",
        "patience = 3  # Number of epochs with no improvement after which training will be stopped due to overfitting\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20  # Adjust the number of epochs as needed\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Early stopping check for overfitting\n",
        "    if epoch > 0 and average_loss < best_val_loss:\n",
        "        best_val_loss = average_loss\n",
        "        best_model_state_dict = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Overfitting detected. Early stopping.\")\n",
        "            break\n",
        "\n",
        "# Load the best model state\n",
        "model.load_state_dict(best_model_state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuvqSuw1Zq-R",
        "outputId": "47555571-ce44-41cf-975f-c5299f39168d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-33f4ade4f096>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Batch 1/553, Loss: 0.1735, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 2/553, Loss: 0.4088, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 3/553, Loss: 0.0602, Time: 0.67 seconds\n",
            "Epoch 1/20, Batch 4/553, Loss: 0.9496, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 5/553, Loss: 0.2855, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 6/553, Loss: 0.1677, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 7/553, Loss: 0.5995, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 8/553, Loss: 0.3286, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 9/553, Loss: 0.3679, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 10/553, Loss: 0.6956, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 11/553, Loss: 0.3047, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 12/553, Loss: 0.1594, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 13/553, Loss: 0.2976, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 14/553, Loss: 0.0576, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 15/553, Loss: 0.2904, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 16/553, Loss: 0.7614, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 17/553, Loss: 0.2403, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 18/553, Loss: 0.5487, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 19/553, Loss: 0.3462, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 20/553, Loss: 0.1384, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 21/553, Loss: 0.3361, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 22/553, Loss: 0.5425, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 23/553, Loss: 0.3190, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 24/553, Loss: 0.0520, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 25/553, Loss: 0.1612, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 26/553, Loss: 0.3871, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 27/553, Loss: 0.3416, Time: 0.69 seconds\n",
            "Epoch 1/20, Batch 28/553, Loss: 0.4937, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 29/553, Loss: 0.4240, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 30/553, Loss: 0.1986, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 31/553, Loss: 1.0148, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 32/553, Loss: 0.4897, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 33/553, Loss: 0.7312, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 34/553, Loss: 0.0604, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 35/553, Loss: 0.0975, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 36/553, Loss: 0.2167, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 37/553, Loss: 0.4358, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 38/553, Loss: 0.1937, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 39/553, Loss: 0.1365, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 40/553, Loss: 0.0043, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 41/553, Loss: 0.7215, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 42/553, Loss: 0.3615, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 43/553, Loss: 0.2719, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 44/553, Loss: 0.3692, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 45/553, Loss: 0.7494, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 46/553, Loss: 0.1884, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 47/553, Loss: 0.1378, Time: 0.70 seconds\n",
            "Epoch 1/20, Batch 48/553, Loss: 0.6977, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 49/553, Loss: 0.1446, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 50/553, Loss: 0.3808, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 51/553, Loss: 0.4023, Time: 0.71 seconds\n",
            "Epoch 1/20, Batch 52/553, Loss: 0.3416, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 53/553, Loss: 0.3713, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 54/553, Loss: 0.4868, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 55/553, Loss: 0.3311, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 56/553, Loss: 0.3539, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 57/553, Loss: 0.3067, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 58/553, Loss: 0.3453, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 59/553, Loss: 0.1056, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 60/553, Loss: 0.6772, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 61/553, Loss: 0.4678, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 62/553, Loss: 0.6118, Time: 0.72 seconds\n",
            "Epoch 1/20, Batch 63/553, Loss: 0.3339, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 64/553, Loss: 0.6805, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 65/553, Loss: 0.2423, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 66/553, Loss: 0.2253, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 67/553, Loss: 0.8768, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 68/553, Loss: 0.1444, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 69/553, Loss: 0.4654, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 70/553, Loss: 0.8568, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 71/553, Loss: 0.4320, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 72/553, Loss: 0.1860, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 73/553, Loss: 0.3604, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 74/553, Loss: 0.2280, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 75/553, Loss: 0.2648, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 76/553, Loss: 0.5088, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 77/553, Loss: 0.4335, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 78/553, Loss: 0.9833, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 79/553, Loss: 0.1822, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 80/553, Loss: 0.7552, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 81/553, Loss: 0.1924, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 82/553, Loss: 0.5661, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 83/553, Loss: 0.4525, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 84/553, Loss: 0.5656, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 85/553, Loss: 0.4430, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 86/553, Loss: 0.1028, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 87/553, Loss: 0.3332, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 88/553, Loss: 0.2506, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 89/553, Loss: 0.3273, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 90/553, Loss: 0.2592, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 91/553, Loss: 0.8465, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 92/553, Loss: 0.5004, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 93/553, Loss: 0.3420, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 94/553, Loss: 0.2336, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 95/553, Loss: 0.3906, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 96/553, Loss: 0.3845, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 97/553, Loss: 0.5537, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 98/553, Loss: 0.3423, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 99/553, Loss: 0.2946, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 100/553, Loss: 0.7234, Time: 0.78 seconds\n",
            "Epoch 1/20, Batch 101/553, Loss: 0.1392, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 102/553, Loss: 0.2544, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 103/553, Loss: 0.6889, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 104/553, Loss: 0.1081, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 105/553, Loss: 0.1749, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 106/553, Loss: 0.3819, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 107/553, Loss: 0.6694, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 108/553, Loss: 0.4258, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 109/553, Loss: 0.2396, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 110/553, Loss: 0.3786, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 111/553, Loss: 0.7158, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 112/553, Loss: 0.2960, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 113/553, Loss: 0.6312, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 114/553, Loss: 0.4070, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 115/553, Loss: 0.7391, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 116/553, Loss: 0.2850, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 117/553, Loss: 0.3840, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 118/553, Loss: 0.3830, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 119/553, Loss: 0.7665, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 120/553, Loss: 0.4303, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 121/553, Loss: 0.2198, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 122/553, Loss: 0.4838, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 123/553, Loss: 0.3152, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 124/553, Loss: 0.2366, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 125/553, Loss: 0.4708, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 126/553, Loss: 0.6530, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 127/553, Loss: 0.8574, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 128/553, Loss: 0.1257, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 129/553, Loss: 0.6175, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 130/553, Loss: 0.4826, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 131/553, Loss: 0.3694, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 132/553, Loss: 0.6653, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 133/553, Loss: 0.6476, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 134/553, Loss: 0.2838, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 135/553, Loss: 0.2237, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 136/553, Loss: 0.4287, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 137/553, Loss: 0.4470, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 138/553, Loss: 0.3027, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 139/553, Loss: 0.2268, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 140/553, Loss: 0.3146, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 141/553, Loss: 0.4447, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 142/553, Loss: 0.3877, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 143/553, Loss: 0.3769, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 144/553, Loss: 0.2683, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 145/553, Loss: 0.1222, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 146/553, Loss: 0.3989, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 147/553, Loss: 0.3250, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 148/553, Loss: 0.3865, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 149/553, Loss: 0.1352, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 150/553, Loss: 0.5535, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 151/553, Loss: 0.3611, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 152/553, Loss: 0.4990, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 153/553, Loss: 0.4745, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 154/553, Loss: 0.2464, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 155/553, Loss: 0.3401, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 156/553, Loss: 0.4390, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 157/553, Loss: 0.3246, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 158/553, Loss: 0.2619, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 159/553, Loss: 0.3690, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 160/553, Loss: 0.3387, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 161/553, Loss: 0.1877, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 162/553, Loss: 1.0863, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 163/553, Loss: 0.2029, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 164/553, Loss: 0.4880, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 165/553, Loss: 0.4438, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 166/553, Loss: 0.3661, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 167/553, Loss: 0.4535, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 168/553, Loss: 0.3638, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 169/553, Loss: 0.2514, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 170/553, Loss: 0.5453, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 171/553, Loss: 0.5635, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 172/553, Loss: 0.6377, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 173/553, Loss: 0.5431, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 174/553, Loss: 0.1315, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 175/553, Loss: 0.2356, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 176/553, Loss: 0.1787, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 177/553, Loss: 0.3077, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 178/553, Loss: 0.5371, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 179/553, Loss: 0.6415, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 180/553, Loss: 0.3359, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 181/553, Loss: 0.6661, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 182/553, Loss: 0.3013, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 183/553, Loss: 0.3874, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 184/553, Loss: 0.8059, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 185/553, Loss: 0.8478, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 186/553, Loss: 0.8886, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 187/553, Loss: 0.3788, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 188/553, Loss: 0.9563, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 189/553, Loss: 0.1879, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 190/553, Loss: 0.4152, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 191/553, Loss: 0.6407, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 192/553, Loss: 0.3828, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 193/553, Loss: 0.4983, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 194/553, Loss: 0.6524, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 195/553, Loss: 0.3228, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 196/553, Loss: 0.2696, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 197/553, Loss: 0.5858, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 198/553, Loss: 0.2958, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 199/553, Loss: 0.3074, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 200/553, Loss: 0.2040, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 201/553, Loss: 0.1345, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 202/553, Loss: 0.2707, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 203/553, Loss: 0.1812, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 204/553, Loss: 0.3218, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 205/553, Loss: 0.2101, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 206/553, Loss: 0.3239, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 207/553, Loss: 0.3787, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 208/553, Loss: 0.2013, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 209/553, Loss: 0.0578, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 210/553, Loss: 0.1625, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 211/553, Loss: 0.3834, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 212/553, Loss: 0.5986, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 213/553, Loss: 0.4450, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 214/553, Loss: 0.3325, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 215/553, Loss: 0.1162, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 216/553, Loss: 0.5722, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 217/553, Loss: 0.3214, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 218/553, Loss: 0.3466, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 219/553, Loss: 0.4416, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 220/553, Loss: 0.3860, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 221/553, Loss: 0.2789, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 222/553, Loss: 0.4925, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 223/553, Loss: 0.2506, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 224/553, Loss: 0.1682, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 225/553, Loss: 0.2469, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 226/553, Loss: 0.9087, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 227/553, Loss: 0.3751, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 228/553, Loss: 0.3139, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 229/553, Loss: 0.1433, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 230/553, Loss: 0.5590, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 231/553, Loss: 0.4818, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 232/553, Loss: 0.4503, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 233/553, Loss: 0.9253, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 234/553, Loss: 0.4126, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 235/553, Loss: 0.4606, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 236/553, Loss: 0.6236, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 237/553, Loss: 0.0785, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 238/553, Loss: 0.4841, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 239/553, Loss: 0.4262, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 240/553, Loss: 0.1247, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 241/553, Loss: 0.3665, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 242/553, Loss: 0.2330, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 243/553, Loss: 0.3809, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 244/553, Loss: 0.6119, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 245/553, Loss: 0.2091, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 246/553, Loss: 0.6188, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 247/553, Loss: 0.3222, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 248/553, Loss: 0.5893, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 249/553, Loss: 0.4612, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 250/553, Loss: 0.2934, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 251/553, Loss: 0.3537, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 252/553, Loss: 0.2642, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 253/553, Loss: 0.1762, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 254/553, Loss: 0.7788, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 255/553, Loss: 0.4988, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 256/553, Loss: 0.7769, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 257/553, Loss: 0.2137, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 258/553, Loss: 0.2514, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 259/553, Loss: 0.3908, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 260/553, Loss: 0.4506, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 261/553, Loss: 0.6489, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 262/553, Loss: 0.3334, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 263/553, Loss: 0.4100, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 264/553, Loss: 0.9219, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 265/553, Loss: 0.6529, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 266/553, Loss: 0.1318, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 267/553, Loss: 0.8422, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 268/553, Loss: 0.3516, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 269/553, Loss: 0.0512, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 270/553, Loss: 0.1028, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 271/553, Loss: 0.6876, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 272/553, Loss: 0.5713, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 273/553, Loss: 0.5577, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 274/553, Loss: 0.3298, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 275/553, Loss: 0.4806, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 276/553, Loss: 0.4759, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 277/553, Loss: 0.4818, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 278/553, Loss: 0.4651, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 279/553, Loss: 0.0464, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 280/553, Loss: 0.3287, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 281/553, Loss: 0.6137, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 282/553, Loss: 0.2616, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 283/553, Loss: 0.2901, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 284/553, Loss: 0.4439, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 285/553, Loss: 0.6239, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 286/553, Loss: 0.3557, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 287/553, Loss: 0.1439, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 288/553, Loss: 0.7165, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 289/553, Loss: 0.7237, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 290/553, Loss: 0.4541, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 291/553, Loss: 0.5406, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 292/553, Loss: 0.0976, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 293/553, Loss: 0.3782, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 294/553, Loss: 0.2548, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 295/553, Loss: 0.2595, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 296/553, Loss: 0.2014, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 297/553, Loss: 0.1922, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 298/553, Loss: 0.4458, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 299/553, Loss: 0.3640, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 300/553, Loss: 0.8309, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 301/553, Loss: 0.5584, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 302/553, Loss: 0.1204, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 303/553, Loss: 0.3161, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 304/553, Loss: 0.6156, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 305/553, Loss: 0.2369, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 306/553, Loss: 0.3248, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 307/553, Loss: 0.3152, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 308/553, Loss: 0.1888, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 309/553, Loss: 0.3249, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 310/553, Loss: 0.6550, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 311/553, Loss: 0.1442, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 312/553, Loss: 0.3780, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 313/553, Loss: 0.2860, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 314/553, Loss: 0.4573, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 315/553, Loss: 0.2038, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 316/553, Loss: 0.4732, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 317/553, Loss: 0.5103, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 318/553, Loss: 0.3936, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 319/553, Loss: 0.2097, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 320/553, Loss: 0.4002, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 321/553, Loss: 0.4732, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 322/553, Loss: 0.2628, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 323/553, Loss: 0.1203, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 324/553, Loss: 0.2240, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 325/553, Loss: 0.3464, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 326/553, Loss: 0.5992, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 327/553, Loss: 0.2135, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 328/553, Loss: 0.3760, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 329/553, Loss: 0.0933, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 330/553, Loss: 0.2802, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 331/553, Loss: 0.4461, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 332/553, Loss: 0.9155, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 333/553, Loss: 0.3549, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 334/553, Loss: 0.3439, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 335/553, Loss: 0.7922, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 336/553, Loss: 0.2102, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 337/553, Loss: 0.4479, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 338/553, Loss: 0.2389, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 339/553, Loss: 1.1417, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 340/553, Loss: 0.2949, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 341/553, Loss: 0.0518, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 342/553, Loss: 0.7562, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 343/553, Loss: 0.3802, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 344/553, Loss: 0.4860, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 345/553, Loss: 0.3721, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 346/553, Loss: 0.6014, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 347/553, Loss: 0.8065, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 348/553, Loss: 0.3528, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 349/553, Loss: 0.4701, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 350/553, Loss: 0.1004, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 351/553, Loss: 0.0540, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 352/553, Loss: 0.1408, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 353/553, Loss: 0.3333, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 354/553, Loss: 0.3320, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 355/553, Loss: 0.4467, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 356/553, Loss: 0.4339, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 357/553, Loss: 0.5063, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 358/553, Loss: 0.7991, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 359/553, Loss: 0.4625, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 360/553, Loss: 0.6779, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 361/553, Loss: 0.3135, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 362/553, Loss: 0.2159, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 363/553, Loss: 0.2556, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 364/553, Loss: 0.3785, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 365/553, Loss: 0.4853, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 366/553, Loss: 0.2886, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 367/553, Loss: 0.6212, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 368/553, Loss: 0.3635, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 369/553, Loss: 0.5083, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 370/553, Loss: 0.3506, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 371/553, Loss: 0.2874, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 372/553, Loss: 0.1916, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 373/553, Loss: 0.2667, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 374/553, Loss: 0.2938, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 375/553, Loss: 0.2720, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 376/553, Loss: 0.4717, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 377/553, Loss: 0.5811, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 378/553, Loss: 0.4123, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 379/553, Loss: 0.6078, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 380/553, Loss: 0.5774, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 381/553, Loss: 0.6849, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 382/553, Loss: 0.4388, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 383/553, Loss: 0.3997, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 384/553, Loss: 0.7448, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 385/553, Loss: 0.5201, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 386/553, Loss: 0.2107, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 387/553, Loss: 0.8073, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 388/553, Loss: 0.1908, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 389/553, Loss: 0.5173, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 390/553, Loss: 0.7857, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 391/553, Loss: 0.4696, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 392/553, Loss: 0.2341, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 393/553, Loss: 0.4327, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 394/553, Loss: 0.2682, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 395/553, Loss: 0.1767, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 396/553, Loss: 0.1954, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 397/553, Loss: 0.4933, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 398/553, Loss: 0.5221, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 399/553, Loss: 0.4102, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 400/553, Loss: 0.4777, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 401/553, Loss: 0.1187, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 402/553, Loss: 0.2069, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 403/553, Loss: 0.4654, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 404/553, Loss: 0.2385, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 405/553, Loss: 0.3111, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 406/553, Loss: 0.4447, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 407/553, Loss: 0.3652, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 408/553, Loss: 0.6297, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 409/553, Loss: 0.2006, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 410/553, Loss: 0.4939, Time: 0.77 seconds\n",
            "Epoch 1/20, Batch 411/553, Loss: 0.6353, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 412/553, Loss: 0.4131, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 413/553, Loss: 0.3289, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 414/553, Loss: 0.2585, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 415/553, Loss: 0.4081, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 416/553, Loss: 0.7072, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 417/553, Loss: 0.0933, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 418/553, Loss: 0.1626, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 419/553, Loss: 0.1457, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 420/553, Loss: 0.2095, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 421/553, Loss: 0.4337, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 422/553, Loss: 0.4756, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 423/553, Loss: 0.5965, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 424/553, Loss: 0.8771, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 425/553, Loss: 0.3137, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 426/553, Loss: 0.3804, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 427/553, Loss: 0.5082, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 428/553, Loss: 0.4610, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 429/553, Loss: 0.2481, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 430/553, Loss: 0.2872, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 431/553, Loss: 0.6737, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 432/553, Loss: 0.7137, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 433/553, Loss: 0.1791, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 434/553, Loss: 0.3388, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 435/553, Loss: 0.4092, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 436/553, Loss: 0.3747, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 437/553, Loss: 0.2499, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 438/553, Loss: 0.6488, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 439/553, Loss: 0.6372, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 440/553, Loss: 0.7754, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 441/553, Loss: 0.8460, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 442/553, Loss: 0.1341, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 443/553, Loss: 0.5400, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 444/553, Loss: 0.2077, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 445/553, Loss: 0.1290, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 446/553, Loss: 0.3179, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 447/553, Loss: 0.6662, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 448/553, Loss: 0.3367, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 449/553, Loss: 0.4110, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 450/553, Loss: 0.1055, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 451/553, Loss: 0.6381, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 452/553, Loss: 0.5977, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 453/553, Loss: 0.6076, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 454/553, Loss: 0.2752, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 455/553, Loss: 0.2612, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 456/553, Loss: 0.5660, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 457/553, Loss: 0.5363, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 458/553, Loss: 0.4137, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 459/553, Loss: 0.7867, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 460/553, Loss: 0.2704, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 461/553, Loss: 0.0927, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 462/553, Loss: 0.0862, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 463/553, Loss: 0.8946, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 464/553, Loss: 0.6338, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 465/553, Loss: 1.0847, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 466/553, Loss: 0.8680, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 467/553, Loss: 0.4741, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 468/553, Loss: 0.6343, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 469/553, Loss: 0.6621, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 470/553, Loss: 0.1062, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 471/553, Loss: 0.2934, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 472/553, Loss: 0.2649, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 473/553, Loss: 0.1449, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 474/553, Loss: 0.1955, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 475/553, Loss: 0.1479, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 476/553, Loss: 0.5470, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 477/553, Loss: 0.1605, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 478/553, Loss: 0.0575, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 479/553, Loss: 0.4555, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 480/553, Loss: 0.7767, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 481/553, Loss: 0.2336, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 482/553, Loss: 0.7642, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 483/553, Loss: 0.2344, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 484/553, Loss: 0.1085, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 485/553, Loss: 0.3704, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 486/553, Loss: 0.6180, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 487/553, Loss: 0.6776, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 488/553, Loss: 0.3763, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 489/553, Loss: 0.3106, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 490/553, Loss: 0.2800, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 491/553, Loss: 0.1690, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 492/553, Loss: 0.5987, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 493/553, Loss: 0.5512, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 494/553, Loss: 0.2824, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 495/553, Loss: 0.6442, Time: 0.73 seconds\n",
            "Epoch 1/20, Batch 496/553, Loss: 0.1011, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 497/553, Loss: 0.1497, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 498/553, Loss: 0.1279, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 499/553, Loss: 0.2677, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 500/553, Loss: 0.3468, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 501/553, Loss: 0.3475, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 502/553, Loss: 0.2967, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 503/553, Loss: 0.2746, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 504/553, Loss: 0.1976, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 505/553, Loss: 0.7746, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 506/553, Loss: 0.1437, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 507/553, Loss: 0.4143, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 508/553, Loss: 0.2677, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 509/553, Loss: 0.6382, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 510/553, Loss: 0.3724, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 511/553, Loss: 0.2304, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 512/553, Loss: 0.5746, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 513/553, Loss: 0.2779, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 514/553, Loss: 0.3796, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 515/553, Loss: 0.3361, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 516/553, Loss: 0.5500, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 517/553, Loss: 0.2433, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 518/553, Loss: 0.4932, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 519/553, Loss: 0.5074, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 520/553, Loss: 0.3419, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 521/553, Loss: 0.4787, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 522/553, Loss: 0.6395, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 523/553, Loss: 0.0558, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 524/553, Loss: 0.2332, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 525/553, Loss: 0.9436, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 526/553, Loss: 0.5310, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 527/553, Loss: 0.5168, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 528/553, Loss: 0.4417, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 529/553, Loss: 0.4596, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 530/553, Loss: 0.3248, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 531/553, Loss: 0.2608, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 532/553, Loss: 0.1600, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 533/553, Loss: 0.6094, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 534/553, Loss: 0.3710, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 535/553, Loss: 0.6156, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 536/553, Loss: 0.2975, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 537/553, Loss: 0.2286, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 538/553, Loss: 0.1531, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 539/553, Loss: 0.4599, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 540/553, Loss: 0.5026, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 541/553, Loss: 0.1470, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 542/553, Loss: 0.7513, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 543/553, Loss: 0.0886, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 544/553, Loss: 0.2818, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 545/553, Loss: 0.0555, Time: 0.74 seconds\n",
            "Epoch 1/20, Batch 546/553, Loss: 0.2319, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 547/553, Loss: 0.8504, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 548/553, Loss: 0.5498, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 549/553, Loss: 0.5915, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 550/553, Loss: 0.5772, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 551/553, Loss: 0.2485, Time: 0.76 seconds\n",
            "Epoch 1/20, Batch 552/553, Loss: 0.6954, Time: 0.75 seconds\n",
            "Epoch 1/20, Batch 553/553, Loss: 1.8905, Time: 0.11 seconds\n",
            "Epoch 1/20, Training Loss: 0.4075, Time: 414.07 seconds\n",
            "Validation Loss: 0.3784, Accuracy: 0.8561\n",
            "Epoch 2/20, Batch 1/553, Loss: 0.4630, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 2/553, Loss: 0.4156, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 3/553, Loss: 0.5436, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 4/553, Loss: 0.2740, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 5/553, Loss: 0.7192, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 6/553, Loss: 0.2659, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 7/553, Loss: 0.1874, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 8/553, Loss: 0.1575, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 9/553, Loss: 0.5543, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 10/553, Loss: 0.7377, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 11/553, Loss: 0.1868, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 12/553, Loss: 0.4347, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 13/553, Loss: 0.8374, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 14/553, Loss: 0.6657, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 15/553, Loss: 0.2341, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 16/553, Loss: 0.4948, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 17/553, Loss: 0.2632, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 18/553, Loss: 0.3841, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 19/553, Loss: 0.2286, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 20/553, Loss: 0.9055, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 21/553, Loss: 0.4694, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 22/553, Loss: 0.5483, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 23/553, Loss: 0.5530, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 24/553, Loss: 0.2154, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 25/553, Loss: 0.5047, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 26/553, Loss: 0.2205, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 27/553, Loss: 0.3014, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 28/553, Loss: 0.1948, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 29/553, Loss: 0.1391, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 30/553, Loss: 0.1112, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 31/553, Loss: 0.4197, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 32/553, Loss: 0.2229, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 33/553, Loss: 0.2174, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 34/553, Loss: 0.2584, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 35/553, Loss: 0.5540, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 36/553, Loss: 0.4786, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 37/553, Loss: 0.5728, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 38/553, Loss: 0.2349, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 39/553, Loss: 0.3208, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 40/553, Loss: 0.5791, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 41/553, Loss: 0.6679, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 42/553, Loss: 0.5027, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 43/553, Loss: 0.4185, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 44/553, Loss: 0.3820, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 45/553, Loss: 0.4498, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 46/553, Loss: 0.5262, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 47/553, Loss: 0.3133, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 48/553, Loss: 0.2624, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 49/553, Loss: 0.7232, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 50/553, Loss: 0.6543, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 51/553, Loss: 0.4570, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 52/553, Loss: 0.4567, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 53/553, Loss: 1.2613, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 54/553, Loss: 0.2302, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 55/553, Loss: 0.6654, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 56/553, Loss: 0.5369, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 57/553, Loss: 0.8236, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 58/553, Loss: 0.3990, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 59/553, Loss: 0.3479, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 60/553, Loss: 0.7519, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 61/553, Loss: 0.8195, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 62/553, Loss: 0.6533, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 63/553, Loss: 0.3518, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 64/553, Loss: 0.1871, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 65/553, Loss: 0.2303, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 66/553, Loss: 0.1789, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 67/553, Loss: 0.2206, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 68/553, Loss: 0.2938, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 69/553, Loss: 0.2112, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 70/553, Loss: 0.4541, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 71/553, Loss: 0.4603, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 72/553, Loss: 0.3764, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 73/553, Loss: 0.6786, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 74/553, Loss: 0.6566, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 75/553, Loss: 0.8341, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 76/553, Loss: 0.1552, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 77/553, Loss: 0.3636, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 78/553, Loss: 0.5962, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 79/553, Loss: 0.2838, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 80/553, Loss: 0.4064, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 81/553, Loss: 0.4236, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 82/553, Loss: 0.4205, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 83/553, Loss: 0.3796, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 84/553, Loss: 0.2904, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 85/553, Loss: 0.3630, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 86/553, Loss: 0.1705, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 87/553, Loss: 0.2667, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 88/553, Loss: 0.6103, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 89/553, Loss: 0.6263, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 90/553, Loss: 0.5568, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 91/553, Loss: 0.3811, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 92/553, Loss: 0.3555, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 93/553, Loss: 0.4258, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 94/553, Loss: 0.6855, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 95/553, Loss: 0.6084, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 96/553, Loss: 0.4556, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 97/553, Loss: 0.3415, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 98/553, Loss: 0.5614, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 99/553, Loss: 0.6537, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 100/553, Loss: 0.4479, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 101/553, Loss: 0.1753, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 102/553, Loss: 0.5169, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 103/553, Loss: 0.3705, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 104/553, Loss: 0.3744, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 105/553, Loss: 0.2899, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 106/553, Loss: 0.2727, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 107/553, Loss: 0.7516, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 108/553, Loss: 0.1817, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 109/553, Loss: 0.3463, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 110/553, Loss: 0.2915, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 111/553, Loss: 0.2109, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 112/553, Loss: 0.4409, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 113/553, Loss: 0.1955, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 114/553, Loss: 0.4529, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 115/553, Loss: 0.2633, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 116/553, Loss: 0.2243, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 117/553, Loss: 0.4641, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 118/553, Loss: 0.0044, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 119/553, Loss: 0.2506, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 120/553, Loss: 0.4146, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 121/553, Loss: 0.4860, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 122/553, Loss: 0.8505, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 123/553, Loss: 0.2364, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 124/553, Loss: 0.3058, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 125/553, Loss: 0.1917, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 126/553, Loss: 0.4571, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 127/553, Loss: 0.4058, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 128/553, Loss: 0.3755, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 129/553, Loss: 0.0950, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 130/553, Loss: 0.6545, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 131/553, Loss: 0.6498, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 132/553, Loss: 0.2466, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 133/553, Loss: 0.5348, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 134/553, Loss: 0.7312, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 135/553, Loss: 0.4584, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 136/553, Loss: 0.5526, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 137/553, Loss: 0.4421, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 138/553, Loss: 0.1575, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 139/553, Loss: 0.0495, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 140/553, Loss: 0.3390, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 141/553, Loss: 0.4819, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 142/553, Loss: 0.4686, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 143/553, Loss: 0.3862, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 144/553, Loss: 0.4490, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 145/553, Loss: 0.1381, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 146/553, Loss: 0.4841, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 147/553, Loss: 0.6171, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 148/553, Loss: 0.4405, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 149/553, Loss: 0.6373, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 150/553, Loss: 0.1674, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 151/553, Loss: 0.2895, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 152/553, Loss: 0.6556, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 153/553, Loss: 0.4088, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 154/553, Loss: 0.5089, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 155/553, Loss: 0.7763, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 156/553, Loss: 0.3303, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 157/553, Loss: 0.2789, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 158/553, Loss: 0.3532, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 159/553, Loss: 0.3526, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 160/553, Loss: 0.7080, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 161/553, Loss: 0.6083, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 162/553, Loss: 0.5959, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 163/553, Loss: 0.0755, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 164/553, Loss: 0.7732, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 165/553, Loss: 0.7754, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 166/553, Loss: 0.6382, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 167/553, Loss: 0.3897, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 168/553, Loss: 0.3611, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 169/553, Loss: 0.4653, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 170/553, Loss: 0.2581, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 171/553, Loss: 0.4011, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 172/553, Loss: 0.3771, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 173/553, Loss: 0.4034, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 174/553, Loss: 0.5509, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 175/553, Loss: 0.7941, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 176/553, Loss: 0.5521, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 177/553, Loss: 0.4153, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 178/553, Loss: 0.9048, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 179/553, Loss: 0.1419, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 180/553, Loss: 0.5694, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 181/553, Loss: 0.6598, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 182/553, Loss: 0.3973, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 183/553, Loss: 0.2369, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 184/553, Loss: 0.4165, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 185/553, Loss: 0.8142, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 186/553, Loss: 0.1337, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 187/553, Loss: 0.4054, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 188/553, Loss: 0.2164, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 189/553, Loss: 0.2138, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 190/553, Loss: 0.5094, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 191/553, Loss: 0.6963, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 192/553, Loss: 0.5883, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 193/553, Loss: 0.7692, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 194/553, Loss: 0.7231, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 195/553, Loss: 0.1834, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 196/553, Loss: 0.2128, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 197/553, Loss: 0.4588, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 198/553, Loss: 0.3849, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 199/553, Loss: 0.3682, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 200/553, Loss: 0.1791, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 201/553, Loss: 0.5699, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 202/553, Loss: 0.4262, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 203/553, Loss: 0.3903, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 204/553, Loss: 0.0364, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 205/553, Loss: 0.2101, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 206/553, Loss: 0.2301, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 207/553, Loss: 0.1205, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 208/553, Loss: 0.4830, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 209/553, Loss: 0.4911, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 210/553, Loss: 0.6600, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 211/553, Loss: 0.3286, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 212/553, Loss: 0.2746, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 213/553, Loss: 0.1738, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 214/553, Loss: 0.4748, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 215/553, Loss: 0.4471, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 216/553, Loss: 0.2787, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 217/553, Loss: 0.5531, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 218/553, Loss: 0.3675, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 219/553, Loss: 0.3613, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 220/553, Loss: 0.3075, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 221/553, Loss: 0.2219, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 222/553, Loss: 0.1760, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 223/553, Loss: 0.5541, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 224/553, Loss: 0.2911, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 225/553, Loss: 0.2031, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 226/553, Loss: 0.2541, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 227/553, Loss: 0.1049, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 228/553, Loss: 0.3225, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 229/553, Loss: 0.2578, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 230/553, Loss: 0.3957, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 231/553, Loss: 0.2979, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 232/553, Loss: 0.4863, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 233/553, Loss: 0.3861, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 234/553, Loss: 0.2143, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 235/553, Loss: 0.0922, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 236/553, Loss: 0.5580, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 237/553, Loss: 0.2461, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 238/553, Loss: 0.2605, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 239/553, Loss: 0.2195, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 240/553, Loss: 0.3976, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 241/553, Loss: 0.2566, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 242/553, Loss: 0.5066, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 243/553, Loss: 0.2432, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 244/553, Loss: 0.0533, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 245/553, Loss: 0.3544, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 246/553, Loss: 0.4629, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 247/553, Loss: 0.3114, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 248/553, Loss: 0.4841, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 249/553, Loss: 0.6159, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 250/553, Loss: 0.2300, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 251/553, Loss: 0.5336, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 252/553, Loss: 0.2634, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 253/553, Loss: 0.8672, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 254/553, Loss: 0.4344, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 255/553, Loss: 0.2749, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 256/553, Loss: 0.1175, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 257/553, Loss: 0.3741, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 258/553, Loss: 0.8242, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 259/553, Loss: 0.3769, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 260/553, Loss: 0.1778, Time: 0.73 seconds\n",
            "Epoch 2/20, Batch 261/553, Loss: 0.6282, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 262/553, Loss: 0.2792, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 263/553, Loss: 0.3693, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 264/553, Loss: 0.6880, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 265/553, Loss: 0.3032, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 266/553, Loss: 0.3637, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 267/553, Loss: 0.1618, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 268/553, Loss: 0.1159, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 269/553, Loss: 0.2986, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 270/553, Loss: 0.2101, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 271/553, Loss: 0.2237, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 272/553, Loss: 0.2944, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 273/553, Loss: 0.3445, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 274/553, Loss: 0.2106, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 275/553, Loss: 0.2287, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 276/553, Loss: 0.5470, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 277/553, Loss: 0.3811, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 278/553, Loss: 0.2492, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 279/553, Loss: 0.0662, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 280/553, Loss: 0.2359, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 281/553, Loss: 0.3675, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 282/553, Loss: 0.5289, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 283/553, Loss: 0.2788, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 284/553, Loss: 0.3624, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 285/553, Loss: 0.4875, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 286/553, Loss: 0.2512, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 287/553, Loss: 0.0919, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 288/553, Loss: 0.3525, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 289/553, Loss: 0.0907, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 290/553, Loss: 0.2811, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 291/553, Loss: 0.2812, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 292/553, Loss: 0.5859, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 293/553, Loss: 0.2960, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 294/553, Loss: 0.0547, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 295/553, Loss: 0.3937, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 296/553, Loss: 0.1131, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 297/553, Loss: 0.3598, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 298/553, Loss: 0.1549, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 299/553, Loss: 0.5017, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 300/553, Loss: 0.0984, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 301/553, Loss: 1.1817, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 302/553, Loss: 0.3589, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 303/553, Loss: 0.3848, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 304/553, Loss: 0.7000, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 305/553, Loss: 0.2138, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 306/553, Loss: 0.3056, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 307/553, Loss: 0.2333, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 308/553, Loss: 0.4353, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 309/553, Loss: 0.1909, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 310/553, Loss: 0.5031, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 311/553, Loss: 0.4708, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 312/553, Loss: 0.1697, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 313/553, Loss: 0.6834, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 314/553, Loss: 0.7897, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 315/553, Loss: 0.6005, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 316/553, Loss: 0.6170, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 317/553, Loss: 0.5022, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 318/553, Loss: 0.4902, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 319/553, Loss: 0.4172, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 320/553, Loss: 0.4152, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 321/553, Loss: 0.2892, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 322/553, Loss: 0.5867, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 323/553, Loss: 0.2764, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 324/553, Loss: 0.4251, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 325/553, Loss: 0.5167, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 326/553, Loss: 0.2869, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 327/553, Loss: 0.6817, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 328/553, Loss: 0.3296, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 329/553, Loss: 0.2411, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 330/553, Loss: 0.3446, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 331/553, Loss: 0.3970, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 332/553, Loss: 0.2421, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 333/553, Loss: 0.1996, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 334/553, Loss: 0.2230, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 335/553, Loss: 0.2913, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 336/553, Loss: 0.4697, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 337/553, Loss: 0.5594, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 338/553, Loss: 0.1727, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 339/553, Loss: 0.5915, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 340/553, Loss: 0.1069, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 341/553, Loss: 0.5344, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 342/553, Loss: 0.3003, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 343/553, Loss: 0.2560, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 344/553, Loss: 0.6947, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 345/553, Loss: 0.0654, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 346/553, Loss: 0.6478, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 347/553, Loss: 0.1441, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 348/553, Loss: 0.1229, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 349/553, Loss: 0.4517, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 350/553, Loss: 0.4750, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 351/553, Loss: 0.6500, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 352/553, Loss: 0.5016, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 353/553, Loss: 0.8183, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 354/553, Loss: 0.4047, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 355/553, Loss: 0.2657, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 356/553, Loss: 0.2016, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 357/553, Loss: 0.2841, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 358/553, Loss: 0.5133, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 359/553, Loss: 0.1729, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 360/553, Loss: 0.2437, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 361/553, Loss: 0.3838, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 362/553, Loss: 0.3765, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 363/553, Loss: 0.6229, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 364/553, Loss: 0.3254, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 365/553, Loss: 0.2152, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 366/553, Loss: 0.1892, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 367/553, Loss: 0.4653, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 368/553, Loss: 0.1886, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 369/553, Loss: 0.2099, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 370/553, Loss: 0.1804, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 371/553, Loss: 0.7253, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 372/553, Loss: 0.6107, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 373/553, Loss: 0.2730, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 374/553, Loss: 0.3444, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 375/553, Loss: 0.3555, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 376/553, Loss: 0.1917, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 377/553, Loss: 0.5656, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 378/553, Loss: 0.5102, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 379/553, Loss: 0.4067, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 380/553, Loss: 0.3143, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 381/553, Loss: 0.8264, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 382/553, Loss: 0.7554, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 383/553, Loss: 0.2263, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 384/553, Loss: 0.1091, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 385/553, Loss: 0.7354, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 386/553, Loss: 0.6352, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 387/553, Loss: 0.9706, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 388/553, Loss: 0.1199, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 389/553, Loss: 0.3509, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 390/553, Loss: 0.3835, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 391/553, Loss: 0.2018, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 392/553, Loss: 0.4501, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 393/553, Loss: 0.4452, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 394/553, Loss: 0.1006, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 395/553, Loss: 0.3805, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 396/553, Loss: 0.4081, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 397/553, Loss: 0.1292, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 398/553, Loss: 0.8817, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 399/553, Loss: 0.1888, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 400/553, Loss: 0.1445, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 401/553, Loss: 0.6883, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 402/553, Loss: 0.6009, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 403/553, Loss: 0.7675, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 404/553, Loss: 0.1015, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 405/553, Loss: 0.3291, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 406/553, Loss: 0.4790, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 407/553, Loss: 0.3768, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 408/553, Loss: 0.2878, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 409/553, Loss: 0.2102, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 410/553, Loss: 0.5549, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 411/553, Loss: 0.4999, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 412/553, Loss: 0.3094, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 413/553, Loss: 0.4781, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 414/553, Loss: 0.2820, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 415/553, Loss: 0.5669, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 416/553, Loss: 0.3890, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 417/553, Loss: 0.4272, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 418/553, Loss: 0.2338, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 419/553, Loss: 0.1575, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 420/553, Loss: 0.3418, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 421/553, Loss: 0.4621, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 422/553, Loss: 0.2485, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 423/553, Loss: 0.2831, Time: 0.73 seconds\n",
            "Epoch 2/20, Batch 424/553, Loss: 0.3327, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 425/553, Loss: 0.4775, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 426/553, Loss: 0.4839, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 427/553, Loss: 0.1436, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 428/553, Loss: 0.1546, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 429/553, Loss: 0.2595, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 430/553, Loss: 0.1892, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 431/553, Loss: 0.5183, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 432/553, Loss: 0.2763, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 433/553, Loss: 0.6723, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 434/553, Loss: 0.3739, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 435/553, Loss: 0.2798, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 436/553, Loss: 0.2077, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 437/553, Loss: 0.3709, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 438/553, Loss: 0.3517, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 439/553, Loss: 0.7036, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 440/553, Loss: 0.4917, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 441/553, Loss: 0.2433, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 442/553, Loss: 0.4579, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 443/553, Loss: 0.3587, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 444/553, Loss: 0.2732, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 445/553, Loss: 0.8316, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 446/553, Loss: 0.3483, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 447/553, Loss: 0.2097, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 448/553, Loss: 0.2051, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 449/553, Loss: 0.1772, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 450/553, Loss: 0.3481, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 451/553, Loss: 0.3867, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 452/553, Loss: 0.1747, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 453/553, Loss: 0.4017, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 454/553, Loss: 0.3247, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 455/553, Loss: 0.1334, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 456/553, Loss: 0.1527, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 457/553, Loss: 0.2921, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 458/553, Loss: 0.1463, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 459/553, Loss: 0.3734, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 460/553, Loss: 0.5134, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 461/553, Loss: 0.5343, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 462/553, Loss: 0.4021, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 463/553, Loss: 0.6622, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 464/553, Loss: 0.7912, Time: 0.77 seconds\n",
            "Epoch 2/20, Batch 465/553, Loss: 0.2499, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 466/553, Loss: 0.7690, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 467/553, Loss: 0.7561, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 468/553, Loss: 0.3319, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 469/553, Loss: 0.3681, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 470/553, Loss: 0.8527, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 471/553, Loss: 0.8183, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 472/553, Loss: 0.5494, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 473/553, Loss: 0.5222, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 474/553, Loss: 0.3312, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 475/553, Loss: 0.6452, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 476/553, Loss: 0.2139, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 477/553, Loss: 0.4092, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 478/553, Loss: 0.5476, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 479/553, Loss: 0.5188, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 480/553, Loss: 0.2924, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 481/553, Loss: 0.1855, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 482/553, Loss: 0.2013, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 483/553, Loss: 0.1372, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 484/553, Loss: 0.7948, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 485/553, Loss: 0.6033, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 486/553, Loss: 0.3443, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 487/553, Loss: 0.7156, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 488/553, Loss: 0.4317, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 489/553, Loss: 0.5573, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 490/553, Loss: 0.4838, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 491/553, Loss: 0.4435, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 492/553, Loss: 0.1927, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 493/553, Loss: 0.5874, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 494/553, Loss: 0.3226, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 495/553, Loss: 0.3634, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 496/553, Loss: 0.6496, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 497/553, Loss: 0.6105, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 498/553, Loss: 0.4371, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 499/553, Loss: 0.4845, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 500/553, Loss: 0.1736, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 501/553, Loss: 0.5416, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 502/553, Loss: 0.2726, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 503/553, Loss: 0.3680, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 504/553, Loss: 0.6728, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 505/553, Loss: 0.4235, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 506/553, Loss: 0.4679, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 507/553, Loss: 0.1387, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 508/553, Loss: 0.3467, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 509/553, Loss: 1.0252, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 510/553, Loss: 0.6820, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 511/553, Loss: 0.2410, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 512/553, Loss: 0.4346, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 513/553, Loss: 0.2583, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 514/553, Loss: 0.2730, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 515/553, Loss: 0.4177, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 516/553, Loss: 0.6443, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 517/553, Loss: 0.2809, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 518/553, Loss: 0.4932, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 519/553, Loss: 0.6582, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 520/553, Loss: 0.6061, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 521/553, Loss: 0.2930, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 522/553, Loss: 0.4961, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 523/553, Loss: 0.2669, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 524/553, Loss: 0.3241, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 525/553, Loss: 0.3639, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 526/553, Loss: 0.3438, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 527/553, Loss: 0.1602, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 528/553, Loss: 0.1604, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 529/553, Loss: 0.4252, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 530/553, Loss: 0.1873, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 531/553, Loss: 0.7745, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 532/553, Loss: 0.4535, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 533/553, Loss: 0.3875, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 534/553, Loss: 0.2060, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 535/553, Loss: 0.3697, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 536/553, Loss: 0.5246, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 537/553, Loss: 0.2458, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 538/553, Loss: 0.4512, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 539/553, Loss: 0.3342, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 540/553, Loss: 0.2344, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 541/553, Loss: 0.4016, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 542/553, Loss: 0.6183, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 543/553, Loss: 0.3130, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 544/553, Loss: 0.1527, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 545/553, Loss: 0.3232, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 546/553, Loss: 0.7666, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 547/553, Loss: 0.3286, Time: 0.74 seconds\n",
            "Epoch 2/20, Batch 548/553, Loss: 0.2431, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 549/553, Loss: 0.4098, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 550/553, Loss: 0.4602, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 551/553, Loss: 0.4654, Time: 0.76 seconds\n",
            "Epoch 2/20, Batch 552/553, Loss: 0.2092, Time: 0.75 seconds\n",
            "Epoch 2/20, Batch 553/553, Loss: 0.7700, Time: 0.10 seconds\n",
            "Epoch 2/20, Training Loss: 0.4030, Time: 417.63 seconds\n",
            "Validation Loss: 0.3835, Accuracy: 0.8561\n",
            "Epoch 3/20, Batch 1/553, Loss: 0.3993, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 2/553, Loss: 0.6901, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 3/553, Loss: 0.2474, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 4/553, Loss: 0.1372, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 5/553, Loss: 0.2758, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 6/553, Loss: 0.1960, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 7/553, Loss: 0.5609, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 8/553, Loss: 0.4190, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 9/553, Loss: 0.2902, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 10/553, Loss: 0.3442, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 11/553, Loss: 0.3185, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 12/553, Loss: 0.3105, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 13/553, Loss: 0.2919, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 14/553, Loss: 0.5541, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 15/553, Loss: 0.5624, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 16/553, Loss: 0.4090, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 17/553, Loss: 0.4135, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 18/553, Loss: 0.2143, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 19/553, Loss: 0.5305, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 20/553, Loss: 0.1647, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 21/553, Loss: 0.2416, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 22/553, Loss: 0.3832, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 23/553, Loss: 0.1785, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 24/553, Loss: 0.5830, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 25/553, Loss: 0.5048, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 26/553, Loss: 0.7300, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 27/553, Loss: 0.3010, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 28/553, Loss: 0.2993, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 29/553, Loss: 0.5835, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 30/553, Loss: 0.0569, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 31/553, Loss: 0.3681, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 32/553, Loss: 0.1990, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 33/553, Loss: 0.2944, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 34/553, Loss: 0.4269, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 35/553, Loss: 0.1082, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 36/553, Loss: 0.4927, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 37/553, Loss: 1.1494, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 38/553, Loss: 0.3056, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 39/553, Loss: 0.2676, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 40/553, Loss: 0.5324, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 41/553, Loss: 0.2411, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 42/553, Loss: 0.2544, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 43/553, Loss: 0.4477, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 44/553, Loss: 0.2703, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 45/553, Loss: 0.7166, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 46/553, Loss: 0.5386, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 47/553, Loss: 0.7300, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 48/553, Loss: 0.2533, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 49/553, Loss: 0.3687, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 50/553, Loss: 0.4820, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 51/553, Loss: 0.5746, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 52/553, Loss: 0.1912, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 53/553, Loss: 0.5186, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 54/553, Loss: 0.3209, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 55/553, Loss: 0.7467, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 56/553, Loss: 0.6992, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 57/553, Loss: 0.8547, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 58/553, Loss: 0.7427, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 59/553, Loss: 0.4982, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 60/553, Loss: 0.2842, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 61/553, Loss: 0.2617, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 62/553, Loss: 0.7930, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 63/553, Loss: 0.2291, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 64/553, Loss: 0.5957, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 65/553, Loss: 0.4510, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 66/553, Loss: 0.2152, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 67/553, Loss: 1.0627, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 68/553, Loss: 0.2419, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 69/553, Loss: 0.3768, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 70/553, Loss: 0.7024, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 71/553, Loss: 0.3860, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 72/553, Loss: 0.3670, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 73/553, Loss: 0.2405, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 74/553, Loss: 0.3347, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 75/553, Loss: 0.2341, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 76/553, Loss: 0.3700, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 77/553, Loss: 0.3618, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 78/553, Loss: 0.1447, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 79/553, Loss: 0.2058, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 80/553, Loss: 0.1990, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 81/553, Loss: 0.5280, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 82/553, Loss: 0.4421, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 83/553, Loss: 0.3924, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 84/553, Loss: 0.2478, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 85/553, Loss: 0.2120, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 86/553, Loss: 0.1508, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 87/553, Loss: 0.2216, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 88/553, Loss: 0.2492, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 89/553, Loss: 0.1430, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 90/553, Loss: 0.2682, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 91/553, Loss: 0.3453, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 92/553, Loss: 0.2452, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 93/553, Loss: 0.2101, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 94/553, Loss: 0.5054, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 95/553, Loss: 0.3452, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 96/553, Loss: 0.5540, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 97/553, Loss: 0.3486, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 98/553, Loss: 0.3527, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 99/553, Loss: 0.6080, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 100/553, Loss: 0.3692, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 101/553, Loss: 0.1536, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 102/553, Loss: 0.2566, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 103/553, Loss: 0.1950, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 104/553, Loss: 0.1169, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 105/553, Loss: 0.5921, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 106/553, Loss: 0.7665, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 107/553, Loss: 0.4912, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 108/553, Loss: 0.1479, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 109/553, Loss: 0.2076, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 110/553, Loss: 0.6087, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 111/553, Loss: 0.3614, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 112/553, Loss: 0.2278, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 113/553, Loss: 0.1424, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 114/553, Loss: 0.3883, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 115/553, Loss: 0.4798, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 116/553, Loss: 0.8320, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 117/553, Loss: 0.2580, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 118/553, Loss: 0.1377, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 119/553, Loss: 0.2281, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 120/553, Loss: 0.3973, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 121/553, Loss: 0.4731, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 122/553, Loss: 0.6440, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 123/553, Loss: 0.3926, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 124/553, Loss: 0.5177, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 125/553, Loss: 0.2148, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 126/553, Loss: 0.2933, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 127/553, Loss: 0.5436, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 128/553, Loss: 0.4488, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 129/553, Loss: 0.0994, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 130/553, Loss: 0.7903, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 131/553, Loss: 0.2578, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 132/553, Loss: 0.6612, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 133/553, Loss: 0.6393, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 134/553, Loss: 0.3709, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 135/553, Loss: 0.1335, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 136/553, Loss: 0.5056, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 137/553, Loss: 0.5957, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 138/553, Loss: 0.1402, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 139/553, Loss: 0.4481, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 140/553, Loss: 0.4217, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 141/553, Loss: 0.4671, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 142/553, Loss: 0.3325, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 143/553, Loss: 0.1522, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 144/553, Loss: 0.1176, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 145/553, Loss: 0.3006, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 146/553, Loss: 0.0563, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 147/553, Loss: 1.0424, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 148/553, Loss: 0.4862, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 149/553, Loss: 0.2173, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 150/553, Loss: 0.6564, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 151/553, Loss: 0.2428, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 152/553, Loss: 0.4402, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 153/553, Loss: 0.0625, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 154/553, Loss: 0.2776, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 155/553, Loss: 0.4458, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 156/553, Loss: 0.7561, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 157/553, Loss: 0.5681, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 158/553, Loss: 0.6754, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 159/553, Loss: 0.2432, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 160/553, Loss: 0.1599, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 161/553, Loss: 0.5228, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 162/553, Loss: 0.4212, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 163/553, Loss: 0.7109, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 164/553, Loss: 0.1460, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 165/553, Loss: 0.5279, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 166/553, Loss: 0.4017, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 167/553, Loss: 0.3270, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 168/553, Loss: 0.1522, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 169/553, Loss: 0.5242, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 170/553, Loss: 0.2046, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 171/553, Loss: 0.4516, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 172/553, Loss: 0.3456, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 173/553, Loss: 0.4239, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 174/553, Loss: 0.2785, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 175/553, Loss: 0.3598, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 176/553, Loss: 0.1067, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 177/553, Loss: 0.0891, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 178/553, Loss: 0.2518, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 179/553, Loss: 0.4200, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 180/553, Loss: 0.3105, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 181/553, Loss: 0.3292, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 182/553, Loss: 0.4637, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 183/553, Loss: 0.5843, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 184/553, Loss: 0.5804, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 185/553, Loss: 0.4548, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 186/553, Loss: 0.5660, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 187/553, Loss: 0.0944, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 188/553, Loss: 0.3797, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 189/553, Loss: 0.5027, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 190/553, Loss: 0.5398, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 191/553, Loss: 0.4705, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 192/553, Loss: 0.6102, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 193/553, Loss: 0.7157, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 194/553, Loss: 0.5005, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 195/553, Loss: 0.1731, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 196/553, Loss: 0.6696, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 197/553, Loss: 0.6200, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 198/553, Loss: 0.2426, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 199/553, Loss: 0.3425, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 200/553, Loss: 0.5781, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 201/553, Loss: 0.3857, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 202/553, Loss: 0.3062, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 203/553, Loss: 0.3959, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 204/553, Loss: 0.1749, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 205/553, Loss: 0.5554, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 206/553, Loss: 0.5801, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 207/553, Loss: 0.1889, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 208/553, Loss: 0.3827, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 209/553, Loss: 0.2870, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 210/553, Loss: 0.5273, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 211/553, Loss: 0.0674, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 212/553, Loss: 0.5938, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 213/553, Loss: 0.4666, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 214/553, Loss: 0.3024, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 215/553, Loss: 0.4420, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 216/553, Loss: 0.3641, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 217/553, Loss: 1.0354, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 218/553, Loss: 0.1999, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 219/553, Loss: 0.8267, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 220/553, Loss: 0.5970, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 221/553, Loss: 0.1936, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 222/553, Loss: 0.5232, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 223/553, Loss: 0.6196, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 224/553, Loss: 0.6637, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 225/553, Loss: 0.6183, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 226/553, Loss: 0.5815, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 227/553, Loss: 0.5377, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 228/553, Loss: 0.3570, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 229/553, Loss: 0.4181, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 230/553, Loss: 0.2464, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 231/553, Loss: 0.2873, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 232/553, Loss: 0.3591, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 233/553, Loss: 0.7528, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 234/553, Loss: 0.1693, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 235/553, Loss: 0.2184, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 236/553, Loss: 0.2810, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 237/553, Loss: 0.3540, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 238/553, Loss: 0.7121, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 239/553, Loss: 0.5670, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 240/553, Loss: 0.2509, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 241/553, Loss: 0.5467, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 242/553, Loss: 0.4158, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 243/553, Loss: 0.3665, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 244/553, Loss: 0.1214, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 245/553, Loss: 0.6900, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 246/553, Loss: 0.1181, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 247/553, Loss: 0.3511, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 248/553, Loss: 0.2673, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 249/553, Loss: 0.3462, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 250/553, Loss: 0.1342, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 251/553, Loss: 0.7087, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 252/553, Loss: 0.2409, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 253/553, Loss: 0.6801, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 254/553, Loss: 0.2396, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 255/553, Loss: 0.1436, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 256/553, Loss: 0.6350, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 257/553, Loss: 0.6980, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 258/553, Loss: 0.2215, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 259/553, Loss: 0.3580, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 260/553, Loss: 0.4494, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 261/553, Loss: 0.3902, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 262/553, Loss: 0.4285, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 263/553, Loss: 0.5899, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 264/553, Loss: 0.4959, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 265/553, Loss: 0.6072, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 266/553, Loss: 0.3401, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 267/553, Loss: 0.1848, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 268/553, Loss: 0.5930, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 269/553, Loss: 0.4830, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 270/553, Loss: 0.5741, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 271/553, Loss: 0.6274, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 272/553, Loss: 0.5301, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 273/553, Loss: 0.2244, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 274/553, Loss: 0.6250, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 275/553, Loss: 0.5345, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 276/553, Loss: 0.7127, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 277/553, Loss: 0.5202, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 278/553, Loss: 0.4187, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 279/553, Loss: 0.2219, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 280/553, Loss: 0.8154, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 281/553, Loss: 0.1785, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 282/553, Loss: 0.4580, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 283/553, Loss: 0.1130, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 284/553, Loss: 0.7773, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 285/553, Loss: 0.4075, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 286/553, Loss: 0.3727, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 287/553, Loss: 0.6449, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 288/553, Loss: 0.7143, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 289/553, Loss: 0.4418, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 290/553, Loss: 0.5418, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 291/553, Loss: 0.3368, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 292/553, Loss: 0.4450, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 293/553, Loss: 0.3594, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 294/553, Loss: 0.1097, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 295/553, Loss: 0.4173, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 296/553, Loss: 0.2027, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 297/553, Loss: 0.1248, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 298/553, Loss: 0.7414, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 299/553, Loss: 0.1231, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 300/553, Loss: 0.6490, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 301/553, Loss: 0.1838, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 302/553, Loss: 0.1715, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 303/553, Loss: 0.3250, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 304/553, Loss: 0.3677, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 305/553, Loss: 0.6289, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 306/553, Loss: 0.2355, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 307/553, Loss: 0.3099, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 308/553, Loss: 1.0027, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 309/553, Loss: 0.5012, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 310/553, Loss: 0.0921, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 311/553, Loss: 0.4155, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 312/553, Loss: 0.3651, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 313/553, Loss: 0.4330, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 314/553, Loss: 0.6523, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 315/553, Loss: 0.6368, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 316/553, Loss: 0.6862, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 317/553, Loss: 0.0516, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 318/553, Loss: 0.4942, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 319/553, Loss: 0.7352, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 320/553, Loss: 0.1525, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 321/553, Loss: 0.5091, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 322/553, Loss: 0.4926, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 323/553, Loss: 0.6449, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 324/553, Loss: 0.3167, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 325/553, Loss: 0.1174, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 326/553, Loss: 1.0668, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 327/553, Loss: 0.2419, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 328/553, Loss: 0.6000, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 329/553, Loss: 0.3793, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 330/553, Loss: 0.4179, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 331/553, Loss: 0.7799, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 332/553, Loss: 0.7079, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 333/553, Loss: 0.2508, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 334/553, Loss: 0.4451, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 335/553, Loss: 0.6526, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 336/553, Loss: 0.4010, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 337/553, Loss: 0.6280, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 338/553, Loss: 0.1086, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 339/553, Loss: 0.3722, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 340/553, Loss: 0.6011, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 341/553, Loss: 0.2437, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 342/553, Loss: 0.2315, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 343/553, Loss: 0.4609, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 344/553, Loss: 0.3570, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 345/553, Loss: 0.4984, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 346/553, Loss: 0.1890, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 347/553, Loss: 0.3811, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 348/553, Loss: 0.3659, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 349/553, Loss: 0.1847, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 350/553, Loss: 0.2767, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 351/553, Loss: 0.3542, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 352/553, Loss: 0.5148, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 353/553, Loss: 0.3568, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 354/553, Loss: 0.4606, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 355/553, Loss: 0.3286, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 356/553, Loss: 0.2189, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 357/553, Loss: 0.5708, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 358/553, Loss: 0.6694, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 359/553, Loss: 0.5612, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 360/553, Loss: 0.3067, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 361/553, Loss: 0.4289, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 362/553, Loss: 0.1190, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 363/553, Loss: 0.3043, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 364/553, Loss: 0.0929, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 365/553, Loss: 0.8866, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 366/553, Loss: 0.7231, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 367/553, Loss: 0.4088, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 368/553, Loss: 0.4718, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 369/553, Loss: 0.6570, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 370/553, Loss: 0.5850, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 371/553, Loss: 0.4179, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 372/553, Loss: 0.7265, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 373/553, Loss: 0.3085, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 374/553, Loss: 0.5055, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 375/553, Loss: 0.3589, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 376/553, Loss: 0.1660, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 377/553, Loss: 0.5884, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 378/553, Loss: 0.1586, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 379/553, Loss: 0.4627, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 380/553, Loss: 0.2619, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 381/553, Loss: 0.2978, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 382/553, Loss: 0.1436, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 383/553, Loss: 0.3272, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 384/553, Loss: 0.4808, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 385/553, Loss: 0.3870, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 386/553, Loss: 0.4276, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 387/553, Loss: 0.4502, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 388/553, Loss: 0.2886, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 389/553, Loss: 0.3290, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 390/553, Loss: 0.0880, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 391/553, Loss: 0.2496, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 392/553, Loss: 0.3984, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 393/553, Loss: 0.2657, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 394/553, Loss: 0.6290, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 395/553, Loss: 0.0982, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 396/553, Loss: 0.3416, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 397/553, Loss: 0.3547, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 398/553, Loss: 0.4259, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 399/553, Loss: 0.1833, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 400/553, Loss: 0.0571, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 401/553, Loss: 0.1577, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 402/553, Loss: 0.1736, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 403/553, Loss: 0.3356, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 404/553, Loss: 0.5839, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 405/553, Loss: 0.8631, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 406/553, Loss: 0.8737, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 407/553, Loss: 0.4053, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 408/553, Loss: 0.3737, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 409/553, Loss: 0.1263, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 410/553, Loss: 0.2504, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 411/553, Loss: 0.2723, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 412/553, Loss: 0.5548, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 413/553, Loss: 0.4293, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 414/553, Loss: 0.2699, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 415/553, Loss: 0.1692, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 416/553, Loss: 0.1537, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 417/553, Loss: 0.1985, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 418/553, Loss: 0.4481, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 419/553, Loss: 0.2261, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 420/553, Loss: 0.5130, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 421/553, Loss: 0.4670, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 422/553, Loss: 0.1438, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 423/553, Loss: 0.4136, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 424/553, Loss: 0.4075, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 425/553, Loss: 0.2350, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 426/553, Loss: 0.5143, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 427/553, Loss: 0.4170, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 428/553, Loss: 0.3827, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 429/553, Loss: 0.1760, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 430/553, Loss: 0.5072, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 431/553, Loss: 0.3465, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 432/553, Loss: 0.2391, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 433/553, Loss: 0.4344, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 434/553, Loss: 0.1741, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 435/553, Loss: 0.3017, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 436/553, Loss: 0.1749, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 437/553, Loss: 0.3488, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 438/553, Loss: 0.3757, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 439/553, Loss: 0.3088, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 440/553, Loss: 0.4244, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 441/553, Loss: 0.5880, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 442/553, Loss: 0.6091, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 443/553, Loss: 0.2789, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 444/553, Loss: 0.2439, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 445/553, Loss: 0.4560, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 446/553, Loss: 0.1883, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 447/553, Loss: 0.3288, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 448/553, Loss: 0.5462, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 449/553, Loss: 0.1541, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 450/553, Loss: 0.3735, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 451/553, Loss: 0.2263, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 452/553, Loss: 0.2776, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 453/553, Loss: 0.2572, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 454/553, Loss: 0.8159, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 455/553, Loss: 0.5404, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 456/553, Loss: 0.4377, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 457/553, Loss: 0.2925, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 458/553, Loss: 0.2548, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 459/553, Loss: 0.3787, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 460/553, Loss: 0.2725, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 461/553, Loss: 0.0799, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 462/553, Loss: 0.3064, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 463/553, Loss: 0.3035, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 464/553, Loss: 0.3533, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 465/553, Loss: 0.1194, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 466/553, Loss: 1.0758, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 467/553, Loss: 0.1082, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 468/553, Loss: 0.5138, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 469/553, Loss: 0.1500, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 470/553, Loss: 0.9453, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 471/553, Loss: 0.4015, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 472/553, Loss: 0.4841, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 473/553, Loss: 0.6349, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 474/553, Loss: 1.0775, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 475/553, Loss: 0.6607, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 476/553, Loss: 0.4651, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 477/553, Loss: 0.3496, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 478/553, Loss: 0.3724, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 479/553, Loss: 0.2688, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 480/553, Loss: 0.5501, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 481/553, Loss: 0.7031, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 482/553, Loss: 0.3729, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 483/553, Loss: 0.3353, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 484/553, Loss: 0.1942, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 485/553, Loss: 0.4441, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 486/553, Loss: 0.4106, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 487/553, Loss: 0.5355, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 488/553, Loss: 0.7060, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 489/553, Loss: 0.4037, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 490/553, Loss: 0.2315, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 491/553, Loss: 0.1311, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 492/553, Loss: 0.5558, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 493/553, Loss: 0.3599, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 494/553, Loss: 0.5825, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 495/553, Loss: 0.8739, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 496/553, Loss: 0.3900, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 497/553, Loss: 0.4077, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 498/553, Loss: 0.1339, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 499/553, Loss: 0.1858, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 500/553, Loss: 0.3861, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 501/553, Loss: 0.3175, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 502/553, Loss: 0.3982, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 503/553, Loss: 0.4288, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 504/553, Loss: 1.0228, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 505/553, Loss: 0.5464, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 506/553, Loss: 0.2483, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 507/553, Loss: 0.2139, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 508/553, Loss: 0.2851, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 509/553, Loss: 0.3782, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 510/553, Loss: 0.3148, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 511/553, Loss: 0.0952, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 512/553, Loss: 0.4171, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 513/553, Loss: 0.3431, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 514/553, Loss: 0.0427, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 515/553, Loss: 0.5930, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 516/553, Loss: 0.3108, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 517/553, Loss: 0.3643, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 518/553, Loss: 0.5780, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 519/553, Loss: 0.0479, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 520/553, Loss: 0.1424, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 521/553, Loss: 0.3344, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 522/553, Loss: 0.5269, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 523/553, Loss: 0.6818, Time: 0.73 seconds\n",
            "Epoch 3/20, Batch 524/553, Loss: 0.4014, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 525/553, Loss: 0.4523, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 526/553, Loss: 0.2985, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 527/553, Loss: 0.8758, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 528/553, Loss: 0.5150, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 529/553, Loss: 0.3851, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 530/553, Loss: 0.6044, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 531/553, Loss: 0.5442, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 532/553, Loss: 0.5134, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 533/553, Loss: 0.2991, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 534/553, Loss: 0.2937, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 535/553, Loss: 0.3862, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 536/553, Loss: 0.2479, Time: 0.77 seconds\n",
            "Epoch 3/20, Batch 537/553, Loss: 0.0878, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 538/553, Loss: 0.2573, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 539/553, Loss: 0.6649, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 540/553, Loss: 0.2285, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 541/553, Loss: 0.4887, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 542/553, Loss: 0.4552, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 543/553, Loss: 0.4931, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 544/553, Loss: 0.4426, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 545/553, Loss: 0.1950, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 546/553, Loss: 0.1763, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 547/553, Loss: 0.1947, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 548/553, Loss: 0.4039, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 549/553, Loss: 0.3077, Time: 0.75 seconds\n",
            "Epoch 3/20, Batch 550/553, Loss: 0.2907, Time: 0.74 seconds\n",
            "Epoch 3/20, Batch 551/553, Loss: 0.3482, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 552/553, Loss: 0.4301, Time: 0.76 seconds\n",
            "Epoch 3/20, Batch 553/553, Loss: 2.0085, Time: 0.11 seconds\n",
            "Epoch 3/20, Training Loss: 0.4054, Time: 417.05 seconds\n",
            "Validation Loss: 0.3808, Accuracy: 0.8561\n",
            "Epoch 4/20, Batch 1/553, Loss: 0.0531, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 2/553, Loss: 0.4233, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 3/553, Loss: 0.4577, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 4/553, Loss: 0.1624, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 5/553, Loss: 0.6244, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 6/553, Loss: 0.2554, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 7/553, Loss: 0.6031, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 8/553, Loss: 0.4043, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 9/553, Loss: 0.2884, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 10/553, Loss: 0.2912, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 11/553, Loss: 0.4553, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 12/553, Loss: 0.1703, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 13/553, Loss: 0.4535, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 14/553, Loss: 0.2844, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 15/553, Loss: 0.5759, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 16/553, Loss: 0.0906, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 17/553, Loss: 0.2999, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 18/553, Loss: 0.4349, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 19/553, Loss: 0.4620, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 20/553, Loss: 0.8178, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 21/553, Loss: 0.1702, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 22/553, Loss: 0.1594, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 23/553, Loss: 0.2878, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 24/553, Loss: 0.3948, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 25/553, Loss: 0.5018, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 26/553, Loss: 0.1431, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 27/553, Loss: 0.4248, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 28/553, Loss: 0.5342, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 29/553, Loss: 0.4880, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 30/553, Loss: 0.3171, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 31/553, Loss: 0.3385, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 32/553, Loss: 0.4867, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 33/553, Loss: 0.5099, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 34/553, Loss: 0.1222, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 35/553, Loss: 0.3322, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 36/553, Loss: 0.4048, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 37/553, Loss: 0.3315, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 38/553, Loss: 0.7039, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 39/553, Loss: 0.8137, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 40/553, Loss: 0.2776, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 41/553, Loss: 0.6003, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 42/553, Loss: 0.5290, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 43/553, Loss: 0.3359, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 44/553, Loss: 0.6657, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 45/553, Loss: 0.3496, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 46/553, Loss: 0.3813, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 47/553, Loss: 0.3210, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 48/553, Loss: 0.1650, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 49/553, Loss: 0.3648, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 50/553, Loss: 0.5087, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 51/553, Loss: 0.2162, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 52/553, Loss: 0.2627, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 53/553, Loss: 0.2132, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 54/553, Loss: 0.2954, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 55/553, Loss: 0.2842, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 56/553, Loss: 0.6717, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 57/553, Loss: 0.3331, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 58/553, Loss: 0.2764, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 59/553, Loss: 0.4767, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 60/553, Loss: 0.4581, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 61/553, Loss: 0.4705, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 62/553, Loss: 0.1505, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 63/553, Loss: 0.4083, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 64/553, Loss: 0.9417, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 65/553, Loss: 0.1977, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 66/553, Loss: 0.4612, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 67/553, Loss: 0.2802, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 68/553, Loss: 0.4878, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 69/553, Loss: 0.3677, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 70/553, Loss: 0.1389, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 71/553, Loss: 0.4353, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 72/553, Loss: 0.4670, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 73/553, Loss: 0.5304, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 74/553, Loss: 0.4858, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 75/553, Loss: 0.0414, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 76/553, Loss: 0.4106, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 77/553, Loss: 0.4838, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 78/553, Loss: 0.8306, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 79/553, Loss: 0.3886, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 80/553, Loss: 0.3588, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 81/553, Loss: 0.4086, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 82/553, Loss: 0.2087, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 83/553, Loss: 0.0645, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 84/553, Loss: 0.1849, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 85/553, Loss: 0.6704, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 86/553, Loss: 0.8085, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 87/553, Loss: 0.2327, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 88/553, Loss: 0.5188, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 89/553, Loss: 0.5397, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 90/553, Loss: 0.4271, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 91/553, Loss: 0.1818, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 92/553, Loss: 0.6058, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 93/553, Loss: 0.3895, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 94/553, Loss: 0.2836, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 95/553, Loss: 0.3123, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 96/553, Loss: 0.1334, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 97/553, Loss: 0.1857, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 98/553, Loss: 0.3670, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 99/553, Loss: 0.1192, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 100/553, Loss: 0.3777, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 101/553, Loss: 0.6585, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 102/553, Loss: 0.4654, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 103/553, Loss: 0.3401, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 104/553, Loss: 0.1175, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 105/553, Loss: 0.2598, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 106/553, Loss: 0.2637, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 107/553, Loss: 0.9757, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 108/553, Loss: 0.0465, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 109/553, Loss: 0.3959, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 110/553, Loss: 0.2364, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 111/553, Loss: 0.0516, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 112/553, Loss: 0.4788, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 113/553, Loss: 0.3390, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 114/553, Loss: 0.3077, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 115/553, Loss: 0.1966, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 116/553, Loss: 0.5449, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 117/553, Loss: 0.4765, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 118/553, Loss: 0.4562, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 119/553, Loss: 0.7929, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 120/553, Loss: 0.0863, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 121/553, Loss: 0.7999, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 122/553, Loss: 0.4171, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 123/553, Loss: 0.4411, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 124/553, Loss: 0.3512, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 125/553, Loss: 0.1691, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 126/553, Loss: 0.3123, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 127/553, Loss: 0.3702, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 128/553, Loss: 0.2667, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 129/553, Loss: 0.2570, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 130/553, Loss: 0.1172, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 131/553, Loss: 0.7880, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 132/553, Loss: 0.3569, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 133/553, Loss: 0.5132, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 134/553, Loss: 0.1079, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 135/553, Loss: 0.1034, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 136/553, Loss: 0.3250, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 137/553, Loss: 0.5785, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 138/553, Loss: 0.1965, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 139/553, Loss: 0.7486, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 140/553, Loss: 0.3619, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 141/553, Loss: 0.4045, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 142/553, Loss: 0.4039, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 143/553, Loss: 0.3270, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 144/553, Loss: 0.8600, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 145/553, Loss: 0.3048, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 146/553, Loss: 0.3747, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 147/553, Loss: 0.1174, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 148/553, Loss: 0.2206, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 149/553, Loss: 0.6970, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 150/553, Loss: 0.7796, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 151/553, Loss: 1.0117, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 152/553, Loss: 0.1705, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 153/553, Loss: 0.6216, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 154/553, Loss: 0.2742, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 155/553, Loss: 0.4947, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 156/553, Loss: 0.2595, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 157/553, Loss: 0.4833, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 158/553, Loss: 0.4151, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 159/553, Loss: 0.4475, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 160/553, Loss: 0.1736, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 161/553, Loss: 0.2835, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 162/553, Loss: 0.4928, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 163/553, Loss: 0.0991, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 164/553, Loss: 0.2233, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 165/553, Loss: 0.5624, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 166/553, Loss: 0.1061, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 167/553, Loss: 0.3730, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 168/553, Loss: 0.1978, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 169/553, Loss: 0.2418, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 170/553, Loss: 0.3046, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 171/553, Loss: 0.5497, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 172/553, Loss: 0.3559, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 173/553, Loss: 0.5003, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 174/553, Loss: 0.4345, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 175/553, Loss: 0.1986, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 176/553, Loss: 0.3693, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 177/553, Loss: 0.4763, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 178/553, Loss: 0.2580, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 179/553, Loss: 0.3731, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 180/553, Loss: 0.1924, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 181/553, Loss: 0.4132, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 182/553, Loss: 0.4125, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 183/553, Loss: 0.4200, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 184/553, Loss: 0.7474, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 185/553, Loss: 0.9107, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 186/553, Loss: 0.2121, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 187/553, Loss: 0.3910, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 188/553, Loss: 0.6801, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 189/553, Loss: 0.4270, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 190/553, Loss: 0.4280, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 191/553, Loss: 0.2991, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 192/553, Loss: 0.2801, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 193/553, Loss: 0.6500, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 194/553, Loss: 0.4993, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 195/553, Loss: 0.4303, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 196/553, Loss: 0.7980, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 197/553, Loss: 0.8172, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 198/553, Loss: 0.3465, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 199/553, Loss: 0.2909, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 200/553, Loss: 0.5110, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 201/553, Loss: 0.5190, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 202/553, Loss: 0.1445, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 203/553, Loss: 0.8485, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 204/553, Loss: 0.8130, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 205/553, Loss: 0.1544, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 206/553, Loss: 0.2450, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 207/553, Loss: 0.3074, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 208/553, Loss: 0.2985, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 209/553, Loss: 0.2686, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 210/553, Loss: 0.0471, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 211/553, Loss: 0.4126, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 212/553, Loss: 0.1684, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 213/553, Loss: 0.5107, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 214/553, Loss: 0.3839, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 215/553, Loss: 0.8126, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 216/553, Loss: 0.1026, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 217/553, Loss: 0.5478, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 218/553, Loss: 0.6729, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 219/553, Loss: 0.3653, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 220/553, Loss: 0.2294, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 221/553, Loss: 0.7654, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 222/553, Loss: 0.2443, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 223/553, Loss: 0.1428, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 224/553, Loss: 0.1283, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 225/553, Loss: 0.6106, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 226/553, Loss: 0.3302, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 227/553, Loss: 0.2834, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 228/553, Loss: 0.2137, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 229/553, Loss: 0.1500, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 230/553, Loss: 0.4455, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 231/553, Loss: 0.2492, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 232/553, Loss: 1.3591, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 233/553, Loss: 0.1441, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 234/553, Loss: 0.4533, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 235/553, Loss: 0.5671, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 236/553, Loss: 0.6818, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 237/553, Loss: 0.3304, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 238/553, Loss: 0.1507, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 239/553, Loss: 0.3748, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 240/553, Loss: 0.3170, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 241/553, Loss: 0.6490, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 242/553, Loss: 0.1845, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 243/553, Loss: 0.3224, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 244/553, Loss: 0.3632, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 245/553, Loss: 0.6373, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 246/553, Loss: 0.1243, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 247/553, Loss: 0.1221, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 248/553, Loss: 0.3430, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 249/553, Loss: 0.1921, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 250/553, Loss: 0.1999, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 251/553, Loss: 0.7155, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 252/553, Loss: 0.3808, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 253/553, Loss: 0.4885, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 254/553, Loss: 0.1712, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 255/553, Loss: 0.3526, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 256/553, Loss: 0.4650, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 257/553, Loss: 0.2428, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 258/553, Loss: 0.6864, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 259/553, Loss: 0.3236, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 260/553, Loss: 0.4927, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 261/553, Loss: 0.6273, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 262/553, Loss: 0.2095, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 263/553, Loss: 0.3247, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 264/553, Loss: 0.5764, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 265/553, Loss: 0.2605, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 266/553, Loss: 0.5125, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 267/553, Loss: 0.4380, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 268/553, Loss: 0.5119, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 269/553, Loss: 0.0859, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 270/553, Loss: 0.3495, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 271/553, Loss: 0.2209, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 272/553, Loss: 0.1313, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 273/553, Loss: 0.6250, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 274/553, Loss: 0.3188, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 275/553, Loss: 0.2374, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 276/553, Loss: 0.0831, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 277/553, Loss: 0.2463, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 278/553, Loss: 0.0870, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 279/553, Loss: 0.2670, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 280/553, Loss: 0.3441, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 281/553, Loss: 0.0538, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 282/553, Loss: 0.2977, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 283/553, Loss: 0.5558, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 284/553, Loss: 0.6697, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 285/553, Loss: 0.3073, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 286/553, Loss: 0.5647, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 287/553, Loss: 0.2378, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 288/553, Loss: 0.3637, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 289/553, Loss: 0.2260, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 290/553, Loss: 0.3838, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 291/553, Loss: 0.5941, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 292/553, Loss: 0.0656, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 293/553, Loss: 0.7225, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 294/553, Loss: 0.1245, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 295/553, Loss: 0.7441, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 296/553, Loss: 0.5820, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 297/553, Loss: 0.4169, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 298/553, Loss: 0.2916, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 299/553, Loss: 0.1731, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 300/553, Loss: 0.5523, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 301/553, Loss: 0.4307, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 302/553, Loss: 0.1350, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 303/553, Loss: 0.5139, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 304/553, Loss: 0.3172, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 305/553, Loss: 0.5899, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 306/553, Loss: 0.1776, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 307/553, Loss: 0.5733, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 308/553, Loss: 0.6504, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 309/553, Loss: 0.3219, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 310/553, Loss: 0.3974, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 311/553, Loss: 0.1691, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 312/553, Loss: 0.3991, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 313/553, Loss: 0.3262, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 314/553, Loss: 0.3593, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 315/553, Loss: 0.4432, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 316/553, Loss: 0.2885, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 317/553, Loss: 0.3880, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 318/553, Loss: 0.3168, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 319/553, Loss: 0.6494, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 320/553, Loss: 0.5084, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 321/553, Loss: 0.2554, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 322/553, Loss: 0.3915, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 323/553, Loss: 0.3831, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 324/553, Loss: 0.4923, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 325/553, Loss: 0.5643, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 326/553, Loss: 0.3539, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 327/553, Loss: 0.7446, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 328/553, Loss: 0.4687, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 329/553, Loss: 0.1865, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 330/553, Loss: 0.8389, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 331/553, Loss: 0.6214, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 332/553, Loss: 0.3901, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 333/553, Loss: 0.1734, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 334/553, Loss: 0.3937, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 335/553, Loss: 0.2546, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 336/553, Loss: 0.3353, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 337/553, Loss: 0.7277, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 338/553, Loss: 0.3967, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 339/553, Loss: 0.1462, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 340/553, Loss: 0.3279, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 341/553, Loss: 0.3649, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 342/553, Loss: 0.6722, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 343/553, Loss: 0.4380, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 344/553, Loss: 0.1832, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 345/553, Loss: 0.4384, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 346/553, Loss: 0.5330, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 347/553, Loss: 0.5501, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 348/553, Loss: 0.4715, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 349/553, Loss: 0.4912, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 350/553, Loss: 0.2219, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 351/553, Loss: 0.4331, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 352/553, Loss: 0.7282, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 353/553, Loss: 0.3476, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 354/553, Loss: 0.4040, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 355/553, Loss: 0.4232, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 356/553, Loss: 0.3241, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 357/553, Loss: 0.5646, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 358/553, Loss: 0.5586, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 359/553, Loss: 0.3037, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 360/553, Loss: 0.2112, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 361/553, Loss: 0.4852, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 362/553, Loss: 0.3162, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 363/553, Loss: 0.3915, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 364/553, Loss: 0.2917, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 365/553, Loss: 0.2267, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 366/553, Loss: 0.4072, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 367/553, Loss: 0.1697, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 368/553, Loss: 0.0551, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 369/553, Loss: 0.2403, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 370/553, Loss: 0.2423, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 371/553, Loss: 0.3388, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 372/553, Loss: 0.2788, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 373/553, Loss: 0.6089, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 374/553, Loss: 0.2102, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 375/553, Loss: 0.1745, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 376/553, Loss: 0.4479, Time: 0.73 seconds\n",
            "Epoch 4/20, Batch 377/553, Loss: 0.4379, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 378/553, Loss: 0.4005, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 379/553, Loss: 0.3290, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 380/553, Loss: 0.3675, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 381/553, Loss: 0.4483, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 382/553, Loss: 0.3285, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 383/553, Loss: 0.5358, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 384/553, Loss: 0.2857, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 385/553, Loss: 0.2298, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 386/553, Loss: 0.1482, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 387/553, Loss: 0.4231, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 388/553, Loss: 0.3314, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 389/553, Loss: 0.6761, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 390/553, Loss: 0.3609, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 391/553, Loss: 0.4995, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 392/553, Loss: 0.3825, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 393/553, Loss: 0.5500, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 394/553, Loss: 0.7450, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 395/553, Loss: 0.3009, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 396/553, Loss: 0.1552, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 397/553, Loss: 0.4755, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 398/553, Loss: 0.6487, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 399/553, Loss: 0.5398, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 400/553, Loss: 0.4435, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 401/553, Loss: 0.3743, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 402/553, Loss: 0.4044, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 403/553, Loss: 0.4481, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 404/553, Loss: 0.5089, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 405/553, Loss: 0.5068, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 406/553, Loss: 0.3379, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 407/553, Loss: 0.7442, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 408/553, Loss: 0.4579, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 409/553, Loss: 0.2116, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 410/553, Loss: 0.5931, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 411/553, Loss: 0.7949, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 412/553, Loss: 0.4899, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 413/553, Loss: 0.7909, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 414/553, Loss: 0.4742, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 415/553, Loss: 0.3336, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 416/553, Loss: 0.1192, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 417/553, Loss: 0.4194, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 418/553, Loss: 0.5095, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 419/553, Loss: 0.2913, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 420/553, Loss: 0.4467, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 421/553, Loss: 0.3618, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 422/553, Loss: 0.3356, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 423/553, Loss: 0.3681, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 424/553, Loss: 0.6580, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 425/553, Loss: 0.4068, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 426/553, Loss: 0.3088, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 427/553, Loss: 0.3533, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 428/553, Loss: 0.8226, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 429/553, Loss: 0.5117, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 430/553, Loss: 0.7741, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 431/553, Loss: 0.2056, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 432/553, Loss: 0.1897, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 433/553, Loss: 0.1947, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 434/553, Loss: 0.7351, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 435/553, Loss: 0.1145, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 436/553, Loss: 0.2618, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 437/553, Loss: 0.2240, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 438/553, Loss: 0.8749, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 439/553, Loss: 0.4004, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 440/553, Loss: 0.3242, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 441/553, Loss: 0.4381, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 442/553, Loss: 0.2891, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 443/553, Loss: 0.2702, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 444/553, Loss: 0.1989, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 445/553, Loss: 0.2308, Time: 0.73 seconds\n",
            "Epoch 4/20, Batch 446/553, Loss: 0.2775, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 447/553, Loss: 0.9172, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 448/553, Loss: 0.5088, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 449/553, Loss: 0.1133, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 450/553, Loss: 0.4723, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 451/553, Loss: 0.2185, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 452/553, Loss: 0.4012, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 453/553, Loss: 0.3839, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 454/553, Loss: 0.1717, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 455/553, Loss: 0.3096, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 456/553, Loss: 0.4893, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 457/553, Loss: 0.3783, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 458/553, Loss: 0.5330, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 459/553, Loss: 0.1166, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 460/553, Loss: 0.5305, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 461/553, Loss: 0.2993, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 462/553, Loss: 0.7355, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 463/553, Loss: 0.7066, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 464/553, Loss: 0.9115, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 465/553, Loss: 0.1949, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 466/553, Loss: 0.4912, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 467/553, Loss: 0.4225, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 468/553, Loss: 0.2779, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 469/553, Loss: 0.3486, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 470/553, Loss: 0.8237, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 471/553, Loss: 0.3984, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 472/553, Loss: 0.4724, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 473/553, Loss: 0.5138, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 474/553, Loss: 0.2042, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 475/553, Loss: 0.4685, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 476/553, Loss: 0.5036, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 477/553, Loss: 0.4929, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 478/553, Loss: 0.5291, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 479/553, Loss: 0.1299, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 480/553, Loss: 0.5892, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 481/553, Loss: 0.2956, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 482/553, Loss: 0.2725, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 483/553, Loss: 0.7467, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 484/553, Loss: 0.2457, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 485/553, Loss: 1.0138, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 486/553, Loss: 0.3917, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 487/553, Loss: 0.3045, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 488/553, Loss: 0.4614, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 489/553, Loss: 0.6005, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 490/553, Loss: 0.5080, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 491/553, Loss: 0.4039, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 492/553, Loss: 0.2997, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 493/553, Loss: 0.3534, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 494/553, Loss: 0.5971, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 495/553, Loss: 0.8971, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 496/553, Loss: 0.4449, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 497/553, Loss: 0.2374, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 498/553, Loss: 0.2364, Time: 0.73 seconds\n",
            "Epoch 4/20, Batch 499/553, Loss: 0.3407, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 500/553, Loss: 0.4401, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 501/553, Loss: 0.2111, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 502/553, Loss: 0.3841, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 503/553, Loss: 0.2272, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 504/553, Loss: 0.4921, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 505/553, Loss: 0.3862, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 506/553, Loss: 0.6084, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 507/553, Loss: 0.7370, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 508/553, Loss: 0.2496, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 509/553, Loss: 0.2833, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 510/553, Loss: 0.5724, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 511/553, Loss: 0.0966, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 512/553, Loss: 0.2750, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 513/553, Loss: 0.4413, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 514/553, Loss: 0.3517, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 515/553, Loss: 0.2587, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 516/553, Loss: 0.4254, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 517/553, Loss: 0.4949, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 518/553, Loss: 0.5917, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 519/553, Loss: 0.9846, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 520/553, Loss: 0.2292, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 521/553, Loss: 0.4413, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 522/553, Loss: 0.2133, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 523/553, Loss: 0.4517, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 524/553, Loss: 0.5782, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 525/553, Loss: 0.1837, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 526/553, Loss: 0.7561, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 527/553, Loss: 0.5171, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 528/553, Loss: 0.6732, Time: 0.77 seconds\n",
            "Epoch 4/20, Batch 529/553, Loss: 0.3808, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 530/553, Loss: 0.6247, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 531/553, Loss: 0.3522, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 532/553, Loss: 0.4558, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 533/553, Loss: 0.4103, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 534/553, Loss: 0.4544, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 535/553, Loss: 0.1937, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 536/553, Loss: 0.3281, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 537/553, Loss: 0.4437, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 538/553, Loss: 0.2941, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 539/553, Loss: 0.3804, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 540/553, Loss: 0.4122, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 541/553, Loss: 0.0039, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 542/553, Loss: 0.4138, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 543/553, Loss: 0.1858, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 544/553, Loss: 0.1898, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 545/553, Loss: 0.5676, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 546/553, Loss: 0.2573, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 547/553, Loss: 0.2647, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 548/553, Loss: 0.4117, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 549/553, Loss: 0.4868, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 550/553, Loss: 0.3386, Time: 0.75 seconds\n",
            "Epoch 4/20, Batch 551/553, Loss: 0.1415, Time: 0.76 seconds\n",
            "Epoch 4/20, Batch 552/553, Loss: 0.4730, Time: 0.74 seconds\n",
            "Epoch 4/20, Batch 553/553, Loss: 0.0025, Time: 0.10 seconds\n",
            "Epoch 4/20, Training Loss: 0.3990, Time: 417.29 seconds\n",
            "Validation Loss: 0.3785, Accuracy: 0.8561\n",
            "Epoch 5/20, Batch 1/553, Loss: 0.6207, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 2/553, Loss: 0.6620, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 3/553, Loss: 0.6576, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 4/553, Loss: 0.1086, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 5/553, Loss: 0.7870, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 6/553, Loss: 0.8790, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 7/553, Loss: 0.2238, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 8/553, Loss: 0.3559, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 9/553, Loss: 0.2091, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 10/553, Loss: 0.6770, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 11/553, Loss: 0.3264, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 12/553, Loss: 0.4068, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 13/553, Loss: 0.6391, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 14/553, Loss: 0.4018, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 15/553, Loss: 0.2959, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 16/553, Loss: 0.7491, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 17/553, Loss: 0.1575, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 18/553, Loss: 0.8349, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 19/553, Loss: 0.1863, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 20/553, Loss: 0.1982, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 21/553, Loss: 0.1818, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 22/553, Loss: 0.2407, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 23/553, Loss: 0.2378, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 24/553, Loss: 0.1438, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 25/553, Loss: 0.2104, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 26/553, Loss: 0.5136, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 27/553, Loss: 0.4108, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 28/553, Loss: 0.0443, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 29/553, Loss: 0.6286, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 30/553, Loss: 0.3574, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 31/553, Loss: 0.6399, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 32/553, Loss: 0.2605, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 33/553, Loss: 0.5372, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 34/553, Loss: 0.5711, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 35/553, Loss: 0.2707, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 36/553, Loss: 0.5306, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 37/553, Loss: 0.3856, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 38/553, Loss: 1.0335, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 39/553, Loss: 0.3911, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 40/553, Loss: 0.1691, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 41/553, Loss: 0.2748, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 42/553, Loss: 0.6741, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 43/553, Loss: 0.9919, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 44/553, Loss: 0.3385, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 45/553, Loss: 0.3201, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 46/553, Loss: 0.5094, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 47/553, Loss: 0.5829, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 48/553, Loss: 0.4701, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 49/553, Loss: 0.6031, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 50/553, Loss: 0.8256, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 51/553, Loss: 0.4535, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 52/553, Loss: 0.6417, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 53/553, Loss: 0.4201, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 54/553, Loss: 0.6655, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 55/553, Loss: 0.1970, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 56/553, Loss: 0.6683, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 57/553, Loss: 0.1471, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 58/553, Loss: 0.5124, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 59/553, Loss: 0.1412, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 60/553, Loss: 0.6467, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 61/553, Loss: 0.6468, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 62/553, Loss: 0.3729, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 63/553, Loss: 0.5657, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 64/553, Loss: 0.0443, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 65/553, Loss: 0.4648, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 66/553, Loss: 0.1282, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 67/553, Loss: 0.3622, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 68/553, Loss: 0.6550, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 69/553, Loss: 0.1146, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 70/553, Loss: 0.6284, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 71/553, Loss: 0.1400, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 72/553, Loss: 0.2761, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 73/553, Loss: 0.1642, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 74/553, Loss: 0.4681, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 75/553, Loss: 0.6353, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 76/553, Loss: 0.0535, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 77/553, Loss: 0.1993, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 78/553, Loss: 0.4914, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 79/553, Loss: 0.0992, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 80/553, Loss: 0.2570, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 81/553, Loss: 0.7073, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 82/553, Loss: 0.6644, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 83/553, Loss: 0.2808, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 84/553, Loss: 0.5005, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 85/553, Loss: 0.4288, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 86/553, Loss: 0.3989, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 87/553, Loss: 0.7418, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 88/553, Loss: 0.1475, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 89/553, Loss: 0.9106, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 90/553, Loss: 0.2826, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 91/553, Loss: 0.1211, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 92/553, Loss: 0.2380, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 93/553, Loss: 0.5417, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 94/553, Loss: 0.0953, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 95/553, Loss: 0.1060, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 96/553, Loss: 0.2080, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 97/553, Loss: 0.4575, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 98/553, Loss: 0.2604, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 99/553, Loss: 0.2379, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 100/553, Loss: 0.6835, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 101/553, Loss: 0.5756, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 102/553, Loss: 0.4596, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 103/553, Loss: 0.4942, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 104/553, Loss: 0.2195, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 105/553, Loss: 0.5994, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 106/553, Loss: 0.2959, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 107/553, Loss: 0.4449, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 108/553, Loss: 0.3353, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 109/553, Loss: 0.4330, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 110/553, Loss: 0.3182, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 111/553, Loss: 0.9650, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 112/553, Loss: 0.1827, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 113/553, Loss: 0.2054, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 114/553, Loss: 0.8189, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 115/553, Loss: 0.4377, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 116/553, Loss: 0.3131, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 117/553, Loss: 0.3644, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 118/553, Loss: 0.2367, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 119/553, Loss: 0.2374, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 120/553, Loss: 0.1890, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 121/553, Loss: 0.2992, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 122/553, Loss: 0.5746, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 123/553, Loss: 0.4115, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 124/553, Loss: 0.1711, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 125/553, Loss: 0.4208, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 126/553, Loss: 0.1272, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 127/553, Loss: 0.1001, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 128/553, Loss: 0.5842, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 129/553, Loss: 0.5535, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 130/553, Loss: 0.3074, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 131/553, Loss: 0.3044, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 132/553, Loss: 0.2788, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 133/553, Loss: 0.2196, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 134/553, Loss: 0.2840, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 135/553, Loss: 0.0520, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 136/553, Loss: 0.1125, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 137/553, Loss: 0.6818, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 138/553, Loss: 0.3706, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 139/553, Loss: 0.3750, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 140/553, Loss: 0.6207, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 141/553, Loss: 0.6981, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 142/553, Loss: 0.7477, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 143/553, Loss: 0.3179, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 144/553, Loss: 0.2492, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 145/553, Loss: 0.7518, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 146/553, Loss: 0.6454, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 147/553, Loss: 0.6591, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 148/553, Loss: 0.3824, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 149/553, Loss: 0.2852, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 150/553, Loss: 0.4898, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 151/553, Loss: 0.2385, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 152/553, Loss: 0.2409, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 153/553, Loss: 0.1010, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 154/553, Loss: 0.4273, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 155/553, Loss: 0.5898, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 156/553, Loss: 0.2434, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 157/553, Loss: 0.1057, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 158/553, Loss: 0.1347, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 159/553, Loss: 0.3191, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 160/553, Loss: 0.2016, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 161/553, Loss: 0.2598, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 162/553, Loss: 0.3589, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 163/553, Loss: 0.2014, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 164/553, Loss: 0.3505, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 165/553, Loss: 0.4140, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 166/553, Loss: 0.2675, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 167/553, Loss: 0.5139, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 168/553, Loss: 0.2571, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 169/553, Loss: 0.7715, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 170/553, Loss: 0.5832, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 171/553, Loss: 0.2551, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 172/553, Loss: 0.1007, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 173/553, Loss: 0.1527, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 174/553, Loss: 0.5663, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 175/553, Loss: 0.3517, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 176/553, Loss: 0.1596, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 177/553, Loss: 0.1585, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 178/553, Loss: 0.2084, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 179/553, Loss: 0.1536, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 180/553, Loss: 0.7553, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 181/553, Loss: 0.1611, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 182/553, Loss: 0.5930, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 183/553, Loss: 0.3772, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 184/553, Loss: 0.2259, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 185/553, Loss: 0.2675, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 186/553, Loss: 0.1508, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 187/553, Loss: 0.9183, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 188/553, Loss: 0.4815, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 189/553, Loss: 0.3061, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 190/553, Loss: 0.7221, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 191/553, Loss: 0.2943, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 192/553, Loss: 0.4891, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 193/553, Loss: 0.2843, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 194/553, Loss: 0.3606, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 195/553, Loss: 0.6435, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 196/553, Loss: 0.5374, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 197/553, Loss: 0.4957, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 198/553, Loss: 0.1917, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 199/553, Loss: 0.4184, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 200/553, Loss: 0.1058, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 201/553, Loss: 0.4060, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 202/553, Loss: 0.1628, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 203/553, Loss: 0.3662, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 204/553, Loss: 0.2089, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 205/553, Loss: 0.2858, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 206/553, Loss: 0.4216, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 207/553, Loss: 0.2525, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 208/553, Loss: 0.3126, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 209/553, Loss: 0.2923, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 210/553, Loss: 0.2396, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 211/553, Loss: 0.2760, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 212/553, Loss: 0.3741, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 213/553, Loss: 0.1722, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 214/553, Loss: 0.4472, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 215/553, Loss: 0.3294, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 216/553, Loss: 0.2875, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 217/553, Loss: 0.4289, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 218/553, Loss: 0.2601, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 219/553, Loss: 0.1753, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 220/553, Loss: 0.3150, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 221/553, Loss: 0.3617, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 222/553, Loss: 0.2949, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 223/553, Loss: 0.1370, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 224/553, Loss: 0.1881, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 225/553, Loss: 0.4630, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 226/553, Loss: 0.6583, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 227/553, Loss: 0.4888, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 228/553, Loss: 0.5196, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 229/553, Loss: 0.3004, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 230/553, Loss: 0.2091, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 231/553, Loss: 0.7027, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 232/553, Loss: 0.4065, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 233/553, Loss: 0.4924, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 234/553, Loss: 0.5731, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 235/553, Loss: 0.2885, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 236/553, Loss: 0.1855, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 237/553, Loss: 0.0022, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 238/553, Loss: 0.3955, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 239/553, Loss: 0.3210, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 240/553, Loss: 0.2614, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 241/553, Loss: 0.9201, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 242/553, Loss: 0.5081, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 243/553, Loss: 0.1058, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 244/553, Loss: 0.5415, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 245/553, Loss: 0.5126, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 246/553, Loss: 0.2799, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 247/553, Loss: 0.3084, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 248/553, Loss: 0.5784, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 249/553, Loss: 0.3257, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 250/553, Loss: 0.8745, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 251/553, Loss: 0.6350, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 252/553, Loss: 0.7291, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 253/553, Loss: 0.8758, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 254/553, Loss: 0.2992, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 255/553, Loss: 0.1903, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 256/553, Loss: 0.2379, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 257/553, Loss: 0.8556, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 258/553, Loss: 0.3334, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 259/553, Loss: 0.2329, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 260/553, Loss: 0.1208, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 261/553, Loss: 0.4955, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 262/553, Loss: 0.5440, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 263/553, Loss: 0.6603, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 264/553, Loss: 0.6026, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 265/553, Loss: 0.5621, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 266/553, Loss: 0.3626, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 267/553, Loss: 0.4712, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 268/553, Loss: 0.4798, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 269/553, Loss: 0.5362, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 270/553, Loss: 0.4459, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 271/553, Loss: 0.2623, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 272/553, Loss: 0.6219, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 273/553, Loss: 0.4163, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 274/553, Loss: 0.6523, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 275/553, Loss: 0.6387, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 276/553, Loss: 0.4313, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 277/553, Loss: 0.4715, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 278/553, Loss: 0.9924, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 279/553, Loss: 0.1827, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 280/553, Loss: 0.7593, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 281/553, Loss: 0.1381, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 282/553, Loss: 0.6300, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 283/553, Loss: 0.4030, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 284/553, Loss: 0.6815, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 285/553, Loss: 0.2018, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 286/553, Loss: 0.3693, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 287/553, Loss: 0.3767, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 288/553, Loss: 0.2675, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 289/553, Loss: 0.4364, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 290/553, Loss: 0.5876, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 291/553, Loss: 0.5552, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 292/553, Loss: 0.3815, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 293/553, Loss: 0.3213, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 294/553, Loss: 0.5782, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 295/553, Loss: 0.3386, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 296/553, Loss: 0.1293, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 297/553, Loss: 0.2700, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 298/553, Loss: 0.5029, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 299/553, Loss: 0.2768, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 300/553, Loss: 0.4593, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 301/553, Loss: 0.3351, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 302/553, Loss: 0.7311, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 303/553, Loss: 0.3203, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 304/553, Loss: 0.3332, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 305/553, Loss: 0.2260, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 306/553, Loss: 0.1702, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 307/553, Loss: 0.7447, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 308/553, Loss: 0.5626, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 309/553, Loss: 0.5339, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 310/553, Loss: 0.6822, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 311/553, Loss: 0.9339, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 312/553, Loss: 0.4090, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 313/553, Loss: 0.4148, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 314/553, Loss: 0.4007, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 315/553, Loss: 0.4035, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 316/553, Loss: 0.5806, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 317/553, Loss: 0.2725, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 318/553, Loss: 0.3953, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 319/553, Loss: 0.5179, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 320/553, Loss: 0.4513, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 321/553, Loss: 0.3942, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 322/553, Loss: 0.0939, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 323/553, Loss: 0.2408, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 324/553, Loss: 0.2967, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 325/553, Loss: 1.0738, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 326/553, Loss: 0.5694, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 327/553, Loss: 0.7641, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 328/553, Loss: 0.3289, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 329/553, Loss: 0.4273, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 330/553, Loss: 0.2681, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 331/553, Loss: 0.2364, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 332/553, Loss: 0.1895, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 333/553, Loss: 0.2771, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 334/553, Loss: 0.5255, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 335/553, Loss: 0.2882, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 336/553, Loss: 0.3341, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 337/553, Loss: 0.3223, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 338/553, Loss: 0.4277, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 339/553, Loss: 0.4919, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 340/553, Loss: 0.5465, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 341/553, Loss: 0.1138, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 342/553, Loss: 0.3894, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 343/553, Loss: 0.4656, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 344/553, Loss: 0.5490, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 345/553, Loss: 0.4918, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 346/553, Loss: 0.4399, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 347/553, Loss: 0.6178, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 348/553, Loss: 0.6420, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 349/553, Loss: 0.2423, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 350/553, Loss: 0.4424, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 351/553, Loss: 0.4501, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 352/553, Loss: 0.5148, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 353/553, Loss: 0.5691, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 354/553, Loss: 0.6248, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 355/553, Loss: 0.3837, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 356/553, Loss: 0.1511, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 357/553, Loss: 0.2505, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 358/553, Loss: 0.5463, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 359/553, Loss: 0.3775, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 360/553, Loss: 0.3066, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 361/553, Loss: 0.3128, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 362/553, Loss: 0.9903, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 363/553, Loss: 0.4481, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 364/553, Loss: 0.3528, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 365/553, Loss: 0.1965, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 366/553, Loss: 0.2102, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 367/553, Loss: 0.4285, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 368/553, Loss: 0.6262, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 369/553, Loss: 0.6660, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 370/553, Loss: 0.4537, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 371/553, Loss: 0.3189, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 372/553, Loss: 0.4343, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 373/553, Loss: 0.0643, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 374/553, Loss: 0.6013, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 375/553, Loss: 0.1256, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 376/553, Loss: 0.5912, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 377/553, Loss: 0.2676, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 378/553, Loss: 1.1654, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 379/553, Loss: 0.3287, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 380/553, Loss: 0.1811, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 381/553, Loss: 0.6638, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 382/553, Loss: 0.2416, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 383/553, Loss: 0.4853, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 384/553, Loss: 0.1838, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 385/553, Loss: 0.1383, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 386/553, Loss: 0.3714, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 387/553, Loss: 0.2208, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 388/553, Loss: 0.8746, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 389/553, Loss: 0.3299, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 390/553, Loss: 0.2720, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 391/553, Loss: 0.1970, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 392/553, Loss: 0.2407, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 393/553, Loss: 0.1812, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 394/553, Loss: 0.4284, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 395/553, Loss: 0.5554, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 396/553, Loss: 0.4745, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 397/553, Loss: 0.4185, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 398/553, Loss: 0.1228, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 399/553, Loss: 0.8222, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 400/553, Loss: 0.3469, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 401/553, Loss: 0.2039, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 402/553, Loss: 0.2934, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 403/553, Loss: 0.3029, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 404/553, Loss: 0.8727, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 405/553, Loss: 0.4429, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 406/553, Loss: 0.6279, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 407/553, Loss: 0.6906, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 408/553, Loss: 0.1044, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 409/553, Loss: 0.4015, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 410/553, Loss: 0.3536, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 411/553, Loss: 0.1002, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 412/553, Loss: 0.5938, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 413/553, Loss: 0.2178, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 414/553, Loss: 0.5525, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 415/553, Loss: 0.3715, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 416/553, Loss: 0.4932, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 417/553, Loss: 0.3342, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 418/553, Loss: 0.4516, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 419/553, Loss: 0.3436, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 420/553, Loss: 0.3803, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 421/553, Loss: 0.2681, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 422/553, Loss: 0.1629, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 423/553, Loss: 0.6354, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 424/553, Loss: 0.2359, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 425/553, Loss: 0.1164, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 426/553, Loss: 0.6991, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 427/553, Loss: 0.2565, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 428/553, Loss: 0.2615, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 429/553, Loss: 0.6171, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 430/553, Loss: 0.1595, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 431/553, Loss: 0.2359, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 432/553, Loss: 0.1595, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 433/553, Loss: 0.3597, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 434/553, Loss: 0.1976, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 435/553, Loss: 0.2363, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 436/553, Loss: 0.4633, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 437/553, Loss: 0.5231, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 438/553, Loss: 0.3437, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 439/553, Loss: 0.1671, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 440/553, Loss: 0.8408, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 441/553, Loss: 0.8401, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 442/553, Loss: 0.2175, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 443/553, Loss: 0.3786, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 444/553, Loss: 1.0139, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 445/553, Loss: 0.4911, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 446/553, Loss: 0.3482, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 447/553, Loss: 0.3113, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 448/553, Loss: 0.3497, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 449/553, Loss: 0.2738, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 450/553, Loss: 0.4531, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 451/553, Loss: 0.7690, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 452/553, Loss: 0.4356, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 453/553, Loss: 0.2263, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 454/553, Loss: 0.6002, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 455/553, Loss: 0.2723, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 456/553, Loss: 0.4907, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 457/553, Loss: 0.3678, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 458/553, Loss: 0.2325, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 459/553, Loss: 0.4019, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 460/553, Loss: 0.3268, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 461/553, Loss: 0.4338, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 462/553, Loss: 0.0631, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 463/553, Loss: 0.2906, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 464/553, Loss: 0.4547, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 465/553, Loss: 1.2297, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 466/553, Loss: 0.3096, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 467/553, Loss: 0.1135, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 468/553, Loss: 0.2141, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 469/553, Loss: 0.5003, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 470/553, Loss: 0.2150, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 471/553, Loss: 0.4017, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 472/553, Loss: 0.5926, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 473/553, Loss: 0.1341, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 474/553, Loss: 0.2355, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 475/553, Loss: 0.2893, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 476/553, Loss: 0.5763, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 477/553, Loss: 0.1518, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 478/553, Loss: 0.3201, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 479/553, Loss: 0.3573, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 480/553, Loss: 0.4006, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 481/553, Loss: 0.4087, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 482/553, Loss: 0.2587, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 483/553, Loss: 0.0520, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 484/553, Loss: 0.5782, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 485/553, Loss: 0.5436, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 486/553, Loss: 0.7560, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 487/553, Loss: 0.9010, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 488/553, Loss: 0.4184, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 489/553, Loss: 0.4728, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 490/553, Loss: 0.6921, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 491/553, Loss: 0.5735, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 492/553, Loss: 0.2279, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 493/553, Loss: 0.1016, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 494/553, Loss: 0.2017, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 495/553, Loss: 0.1966, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 496/553, Loss: 0.1575, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 497/553, Loss: 0.8073, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 498/553, Loss: 0.2498, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 499/553, Loss: 0.1951, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 500/553, Loss: 0.3702, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 501/553, Loss: 0.2968, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 502/553, Loss: 0.3626, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 503/553, Loss: 0.3248, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 504/553, Loss: 0.3625, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 505/553, Loss: 0.3344, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 506/553, Loss: 0.2731, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 507/553, Loss: 0.4626, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 508/553, Loss: 0.2170, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 509/553, Loss: 0.4138, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 510/553, Loss: 0.4468, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 511/553, Loss: 0.1266, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 512/553, Loss: 0.3739, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 513/553, Loss: 0.4759, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 514/553, Loss: 0.1566, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 515/553, Loss: 0.1342, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 516/553, Loss: 0.2224, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 517/553, Loss: 0.3776, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 518/553, Loss: 0.3568, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 519/553, Loss: 0.4240, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 520/553, Loss: 0.4585, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 521/553, Loss: 0.1517, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 522/553, Loss: 0.4391, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 523/553, Loss: 0.3975, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 524/553, Loss: 0.2918, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 525/553, Loss: 0.2878, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 526/553, Loss: 0.5502, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 527/553, Loss: 0.6513, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 528/553, Loss: 0.1837, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 529/553, Loss: 0.6109, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 530/553, Loss: 0.6239, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 531/553, Loss: 0.4612, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 532/553, Loss: 0.3989, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 533/553, Loss: 0.2864, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 534/553, Loss: 0.3349, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 535/553, Loss: 0.3364, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 536/553, Loss: 0.4832, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 537/553, Loss: 0.7530, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 538/553, Loss: 0.1409, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 539/553, Loss: 0.4301, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 540/553, Loss: 0.4702, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 541/553, Loss: 0.1019, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 542/553, Loss: 0.4872, Time: 0.73 seconds\n",
            "Epoch 5/20, Batch 543/553, Loss: 0.5050, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 544/553, Loss: 0.6645, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 545/553, Loss: 0.3388, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 546/553, Loss: 0.0781, Time: 0.77 seconds\n",
            "Epoch 5/20, Batch 547/553, Loss: 0.2865, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 548/553, Loss: 0.5093, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 549/553, Loss: 0.9588, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 550/553, Loss: 0.5928, Time: 0.74 seconds\n",
            "Epoch 5/20, Batch 551/553, Loss: 0.2645, Time: 0.75 seconds\n",
            "Epoch 5/20, Batch 552/553, Loss: 0.9049, Time: 0.76 seconds\n",
            "Epoch 5/20, Batch 553/553, Loss: 0.0108, Time: 0.10 seconds\n",
            "Epoch 5/20, Training Loss: 0.4036, Time: 417.40 seconds\n",
            "Validation Loss: 0.3785, Accuracy: 0.8561\n",
            "Epoch 6/20, Batch 1/553, Loss: 0.3733, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 2/553, Loss: 0.7278, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 3/553, Loss: 0.5965, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 4/553, Loss: 0.4313, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 5/553, Loss: 0.3484, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 6/553, Loss: 0.4762, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 7/553, Loss: 0.6005, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 8/553, Loss: 0.0977, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 9/553, Loss: 0.6064, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 10/553, Loss: 0.3932, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 11/553, Loss: 0.2741, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 12/553, Loss: 0.5200, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 13/553, Loss: 0.5110, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 14/553, Loss: 0.2104, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 15/553, Loss: 0.2681, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 16/553, Loss: 0.3454, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 17/553, Loss: 0.2895, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 18/553, Loss: 0.5621, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 19/553, Loss: 0.4468, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 20/553, Loss: 0.2248, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 21/553, Loss: 0.5349, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 22/553, Loss: 0.4495, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 23/553, Loss: 0.4181, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 24/553, Loss: 0.4724, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 25/553, Loss: 0.2447, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 26/553, Loss: 0.5276, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 27/553, Loss: 0.6969, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 28/553, Loss: 0.3826, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 29/553, Loss: 0.6987, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 30/553, Loss: 0.3930, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 31/553, Loss: 0.3472, Time: 0.73 seconds\n",
            "Epoch 6/20, Batch 32/553, Loss: 0.2477, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 33/553, Loss: 0.6527, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 34/553, Loss: 0.6667, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 35/553, Loss: 0.0498, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 36/553, Loss: 0.5240, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 37/553, Loss: 0.4053, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 38/553, Loss: 0.0638, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 39/553, Loss: 0.3044, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 40/553, Loss: 0.2439, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 41/553, Loss: 0.5587, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 42/553, Loss: 0.5205, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 43/553, Loss: 0.5115, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 44/553, Loss: 0.4155, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 45/553, Loss: 0.4302, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 46/553, Loss: 0.6777, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 47/553, Loss: 0.4172, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 48/553, Loss: 0.7722, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 49/553, Loss: 0.2931, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 50/553, Loss: 0.3897, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 51/553, Loss: 0.6938, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 52/553, Loss: 0.4581, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 53/553, Loss: 0.2824, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 54/553, Loss: 0.2353, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 55/553, Loss: 0.2656, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 56/553, Loss: 0.5962, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 57/553, Loss: 0.6037, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 58/553, Loss: 0.4285, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 59/553, Loss: 0.3458, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 60/553, Loss: 0.2027, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 61/553, Loss: 0.4774, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 62/553, Loss: 0.4133, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 63/553, Loss: 0.1802, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 64/553, Loss: 0.5438, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 65/553, Loss: 0.7189, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 66/553, Loss: 0.1343, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 67/553, Loss: 0.2743, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 68/553, Loss: 0.2988, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 69/553, Loss: 0.1165, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 70/553, Loss: 0.4603, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 71/553, Loss: 0.2938, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 72/553, Loss: 0.8265, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 73/553, Loss: 0.7111, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 74/553, Loss: 0.7705, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 75/553, Loss: 0.2599, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 76/553, Loss: 0.4876, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 77/553, Loss: 0.5555, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 78/553, Loss: 0.4565, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 79/553, Loss: 0.2169, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 80/553, Loss: 0.5584, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 81/553, Loss: 0.6529, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 82/553, Loss: 0.5496, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 83/553, Loss: 0.4164, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 84/553, Loss: 0.1081, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 85/553, Loss: 0.4345, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 86/553, Loss: 0.5441, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 87/553, Loss: 0.0858, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 88/553, Loss: 0.5512, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 89/553, Loss: 0.3477, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 90/553, Loss: 0.5377, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 91/553, Loss: 0.1219, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 92/553, Loss: 0.3649, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 93/553, Loss: 0.3141, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 94/553, Loss: 0.3334, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 95/553, Loss: 0.2212, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 96/553, Loss: 0.4623, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 97/553, Loss: 0.4874, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 98/553, Loss: 0.6979, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 99/553, Loss: 0.3107, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 100/553, Loss: 0.6915, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 101/553, Loss: 0.8019, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 102/553, Loss: 0.5860, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 103/553, Loss: 0.2850, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 104/553, Loss: 1.1566, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 105/553, Loss: 0.4789, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 106/553, Loss: 0.7814, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 107/553, Loss: 0.1524, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 108/553, Loss: 0.1611, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 109/553, Loss: 0.7380, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 110/553, Loss: 0.2427, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 111/553, Loss: 0.5840, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 112/553, Loss: 0.2690, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 113/553, Loss: 0.4872, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 114/553, Loss: 0.5581, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 115/553, Loss: 0.4223, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 116/553, Loss: 0.1851, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 117/553, Loss: 0.3922, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 118/553, Loss: 0.6588, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 119/553, Loss: 0.4627, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 120/553, Loss: 0.1844, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 121/553, Loss: 0.3873, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 122/553, Loss: 0.2766, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 123/553, Loss: 0.6540, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 124/553, Loss: 0.4151, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 125/553, Loss: 0.2575, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 126/553, Loss: 0.5724, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 127/553, Loss: 0.3907, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 128/553, Loss: 0.0686, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 129/553, Loss: 0.2178, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 130/553, Loss: 0.3204, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 131/553, Loss: 0.4665, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 132/553, Loss: 0.5092, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 133/553, Loss: 0.3262, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 134/553, Loss: 0.2563, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 135/553, Loss: 0.2258, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 136/553, Loss: 0.4051, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 137/553, Loss: 0.1432, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 138/553, Loss: 0.0367, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 139/553, Loss: 0.4022, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 140/553, Loss: 0.2711, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 141/553, Loss: 0.7034, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 142/553, Loss: 0.3025, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 143/553, Loss: 0.3315, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 144/553, Loss: 0.1911, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 145/553, Loss: 0.5109, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 146/553, Loss: 0.3984, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 147/553, Loss: 0.4683, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 148/553, Loss: 0.0529, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 149/553, Loss: 0.4684, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 150/553, Loss: 0.6863, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 151/553, Loss: 0.2338, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 152/553, Loss: 0.4488, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 153/553, Loss: 0.5797, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 154/553, Loss: 0.3427, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 155/553, Loss: 0.4000, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 156/553, Loss: 0.4030, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 157/553, Loss: 0.4754, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 158/553, Loss: 0.5168, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 159/553, Loss: 0.6367, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 160/553, Loss: 0.3041, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 161/553, Loss: 0.3499, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 162/553, Loss: 0.4594, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 163/553, Loss: 0.6871, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 164/553, Loss: 0.3962, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 165/553, Loss: 0.5063, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 166/553, Loss: 0.4121, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 167/553, Loss: 0.2983, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 168/553, Loss: 0.2726, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 169/553, Loss: 0.1944, Time: 0.73 seconds\n",
            "Epoch 6/20, Batch 170/553, Loss: 0.3519, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 171/553, Loss: 0.4391, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 172/553, Loss: 0.5755, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 173/553, Loss: 0.3114, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 174/553, Loss: 0.5097, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 175/553, Loss: 0.2955, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 176/553, Loss: 0.4674, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 177/553, Loss: 0.4187, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 178/553, Loss: 0.3153, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 179/553, Loss: 0.6228, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 180/553, Loss: 0.2604, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 181/553, Loss: 0.3717, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 182/553, Loss: 0.5220, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 183/553, Loss: 0.1609, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 184/553, Loss: 0.3069, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 185/553, Loss: 0.3059, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 186/553, Loss: 0.1807, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 187/553, Loss: 0.4400, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 188/553, Loss: 0.3233, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 189/553, Loss: 0.4800, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 190/553, Loss: 0.0962, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 191/553, Loss: 0.0853, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 192/553, Loss: 0.9952, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 193/553, Loss: 0.2621, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 194/553, Loss: 1.4879, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 195/553, Loss: 0.5479, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 196/553, Loss: 0.4027, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 197/553, Loss: 0.1840, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 198/553, Loss: 0.1416, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 199/553, Loss: 0.7392, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 200/553, Loss: 0.3941, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 201/553, Loss: 0.3424, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 202/553, Loss: 0.3217, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 203/553, Loss: 0.2784, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 204/553, Loss: 0.3674, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 205/553, Loss: 0.2059, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 206/553, Loss: 0.2993, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 207/553, Loss: 0.2353, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 208/553, Loss: 0.4694, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 209/553, Loss: 0.6027, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 210/553, Loss: 0.3787, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 211/553, Loss: 0.6411, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 212/553, Loss: 0.2288, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 213/553, Loss: 0.4637, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 214/553, Loss: 0.3693, Time: 0.73 seconds\n",
            "Epoch 6/20, Batch 215/553, Loss: 0.1750, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 216/553, Loss: 0.2554, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 217/553, Loss: 0.8345, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 218/553, Loss: 0.3935, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 219/553, Loss: 0.2156, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 220/553, Loss: 0.3549, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 221/553, Loss: 0.3354, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 222/553, Loss: 0.2364, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 223/553, Loss: 0.4075, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 224/553, Loss: 0.6965, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 225/553, Loss: 0.8639, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 226/553, Loss: 0.6990, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 227/553, Loss: 0.2613, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 228/553, Loss: 0.3656, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 229/553, Loss: 0.6052, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 230/553, Loss: 0.6017, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 231/553, Loss: 0.2539, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 232/553, Loss: 0.3878, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 233/553, Loss: 0.6236, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 234/553, Loss: 0.5178, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 235/553, Loss: 0.6989, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 236/553, Loss: 0.2299, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 237/553, Loss: 0.3600, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 238/553, Loss: 0.0717, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 239/553, Loss: 0.5157, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 240/553, Loss: 0.4336, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 241/553, Loss: 0.2257, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 242/553, Loss: 0.4155, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 243/553, Loss: 0.5547, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 244/553, Loss: 0.4605, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 245/553, Loss: 0.1901, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 246/553, Loss: 0.2343, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 247/553, Loss: 0.5568, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 248/553, Loss: 0.2747, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 249/553, Loss: 0.5318, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 250/553, Loss: 0.0446, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 251/553, Loss: 0.1916, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 252/553, Loss: 0.4804, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 253/553, Loss: 0.3788, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 254/553, Loss: 0.6174, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 255/553, Loss: 0.8862, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 256/553, Loss: 0.4240, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 257/553, Loss: 0.4287, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 258/553, Loss: 0.2857, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 259/553, Loss: 0.5306, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 260/553, Loss: 0.1952, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 261/553, Loss: 0.3825, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 262/553, Loss: 0.8495, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 263/553, Loss: 0.2821, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 264/553, Loss: 0.0908, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 265/553, Loss: 0.4046, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 266/553, Loss: 0.3721, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 267/553, Loss: 0.6773, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 268/553, Loss: 0.2563, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 269/553, Loss: 0.1985, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 270/553, Loss: 0.2401, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 271/553, Loss: 0.2638, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 272/553, Loss: 0.3514, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 273/553, Loss: 0.0974, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 274/553, Loss: 0.3542, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 275/553, Loss: 0.2070, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 276/553, Loss: 0.4382, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 277/553, Loss: 0.3660, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 278/553, Loss: 0.1358, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 279/553, Loss: 0.2022, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 280/553, Loss: 0.1685, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 281/553, Loss: 0.3285, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 282/553, Loss: 0.2479, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 283/553, Loss: 1.0497, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 284/553, Loss: 0.2269, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 285/553, Loss: 0.0456, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 286/553, Loss: 0.2714, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 287/553, Loss: 0.0922, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 288/553, Loss: 0.8697, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 289/553, Loss: 0.4525, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 290/553, Loss: 0.3915, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 291/553, Loss: 0.5832, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 292/553, Loss: 0.6093, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 293/553, Loss: 0.2812, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 294/553, Loss: 0.3076, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 295/553, Loss: 0.2442, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 296/553, Loss: 0.4141, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 297/553, Loss: 0.2590, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 298/553, Loss: 0.1538, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 299/553, Loss: 0.3870, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 300/553, Loss: 0.5097, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 301/553, Loss: 0.4431, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 302/553, Loss: 0.1190, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 303/553, Loss: 0.1781, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 304/553, Loss: 0.4292, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 305/553, Loss: 0.5933, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 306/553, Loss: 0.2942, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 307/553, Loss: 0.2937, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 308/553, Loss: 0.2793, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 309/553, Loss: 0.2149, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 310/553, Loss: 0.3879, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 311/553, Loss: 0.0947, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 312/553, Loss: 0.7061, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 313/553, Loss: 0.2381, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 314/553, Loss: 0.4681, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 315/553, Loss: 0.3273, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 316/553, Loss: 0.0059, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 317/553, Loss: 0.2459, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 318/553, Loss: 0.4052, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 319/553, Loss: 0.5386, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 320/553, Loss: 0.3803, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 321/553, Loss: 0.4474, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 322/553, Loss: 0.2865, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 323/553, Loss: 0.6264, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 324/553, Loss: 0.4490, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 325/553, Loss: 0.4666, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 326/553, Loss: 0.2171, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 327/553, Loss: 0.1218, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 328/553, Loss: 0.3561, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 329/553, Loss: 0.1069, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 330/553, Loss: 0.1811, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 331/553, Loss: 0.3410, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 332/553, Loss: 0.4898, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 333/553, Loss: 0.4187, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 334/553, Loss: 0.1106, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 335/553, Loss: 0.0958, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 336/553, Loss: 0.1582, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 337/553, Loss: 0.2554, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 338/553, Loss: 0.5238, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 339/553, Loss: 0.4097, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 340/553, Loss: 0.2610, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 341/553, Loss: 0.3303, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 342/553, Loss: 0.1719, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 343/553, Loss: 0.2327, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 344/553, Loss: 0.4926, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 345/553, Loss: 0.4556, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 346/553, Loss: 0.8512, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 347/553, Loss: 0.5288, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 348/553, Loss: 0.0599, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 349/553, Loss: 0.1435, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 350/553, Loss: 0.1755, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 351/553, Loss: 0.5915, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 352/553, Loss: 0.4577, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 353/553, Loss: 0.4172, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 354/553, Loss: 0.1884, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 355/553, Loss: 0.5396, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 356/553, Loss: 0.0534, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 357/553, Loss: 0.4740, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 358/553, Loss: 0.3475, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 359/553, Loss: 0.3976, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 360/553, Loss: 0.6038, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 361/553, Loss: 0.4132, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 362/553, Loss: 0.7646, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 363/553, Loss: 0.6760, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 364/553, Loss: 0.4808, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 365/553, Loss: 0.4485, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 366/553, Loss: 0.5061, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 367/553, Loss: 0.3042, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 368/553, Loss: 0.2333, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 369/553, Loss: 0.1346, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 370/553, Loss: 0.3836, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 371/553, Loss: 0.0551, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 372/553, Loss: 0.3071, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 373/553, Loss: 0.3274, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 374/553, Loss: 0.0995, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 375/553, Loss: 0.3493, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 376/553, Loss: 0.3576, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 377/553, Loss: 0.8032, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 378/553, Loss: 0.7880, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 379/553, Loss: 0.2270, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 380/553, Loss: 0.5880, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 381/553, Loss: 0.4218, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 382/553, Loss: 0.7682, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 383/553, Loss: 0.2593, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 384/553, Loss: 0.3228, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 385/553, Loss: 0.3380, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 386/553, Loss: 0.5068, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 387/553, Loss: 0.8028, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 388/553, Loss: 0.2844, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 389/553, Loss: 0.2680, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 390/553, Loss: 0.8202, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 391/553, Loss: 0.0587, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 392/553, Loss: 0.3797, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 393/553, Loss: 0.6142, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 394/553, Loss: 0.5969, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 395/553, Loss: 0.3881, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 396/553, Loss: 0.1722, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 397/553, Loss: 0.3345, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 398/553, Loss: 0.8100, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 399/553, Loss: 0.5600, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 400/553, Loss: 0.2290, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 401/553, Loss: 0.3816, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 402/553, Loss: 0.7514, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 403/553, Loss: 0.2520, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 404/553, Loss: 0.8073, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 405/553, Loss: 0.6908, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 406/553, Loss: 0.3492, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 407/553, Loss: 0.5668, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 408/553, Loss: 0.1830, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 409/553, Loss: 0.1287, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 410/553, Loss: 0.2108, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 411/553, Loss: 0.4913, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 412/553, Loss: 0.2765, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 413/553, Loss: 1.0078, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 414/553, Loss: 0.4561, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 415/553, Loss: 0.6474, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 416/553, Loss: 0.0866, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 417/553, Loss: 0.6512, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 418/553, Loss: 0.3441, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 419/553, Loss: 0.3403, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 420/553, Loss: 0.1015, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 421/553, Loss: 0.4309, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 422/553, Loss: 0.3125, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 423/553, Loss: 0.5983, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 424/553, Loss: 0.5857, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 425/553, Loss: 0.5960, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 426/553, Loss: 0.1721, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 427/553, Loss: 0.4290, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 428/553, Loss: 0.0409, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 429/553, Loss: 0.5050, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 430/553, Loss: 0.3335, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 431/553, Loss: 0.5101, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 432/553, Loss: 0.4740, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 433/553, Loss: 0.6045, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 434/553, Loss: 0.3915, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 435/553, Loss: 0.4681, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 436/553, Loss: 0.3849, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 437/553, Loss: 0.4987, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 438/553, Loss: 0.4908, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 439/553, Loss: 0.2260, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 440/553, Loss: 0.4453, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 441/553, Loss: 0.4091, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 442/553, Loss: 0.2694, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 443/553, Loss: 0.1727, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 444/553, Loss: 0.4191, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 445/553, Loss: 0.6314, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 446/553, Loss: 0.2958, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 447/553, Loss: 0.2692, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 448/553, Loss: 0.4722, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 449/553, Loss: 0.4473, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 450/553, Loss: 0.3552, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 451/553, Loss: 0.3230, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 452/553, Loss: 0.2021, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 453/553, Loss: 0.6545, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 454/553, Loss: 0.2831, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 455/553, Loss: 0.2081, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 456/553, Loss: 0.3188, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 457/553, Loss: 0.6804, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 458/553, Loss: 0.4742, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 459/553, Loss: 0.3275, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 460/553, Loss: 0.3747, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 461/553, Loss: 0.2875, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 462/553, Loss: 0.5818, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 463/553, Loss: 1.0627, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 464/553, Loss: 0.4509, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 465/553, Loss: 0.3399, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 466/553, Loss: 0.4435, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 467/553, Loss: 0.6298, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 468/553, Loss: 0.8371, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 469/553, Loss: 0.3765, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 470/553, Loss: 0.6869, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 471/553, Loss: 0.4288, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 472/553, Loss: 0.4722, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 473/553, Loss: 0.4639, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 474/553, Loss: 0.2182, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 475/553, Loss: 1.1046, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 476/553, Loss: 0.4083, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 477/553, Loss: 0.2668, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 478/553, Loss: 0.7590, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 479/553, Loss: 0.3915, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 480/553, Loss: 0.1037, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 481/553, Loss: 0.3964, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 482/553, Loss: 0.5441, Time: 0.77 seconds\n",
            "Epoch 6/20, Batch 483/553, Loss: 0.0925, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 484/553, Loss: 0.1981, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 485/553, Loss: 0.2347, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 486/553, Loss: 0.5046, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 487/553, Loss: 0.3351, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 488/553, Loss: 0.6888, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 489/553, Loss: 0.8277, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 490/553, Loss: 0.2386, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 491/553, Loss: 0.5285, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 492/553, Loss: 0.3036, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 493/553, Loss: 0.5236, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 494/553, Loss: 0.5466, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 495/553, Loss: 0.2921, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 496/553, Loss: 0.3138, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 497/553, Loss: 0.3736, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 498/553, Loss: 0.0891, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 499/553, Loss: 0.4379, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 500/553, Loss: 0.4294, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 501/553, Loss: 0.6567, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 502/553, Loss: 0.5805, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 503/553, Loss: 0.3960, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 504/553, Loss: 0.1452, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 505/553, Loss: 0.1613, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 506/553, Loss: 0.5484, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 507/553, Loss: 0.2675, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 508/553, Loss: 0.4762, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 509/553, Loss: 0.2073, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 510/553, Loss: 0.4111, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 511/553, Loss: 0.3214, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 512/553, Loss: 0.4369, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 513/553, Loss: 0.5232, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 514/553, Loss: 0.2249, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 515/553, Loss: 0.0906, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 516/553, Loss: 0.3197, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 517/553, Loss: 0.1117, Time: 0.73 seconds\n",
            "Epoch 6/20, Batch 518/553, Loss: 0.0442, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 519/553, Loss: 0.6709, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 520/553, Loss: 0.4192, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 521/553, Loss: 0.1958, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 522/553, Loss: 0.2024, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 523/553, Loss: 0.5253, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 524/553, Loss: 0.3297, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 525/553, Loss: 0.5649, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 526/553, Loss: 0.4319, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 527/553, Loss: 0.3999, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 528/553, Loss: 0.2659, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 529/553, Loss: 0.1471, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 530/553, Loss: 0.4325, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 531/553, Loss: 0.3097, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 532/553, Loss: 0.7266, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 533/553, Loss: 0.5526, Time: 0.73 seconds\n",
            "Epoch 6/20, Batch 534/553, Loss: 0.3795, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 535/553, Loss: 0.2860, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 536/553, Loss: 0.4454, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 537/553, Loss: 0.4202, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 538/553, Loss: 0.4378, Time: 0.74 seconds\n",
            "Epoch 6/20, Batch 539/553, Loss: 0.9157, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 540/553, Loss: 0.1082, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 541/553, Loss: 0.1383, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 542/553, Loss: 0.3795, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 543/553, Loss: 0.4005, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 544/553, Loss: 0.6829, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 545/553, Loss: 0.7016, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 546/553, Loss: 0.2089, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 547/553, Loss: 0.4550, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 548/553, Loss: 0.2765, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 549/553, Loss: 0.6241, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 550/553, Loss: 0.1857, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 551/553, Loss: 0.2083, Time: 0.76 seconds\n",
            "Epoch 6/20, Batch 552/553, Loss: 0.4321, Time: 0.75 seconds\n",
            "Epoch 6/20, Batch 553/553, Loss: 0.3837, Time: 0.10 seconds\n",
            "Epoch 6/20, Training Loss: 0.4039, Time: 417.20 seconds\n",
            "Validation Loss: 0.3784, Accuracy: 0.8561\n",
            "Epoch 7/20, Batch 1/553, Loss: 0.2828, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 2/553, Loss: 0.6228, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 3/553, Loss: 0.7631, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 4/553, Loss: 0.3521, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 5/553, Loss: 0.5298, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 6/553, Loss: 0.6538, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 7/553, Loss: 0.3897, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 8/553, Loss: 0.5054, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 9/553, Loss: 0.2303, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 10/553, Loss: 0.6732, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 11/553, Loss: 0.4843, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 12/553, Loss: 0.4184, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 13/553, Loss: 0.3821, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 14/553, Loss: 0.3146, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 15/553, Loss: 0.2826, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 16/553, Loss: 0.4319, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 17/553, Loss: 0.3281, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 18/553, Loss: 0.2723, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 19/553, Loss: 0.6625, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 20/553, Loss: 0.1715, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 21/553, Loss: 0.2212, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 22/553, Loss: 0.5575, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 23/553, Loss: 0.1597, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 24/553, Loss: 0.1156, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 25/553, Loss: 0.2751, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 26/553, Loss: 0.4179, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 27/553, Loss: 0.1460, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 28/553, Loss: 0.3103, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 29/553, Loss: 0.5386, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 30/553, Loss: 0.8368, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 31/553, Loss: 0.3445, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 32/553, Loss: 0.1151, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 33/553, Loss: 0.3092, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 34/553, Loss: 0.4291, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 35/553, Loss: 0.2946, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 36/553, Loss: 0.1449, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 37/553, Loss: 0.5802, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 38/553, Loss: 0.4611, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 39/553, Loss: 0.3035, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 40/553, Loss: 0.3127, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 41/553, Loss: 0.4081, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 42/553, Loss: 0.1896, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 43/553, Loss: 0.2724, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 44/553, Loss: 0.2920, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 45/553, Loss: 0.7317, Time: 0.77 seconds\n",
            "Epoch 7/20, Batch 46/553, Loss: 0.2269, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 47/553, Loss: 0.3678, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 48/553, Loss: 0.4816, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 49/553, Loss: 0.6565, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 50/553, Loss: 0.3035, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 51/553, Loss: 0.5382, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 52/553, Loss: 0.3517, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 53/553, Loss: 0.5506, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 54/553, Loss: 0.3986, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 55/553, Loss: 0.4372, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 56/553, Loss: 0.6324, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 57/553, Loss: 0.3477, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 58/553, Loss: 0.3758, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 59/553, Loss: 0.1625, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 60/553, Loss: 0.1452, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 61/553, Loss: 0.8758, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 62/553, Loss: 0.4629, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 63/553, Loss: 0.3729, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 64/553, Loss: 0.1869, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 65/553, Loss: 0.3503, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 66/553, Loss: 0.4418, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 67/553, Loss: 0.5965, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 68/553, Loss: 0.4989, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 69/553, Loss: 0.5608, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 70/553, Loss: 0.5962, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 71/553, Loss: 0.1542, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 72/553, Loss: 0.4141, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 73/553, Loss: 0.2877, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 74/553, Loss: 0.5493, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 75/553, Loss: 0.4047, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 76/553, Loss: 0.0884, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 77/553, Loss: 0.2425, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 78/553, Loss: 0.4856, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 79/553, Loss: 0.3303, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 80/553, Loss: 0.3460, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 81/553, Loss: 0.3706, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 82/553, Loss: 0.5265, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 83/553, Loss: 0.3678, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 84/553, Loss: 0.4956, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 85/553, Loss: 0.3421, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 86/553, Loss: 0.1680, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 87/553, Loss: 0.4790, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 88/553, Loss: 0.1533, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 89/553, Loss: 0.3149, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 90/553, Loss: 0.2664, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 91/553, Loss: 0.1547, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 92/553, Loss: 0.5412, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 93/553, Loss: 0.3176, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 94/553, Loss: 0.5533, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 95/553, Loss: 0.3718, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 96/553, Loss: 0.1254, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 97/553, Loss: 0.1466, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 98/553, Loss: 0.5505, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 99/553, Loss: 0.3156, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 100/553, Loss: 0.4670, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 101/553, Loss: 0.0527, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 102/553, Loss: 0.3895, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 103/553, Loss: 0.2801, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 104/553, Loss: 0.2610, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 105/553, Loss: 0.2636, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 106/553, Loss: 0.8876, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 107/553, Loss: 0.3368, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 108/553, Loss: 0.4354, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 109/553, Loss: 0.4165, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 110/553, Loss: 0.1132, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 111/553, Loss: 0.4034, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 112/553, Loss: 0.4704, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 113/553, Loss: 0.7395, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 114/553, Loss: 0.1362, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 115/553, Loss: 0.5432, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 116/553, Loss: 0.3631, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 117/553, Loss: 0.4344, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 118/553, Loss: 0.2339, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 119/553, Loss: 0.5688, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 120/553, Loss: 0.5948, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 121/553, Loss: 0.2511, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 122/553, Loss: 0.4021, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 123/553, Loss: 0.2698, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 124/553, Loss: 0.1792, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 125/553, Loss: 0.2663, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 126/553, Loss: 0.1300, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 127/553, Loss: 0.2767, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 128/553, Loss: 0.2748, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 129/553, Loss: 0.3767, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 130/553, Loss: 0.3249, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 131/553, Loss: 0.1432, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 132/553, Loss: 0.2848, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 133/553, Loss: 0.3457, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 134/553, Loss: 0.0288, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 135/553, Loss: 0.2340, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 136/553, Loss: 0.2508, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 137/553, Loss: 0.3059, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 138/553, Loss: 0.3399, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 139/553, Loss: 0.5262, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 140/553, Loss: 0.7742, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 141/553, Loss: 0.2759, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 142/553, Loss: 0.5378, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 143/553, Loss: 0.2986, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 144/553, Loss: 0.1541, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 145/553, Loss: 0.3635, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 146/553, Loss: 0.3140, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 147/553, Loss: 0.6462, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 148/553, Loss: 0.1740, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 149/553, Loss: 0.1572, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 150/553, Loss: 0.3182, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 151/553, Loss: 0.2983, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 152/553, Loss: 0.4199, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 153/553, Loss: 0.8401, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 154/553, Loss: 0.1599, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 155/553, Loss: 0.3831, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 156/553, Loss: 0.0061, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 157/553, Loss: 0.2982, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 158/553, Loss: 0.2106, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 159/553, Loss: 0.2620, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 160/553, Loss: 0.7748, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 161/553, Loss: 0.1888, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 162/553, Loss: 0.4189, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 163/553, Loss: 0.5241, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 164/553, Loss: 0.4974, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 165/553, Loss: 0.6493, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 166/553, Loss: 0.2377, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 167/553, Loss: 0.4846, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 168/553, Loss: 0.6207, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 169/553, Loss: 0.2421, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 170/553, Loss: 0.5581, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 171/553, Loss: 0.6897, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 172/553, Loss: 0.3185, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 173/553, Loss: 0.5472, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 174/553, Loss: 0.1637, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 175/553, Loss: 0.3427, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 176/553, Loss: 0.2925, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 177/553, Loss: 0.4946, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 178/553, Loss: 0.1798, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 179/553, Loss: 0.3702, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 180/553, Loss: 0.0697, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 181/553, Loss: 0.3650, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 182/553, Loss: 0.3063, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 183/553, Loss: 0.2752, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 184/553, Loss: 0.1360, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 185/553, Loss: 0.2470, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 186/553, Loss: 0.3554, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 187/553, Loss: 0.3037, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 188/553, Loss: 0.3712, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 189/553, Loss: 0.1692, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 190/553, Loss: 0.9762, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 191/553, Loss: 0.1031, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 192/553, Loss: 0.5972, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 193/553, Loss: 0.3380, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 194/553, Loss: 0.0532, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 195/553, Loss: 0.1519, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 196/553, Loss: 0.4917, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 197/553, Loss: 0.3305, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 198/553, Loss: 0.5473, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 199/553, Loss: 0.2031, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 200/553, Loss: 0.1678, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 201/553, Loss: 0.4212, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 202/553, Loss: 0.3811, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 203/553, Loss: 0.6695, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 204/553, Loss: 0.1394, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 205/553, Loss: 0.3168, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 206/553, Loss: 0.3034, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 207/553, Loss: 0.8056, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 208/553, Loss: 0.5241, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 209/553, Loss: 0.1751, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 210/553, Loss: 0.6867, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 211/553, Loss: 0.3687, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 212/553, Loss: 0.5591, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 213/553, Loss: 0.2480, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 214/553, Loss: 0.5719, Time: 0.73 seconds\n",
            "Epoch 7/20, Batch 215/553, Loss: 0.2960, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 216/553, Loss: 0.1798, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 217/553, Loss: 0.9938, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 218/553, Loss: 0.6769, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 219/553, Loss: 0.5508, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 220/553, Loss: 0.5924, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 221/553, Loss: 0.5635, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 222/553, Loss: 0.3740, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 223/553, Loss: 0.4381, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 224/553, Loss: 0.6306, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 225/553, Loss: 0.7743, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 226/553, Loss: 0.4499, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 227/553, Loss: 0.2648, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 228/553, Loss: 0.5263, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 229/553, Loss: 0.3674, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 230/553, Loss: 0.4481, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 231/553, Loss: 0.4179, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 232/553, Loss: 0.7609, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 233/553, Loss: 0.1595, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 234/553, Loss: 0.4688, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 235/553, Loss: 0.2264, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 236/553, Loss: 0.1990, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 237/553, Loss: 0.1829, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 238/553, Loss: 0.3774, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 239/553, Loss: 0.5412, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 240/553, Loss: 0.6310, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 241/553, Loss: 0.5798, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 242/553, Loss: 0.5682, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 243/553, Loss: 0.2694, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 244/553, Loss: 0.7137, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 245/553, Loss: 0.3300, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 246/553, Loss: 0.3071, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 247/553, Loss: 0.3659, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 248/553, Loss: 0.3280, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 249/553, Loss: 0.2700, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 250/553, Loss: 0.7268, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 251/553, Loss: 0.4561, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 252/553, Loss: 0.8083, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 253/553, Loss: 0.3199, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 254/553, Loss: 0.3365, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 255/553, Loss: 0.5054, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 256/553, Loss: 0.2842, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 257/553, Loss: 0.5444, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 258/553, Loss: 0.4029, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 259/553, Loss: 0.3247, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 260/553, Loss: 0.2168, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 261/553, Loss: 0.2419, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 262/553, Loss: 0.5258, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 263/553, Loss: 0.2924, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 264/553, Loss: 0.4155, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 265/553, Loss: 0.5453, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 266/553, Loss: 0.3837, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 267/553, Loss: 0.5194, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 268/553, Loss: 0.6824, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 269/553, Loss: 0.5052, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 270/553, Loss: 0.2370, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 271/553, Loss: 0.1429, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 272/553, Loss: 0.5606, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 273/553, Loss: 0.4477, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 274/553, Loss: 0.4365, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 275/553, Loss: 0.3916, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 276/553, Loss: 0.2958, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 277/553, Loss: 0.3893, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 278/553, Loss: 0.4283, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 279/553, Loss: 0.4080, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 280/553, Loss: 0.5846, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 281/553, Loss: 0.4611, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 282/553, Loss: 0.7089, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 283/553, Loss: 0.7961, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 284/553, Loss: 0.2418, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 285/553, Loss: 0.1085, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 286/553, Loss: 0.1072, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 287/553, Loss: 0.4105, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 288/553, Loss: 0.0897, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 289/553, Loss: 0.2323, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 290/553, Loss: 0.4136, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 291/553, Loss: 0.5551, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 292/553, Loss: 0.4666, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 293/553, Loss: 0.5951, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 294/553, Loss: 0.2356, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 295/553, Loss: 0.4949, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 296/553, Loss: 0.6924, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 297/553, Loss: 0.2390, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 298/553, Loss: 0.4606, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 299/553, Loss: 0.3718, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 300/553, Loss: 0.6455, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 301/553, Loss: 0.3858, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 302/553, Loss: 0.5016, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 303/553, Loss: 0.2235, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 304/553, Loss: 0.4995, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 305/553, Loss: 0.3511, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 306/553, Loss: 0.3563, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 307/553, Loss: 0.4116, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 308/553, Loss: 0.3474, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 309/553, Loss: 0.3402, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 310/553, Loss: 0.2349, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 311/553, Loss: 0.3838, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 312/553, Loss: 0.3430, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 313/553, Loss: 0.4793, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 314/553, Loss: 0.3866, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 315/553, Loss: 0.4746, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 316/553, Loss: 0.5040, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 317/553, Loss: 0.5338, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 318/553, Loss: 0.5220, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 319/553, Loss: 0.2920, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 320/553, Loss: 0.2743, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 321/553, Loss: 0.0059, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 322/553, Loss: 0.4117, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 323/553, Loss: 0.4343, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 324/553, Loss: 0.7373, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 325/553, Loss: 0.4266, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 326/553, Loss: 0.5961, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 327/553, Loss: 0.3511, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 328/553, Loss: 0.5167, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 329/553, Loss: 0.5939, Time: 0.77 seconds\n",
            "Epoch 7/20, Batch 330/553, Loss: 0.5096, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 331/553, Loss: 0.5637, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 332/553, Loss: 0.2921, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 333/553, Loss: 0.5165, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 334/553, Loss: 0.2492, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 335/553, Loss: 0.5844, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 336/553, Loss: 0.3683, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 337/553, Loss: 0.5698, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 338/553, Loss: 0.3450, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 339/553, Loss: 0.2434, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 340/553, Loss: 0.5938, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 341/553, Loss: 0.3703, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 342/553, Loss: 0.0814, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 343/553, Loss: 0.3862, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 344/553, Loss: 0.8169, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 345/553, Loss: 0.8126, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 346/553, Loss: 0.3829, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 347/553, Loss: 0.4687, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 348/553, Loss: 0.6519, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 349/553, Loss: 0.3717, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 350/553, Loss: 0.6295, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 351/553, Loss: 0.5849, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 352/553, Loss: 0.3675, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 353/553, Loss: 0.3567, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 354/553, Loss: 0.1329, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 355/553, Loss: 0.6162, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 356/553, Loss: 0.3133, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 357/553, Loss: 0.2700, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 358/553, Loss: 0.1907, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 359/553, Loss: 0.5770, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 360/553, Loss: 0.6216, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 361/553, Loss: 0.3522, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 362/553, Loss: 0.5601, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 363/553, Loss: 0.4713, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 364/553, Loss: 0.7213, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 365/553, Loss: 0.6636, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 366/553, Loss: 0.3599, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 367/553, Loss: 0.1679, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 368/553, Loss: 0.3418, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 369/553, Loss: 0.4240, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 370/553, Loss: 0.5558, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 371/553, Loss: 0.5421, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 372/553, Loss: 0.5958, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 373/553, Loss: 0.3274, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 374/553, Loss: 0.6021, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 375/553, Loss: 0.4300, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 376/553, Loss: 0.3648, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 377/553, Loss: 0.3905, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 378/553, Loss: 0.9617, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 379/553, Loss: 0.5146, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 380/553, Loss: 0.5332, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 381/553, Loss: 0.6140, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 382/553, Loss: 0.5096, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 383/553, Loss: 0.6019, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 384/553, Loss: 0.2407, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 385/553, Loss: 0.2822, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 386/553, Loss: 0.2039, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 387/553, Loss: 0.2168, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 388/553, Loss: 0.1699, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 389/553, Loss: 0.4022, Time: 0.77 seconds\n",
            "Epoch 7/20, Batch 390/553, Loss: 0.8860, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 391/553, Loss: 0.1553, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 392/553, Loss: 0.6957, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 393/553, Loss: 0.5196, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 394/553, Loss: 0.5895, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 395/553, Loss: 0.3336, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 396/553, Loss: 0.3062, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 397/553, Loss: 0.3455, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 398/553, Loss: 0.5998, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 399/553, Loss: 0.2170, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 400/553, Loss: 0.4166, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 401/553, Loss: 0.5250, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 402/553, Loss: 0.6378, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 403/553, Loss: 0.3911, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 404/553, Loss: 0.2981, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 405/553, Loss: 0.3064, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 406/553, Loss: 0.1012, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 407/553, Loss: 0.5189, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 408/553, Loss: 0.5499, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 409/553, Loss: 0.5867, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 410/553, Loss: 0.7909, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 411/553, Loss: 0.1447, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 412/553, Loss: 0.4576, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 413/553, Loss: 0.4500, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 414/553, Loss: 0.5771, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 415/553, Loss: 0.3438, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 416/553, Loss: 0.5394, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 417/553, Loss: 0.6715, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 418/553, Loss: 0.4565, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 419/553, Loss: 0.3737, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 420/553, Loss: 0.2010, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 421/553, Loss: 0.2996, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 422/553, Loss: 0.3863, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 423/553, Loss: 0.3317, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 424/553, Loss: 0.2855, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 425/553, Loss: 0.4114, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 426/553, Loss: 0.0591, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 427/553, Loss: 0.4599, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 428/553, Loss: 0.6309, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 429/553, Loss: 0.2022, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 430/553, Loss: 0.3704, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 431/553, Loss: 0.1791, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 432/553, Loss: 0.8404, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 433/553, Loss: 0.3269, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 434/553, Loss: 0.2274, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 435/553, Loss: 0.3748, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 436/553, Loss: 0.3168, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 437/553, Loss: 0.2387, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 438/553, Loss: 0.2077, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 439/553, Loss: 0.3245, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 440/553, Loss: 0.3054, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 441/553, Loss: 0.2602, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 442/553, Loss: 0.2065, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 443/553, Loss: 0.3193, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 444/553, Loss: 0.7589, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 445/553, Loss: 0.3466, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 446/553, Loss: 0.5427, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 447/553, Loss: 0.5556, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 448/553, Loss: 0.3214, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 449/553, Loss: 0.1924, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 450/553, Loss: 0.6564, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 451/553, Loss: 0.1244, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 452/553, Loss: 0.2694, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 453/553, Loss: 0.7524, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 454/553, Loss: 0.4343, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 455/553, Loss: 0.4877, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 456/553, Loss: 0.3335, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 457/553, Loss: 0.6766, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 458/553, Loss: 0.2400, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 459/553, Loss: 0.4053, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 460/553, Loss: 0.1967, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 461/553, Loss: 0.4414, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 462/553, Loss: 0.2868, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 463/553, Loss: 0.9765, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 464/553, Loss: 0.1674, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 465/553, Loss: 0.3518, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 466/553, Loss: 0.4002, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 467/553, Loss: 0.2686, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 468/553, Loss: 0.2966, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 469/553, Loss: 0.8700, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 470/553, Loss: 0.8534, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 471/553, Loss: 0.3751, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 472/553, Loss: 0.2940, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 473/553, Loss: 0.1740, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 474/553, Loss: 0.3023, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 475/553, Loss: 0.4689, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 476/553, Loss: 0.2282, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 477/553, Loss: 0.2013, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 478/553, Loss: 0.2474, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 479/553, Loss: 0.9050, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 480/553, Loss: 0.4219, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 481/553, Loss: 0.7661, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 482/553, Loss: 0.2204, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 483/553, Loss: 0.2435, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 484/553, Loss: 0.3823, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 485/553, Loss: 0.4247, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 486/553, Loss: 0.3089, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 487/553, Loss: 0.3994, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 488/553, Loss: 0.3664, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 489/553, Loss: 0.4330, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 490/553, Loss: 0.2190, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 491/553, Loss: 0.9251, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 492/553, Loss: 0.7383, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 493/553, Loss: 0.6988, Time: 0.77 seconds\n",
            "Epoch 7/20, Batch 494/553, Loss: 0.1109, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 495/553, Loss: 0.3284, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 496/553, Loss: 0.2645, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 497/553, Loss: 0.4586, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 498/553, Loss: 0.8677, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 499/553, Loss: 0.5946, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 500/553, Loss: 0.1052, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 501/553, Loss: 0.5573, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 502/553, Loss: 0.6679, Time: 0.77 seconds\n",
            "Epoch 7/20, Batch 503/553, Loss: 0.2727, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 504/553, Loss: 0.3324, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 505/553, Loss: 0.1919, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 506/553, Loss: 0.6591, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 507/553, Loss: 0.5706, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 508/553, Loss: 0.5260, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 509/553, Loss: 0.7538, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 510/553, Loss: 0.2577, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 511/553, Loss: 0.2039, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 512/553, Loss: 0.3734, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 513/553, Loss: 0.7957, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 514/553, Loss: 0.6330, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 515/553, Loss: 0.3016, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 516/553, Loss: 0.3140, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 517/553, Loss: 0.5915, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 518/553, Loss: 0.4865, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 519/553, Loss: 0.2840, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 520/553, Loss: 0.0915, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 521/553, Loss: 0.3403, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 522/553, Loss: 0.4998, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 523/553, Loss: 0.1975, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 524/553, Loss: 0.2519, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 525/553, Loss: 0.6337, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 526/553, Loss: 0.5712, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 527/553, Loss: 0.1432, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 528/553, Loss: 0.1306, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 529/553, Loss: 0.4313, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 530/553, Loss: 0.2067, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 531/553, Loss: 0.2395, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 532/553, Loss: 0.0868, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 533/553, Loss: 0.5617, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 534/553, Loss: 0.4503, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 535/553, Loss: 0.2501, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 536/553, Loss: 0.3988, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 537/553, Loss: 0.4871, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 538/553, Loss: 0.4606, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 539/553, Loss: 0.7840, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 540/553, Loss: 0.3439, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 541/553, Loss: 0.1010, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 542/553, Loss: 0.1406, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 543/553, Loss: 0.4484, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 544/553, Loss: 0.4810, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 545/553, Loss: 0.4185, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 546/553, Loss: 0.4847, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 547/553, Loss: 0.4541, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 548/553, Loss: 0.1321, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 549/553, Loss: 0.3240, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 550/553, Loss: 0.1166, Time: 0.74 seconds\n",
            "Epoch 7/20, Batch 551/553, Loss: 0.4410, Time: 0.76 seconds\n",
            "Epoch 7/20, Batch 552/553, Loss: 0.3454, Time: 0.75 seconds\n",
            "Epoch 7/20, Batch 553/553, Loss: 0.8761, Time: 0.10 seconds\n",
            "Epoch 7/20, Training Loss: 0.4048, Time: 417.05 seconds\n",
            "Validation Loss: 0.3784, Accuracy: 0.8561\n",
            "Overfitting detected. Early stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"./trained_models/semi_supervised/fine_tuned\")"
      ],
      "metadata": {
        "id": "7AbyKTUlBdX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"./trained_models/semi_supervised/first_semi_unbalanced\")"
      ],
      "metadata": {
        "id": "0qmqlpoKX9HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/semi_supervised/third_semi_unbalanced\")"
      ],
      "metadata": {
        "id": "ZioPI7tHhEzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi Supervised (new way)"
      ],
      "metadata": {
        "id": "edC2wi3SR00k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked = pd.read_csv('chunked_dataset.csv')\n",
        "original = pd.read_csv('dataset.csv')\n",
        "del original['Unnamed: 0']\n",
        "del original['labels']\n",
        "del chunked['token_numbers']\n",
        "del chunked['Unnamed: 0']\n",
        "df = pd.concat([chunked, original], ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "HPdwRr_qOUaS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "51e082c8-1ef0-42cf-8030-9474c5691d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent             RootCause\n",
              "0     metrics2.impl.\\n\\nMetricsConfig: loaded proper...           MachineDown\n",
              "1     MapTask: Processing split: hdfs://msra-sa-41:9...           MachineDown\n",
              "2     MapTask: kvstart = 11165416(44661664); kvend =...           MachineDown\n",
              "3     [SpillThread] mapred.\\n\\nMapTask: Finished spi...           MachineDown\n",
              "4     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection\n",
              "...                                                 ...                   ...\n",
              "4795     metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "4796     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "4797     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "4798     metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "4799     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "\n",
              "[4800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b27df8b-4ad1-4354-ad08-12d8004b808a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: Processing split: hdfs://msra-sa-41:9...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MapTask: kvstart = 11165416(44661664); kvend =...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SpillThread] mapred.\\n\\nMapTask: Finished spi...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b27df8b-4ad1-4354-ad08-12d8004b808a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b27df8b-4ad1-4354-ad08-12d8004b808a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b27df8b-4ad1-4354-ad08-12d8004b808a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8377c7ba-819d-42e6-b627-8e72659da583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8377c7ba-819d-42e6-b627-8e72659da583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8377c7ba-819d-42e6-b627-8e72659da583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1579bffc-b5c5-4ee7-a66a-8b466a17ba4b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1579bffc-b5c5-4ee7-a66a-8b466a17ba4b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df['RootCause'].unique().tolist()\n",
        "labels = [s.strip() for s in labels ]\n",
        "NUM_LABELS= len(labels)\n",
        "\n",
        "id2label={id:label for id,label in enumerate(labels)}\n",
        "\n",
        "label2id={label:id for id,label in enumerate(labels)}\n",
        "df[\"labels\"]=df.RootCause.map(lambda x: label2id[x.strip()])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "K-dwVZ_kSEny",
        "outputId": "10a12d22-d2a3-40db-8089-2bd4b760b958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent             RootCause  \\\n",
              "0     metrics2.impl.\\n\\nMetricsConfig: loaded proper...           MachineDown   \n",
              "1     MapTask: Processing split: hdfs://msra-sa-41:9...           MachineDown   \n",
              "2     MapTask: kvstart = 11165416(44661664); kvend =...           MachineDown   \n",
              "3     [SpillThread] mapred.\\n\\nMapTask: Finished spi...           MachineDown   \n",
              "4     metrics2.impl.\\n\\nMetricsConfig: loaded proper...  NetworkDisconnection   \n",
              "...                                                 ...                   ...   \n",
              "4795     metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "4796     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4797     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4798     metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "4799     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "      labels  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          1  \n",
              "...      ...  \n",
              "4795       1  \n",
              "4796       0  \n",
              "4797       0  \n",
              "4798       2  \n",
              "4799       0  \n",
              "\n",
              "[4800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55ae4616-a7ba-452e-b557-7e588cc3961c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: Processing split: hdfs://msra-sa-41:9...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MapTask: kvstart = 11165416(44661664); kvend =...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SpillThread] mapred.\\n\\nMapTask: Finished spi...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55ae4616-a7ba-452e-b557-7e588cc3961c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55ae4616-a7ba-452e-b557-7e588cc3961c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55ae4616-a7ba-452e-b557-7e588cc3961c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-486da01b-8116-4cda-832b-f2dca143d7f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-486da01b-8116-4cda-832b-f2dca143d7f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-486da01b-8116-4cda-832b-f2dca143d7f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6063f840-0450-4204-9821-35316a4d76e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6063f840-0450-4204-9821-35316a4d76e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "3PyJdqy-SgwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into labeled and unlabeled datasets (90-10 split)\n",
        "labeled, unlabeled = train_test_split(df, test_size=0.1, random_state=100, shuffle=True)\n",
        "labeled = labeled.reset_index(drop=True)\n",
        "unlabeled = unlabeled.reset_index(drop=True)\n",
        "labeled['labels'].value_counts()\n",
        "# labeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_NHweMxSsmA",
        "outputId": "2b078bb1-e00c-433c-9c3f-15fb1cf5be7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2830\n",
              "1     793\n",
              "2     697\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_dataset = CustomDataset(texts=list(labeled['LogContent']), labels=labeled['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader for labeled dataset\n",
        "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "k6pRcriaSxER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3FqanYpTPtB",
        "outputId": "3e03c14a-3f86-4c02-c220-7ddf4383906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming labeled_train_dataloader is your DataLoader for labeled training data\n",
        "\n",
        "# Fine-tuning loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the labeled training DataLoader\n",
        "    for batch_idx, batch in enumerate(labeled_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        # label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        # print(f\"Batch {batch_idx + 1}/{len(labeled_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(labeled_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(labeled_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCkTzF_qTSIE",
        "outputId": "80737759-1b4e-42ad-f98d-8f9728c9e306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ef9e455f6b36>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Batch 1/270, Loss: 1.0872, Time: 2.19 seconds\n",
            "Epoch 1/2, Batch 2/270, Loss: 0.9036, Time: 1.44 seconds\n",
            "Epoch 1/2, Batch 3/270, Loss: 1.0897, Time: 1.44 seconds\n",
            "Epoch 1/2, Batch 4/270, Loss: 1.2179, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 5/270, Loss: 1.0850, Time: 1.44 seconds\n",
            "Epoch 1/2, Batch 6/270, Loss: 0.7738, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 7/270, Loss: 0.6794, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 8/270, Loss: 0.7063, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 9/270, Loss: 0.4248, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 10/270, Loss: 0.7465, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 11/270, Loss: 0.6434, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 12/270, Loss: 0.7231, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 13/270, Loss: 0.8990, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 14/270, Loss: 1.5212, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 15/270, Loss: 0.4809, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 16/270, Loss: 1.2654, Time: 1.53 seconds\n",
            "Epoch 1/2, Batch 17/270, Loss: 0.9324, Time: 1.54 seconds\n",
            "Epoch 1/2, Batch 18/270, Loss: 0.9588, Time: 1.53 seconds\n",
            "Epoch 1/2, Batch 19/270, Loss: 0.7292, Time: 1.54 seconds\n",
            "Epoch 1/2, Batch 20/270, Loss: 0.8349, Time: 1.58 seconds\n",
            "Epoch 1/2, Batch 21/270, Loss: 0.8746, Time: 1.55 seconds\n",
            "Epoch 1/2, Batch 22/270, Loss: 0.7168, Time: 1.57 seconds\n",
            "Epoch 1/2, Batch 23/270, Loss: 0.7094, Time: 1.57 seconds\n",
            "Epoch 1/2, Batch 24/270, Loss: 0.9442, Time: 1.58 seconds\n",
            "Epoch 1/2, Batch 25/270, Loss: 0.9033, Time: 1.56 seconds\n",
            "Epoch 1/2, Batch 26/270, Loss: 0.6421, Time: 1.59 seconds\n",
            "Epoch 1/2, Batch 27/270, Loss: 0.6816, Time: 1.55 seconds\n",
            "Epoch 1/2, Batch 28/270, Loss: 0.8849, Time: 1.55 seconds\n",
            "Epoch 1/2, Batch 29/270, Loss: 0.8403, Time: 1.54 seconds\n",
            "Epoch 1/2, Batch 30/270, Loss: 0.7544, Time: 1.54 seconds\n",
            "Epoch 1/2, Batch 31/270, Loss: 0.9205, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 32/270, Loss: 0.8546, Time: 1.53 seconds\n",
            "Epoch 1/2, Batch 33/270, Loss: 0.9331, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 34/270, Loss: 0.7459, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 35/270, Loss: 0.9983, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 36/270, Loss: 1.4824, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 37/270, Loss: 1.0316, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 38/270, Loss: 1.0329, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 39/270, Loss: 1.1042, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 40/270, Loss: 0.9269, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 41/270, Loss: 1.0066, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 42/270, Loss: 0.7970, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 43/270, Loss: 0.9728, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 44/270, Loss: 0.8628, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 45/270, Loss: 0.9360, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 46/270, Loss: 0.8947, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 47/270, Loss: 0.8034, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 48/270, Loss: 0.8777, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 49/270, Loss: 0.8402, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 50/270, Loss: 0.6980, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 51/270, Loss: 1.1411, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 52/270, Loss: 1.0588, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 53/270, Loss: 0.6596, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 54/270, Loss: 0.7936, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 55/270, Loss: 0.7574, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 56/270, Loss: 1.0814, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 57/270, Loss: 0.9221, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 58/270, Loss: 0.7199, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 59/270, Loss: 1.1117, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 60/270, Loss: 0.8315, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 61/270, Loss: 1.0249, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 62/270, Loss: 1.1483, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 63/270, Loss: 0.8691, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 64/270, Loss: 0.7186, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 65/270, Loss: 0.8659, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 66/270, Loss: 0.9682, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 67/270, Loss: 1.0922, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 68/270, Loss: 1.2267, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 69/270, Loss: 0.9272, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 70/270, Loss: 0.8314, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 71/270, Loss: 0.9864, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 72/270, Loss: 0.7879, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 73/270, Loss: 1.0760, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 74/270, Loss: 0.7015, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 75/270, Loss: 1.0151, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 76/270, Loss: 0.9455, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 77/270, Loss: 0.5387, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 78/270, Loss: 1.0120, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 79/270, Loss: 0.8819, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 80/270, Loss: 0.7223, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 81/270, Loss: 1.0588, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 82/270, Loss: 0.6761, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 83/270, Loss: 0.9143, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 84/270, Loss: 0.8857, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 85/270, Loss: 1.0831, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 86/270, Loss: 0.8654, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 87/270, Loss: 1.1863, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 88/270, Loss: 1.0332, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 89/270, Loss: 0.9301, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 90/270, Loss: 1.0616, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 91/270, Loss: 0.6156, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 92/270, Loss: 0.9880, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 93/270, Loss: 0.8746, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 94/270, Loss: 0.9457, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 95/270, Loss: 0.9735, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 96/270, Loss: 0.8028, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 97/270, Loss: 0.9230, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 98/270, Loss: 0.8864, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 99/270, Loss: 0.7378, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 100/270, Loss: 0.9645, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 101/270, Loss: 0.8861, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 102/270, Loss: 0.8782, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 103/270, Loss: 0.8535, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 104/270, Loss: 0.9794, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 105/270, Loss: 0.9729, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 106/270, Loss: 0.8199, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 107/270, Loss: 1.0737, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 108/270, Loss: 1.2949, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 109/270, Loss: 0.5747, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 110/270, Loss: 0.9902, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 111/270, Loss: 0.9712, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 112/270, Loss: 0.7649, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 113/270, Loss: 0.9491, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 114/270, Loss: 0.8192, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 115/270, Loss: 1.0289, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 116/270, Loss: 0.9108, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 117/270, Loss: 0.7652, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 118/270, Loss: 0.8803, Time: 1.47 seconds\n",
            "Epoch 1/2, Batch 119/270, Loss: 0.8123, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 120/270, Loss: 0.6870, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 121/270, Loss: 0.5386, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 122/270, Loss: 0.9253, Time: 1.46 seconds\n",
            "Epoch 1/2, Batch 123/270, Loss: 0.9238, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 124/270, Loss: 0.9856, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 125/270, Loss: 0.7511, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 126/270, Loss: 0.5710, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 127/270, Loss: 0.6014, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 128/270, Loss: 0.8995, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 129/270, Loss: 0.7739, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 130/270, Loss: 0.9422, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 131/270, Loss: 0.7921, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 132/270, Loss: 0.7179, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 133/270, Loss: 0.7839, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 134/270, Loss: 0.7931, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 135/270, Loss: 0.7807, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 136/270, Loss: 0.7069, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 137/270, Loss: 0.7423, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 138/270, Loss: 0.8969, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 139/270, Loss: 0.8737, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 140/270, Loss: 0.6464, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 141/270, Loss: 0.9717, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 142/270, Loss: 0.9006, Time: 1.52 seconds\n",
            "Epoch 1/2, Batch 143/270, Loss: 0.7909, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 144/270, Loss: 0.7221, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 145/270, Loss: 0.7452, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 146/270, Loss: 0.7789, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 147/270, Loss: 0.6727, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 148/270, Loss: 0.5073, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 149/270, Loss: 1.0029, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 150/270, Loss: 0.8222, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 151/270, Loss: 0.6523, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 152/270, Loss: 0.8813, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 153/270, Loss: 0.9222, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 154/270, Loss: 0.5493, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 155/270, Loss: 0.6478, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 156/270, Loss: 0.7634, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 157/270, Loss: 0.8457, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 158/270, Loss: 0.6372, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 159/270, Loss: 0.8294, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 160/270, Loss: 0.8300, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 161/270, Loss: 0.6024, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 162/270, Loss: 0.7963, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 163/270, Loss: 0.5177, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 164/270, Loss: 1.0525, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 165/270, Loss: 0.6896, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 166/270, Loss: 0.5281, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 167/270, Loss: 0.5267, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 168/270, Loss: 0.9284, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 169/270, Loss: 0.7596, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 170/270, Loss: 0.7866, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 171/270, Loss: 0.7478, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 172/270, Loss: 0.7250, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 173/270, Loss: 0.6892, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 174/270, Loss: 0.8266, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 175/270, Loss: 0.8722, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 176/270, Loss: 0.8096, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 177/270, Loss: 0.6720, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 178/270, Loss: 0.6355, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 179/270, Loss: 0.5979, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 180/270, Loss: 0.6017, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 181/270, Loss: 0.7725, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 182/270, Loss: 0.9584, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 183/270, Loss: 0.4354, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 184/270, Loss: 0.8005, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 185/270, Loss: 0.6643, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 186/270, Loss: 0.6138, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 187/270, Loss: 0.6986, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 188/270, Loss: 0.6387, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 189/270, Loss: 0.7047, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 190/270, Loss: 0.5316, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 191/270, Loss: 0.9042, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 192/270, Loss: 0.4657, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 193/270, Loss: 0.5651, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 194/270, Loss: 0.8751, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 195/270, Loss: 0.7464, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 196/270, Loss: 0.4291, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 197/270, Loss: 0.5695, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 198/270, Loss: 0.7735, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 199/270, Loss: 0.5216, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 200/270, Loss: 0.4995, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 201/270, Loss: 0.4674, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 202/270, Loss: 0.6167, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 203/270, Loss: 0.6274, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 204/270, Loss: 0.5855, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 205/270, Loss: 0.6827, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 206/270, Loss: 0.5489, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 207/270, Loss: 0.5366, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 208/270, Loss: 0.5956, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 209/270, Loss: 0.8200, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 210/270, Loss: 0.4530, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 211/270, Loss: 0.7283, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 212/270, Loss: 0.6559, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 213/270, Loss: 0.9055, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 214/270, Loss: 0.5862, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 215/270, Loss: 0.6497, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 216/270, Loss: 0.9479, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 217/270, Loss: 0.4403, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 218/270, Loss: 0.9841, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 219/270, Loss: 0.7447, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 220/270, Loss: 0.4137, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 221/270, Loss: 1.0302, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 222/270, Loss: 0.9861, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 223/270, Loss: 0.4957, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 224/270, Loss: 0.4990, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 225/270, Loss: 0.6974, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 226/270, Loss: 0.6327, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 227/270, Loss: 0.4984, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 228/270, Loss: 0.5965, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 229/270, Loss: 0.3165, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 230/270, Loss: 0.5476, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 231/270, Loss: 0.7246, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 232/270, Loss: 0.4857, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 233/270, Loss: 0.5370, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 234/270, Loss: 0.5735, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 235/270, Loss: 0.5170, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 236/270, Loss: 0.6657, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 237/270, Loss: 0.5987, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 238/270, Loss: 0.2786, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 239/270, Loss: 0.3175, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 240/270, Loss: 0.5462, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 241/270, Loss: 0.9777, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 242/270, Loss: 0.7499, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 243/270, Loss: 0.3414, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 244/270, Loss: 0.6686, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 245/270, Loss: 0.2141, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 246/270, Loss: 0.4338, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 247/270, Loss: 0.4923, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 248/270, Loss: 0.4043, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 249/270, Loss: 0.4201, Time: 1.51 seconds\n",
            "Epoch 1/2, Batch 250/270, Loss: 0.2794, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 251/270, Loss: 0.9012, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 252/270, Loss: 0.5236, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 253/270, Loss: 0.5194, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 254/270, Loss: 0.5682, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 255/270, Loss: 0.7078, Time: 1.53 seconds\n",
            "Epoch 1/2, Batch 256/270, Loss: 0.3812, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 257/270, Loss: 0.4691, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 258/270, Loss: 0.4602, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 259/270, Loss: 0.8062, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 260/270, Loss: 0.4404, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 261/270, Loss: 0.2673, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 262/270, Loss: 0.4862, Time: 1.48 seconds\n",
            "Epoch 1/2, Batch 263/270, Loss: 0.2542, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 264/270, Loss: 0.4702, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 265/270, Loss: 0.3732, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 266/270, Loss: 0.5698, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 267/270, Loss: 0.5385, Time: 1.49 seconds\n",
            "Epoch 1/2, Batch 268/270, Loss: 0.3974, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 269/270, Loss: 0.3623, Time: 1.50 seconds\n",
            "Epoch 1/2, Batch 270/270, Loss: 0.2887, Time: 1.51 seconds\n",
            "Epoch 1/2, Training Loss: 0.7632, Time: 404.88 seconds\n",
            "Epoch 2/2, Batch 1/270, Loss: 0.4311, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 2/270, Loss: 0.4479, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 3/270, Loss: 0.4109, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 4/270, Loss: 0.2913, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 5/270, Loss: 0.7643, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 6/270, Loss: 0.2874, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 7/270, Loss: 0.2938, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 8/270, Loss: 0.4338, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 9/270, Loss: 0.3521, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 10/270, Loss: 0.3603, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 11/270, Loss: 0.2493, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 12/270, Loss: 0.4685, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 13/270, Loss: 0.0693, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 14/270, Loss: 0.3885, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 15/270, Loss: 0.2271, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 16/270, Loss: 0.4069, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 17/270, Loss: 0.2693, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 18/270, Loss: 0.5589, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 19/270, Loss: 0.3668, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 20/270, Loss: 0.1029, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 21/270, Loss: 0.2073, Time: 1.47 seconds\n",
            "Epoch 2/2, Batch 22/270, Loss: 0.6083, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 23/270, Loss: 0.2535, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 24/270, Loss: 0.4394, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 25/270, Loss: 0.4494, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 26/270, Loss: 0.2368, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 27/270, Loss: 0.7001, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 28/270, Loss: 0.2377, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 29/270, Loss: 0.5819, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 30/270, Loss: 0.6918, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 31/270, Loss: 0.3399, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 32/270, Loss: 0.5242, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 33/270, Loss: 0.5184, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 34/270, Loss: 0.3163, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 35/270, Loss: 0.6141, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 36/270, Loss: 0.3794, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 37/270, Loss: 0.2505, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 38/270, Loss: 0.5890, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 39/270, Loss: 0.2850, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 40/270, Loss: 0.6333, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 41/270, Loss: 0.2295, Time: 1.52 seconds\n",
            "Epoch 2/2, Batch 42/270, Loss: 0.2107, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 43/270, Loss: 0.5090, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 44/270, Loss: 0.5398, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 45/270, Loss: 0.6230, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 46/270, Loss: 0.4155, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 47/270, Loss: 0.7220, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 48/270, Loss: 0.4020, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 49/270, Loss: 0.4881, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 50/270, Loss: 0.5503, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 51/270, Loss: 0.2915, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 52/270, Loss: 0.6297, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 53/270, Loss: 0.5624, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 54/270, Loss: 0.6360, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 55/270, Loss: 0.7657, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 56/270, Loss: 0.2600, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 57/270, Loss: 0.2902, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 58/270, Loss: 0.3496, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 59/270, Loss: 1.0372, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 60/270, Loss: 0.6324, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 61/270, Loss: 0.4404, Time: 1.52 seconds\n",
            "Epoch 2/2, Batch 62/270, Loss: 0.3022, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 63/270, Loss: 0.2996, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 64/270, Loss: 0.4837, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 65/270, Loss: 0.6217, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 66/270, Loss: 0.5667, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 67/270, Loss: 0.4267, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 68/270, Loss: 0.4459, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 69/270, Loss: 0.3544, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 70/270, Loss: 0.3074, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 71/270, Loss: 0.5827, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 72/270, Loss: 0.4392, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 73/270, Loss: 0.5304, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 74/270, Loss: 0.4527, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 75/270, Loss: 0.5197, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 76/270, Loss: 0.3733, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 77/270, Loss: 0.1689, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 78/270, Loss: 0.5281, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 79/270, Loss: 0.4397, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 80/270, Loss: 0.4267, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 81/270, Loss: 0.2418, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 82/270, Loss: 0.4755, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 83/270, Loss: 0.8533, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 84/270, Loss: 0.2733, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 85/270, Loss: 0.3557, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 86/270, Loss: 0.3719, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 87/270, Loss: 0.9623, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 88/270, Loss: 0.2990, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 89/270, Loss: 0.2540, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 90/270, Loss: 0.6486, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 91/270, Loss: 0.7080, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 92/270, Loss: 0.3176, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 93/270, Loss: 0.5211, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 94/270, Loss: 0.3959, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 95/270, Loss: 0.3497, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 96/270, Loss: 0.5105, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 97/270, Loss: 0.3558, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 98/270, Loss: 0.4851, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 99/270, Loss: 0.7141, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 100/270, Loss: 0.2737, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 101/270, Loss: 0.1329, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 102/270, Loss: 0.4540, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 103/270, Loss: 0.3775, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 104/270, Loss: 0.3789, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 105/270, Loss: 0.2805, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 106/270, Loss: 0.2347, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 107/270, Loss: 0.3891, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 108/270, Loss: 0.2130, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 109/270, Loss: 0.4116, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 110/270, Loss: 0.4641, Time: 1.52 seconds\n",
            "Epoch 2/2, Batch 111/270, Loss: 0.5098, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 112/270, Loss: 0.4233, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 113/270, Loss: 0.6737, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 114/270, Loss: 0.3335, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 115/270, Loss: 0.1731, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 116/270, Loss: 0.4940, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 117/270, Loss: 0.0577, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 118/270, Loss: 0.6413, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 119/270, Loss: 0.2261, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 120/270, Loss: 0.2729, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 121/270, Loss: 0.4607, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 122/270, Loss: 0.5411, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 123/270, Loss: 0.2483, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 124/270, Loss: 0.4178, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 125/270, Loss: 0.3973, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 126/270, Loss: 0.3158, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 127/270, Loss: 0.6135, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 128/270, Loss: 0.1821, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 129/270, Loss: 0.3111, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 130/270, Loss: 0.3754, Time: 1.52 seconds\n",
            "Epoch 2/2, Batch 131/270, Loss: 0.3017, Time: 1.47 seconds\n",
            "Epoch 2/2, Batch 132/270, Loss: 0.3813, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 133/270, Loss: 0.2469, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 134/270, Loss: 0.1984, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 135/270, Loss: 0.3129, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 136/270, Loss: 0.1055, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 137/270, Loss: 0.7716, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 138/270, Loss: 0.2312, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 139/270, Loss: 0.4974, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 140/270, Loss: 0.3745, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 141/270, Loss: 0.4413, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 142/270, Loss: 0.4327, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 143/270, Loss: 0.3323, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 144/270, Loss: 0.3311, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 145/270, Loss: 0.3133, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 146/270, Loss: 0.4500, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 147/270, Loss: 0.3190, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 148/270, Loss: 0.5360, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 149/270, Loss: 0.5340, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 150/270, Loss: 0.2013, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 151/270, Loss: 0.4136, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 152/270, Loss: 0.3213, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 153/270, Loss: 0.3218, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 154/270, Loss: 0.4068, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 155/270, Loss: 0.3907, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 156/270, Loss: 0.4261, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 157/270, Loss: 0.7489, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 158/270, Loss: 0.2504, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 159/270, Loss: 0.4960, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 160/270, Loss: 0.2649, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 161/270, Loss: 0.4309, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 162/270, Loss: 0.2033, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 163/270, Loss: 0.2704, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 164/270, Loss: 0.2864, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 165/270, Loss: 0.2919, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 166/270, Loss: 0.3492, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 167/270, Loss: 0.5011, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 168/270, Loss: 0.5020, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 169/270, Loss: 0.1513, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 170/270, Loss: 0.5761, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 171/270, Loss: 0.5244, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 172/270, Loss: 0.2302, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 173/270, Loss: 0.8386, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 174/270, Loss: 0.4043, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 175/270, Loss: 0.4418, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 176/270, Loss: 0.1505, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 177/270, Loss: 0.4582, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 178/270, Loss: 0.4088, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 179/270, Loss: 0.2244, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 180/270, Loss: 0.3628, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 181/270, Loss: 0.1562, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 182/270, Loss: 0.2018, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 183/270, Loss: 0.3864, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 184/270, Loss: 0.5175, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 185/270, Loss: 0.2397, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 186/270, Loss: 0.5152, Time: 1.52 seconds\n",
            "Epoch 2/2, Batch 187/270, Loss: 0.4906, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 188/270, Loss: 0.1965, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 189/270, Loss: 0.5113, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 190/270, Loss: 0.4209, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 191/270, Loss: 0.3080, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 192/270, Loss: 0.2460, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 193/270, Loss: 0.4008, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 194/270, Loss: 0.1937, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 195/270, Loss: 0.2474, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 196/270, Loss: 0.2087, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 197/270, Loss: 0.4217, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 198/270, Loss: 0.1864, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 199/270, Loss: 0.3455, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 200/270, Loss: 0.6032, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 201/270, Loss: 0.4289, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 202/270, Loss: 0.4061, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 203/270, Loss: 0.3335, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 204/270, Loss: 0.2957, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 205/270, Loss: 0.2916, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 206/270, Loss: 0.3512, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 207/270, Loss: 0.4095, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 208/270, Loss: 0.3175, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 209/270, Loss: 0.7182, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 210/270, Loss: 0.4974, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 211/270, Loss: 0.8375, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 212/270, Loss: 0.4415, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 213/270, Loss: 0.6340, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 214/270, Loss: 0.4304, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 215/270, Loss: 0.3801, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 216/270, Loss: 0.3289, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 217/270, Loss: 0.2925, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 218/270, Loss: 0.2144, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 219/270, Loss: 0.1403, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 220/270, Loss: 0.4085, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 221/270, Loss: 0.4258, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 222/270, Loss: 0.2486, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 223/270, Loss: 0.3900, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 224/270, Loss: 0.4322, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 225/270, Loss: 0.2192, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 226/270, Loss: 0.4167, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 227/270, Loss: 0.3823, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 228/270, Loss: 0.5645, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 229/270, Loss: 0.1385, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 230/270, Loss: 0.6645, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 231/270, Loss: 0.4948, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 232/270, Loss: 0.3306, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 233/270, Loss: 0.3655, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 234/270, Loss: 0.4235, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 235/270, Loss: 0.4408, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 236/270, Loss: 0.4824, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 237/270, Loss: 0.4257, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 238/270, Loss: 0.4414, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 239/270, Loss: 0.4436, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 240/270, Loss: 0.3666, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 241/270, Loss: 0.4475, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 242/270, Loss: 0.4024, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 243/270, Loss: 0.6593, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 244/270, Loss: 0.4067, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 245/270, Loss: 0.1413, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 246/270, Loss: 0.4463, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 247/270, Loss: 0.2789, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 248/270, Loss: 0.4997, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 249/270, Loss: 0.4354, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 250/270, Loss: 0.3188, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 251/270, Loss: 0.4317, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 252/270, Loss: 0.3122, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 253/270, Loss: 0.5516, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 254/270, Loss: 0.2732, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 255/270, Loss: 0.2464, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 256/270, Loss: 0.3638, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 257/270, Loss: 0.3890, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 258/270, Loss: 0.2019, Time: 1.48 seconds\n",
            "Epoch 2/2, Batch 259/270, Loss: 0.3052, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 260/270, Loss: 0.5766, Time: 1.51 seconds\n",
            "Epoch 2/2, Batch 261/270, Loss: 0.3702, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 262/270, Loss: 0.5214, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 263/270, Loss: 0.4231, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 264/270, Loss: 0.3840, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 265/270, Loss: 0.3882, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 266/270, Loss: 0.2916, Time: 1.50 seconds\n",
            "Epoch 2/2, Batch 267/270, Loss: 0.3206, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 268/270, Loss: 0.2304, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 269/270, Loss: 0.1782, Time: 1.49 seconds\n",
            "Epoch 2/2, Batch 270/270, Loss: 0.2685, Time: 1.48 seconds\n",
            "Epoch 2/2, Training Loss: 0.4013, Time: 404.59 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/semi_supervised_new/fine_tuned\")"
      ],
      "metadata": {
        "id": "_1JcBJHjTZ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QRCfJBP3X_UB",
        "outputId": "ffe9310c-b702-41e8-f014-ec26c04dc96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent             RootCause  \\\n",
              "0        metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "1     MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  NetworkDisconnection   \n",
              "2        metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "3     NetUtils.wrapException(NetUtils.java:757)\\n\\ta...  NetworkDisconnection   \n",
              "4     MapTask: (EQUATOR) 9745912 kvi 2436472(9745888...  NetworkDisconnection   \n",
              "...                                                 ...                   ...   \n",
              "3835  MapTask: (EQUATOR) 9811814 kvi 2452948(9811792...           MachineDown   \n",
              "3836  MapTask: kvstart = 14562400(58249600); kvend =...           MachineDown   \n",
              "3837  ContainerManagementProtocolProxy:\\n\\nOpening p...           MachineDown   \n",
              "3838  MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...           MachineDown   \n",
              "3839  Already tried 2 time(s); maxRetries=45\\n   ipc...           MachineDown   \n",
              "\n",
              "      labels  \n",
              "0          0  \n",
              "1          1  \n",
              "2          0  \n",
              "3          1  \n",
              "4          1  \n",
              "...      ...  \n",
              "3835       0  \n",
              "3836       0  \n",
              "3837       0  \n",
              "3838       0  \n",
              "3839       0  \n",
              "\n",
              "[3840 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca39570a-8cd0-4be2-9363-5651272cb017\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NetUtils.wrapException(NetUtils.java:757)\\n\\ta...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MapTask: (EQUATOR) 9745912 kvi 2436472(9745888...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3835</th>\n",
              "      <td>MapTask: (EQUATOR) 9811814 kvi 2452948(9811792...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3836</th>\n",
              "      <td>MapTask: kvstart = 14562400(58249600); kvend =...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3837</th>\n",
              "      <td>ContainerManagementProtocolProxy:\\n\\nOpening p...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3838</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3839</th>\n",
              "      <td>Already tried 2 time(s); maxRetries=45\\n   ipc...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3840 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca39570a-8cd0-4be2-9363-5651272cb017')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca39570a-8cd0-4be2-9363-5651272cb017 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca39570a-8cd0-4be2-9363-5651272cb017');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80aa6396-9093-4cca-abef-39e1b0bf0859\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80aa6396-9093-4cca-abef-39e1b0bf0859')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80aa6396-9093-4cca-abef-39e1b0bf0859 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9618b39b-62f0-4241-b15b-065ac09652f3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('labeled')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9618b39b-62f0-4241-b15b-065ac09652f3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('labeled');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model and unlabeled dataset if needed\n",
        "# model_path = \"./trained_models/old_way\"\n",
        "# model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# labeled = pd.read_csv('./trained_models/semi_supervised/labeled.csv')\n",
        "# unlabeled = pd.read_csv('./trained_models/semi_supervised/unlabeled.csv')\n",
        "\n",
        "# Move the model to the same device as the training\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Assuming 'unlabeled' is your unlabeled dataset\n",
        "batch_size = 8  # Adjust the batch size based on your available GPU memory\n",
        "\n",
        "# Tokenize the unlabeled texts\n",
        "unlabeled_texts = unlabeled['LogContent'].tolist()\n",
        "num_batches = int(np.ceil(len(unlabeled_texts) / batch_size))\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "# Make predictions batch-wise\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, len(unlabeled_texts))\n",
        "\n",
        "        batch_texts = unlabeled_texts[start_idx:end_idx]\n",
        "\n",
        "        # Tokenize the batch\n",
        "        batch_encodings = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "        batch_inputs = {key: val.to(device) for key, val in batch_encodings.items()}\n",
        "\n",
        "        # Make predictions for the batch\n",
        "        outputs = model(**batch_inputs)\n",
        "        batch_predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        predicted_labels.extend(batch_predictions.cpu().numpy())\n",
        "\n",
        "# Create a new dataframe with the original columns and the predicted labels\n",
        "predicted_df = pd.DataFrame({\n",
        "    'LogContent': unlabeled['LogContent'],\n",
        "    'RootCause': unlabeled['RootCause'],\n",
        "    'PredictedLabels': predicted_labels\n",
        "})\n",
        "\n",
        "predicted_df = predicted_df.rename(columns={'PredictedLabels': 'labels'})\n",
        "\n",
        "predicted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Jpg2jKU4T1ls",
        "outputId": "af4f1d16-4444-474d-ac96-ec515e667b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent    RootCause  labels\n",
              "0    MapTask: Spilling map output\\n   mapred.\\n\\nMa...  MachineDown       0\n",
              "1    MapTask: kvstart = 7315060(29260240); kvend = ...  MachineDown       0\n",
              "2    ShuffleSchedulerImpl: assigned 1 of 1 to MSRA-...  MachineDown       0\n",
              "3    MapTask: kvstart = 7315060(29260240); kvend = ...     DiskFull       2\n",
              "4    MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...  MachineDown       0\n",
              "..                                                 ...          ...     ...\n",
              "475  RackResolver: Resolved MSRA-SA-39.fareast.corp...  MachineDown       0\n",
              "476  Fetcher: for url=13562/mapOutput?job=job_14451...     DiskFull       2\n",
              "477     metrics2.impl.MetricsConfig: loaded propert...  MachineDown       0\n",
              "478  metrics2.impl.\\n\\nMetricsConfig: loaded proper...  MachineDown       0\n",
              "479  MapTask: (EQUATOR) 89320393 kvi 22330092(89320...  MachineDown       0\n",
              "\n",
              "[480 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-198671c3-5a7f-48e1-bde3-95324c764a40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MapTask: Spilling map output\\n   mapred.\\n\\nMa...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MapTask: kvstart = 7315060(29260240); kvend = ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ShuffleSchedulerImpl: assigned 1 of 1 to MSRA-...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MapTask: kvstart = 7315060(29260240); kvend = ...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MapTask: (EQUATOR) 0\\n\\nkvi 26214396(104857584...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>RackResolver: Resolved MSRA-SA-39.fareast.corp...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>Fetcher: for url=13562/mapOutput?job=job_14451...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>metrics2.impl.\\n\\nMetricsConfig: loaded proper...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>MapTask: (EQUATOR) 89320393 kvi 22330092(89320...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>480 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-198671c3-5a7f-48e1-bde3-95324c764a40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-198671c3-5a7f-48e1-bde3-95324c764a40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-198671c3-5a7f-48e1-bde3-95324c764a40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6675c87-fa42-4905-9a18-b4ee939ef0ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6675c87-fa42-4905-9a18-b4ee939ef0ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6675c87-fa42-4905-9a18-b4ee939ef0ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0a1ae7df-f16e-4ebe-bc6f-ce67290c982c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('predicted_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0a1ae7df-f16e-4ebe-bc6f-ce67290c982c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('predicted_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43SXrr9HYKop",
        "outputId": "3902512f-9be6-49a1-d436-decb789e6b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    340\n",
              "1     83\n",
              "2     57\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N07vHCHJYJLy",
        "outputId": "d453a8ac-aaf1-4752-81ad-812a22818c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    382\n",
              "1     58\n",
              "2     40\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_labeled = pd.concat([labeled, predicted_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "thJKiI02YJEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_labeled['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmvdCs0fYB10",
        "outputId": "2b912c19-1e5a-490c-9b90-7e0ef50d47d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3212\n",
              "1     851\n",
              "2     737\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation datasets (80-20 split)\n",
        "train, val = train_test_split(pseudo_labeled, test_size=0.2, random_state=100, shuffle=True)\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "66uvFJP6ZBFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDataset(texts=list(train['LogContent']), labels=train['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDataset(texts=list(val['LogContent']), labels=val['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgYB56fIZImk",
        "outputId": "bb1ee423-68b5-4602-80f7-3885bc7a0ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Training loop without early stopping\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "0v6ZmEriZJWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0357b95f-36e4-4b41-f574-576eb8a752e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ef9e455f6b36>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 1/480, Loss: 0.4445, Time: 0.80 seconds\n",
            "Batch 2/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 2/480, Loss: 0.2836, Time: 0.79 seconds\n",
            "Batch 3/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 3/480, Loss: 0.3159, Time: 0.79 seconds\n",
            "Batch 4/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 4/480, Loss: 0.2976, Time: 0.78 seconds\n",
            "Batch 5/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 5/480, Loss: 0.5347, Time: 0.78 seconds\n",
            "Batch 6/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 6/480, Loss: 0.2952, Time: 0.78 seconds\n",
            "Batch 7/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 7/480, Loss: 0.2000, Time: 0.79 seconds\n",
            "Batch 8/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 8/480, Loss: 0.7093, Time: 0.80 seconds\n",
            "Batch 9/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 9/480, Loss: 0.1332, Time: 0.79 seconds\n",
            "Batch 10/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 10/480, Loss: 0.6154, Time: 0.79 seconds\n",
            "Batch 11/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 11/480, Loss: 0.3477, Time: 0.80 seconds\n",
            "Batch 12/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 12/480, Loss: 0.2627, Time: 0.82 seconds\n",
            "Batch 13/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 13/480, Loss: 0.3549, Time: 0.80 seconds\n",
            "Batch 14/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 14/480, Loss: 0.1404, Time: 0.81 seconds\n",
            "Batch 15/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 15/480, Loss: 0.2431, Time: 0.80 seconds\n",
            "Batch 16/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 16/480, Loss: 0.3398, Time: 0.80 seconds\n",
            "Batch 17/480, Label Counts: {0: 2, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 17/480, Loss: 0.8591, Time: 0.82 seconds\n",
            "Batch 18/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 18/480, Loss: 0.1808, Time: 0.82 seconds\n",
            "Batch 19/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 19/480, Loss: 0.0668, Time: 0.80 seconds\n",
            "Batch 20/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 20/480, Loss: 0.4023, Time: 0.81 seconds\n",
            "Batch 21/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 21/480, Loss: 0.6357, Time: 0.81 seconds\n",
            "Batch 22/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 22/480, Loss: 0.0558, Time: 0.81 seconds\n",
            "Batch 23/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 23/480, Loss: 0.5518, Time: 0.81 seconds\n",
            "Batch 24/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 24/480, Loss: 0.3524, Time: 0.81 seconds\n",
            "Batch 25/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 25/480, Loss: 0.2229, Time: 0.80 seconds\n",
            "Batch 26/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 26/480, Loss: 0.1292, Time: 0.80 seconds\n",
            "Batch 27/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 27/480, Loss: 0.1798, Time: 0.80 seconds\n",
            "Batch 28/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 28/480, Loss: 0.2999, Time: 0.79 seconds\n",
            "Batch 29/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 29/480, Loss: 0.2993, Time: 0.79 seconds\n",
            "Batch 30/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 30/480, Loss: 0.1323, Time: 0.80 seconds\n",
            "Batch 31/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 31/480, Loss: 0.0662, Time: 0.78 seconds\n",
            "Batch 32/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 32/480, Loss: 0.2731, Time: 0.77 seconds\n",
            "Batch 33/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 33/480, Loss: 0.4398, Time: 0.79 seconds\n",
            "Batch 34/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 34/480, Loss: 0.0459, Time: 0.77 seconds\n",
            "Batch 35/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 35/480, Loss: 0.2690, Time: 0.78 seconds\n",
            "Batch 36/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 36/480, Loss: 0.3413, Time: 0.78 seconds\n",
            "Batch 37/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 37/480, Loss: 0.0665, Time: 0.78 seconds\n",
            "Batch 38/480, Label Counts: {0: 4, 2: 4}\n",
            "Epoch 1/3, Batch 38/480, Loss: 0.3539, Time: 0.78 seconds\n",
            "Batch 39/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 39/480, Loss: 0.4314, Time: 0.77 seconds\n",
            "Batch 40/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 40/480, Loss: 0.0870, Time: 0.77 seconds\n",
            "Batch 41/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 41/480, Loss: 0.3868, Time: 0.77 seconds\n",
            "Batch 42/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 42/480, Loss: 0.3032, Time: 0.78 seconds\n",
            "Batch 43/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 43/480, Loss: 0.4866, Time: 0.76 seconds\n",
            "Batch 44/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 44/480, Loss: 0.3308, Time: 0.77 seconds\n",
            "Batch 45/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 45/480, Loss: 0.0622, Time: 0.76 seconds\n",
            "Batch 46/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 46/480, Loss: 0.0015, Time: 0.76 seconds\n",
            "Batch 47/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 47/480, Loss: 0.5836, Time: 0.79 seconds\n",
            "Batch 48/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 48/480, Loss: 0.0960, Time: 0.77 seconds\n",
            "Batch 49/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 49/480, Loss: 0.3406, Time: 0.78 seconds\n",
            "Batch 50/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 50/480, Loss: 0.0668, Time: 0.76 seconds\n",
            "Batch 51/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 51/480, Loss: 0.4599, Time: 0.77 seconds\n",
            "Batch 52/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 52/480, Loss: 0.5236, Time: 0.77 seconds\n",
            "Batch 53/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 53/480, Loss: 0.4093, Time: 0.78 seconds\n",
            "Batch 54/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 54/480, Loss: 0.3261, Time: 0.76 seconds\n",
            "Batch 55/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 55/480, Loss: 0.3487, Time: 0.77 seconds\n",
            "Batch 56/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 56/480, Loss: 0.7014, Time: 0.75 seconds\n",
            "Batch 57/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 57/480, Loss: 0.2396, Time: 0.77 seconds\n",
            "Batch 58/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 58/480, Loss: 0.6403, Time: 0.76 seconds\n",
            "Batch 59/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 59/480, Loss: 0.5514, Time: 0.76 seconds\n",
            "Batch 60/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 60/480, Loss: 0.1477, Time: 0.75 seconds\n",
            "Batch 61/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 61/480, Loss: 0.3948, Time: 0.75 seconds\n",
            "Batch 62/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 62/480, Loss: 0.7130, Time: 0.75 seconds\n",
            "Batch 63/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 63/480, Loss: 0.3679, Time: 0.76 seconds\n",
            "Batch 64/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 64/480, Loss: 0.6963, Time: 0.75 seconds\n",
            "Batch 65/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 65/480, Loss: 0.7891, Time: 0.77 seconds\n",
            "Batch 66/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 66/480, Loss: 0.3668, Time: 0.74 seconds\n",
            "Batch 67/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 67/480, Loss: 0.4180, Time: 0.75 seconds\n",
            "Batch 68/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 68/480, Loss: 0.6022, Time: 0.74 seconds\n",
            "Batch 69/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 69/480, Loss: 0.3687, Time: 0.75 seconds\n",
            "Batch 70/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 70/480, Loss: 0.2255, Time: 0.75 seconds\n",
            "Batch 71/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 71/480, Loss: 0.4178, Time: 0.77 seconds\n",
            "Batch 72/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 72/480, Loss: 0.3876, Time: 0.76 seconds\n",
            "Batch 73/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 73/480, Loss: 0.3645, Time: 0.77 seconds\n",
            "Batch 74/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 74/480, Loss: 0.5169, Time: 0.76 seconds\n",
            "Batch 75/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 75/480, Loss: 0.4173, Time: 0.76 seconds\n",
            "Batch 76/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 76/480, Loss: 0.1451, Time: 0.75 seconds\n",
            "Batch 77/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 77/480, Loss: 0.2000, Time: 0.76 seconds\n",
            "Batch 78/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 78/480, Loss: 0.3378, Time: 0.75 seconds\n",
            "Batch 79/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 79/480, Loss: 0.1054, Time: 0.75 seconds\n",
            "Batch 80/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 80/480, Loss: 0.1516, Time: 0.75 seconds\n",
            "Batch 81/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 81/480, Loss: 0.4369, Time: 0.75 seconds\n",
            "Batch 82/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 82/480, Loss: 0.2094, Time: 0.75 seconds\n",
            "Batch 83/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 83/480, Loss: 0.1247, Time: 0.75 seconds\n",
            "Batch 84/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 84/480, Loss: 0.1206, Time: 0.76 seconds\n",
            "Batch 85/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 85/480, Loss: 0.4346, Time: 0.74 seconds\n",
            "Batch 86/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 86/480, Loss: 0.9981, Time: 0.76 seconds\n",
            "Batch 87/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 87/480, Loss: 0.3058, Time: 0.76 seconds\n",
            "Batch 88/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 88/480, Loss: 0.1249, Time: 0.75 seconds\n",
            "Batch 89/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 89/480, Loss: 0.3350, Time: 0.75 seconds\n",
            "Batch 90/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 90/480, Loss: 0.3079, Time: 0.76 seconds\n",
            "Batch 91/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 91/480, Loss: 0.0550, Time: 0.75 seconds\n",
            "Batch 92/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 92/480, Loss: 0.4234, Time: 0.77 seconds\n",
            "Batch 93/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 93/480, Loss: 0.6951, Time: 0.76 seconds\n",
            "Batch 94/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 94/480, Loss: 0.2915, Time: 0.76 seconds\n",
            "Batch 95/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 95/480, Loss: 0.4151, Time: 0.75 seconds\n",
            "Batch 96/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 96/480, Loss: 0.3376, Time: 0.76 seconds\n",
            "Batch 97/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 97/480, Loss: 0.5760, Time: 0.77 seconds\n",
            "Batch 98/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 98/480, Loss: 0.3812, Time: 0.75 seconds\n",
            "Batch 99/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 99/480, Loss: 0.3537, Time: 0.76 seconds\n",
            "Batch 100/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 100/480, Loss: 0.3746, Time: 0.76 seconds\n",
            "Batch 101/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 101/480, Loss: 0.1339, Time: 0.75 seconds\n",
            "Batch 102/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 102/480, Loss: 0.0799, Time: 0.76 seconds\n",
            "Batch 103/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 103/480, Loss: 0.1321, Time: 0.77 seconds\n",
            "Batch 104/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 104/480, Loss: 0.1159, Time: 0.75 seconds\n",
            "Batch 105/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 105/480, Loss: 0.4146, Time: 0.78 seconds\n",
            "Batch 106/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 106/480, Loss: 0.1381, Time: 0.76 seconds\n",
            "Batch 107/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 107/480, Loss: 0.2420, Time: 0.76 seconds\n",
            "Batch 108/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 108/480, Loss: 0.1552, Time: 0.76 seconds\n",
            "Batch 109/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 109/480, Loss: 0.0525, Time: 0.76 seconds\n",
            "Batch 110/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 110/480, Loss: 0.0497, Time: 0.77 seconds\n",
            "Batch 111/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 111/480, Loss: 0.0375, Time: 0.76 seconds\n",
            "Batch 112/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 112/480, Loss: 0.1976, Time: 0.77 seconds\n",
            "Batch 113/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 113/480, Loss: 0.4174, Time: 0.77 seconds\n",
            "Batch 114/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 114/480, Loss: 0.8278, Time: 0.77 seconds\n",
            "Batch 115/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 115/480, Loss: 1.2960, Time: 0.78 seconds\n",
            "Batch 116/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 116/480, Loss: 0.4536, Time: 0.77 seconds\n",
            "Batch 117/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 117/480, Loss: 0.1421, Time: 0.78 seconds\n",
            "Batch 118/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 118/480, Loss: 0.1601, Time: 0.77 seconds\n",
            "Batch 119/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 119/480, Loss: 0.3185, Time: 0.77 seconds\n",
            "Batch 120/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 120/480, Loss: 0.6670, Time: 0.76 seconds\n",
            "Batch 121/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 121/480, Loss: 0.2332, Time: 0.76 seconds\n",
            "Batch 122/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 122/480, Loss: 0.6951, Time: 0.78 seconds\n",
            "Batch 123/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 123/480, Loss: 0.1580, Time: 0.77 seconds\n",
            "Batch 124/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 124/480, Loss: 0.5681, Time: 0.78 seconds\n",
            "Batch 125/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 125/480, Loss: 0.7715, Time: 0.78 seconds\n",
            "Batch 126/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 126/480, Loss: 0.5226, Time: 0.77 seconds\n",
            "Batch 127/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 127/480, Loss: 0.3868, Time: 0.78 seconds\n",
            "Batch 128/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 128/480, Loss: 0.4218, Time: 0.77 seconds\n",
            "Batch 129/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 129/480, Loss: 0.4276, Time: 0.79 seconds\n",
            "Batch 130/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 130/480, Loss: 0.2524, Time: 0.77 seconds\n",
            "Batch 131/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 131/480, Loss: 0.2015, Time: 0.78 seconds\n",
            "Batch 132/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 132/480, Loss: 0.2239, Time: 0.77 seconds\n",
            "Batch 133/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 133/480, Loss: 0.5100, Time: 0.78 seconds\n",
            "Batch 134/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 134/480, Loss: 0.1934, Time: 0.76 seconds\n",
            "Batch 135/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 135/480, Loss: 0.7984, Time: 0.78 seconds\n",
            "Batch 136/480, Label Counts: {0: 2, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 136/480, Loss: 0.5377, Time: 0.78 seconds\n",
            "Batch 137/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 137/480, Loss: 0.2925, Time: 0.77 seconds\n",
            "Batch 138/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 138/480, Loss: 0.1461, Time: 0.77 seconds\n",
            "Batch 139/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 139/480, Loss: 0.3075, Time: 0.77 seconds\n",
            "Batch 140/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 140/480, Loss: 0.2880, Time: 0.77 seconds\n",
            "Batch 141/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 141/480, Loss: 0.6333, Time: 0.77 seconds\n",
            "Batch 142/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 142/480, Loss: 0.1345, Time: 0.77 seconds\n",
            "Batch 143/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 143/480, Loss: 0.8748, Time: 0.78 seconds\n",
            "Batch 144/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 144/480, Loss: 0.1038, Time: 0.76 seconds\n",
            "Batch 145/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 145/480, Loss: 1.0833, Time: 0.77 seconds\n",
            "Batch 146/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 146/480, Loss: 0.0705, Time: 0.76 seconds\n",
            "Batch 147/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 147/480, Loss: 0.1301, Time: 0.77 seconds\n",
            "Batch 148/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 148/480, Loss: 2.1653, Time: 0.77 seconds\n",
            "Batch 149/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 149/480, Loss: 0.3485, Time: 0.75 seconds\n",
            "Batch 150/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 150/480, Loss: 0.4228, Time: 0.78 seconds\n",
            "Batch 151/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 151/480, Loss: 0.7392, Time: 0.78 seconds\n",
            "Batch 152/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 152/480, Loss: 0.5511, Time: 0.77 seconds\n",
            "Batch 153/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 153/480, Loss: 0.0832, Time: 0.76 seconds\n",
            "Batch 154/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 154/480, Loss: 0.4462, Time: 0.78 seconds\n",
            "Batch 155/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 155/480, Loss: 0.1860, Time: 0.77 seconds\n",
            "Batch 156/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 156/480, Loss: 0.3512, Time: 0.75 seconds\n",
            "Batch 157/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 157/480, Loss: 0.5816, Time: 0.77 seconds\n",
            "Batch 158/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 158/480, Loss: 0.4917, Time: 0.77 seconds\n",
            "Batch 159/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 159/480, Loss: 0.3118, Time: 0.76 seconds\n",
            "Batch 160/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 160/480, Loss: 0.5159, Time: 0.75 seconds\n",
            "Batch 161/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 161/480, Loss: 0.3763, Time: 0.77 seconds\n",
            "Batch 162/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 162/480, Loss: 0.0993, Time: 0.76 seconds\n",
            "Batch 163/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 163/480, Loss: 0.6634, Time: 0.76 seconds\n",
            "Batch 164/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 164/480, Loss: 0.3946, Time: 0.77 seconds\n",
            "Batch 165/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 165/480, Loss: 0.4277, Time: 0.76 seconds\n",
            "Batch 166/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 166/480, Loss: 0.2747, Time: 0.77 seconds\n",
            "Batch 167/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 167/480, Loss: 0.2460, Time: 0.77 seconds\n",
            "Batch 168/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 168/480, Loss: 0.4199, Time: 0.77 seconds\n",
            "Batch 169/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 169/480, Loss: 0.2871, Time: 0.78 seconds\n",
            "Batch 170/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 170/480, Loss: 0.3383, Time: 0.75 seconds\n",
            "Batch 171/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 171/480, Loss: 0.9853, Time: 0.77 seconds\n",
            "Batch 172/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 172/480, Loss: 0.4674, Time: 0.75 seconds\n",
            "Batch 173/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 173/480, Loss: 0.1506, Time: 0.77 seconds\n",
            "Batch 174/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 174/480, Loss: 0.4636, Time: 0.76 seconds\n",
            "Batch 175/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 175/480, Loss: 0.7607, Time: 0.76 seconds\n",
            "Batch 176/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 176/480, Loss: 0.0449, Time: 0.75 seconds\n",
            "Batch 177/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 177/480, Loss: 0.3104, Time: 0.76 seconds\n",
            "Batch 178/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 178/480, Loss: 0.1381, Time: 0.76 seconds\n",
            "Batch 179/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 179/480, Loss: 0.4328, Time: 0.77 seconds\n",
            "Batch 180/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 180/480, Loss: 3.1448, Time: 0.75 seconds\n",
            "Batch 181/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 181/480, Loss: 1.0119, Time: 0.77 seconds\n",
            "Batch 182/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 182/480, Loss: 0.6242, Time: 0.75 seconds\n",
            "Batch 183/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 183/480, Loss: 0.5085, Time: 0.76 seconds\n",
            "Batch 184/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 184/480, Loss: 0.8043, Time: 0.75 seconds\n",
            "Batch 185/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 185/480, Loss: 0.3324, Time: 0.75 seconds\n",
            "Batch 186/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 186/480, Loss: 1.0108, Time: 0.76 seconds\n",
            "Batch 187/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 187/480, Loss: 1.0097, Time: 0.76 seconds\n",
            "Batch 188/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 188/480, Loss: 0.4202, Time: 0.76 seconds\n",
            "Batch 189/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 189/480, Loss: 0.1747, Time: 0.77 seconds\n",
            "Batch 190/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 190/480, Loss: 0.5457, Time: 0.77 seconds\n",
            "Batch 191/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 191/480, Loss: 0.7954, Time: 0.76 seconds\n",
            "Batch 192/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 192/480, Loss: 0.6218, Time: 0.76 seconds\n",
            "Batch 193/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 193/480, Loss: 0.6805, Time: 0.76 seconds\n",
            "Batch 194/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 194/480, Loss: 0.8895, Time: 0.76 seconds\n",
            "Batch 195/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 195/480, Loss: 0.5360, Time: 0.77 seconds\n",
            "Batch 196/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 196/480, Loss: 0.3252, Time: 0.76 seconds\n",
            "Batch 197/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 197/480, Loss: 0.7987, Time: 0.77 seconds\n",
            "Batch 198/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 198/480, Loss: 0.7795, Time: 0.75 seconds\n",
            "Batch 199/480, Label Counts: {0: 2, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 199/480, Loss: 0.8665, Time: 0.76 seconds\n",
            "Batch 200/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 200/480, Loss: 0.6062, Time: 0.75 seconds\n",
            "Batch 201/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 201/480, Loss: 0.8967, Time: 0.75 seconds\n",
            "Batch 202/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 202/480, Loss: 0.5554, Time: 0.75 seconds\n",
            "Batch 203/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 203/480, Loss: 0.5555, Time: 0.76 seconds\n",
            "Batch 204/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 204/480, Loss: 0.4479, Time: 0.76 seconds\n",
            "Batch 205/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 205/480, Loss: 0.6846, Time: 0.76 seconds\n",
            "Batch 206/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 206/480, Loss: 0.3750, Time: 0.76 seconds\n",
            "Batch 207/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 207/480, Loss: 0.6678, Time: 0.77 seconds\n",
            "Batch 208/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 208/480, Loss: 0.5567, Time: 0.77 seconds\n",
            "Batch 209/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 209/480, Loss: 0.8702, Time: 0.75 seconds\n",
            "Batch 210/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 210/480, Loss: 1.2135, Time: 0.77 seconds\n",
            "Batch 211/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 211/480, Loss: 0.3932, Time: 0.76 seconds\n",
            "Batch 212/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 212/480, Loss: 0.9341, Time: 0.76 seconds\n",
            "Batch 213/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 213/480, Loss: 0.5304, Time: 0.76 seconds\n",
            "Batch 214/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 214/480, Loss: 0.5451, Time: 0.76 seconds\n",
            "Batch 215/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 215/480, Loss: 0.5028, Time: 0.76 seconds\n",
            "Batch 216/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 216/480, Loss: 0.6763, Time: 0.77 seconds\n",
            "Batch 217/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 217/480, Loss: 0.2712, Time: 0.77 seconds\n",
            "Batch 218/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 218/480, Loss: 0.8104, Time: 0.77 seconds\n",
            "Batch 219/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 219/480, Loss: 0.3622, Time: 0.77 seconds\n",
            "Batch 220/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 220/480, Loss: 1.1088, Time: 0.76 seconds\n",
            "Batch 221/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 221/480, Loss: 0.6644, Time: 0.77 seconds\n",
            "Batch 222/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 222/480, Loss: 0.3272, Time: 0.77 seconds\n",
            "Batch 223/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 223/480, Loss: 0.6428, Time: 0.77 seconds\n",
            "Batch 224/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 224/480, Loss: 0.3926, Time: 0.75 seconds\n",
            "Batch 225/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 225/480, Loss: 0.2963, Time: 0.77 seconds\n",
            "Batch 226/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 226/480, Loss: 0.4112, Time: 0.77 seconds\n",
            "Batch 227/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 227/480, Loss: 0.5278, Time: 0.75 seconds\n",
            "Batch 228/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 228/480, Loss: 0.3462, Time: 0.77 seconds\n",
            "Batch 229/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 229/480, Loss: 0.3124, Time: 0.76 seconds\n",
            "Batch 230/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 230/480, Loss: 0.6544, Time: 0.76 seconds\n",
            "Batch 231/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 231/480, Loss: 0.8428, Time: 0.76 seconds\n",
            "Batch 232/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 232/480, Loss: 0.2569, Time: 0.77 seconds\n",
            "Batch 233/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 233/480, Loss: 0.9522, Time: 0.77 seconds\n",
            "Batch 234/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 234/480, Loss: 0.9744, Time: 0.76 seconds\n",
            "Batch 235/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 235/480, Loss: 0.6357, Time: 0.77 seconds\n",
            "Batch 236/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 236/480, Loss: 0.7461, Time: 0.75 seconds\n",
            "Batch 237/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 237/480, Loss: 0.2892, Time: 0.77 seconds\n",
            "Batch 238/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 238/480, Loss: 0.6118, Time: 0.75 seconds\n",
            "Batch 239/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 239/480, Loss: 0.6715, Time: 0.76 seconds\n",
            "Batch 240/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 240/480, Loss: 0.3020, Time: 0.75 seconds\n",
            "Batch 241/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 241/480, Loss: 0.2665, Time: 0.75 seconds\n",
            "Batch 242/480, Label Counts: {0: 2, 2: 6}\n",
            "Epoch 1/3, Batch 242/480, Loss: 0.9087, Time: 0.77 seconds\n",
            "Batch 243/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 243/480, Loss: 0.4598, Time: 0.76 seconds\n",
            "Batch 244/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 244/480, Loss: 0.5960, Time: 0.76 seconds\n",
            "Batch 245/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 245/480, Loss: 0.3553, Time: 0.76 seconds\n",
            "Batch 246/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 246/480, Loss: 0.7690, Time: 0.76 seconds\n",
            "Batch 247/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 247/480, Loss: 0.7732, Time: 0.77 seconds\n",
            "Batch 248/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 248/480, Loss: 0.3545, Time: 0.76 seconds\n",
            "Batch 249/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 249/480, Loss: 0.4948, Time: 0.76 seconds\n",
            "Batch 250/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 250/480, Loss: 0.4537, Time: 0.78 seconds\n",
            "Batch 251/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 251/480, Loss: 0.5453, Time: 0.77 seconds\n",
            "Batch 252/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 252/480, Loss: 0.6316, Time: 0.76 seconds\n",
            "Batch 253/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 253/480, Loss: 0.2445, Time: 0.77 seconds\n",
            "Batch 254/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 254/480, Loss: 0.5264, Time: 0.76 seconds\n",
            "Batch 255/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 255/480, Loss: 0.4801, Time: 0.76 seconds\n",
            "Batch 256/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 256/480, Loss: 0.6850, Time: 0.76 seconds\n",
            "Batch 257/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 257/480, Loss: 0.1784, Time: 0.77 seconds\n",
            "Batch 258/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 258/480, Loss: 0.1719, Time: 0.77 seconds\n",
            "Batch 259/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 259/480, Loss: 0.5279, Time: 0.78 seconds\n",
            "Batch 260/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 260/480, Loss: 0.6470, Time: 0.77 seconds\n",
            "Batch 261/480, Label Counts: {0: 2, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 261/480, Loss: 1.6897, Time: 0.77 seconds\n",
            "Batch 262/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 262/480, Loss: 0.3001, Time: 0.76 seconds\n",
            "Batch 263/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 263/480, Loss: 0.0220, Time: 0.76 seconds\n",
            "Batch 264/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 264/480, Loss: 0.3629, Time: 0.76 seconds\n",
            "Batch 265/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 265/480, Loss: 0.1018, Time: 0.76 seconds\n",
            "Batch 266/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 266/480, Loss: 0.4032, Time: 0.77 seconds\n",
            "Batch 267/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 267/480, Loss: 0.6426, Time: 0.78 seconds\n",
            "Batch 268/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 268/480, Loss: 0.3593, Time: 0.76 seconds\n",
            "Batch 269/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 269/480, Loss: 0.7625, Time: 0.77 seconds\n",
            "Batch 270/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 270/480, Loss: 0.4039, Time: 0.75 seconds\n",
            "Batch 271/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 271/480, Loss: 0.3405, Time: 0.76 seconds\n",
            "Batch 272/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 272/480, Loss: 0.4782, Time: 0.76 seconds\n",
            "Batch 273/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 273/480, Loss: 0.6434, Time: 0.76 seconds\n",
            "Batch 274/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 274/480, Loss: 0.0933, Time: 0.76 seconds\n",
            "Batch 275/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 275/480, Loss: 0.4266, Time: 0.77 seconds\n",
            "Batch 276/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 276/480, Loss: 0.4680, Time: 0.76 seconds\n",
            "Batch 277/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 277/480, Loss: 0.3288, Time: 0.77 seconds\n",
            "Batch 278/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 278/480, Loss: 0.5117, Time: 0.75 seconds\n",
            "Batch 279/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 279/480, Loss: 0.1557, Time: 0.75 seconds\n",
            "Batch 280/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 280/480, Loss: 0.1190, Time: 0.76 seconds\n",
            "Batch 281/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 281/480, Loss: 0.1262, Time: 0.76 seconds\n",
            "Batch 282/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 282/480, Loss: 0.7060, Time: 0.77 seconds\n",
            "Batch 283/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 283/480, Loss: 0.3426, Time: 0.77 seconds\n",
            "Batch 284/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 284/480, Loss: 0.3280, Time: 0.76 seconds\n",
            "Batch 285/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 285/480, Loss: 0.2901, Time: 0.76 seconds\n",
            "Batch 286/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 286/480, Loss: 0.4746, Time: 0.76 seconds\n",
            "Batch 287/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 287/480, Loss: 0.6623, Time: 0.77 seconds\n",
            "Batch 288/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 288/480, Loss: 0.3056, Time: 0.75 seconds\n",
            "Batch 289/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 289/480, Loss: 0.5259, Time: 0.76 seconds\n",
            "Batch 290/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 290/480, Loss: 0.4069, Time: 0.76 seconds\n",
            "Batch 291/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 291/480, Loss: 0.4703, Time: 0.76 seconds\n",
            "Batch 292/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 292/480, Loss: 0.4326, Time: 0.77 seconds\n",
            "Batch 293/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 293/480, Loss: 0.3291, Time: 0.76 seconds\n",
            "Batch 294/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 294/480, Loss: 0.3504, Time: 0.76 seconds\n",
            "Batch 295/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 295/480, Loss: 0.0363, Time: 0.75 seconds\n",
            "Batch 296/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 296/480, Loss: 0.6600, Time: 0.76 seconds\n",
            "Batch 297/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 297/480, Loss: 0.5673, Time: 0.76 seconds\n",
            "Batch 298/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 298/480, Loss: 0.1864, Time: 0.76 seconds\n",
            "Batch 299/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 299/480, Loss: 0.1447, Time: 0.78 seconds\n",
            "Batch 300/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 300/480, Loss: 0.3187, Time: 0.76 seconds\n",
            "Batch 301/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 301/480, Loss: 0.3470, Time: 0.76 seconds\n",
            "Batch 302/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 302/480, Loss: 0.1513, Time: 0.76 seconds\n",
            "Batch 303/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 303/480, Loss: 0.3127, Time: 0.76 seconds\n",
            "Batch 304/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 304/480, Loss: 0.4151, Time: 0.77 seconds\n",
            "Batch 305/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 305/480, Loss: 0.6120, Time: 0.77 seconds\n",
            "Batch 306/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 306/480, Loss: 0.2530, Time: 0.75 seconds\n",
            "Batch 307/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 307/480, Loss: 0.0913, Time: 0.76 seconds\n",
            "Batch 308/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 308/480, Loss: 0.5608, Time: 0.75 seconds\n",
            "Batch 309/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 309/480, Loss: 0.0662, Time: 0.76 seconds\n",
            "Batch 310/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 310/480, Loss: 0.7023, Time: 0.76 seconds\n",
            "Batch 311/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 311/480, Loss: 0.3873, Time: 0.75 seconds\n",
            "Batch 312/480, Label Counts: {0: 2, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 312/480, Loss: 0.9774, Time: 0.76 seconds\n",
            "Batch 313/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 313/480, Loss: 0.1282, Time: 0.77 seconds\n",
            "Batch 314/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 314/480, Loss: 0.4760, Time: 0.76 seconds\n",
            "Batch 315/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 315/480, Loss: 0.4559, Time: 0.77 seconds\n",
            "Batch 316/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 316/480, Loss: 0.3445, Time: 0.75 seconds\n",
            "Batch 317/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 317/480, Loss: 0.5927, Time: 0.77 seconds\n",
            "Batch 318/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 318/480, Loss: 0.2470, Time: 0.75 seconds\n",
            "Batch 319/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 319/480, Loss: 0.3848, Time: 0.77 seconds\n",
            "Batch 320/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 320/480, Loss: 0.4328, Time: 0.76 seconds\n",
            "Batch 321/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 321/480, Loss: 0.2717, Time: 0.75 seconds\n",
            "Batch 322/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 322/480, Loss: 0.1045, Time: 0.76 seconds\n",
            "Batch 323/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 323/480, Loss: 0.7941, Time: 0.77 seconds\n",
            "Batch 324/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 324/480, Loss: 0.2175, Time: 0.75 seconds\n",
            "Batch 325/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 325/480, Loss: 0.2950, Time: 0.75 seconds\n",
            "Batch 326/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 326/480, Loss: 0.1291, Time: 0.77 seconds\n",
            "Batch 327/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 327/480, Loss: 1.0126, Time: 0.75 seconds\n",
            "Batch 328/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 328/480, Loss: 0.1368, Time: 0.77 seconds\n",
            "Batch 329/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 329/480, Loss: 0.0521, Time: 0.76 seconds\n",
            "Batch 330/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 330/480, Loss: 0.1873, Time: 0.76 seconds\n",
            "Batch 331/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 331/480, Loss: 0.4582, Time: 0.75 seconds\n",
            "Batch 332/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 332/480, Loss: 0.5383, Time: 0.77 seconds\n",
            "Batch 333/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 333/480, Loss: 0.8789, Time: 0.75 seconds\n",
            "Batch 334/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 334/480, Loss: 0.1666, Time: 0.76 seconds\n",
            "Batch 335/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 335/480, Loss: 0.0733, Time: 0.76 seconds\n",
            "Batch 336/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 336/480, Loss: 0.5712, Time: 0.77 seconds\n",
            "Batch 337/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 337/480, Loss: 0.1194, Time: 0.77 seconds\n",
            "Batch 338/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 338/480, Loss: 0.3786, Time: 0.76 seconds\n",
            "Batch 339/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 339/480, Loss: 0.8125, Time: 0.77 seconds\n",
            "Batch 340/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 340/480, Loss: 0.3520, Time: 0.77 seconds\n",
            "Batch 341/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 341/480, Loss: 0.4977, Time: 0.75 seconds\n",
            "Batch 342/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 342/480, Loss: 0.0926, Time: 0.77 seconds\n",
            "Batch 343/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 343/480, Loss: 0.4085, Time: 0.76 seconds\n",
            "Batch 344/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 344/480, Loss: 0.2480, Time: 0.75 seconds\n",
            "Batch 345/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 345/480, Loss: 0.1624, Time: 0.75 seconds\n",
            "Batch 346/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 346/480, Loss: 0.3291, Time: 0.76 seconds\n",
            "Batch 347/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 347/480, Loss: 0.8148, Time: 0.76 seconds\n",
            "Batch 348/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 348/480, Loss: 0.2968, Time: 0.77 seconds\n",
            "Batch 349/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 349/480, Loss: 0.2018, Time: 0.77 seconds\n",
            "Batch 350/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 350/480, Loss: 0.5186, Time: 0.76 seconds\n",
            "Batch 351/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 351/480, Loss: 0.2883, Time: 0.77 seconds\n",
            "Batch 352/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 352/480, Loss: 1.0492, Time: 0.75 seconds\n",
            "Batch 353/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 353/480, Loss: 0.1034, Time: 0.75 seconds\n",
            "Batch 354/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 354/480, Loss: 0.6430, Time: 0.76 seconds\n",
            "Batch 355/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 355/480, Loss: 0.4563, Time: 0.76 seconds\n",
            "Batch 356/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 356/480, Loss: 0.1201, Time: 0.75 seconds\n",
            "Batch 357/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 357/480, Loss: 0.0761, Time: 0.76 seconds\n",
            "Batch 358/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 358/480, Loss: 0.0514, Time: 0.78 seconds\n",
            "Batch 359/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 359/480, Loss: 0.0411, Time: 0.76 seconds\n",
            "Batch 360/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 360/480, Loss: 0.0615, Time: 0.75 seconds\n",
            "Batch 361/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 361/480, Loss: 0.1229, Time: 0.76 seconds\n",
            "Batch 362/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 362/480, Loss: 0.6051, Time: 0.77 seconds\n",
            "Batch 363/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 363/480, Loss: 0.0921, Time: 0.76 seconds\n",
            "Batch 364/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 364/480, Loss: 0.4857, Time: 0.76 seconds\n",
            "Batch 365/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 365/480, Loss: 0.0871, Time: 0.75 seconds\n",
            "Batch 366/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 366/480, Loss: 0.4276, Time: 0.77 seconds\n",
            "Batch 367/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 367/480, Loss: 0.3896, Time: 0.76 seconds\n",
            "Batch 368/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 368/480, Loss: 1.0608, Time: 0.76 seconds\n",
            "Batch 369/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 369/480, Loss: 0.9656, Time: 0.76 seconds\n",
            "Batch 370/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 370/480, Loss: 0.5698, Time: 0.76 seconds\n",
            "Batch 371/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 371/480, Loss: 0.4572, Time: 0.76 seconds\n",
            "Batch 372/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 372/480, Loss: 0.1385, Time: 0.77 seconds\n",
            "Batch 373/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 373/480, Loss: 0.1025, Time: 0.77 seconds\n",
            "Batch 374/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 374/480, Loss: 0.2722, Time: 0.76 seconds\n",
            "Batch 375/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 375/480, Loss: 0.2690, Time: 0.76 seconds\n",
            "Batch 376/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 376/480, Loss: 0.3784, Time: 0.77 seconds\n",
            "Batch 377/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 377/480, Loss: 0.1576, Time: 0.76 seconds\n",
            "Batch 378/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 378/480, Loss: 0.3489, Time: 0.77 seconds\n",
            "Batch 379/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 379/480, Loss: 0.5696, Time: 0.75 seconds\n",
            "Batch 380/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 380/480, Loss: 0.3241, Time: 0.75 seconds\n",
            "Batch 381/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 381/480, Loss: 0.3780, Time: 0.76 seconds\n",
            "Batch 382/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 382/480, Loss: 0.4685, Time: 0.76 seconds\n",
            "Batch 383/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 383/480, Loss: 0.5121, Time: 0.76 seconds\n",
            "Batch 384/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 384/480, Loss: 0.1796, Time: 0.76 seconds\n",
            "Batch 385/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 385/480, Loss: 0.8078, Time: 0.77 seconds\n",
            "Batch 386/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 386/480, Loss: 0.0930, Time: 0.75 seconds\n",
            "Batch 387/480, Label Counts: {0: 2, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 387/480, Loss: 0.3450, Time: 0.77 seconds\n",
            "Batch 388/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 388/480, Loss: 0.0745, Time: 0.75 seconds\n",
            "Batch 389/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 389/480, Loss: 0.8656, Time: 0.77 seconds\n",
            "Batch 390/480, Label Counts: {0: 2, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 390/480, Loss: 0.3552, Time: 0.76 seconds\n",
            "Batch 391/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 391/480, Loss: 0.0696, Time: 0.76 seconds\n",
            "Batch 392/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 392/480, Loss: 0.3833, Time: 0.77 seconds\n",
            "Batch 393/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 393/480, Loss: 0.7746, Time: 0.76 seconds\n",
            "Batch 394/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 394/480, Loss: 0.1034, Time: 0.75 seconds\n",
            "Batch 395/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 395/480, Loss: 0.3540, Time: 0.77 seconds\n",
            "Batch 396/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 396/480, Loss: 0.4315, Time: 0.75 seconds\n",
            "Batch 397/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 397/480, Loss: 0.1761, Time: 0.75 seconds\n",
            "Batch 398/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 398/480, Loss: 0.5096, Time: 0.77 seconds\n",
            "Batch 399/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 399/480, Loss: 0.3046, Time: 0.76 seconds\n",
            "Batch 400/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 400/480, Loss: 0.5696, Time: 0.76 seconds\n",
            "Batch 401/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 401/480, Loss: 0.0893, Time: 0.76 seconds\n",
            "Batch 402/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 402/480, Loss: 0.2246, Time: 0.77 seconds\n",
            "Batch 403/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 403/480, Loss: 0.4103, Time: 0.76 seconds\n",
            "Batch 404/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 404/480, Loss: 0.1218, Time: 0.75 seconds\n",
            "Batch 405/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 405/480, Loss: 0.1066, Time: 0.75 seconds\n",
            "Batch 406/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 406/480, Loss: 0.7323, Time: 0.76 seconds\n",
            "Batch 407/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 407/480, Loss: 0.4185, Time: 0.77 seconds\n",
            "Batch 408/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 408/480, Loss: 0.1197, Time: 0.77 seconds\n",
            "Batch 409/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 409/480, Loss: 0.5019, Time: 0.76 seconds\n",
            "Batch 410/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 410/480, Loss: 0.3809, Time: 0.77 seconds\n",
            "Batch 411/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 411/480, Loss: 0.2288, Time: 0.77 seconds\n",
            "Batch 412/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 412/480, Loss: 0.0027, Time: 0.76 seconds\n",
            "Batch 413/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 413/480, Loss: 0.4525, Time: 0.76 seconds\n",
            "Batch 414/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 414/480, Loss: 0.3481, Time: 0.76 seconds\n",
            "Batch 415/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 415/480, Loss: 0.5432, Time: 0.76 seconds\n",
            "Batch 416/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 416/480, Loss: 0.3560, Time: 0.76 seconds\n",
            "Batch 417/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 417/480, Loss: 0.1637, Time: 0.76 seconds\n",
            "Batch 418/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 418/480, Loss: 0.2608, Time: 0.76 seconds\n",
            "Batch 419/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 419/480, Loss: 0.5926, Time: 0.75 seconds\n",
            "Batch 420/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 420/480, Loss: 0.3207, Time: 0.76 seconds\n",
            "Batch 421/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 421/480, Loss: 0.1295, Time: 0.76 seconds\n",
            "Batch 422/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 422/480, Loss: 0.3674, Time: 0.76 seconds\n",
            "Batch 423/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 423/480, Loss: 0.0720, Time: 0.77 seconds\n",
            "Batch 424/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 424/480, Loss: 0.6145, Time: 0.75 seconds\n",
            "Batch 425/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 425/480, Loss: 1.1589, Time: 0.77 seconds\n",
            "Batch 426/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 426/480, Loss: 0.6160, Time: 0.77 seconds\n",
            "Batch 427/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 427/480, Loss: 0.6307, Time: 0.75 seconds\n",
            "Batch 428/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 428/480, Loss: 0.3840, Time: 0.76 seconds\n",
            "Batch 429/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 429/480, Loss: 0.1199, Time: 0.76 seconds\n",
            "Batch 430/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 430/480, Loss: 0.3872, Time: 0.77 seconds\n",
            "Batch 431/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 431/480, Loss: 0.3353, Time: 0.76 seconds\n",
            "Batch 432/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 432/480, Loss: 0.4620, Time: 0.76 seconds\n",
            "Batch 433/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 433/480, Loss: 0.0456, Time: 0.77 seconds\n",
            "Batch 434/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 434/480, Loss: 0.5650, Time: 0.77 seconds\n",
            "Batch 435/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 435/480, Loss: 0.2535, Time: 0.76 seconds\n",
            "Batch 436/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 436/480, Loss: 0.7651, Time: 0.76 seconds\n",
            "Batch 437/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 437/480, Loss: 0.1180, Time: 0.76 seconds\n",
            "Batch 438/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 438/480, Loss: 0.1022, Time: 0.76 seconds\n",
            "Batch 439/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 439/480, Loss: 0.3770, Time: 0.76 seconds\n",
            "Batch 440/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 440/480, Loss: 0.8863, Time: 0.76 seconds\n",
            "Batch 441/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 441/480, Loss: 0.2291, Time: 0.76 seconds\n",
            "Batch 442/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 442/480, Loss: 0.4306, Time: 0.77 seconds\n",
            "Batch 443/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 443/480, Loss: 0.1369, Time: 0.76 seconds\n",
            "Batch 444/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 444/480, Loss: 0.2554, Time: 0.77 seconds\n",
            "Batch 445/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 445/480, Loss: 0.0542, Time: 0.74 seconds\n",
            "Batch 446/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 446/480, Loss: 0.3645, Time: 0.76 seconds\n",
            "Batch 447/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 447/480, Loss: 0.0669, Time: 0.77 seconds\n",
            "Batch 448/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 1/3, Batch 448/480, Loss: 0.4922, Time: 0.76 seconds\n",
            "Batch 449/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 449/480, Loss: 0.1258, Time: 0.77 seconds\n",
            "Batch 450/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 450/480, Loss: 0.2186, Time: 0.76 seconds\n",
            "Batch 451/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 451/480, Loss: 0.4318, Time: 0.75 seconds\n",
            "Batch 452/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 452/480, Loss: 0.3913, Time: 0.77 seconds\n",
            "Batch 453/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 453/480, Loss: 0.8119, Time: 0.75 seconds\n",
            "Batch 454/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 454/480, Loss: 0.5216, Time: 0.76 seconds\n",
            "Batch 455/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 455/480, Loss: 0.0019, Time: 0.76 seconds\n",
            "Batch 456/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 456/480, Loss: 0.3986, Time: 0.76 seconds\n",
            "Batch 457/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 457/480, Loss: 0.2470, Time: 0.76 seconds\n",
            "Batch 458/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 458/480, Loss: 0.5948, Time: 0.76 seconds\n",
            "Batch 459/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 459/480, Loss: 0.4158, Time: 0.76 seconds\n",
            "Batch 460/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 460/480, Loss: 0.2086, Time: 0.77 seconds\n",
            "Batch 461/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 461/480, Loss: 0.1959, Time: 0.76 seconds\n",
            "Batch 462/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 462/480, Loss: 0.3726, Time: 0.76 seconds\n",
            "Batch 463/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 463/480, Loss: 0.6500, Time: 0.76 seconds\n",
            "Batch 464/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 464/480, Loss: 0.5539, Time: 0.77 seconds\n",
            "Batch 465/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 1/3, Batch 465/480, Loss: 0.3082, Time: 0.77 seconds\n",
            "Batch 466/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 466/480, Loss: 0.8112, Time: 0.77 seconds\n",
            "Batch 467/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 467/480, Loss: 0.4739, Time: 0.76 seconds\n",
            "Batch 468/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 468/480, Loss: 0.2987, Time: 0.77 seconds\n",
            "Batch 469/480, Label Counts: {0: 8}\n",
            "Epoch 1/3, Batch 469/480, Loss: 0.1936, Time: 0.75 seconds\n",
            "Batch 470/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 470/480, Loss: 0.0731, Time: 0.76 seconds\n",
            "Batch 471/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 471/480, Loss: 0.2271, Time: 0.76 seconds\n",
            "Batch 472/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 1/3, Batch 472/480, Loss: 0.6004, Time: 0.75 seconds\n",
            "Batch 473/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 473/480, Loss: 0.1801, Time: 0.76 seconds\n",
            "Batch 474/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 474/480, Loss: 0.3545, Time: 0.77 seconds\n",
            "Batch 475/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 1/3, Batch 475/480, Loss: 0.0752, Time: 0.76 seconds\n",
            "Batch 476/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 476/480, Loss: 0.6485, Time: 0.76 seconds\n",
            "Batch 477/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 1/3, Batch 477/480, Loss: 0.1140, Time: 0.77 seconds\n",
            "Batch 478/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 478/480, Loss: 0.3127, Time: 0.74 seconds\n",
            "Batch 479/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 1/3, Batch 479/480, Loss: 0.2191, Time: 0.75 seconds\n",
            "Batch 480/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 1/3, Batch 480/480, Loss: 0.5093, Time: 0.76 seconds\n",
            "Epoch 1/3, Training Loss: 0.4136, Time: 368.32 seconds\n",
            "Validation Loss: 0.3708, Accuracy: 0.8510\n",
            "Batch 1/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 1/480, Loss: 0.1392, Time: 0.76 seconds\n",
            "Batch 2/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 2/480, Loss: 0.1620, Time: 0.75 seconds\n",
            "Batch 3/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 3/480, Loss: 0.2988, Time: 0.76 seconds\n",
            "Batch 4/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 4/480, Loss: 0.3047, Time: 0.76 seconds\n",
            "Batch 5/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 5/480, Loss: 0.5577, Time: 0.76 seconds\n",
            "Batch 6/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 2/3, Batch 6/480, Loss: 0.7989, Time: 0.75 seconds\n",
            "Batch 7/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 7/480, Loss: 0.5159, Time: 0.76 seconds\n",
            "Batch 8/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 8/480, Loss: 0.2873, Time: 0.76 seconds\n",
            "Batch 9/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 9/480, Loss: 0.3978, Time: 0.75 seconds\n",
            "Batch 10/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 10/480, Loss: 0.1159, Time: 0.76 seconds\n",
            "Batch 11/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 11/480, Loss: 0.3550, Time: 0.76 seconds\n",
            "Batch 12/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 12/480, Loss: 0.5362, Time: 0.76 seconds\n",
            "Batch 13/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 13/480, Loss: 0.1868, Time: 0.76 seconds\n",
            "Batch 14/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 14/480, Loss: 0.0600, Time: 0.75 seconds\n",
            "Batch 15/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 15/480, Loss: 0.3812, Time: 0.76 seconds\n",
            "Batch 16/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 16/480, Loss: 0.3179, Time: 0.76 seconds\n",
            "Batch 17/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 17/480, Loss: 0.2298, Time: 0.75 seconds\n",
            "Batch 18/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 18/480, Loss: 0.1118, Time: 0.76 seconds\n",
            "Batch 19/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 19/480, Loss: 0.4501, Time: 0.76 seconds\n",
            "Batch 20/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 20/480, Loss: 0.0305, Time: 0.77 seconds\n",
            "Batch 21/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 21/480, Loss: 0.3970, Time: 0.76 seconds\n",
            "Batch 22/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 22/480, Loss: 0.3839, Time: 0.76 seconds\n",
            "Batch 23/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 23/480, Loss: 0.2150, Time: 0.75 seconds\n",
            "Batch 24/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 24/480, Loss: 0.3747, Time: 0.76 seconds\n",
            "Batch 25/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 25/480, Loss: 0.3299, Time: 0.76 seconds\n",
            "Batch 26/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 26/480, Loss: 0.3071, Time: 0.76 seconds\n",
            "Batch 27/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 2/3, Batch 27/480, Loss: 0.2499, Time: 0.76 seconds\n",
            "Batch 28/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 28/480, Loss: 0.0797, Time: 0.76 seconds\n",
            "Batch 29/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 29/480, Loss: 0.5586, Time: 0.76 seconds\n",
            "Batch 30/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 30/480, Loss: 0.4791, Time: 0.77 seconds\n",
            "Batch 31/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 31/480, Loss: 0.1390, Time: 0.77 seconds\n",
            "Batch 32/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 32/480, Loss: 0.1349, Time: 0.75 seconds\n",
            "Batch 33/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 33/480, Loss: 0.4692, Time: 0.76 seconds\n",
            "Batch 34/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 34/480, Loss: 0.2620, Time: 0.77 seconds\n",
            "Batch 35/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 35/480, Loss: 0.3283, Time: 0.77 seconds\n",
            "Batch 36/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 36/480, Loss: 0.4107, Time: 0.76 seconds\n",
            "Batch 37/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 37/480, Loss: 0.0638, Time: 0.76 seconds\n",
            "Batch 38/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 38/480, Loss: 0.1216, Time: 0.76 seconds\n",
            "Batch 39/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 39/480, Loss: 0.6068, Time: 0.76 seconds\n",
            "Batch 40/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 40/480, Loss: 0.6488, Time: 0.77 seconds\n",
            "Batch 41/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 41/480, Loss: 0.4340, Time: 0.77 seconds\n",
            "Batch 42/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 42/480, Loss: 0.4325, Time: 0.76 seconds\n",
            "Batch 43/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 43/480, Loss: 0.0459, Time: 0.75 seconds\n",
            "Batch 44/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 44/480, Loss: 0.0058, Time: 0.76 seconds\n",
            "Batch 45/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 45/480, Loss: 0.5788, Time: 0.76 seconds\n",
            "Batch 46/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 46/480, Loss: 0.2708, Time: 0.77 seconds\n",
            "Batch 47/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 47/480, Loss: 0.0560, Time: 0.76 seconds\n",
            "Batch 48/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 48/480, Loss: 0.0862, Time: 0.76 seconds\n",
            "Batch 49/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 49/480, Loss: 0.0819, Time: 0.75 seconds\n",
            "Batch 50/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 50/480, Loss: 0.5536, Time: 0.77 seconds\n",
            "Batch 51/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 51/480, Loss: 0.3398, Time: 0.76 seconds\n",
            "Batch 52/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 52/480, Loss: 0.5989, Time: 0.76 seconds\n",
            "Batch 53/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 53/480, Loss: 0.3338, Time: 0.77 seconds\n",
            "Batch 54/480, Label Counts: {0: 4, 2: 4}\n",
            "Epoch 2/3, Batch 54/480, Loss: 0.2933, Time: 0.77 seconds\n",
            "Batch 55/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 55/480, Loss: 0.1799, Time: 0.77 seconds\n",
            "Batch 56/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 56/480, Loss: 0.3114, Time: 0.76 seconds\n",
            "Batch 57/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 57/480, Loss: 0.1707, Time: 0.77 seconds\n",
            "Batch 58/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 58/480, Loss: 0.7281, Time: 0.77 seconds\n",
            "Batch 59/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 59/480, Loss: 0.0851, Time: 0.76 seconds\n",
            "Batch 60/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 60/480, Loss: 0.3723, Time: 0.76 seconds\n",
            "Batch 61/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 61/480, Loss: 0.1739, Time: 0.76 seconds\n",
            "Batch 62/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 62/480, Loss: 0.1262, Time: 0.77 seconds\n",
            "Batch 63/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 63/480, Loss: 0.3059, Time: 0.76 seconds\n",
            "Batch 64/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 64/480, Loss: 0.0073, Time: 0.76 seconds\n",
            "Batch 65/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 65/480, Loss: 0.7670, Time: 0.77 seconds\n",
            "Batch 66/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 66/480, Loss: 0.2721, Time: 0.76 seconds\n",
            "Batch 67/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 67/480, Loss: 0.0796, Time: 0.77 seconds\n",
            "Batch 68/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 68/480, Loss: 0.8764, Time: 0.75 seconds\n",
            "Batch 69/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 69/480, Loss: 0.4543, Time: 0.76 seconds\n",
            "Batch 70/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 70/480, Loss: 0.5962, Time: 0.77 seconds\n",
            "Batch 71/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 71/480, Loss: 0.3906, Time: 0.75 seconds\n",
            "Batch 72/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 72/480, Loss: 0.0713, Time: 0.77 seconds\n",
            "Batch 73/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 73/480, Loss: 0.0009, Time: 0.76 seconds\n",
            "Batch 74/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 74/480, Loss: 0.4992, Time: 0.76 seconds\n",
            "Batch 75/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 75/480, Loss: 0.6189, Time: 0.77 seconds\n",
            "Batch 76/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 76/480, Loss: 0.0463, Time: 0.76 seconds\n",
            "Batch 77/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 77/480, Loss: 0.7939, Time: 0.75 seconds\n",
            "Batch 78/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 78/480, Loss: 0.3390, Time: 0.76 seconds\n",
            "Batch 79/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 79/480, Loss: 0.6200, Time: 0.75 seconds\n",
            "Batch 80/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 80/480, Loss: 0.0527, Time: 0.76 seconds\n",
            "Batch 81/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 81/480, Loss: 0.6164, Time: 0.77 seconds\n",
            "Batch 82/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 82/480, Loss: 0.0743, Time: 0.77 seconds\n",
            "Batch 83/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 83/480, Loss: 0.2027, Time: 0.76 seconds\n",
            "Batch 84/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 84/480, Loss: 0.3903, Time: 0.76 seconds\n",
            "Batch 85/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 85/480, Loss: 0.0544, Time: 0.76 seconds\n",
            "Batch 86/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 86/480, Loss: 0.5639, Time: 0.76 seconds\n",
            "Batch 87/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 87/480, Loss: 0.5497, Time: 0.76 seconds\n",
            "Batch 88/480, Label Counts: {0: 2, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 88/480, Loss: 0.4794, Time: 0.76 seconds\n",
            "Batch 89/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 89/480, Loss: 0.6309, Time: 0.76 seconds\n",
            "Batch 90/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 90/480, Loss: 0.3353, Time: 0.75 seconds\n",
            "Batch 91/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 91/480, Loss: 0.3950, Time: 0.76 seconds\n",
            "Batch 92/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 92/480, Loss: 0.3706, Time: 0.76 seconds\n",
            "Batch 93/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 93/480, Loss: 0.3879, Time: 0.77 seconds\n",
            "Batch 94/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 94/480, Loss: 0.0020, Time: 0.75 seconds\n",
            "Batch 95/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 95/480, Loss: 0.4183, Time: 0.76 seconds\n",
            "Batch 96/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 96/480, Loss: 0.2741, Time: 0.77 seconds\n",
            "Batch 97/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 97/480, Loss: 0.0699, Time: 0.76 seconds\n",
            "Batch 98/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 98/480, Loss: 0.3434, Time: 0.76 seconds\n",
            "Batch 99/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 99/480, Loss: 0.6681, Time: 0.75 seconds\n",
            "Batch 100/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 100/480, Loss: 0.4504, Time: 0.76 seconds\n",
            "Batch 101/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 101/480, Loss: 0.9565, Time: 0.77 seconds\n",
            "Batch 102/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 102/480, Loss: 0.2857, Time: 0.75 seconds\n",
            "Batch 103/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 103/480, Loss: 0.7074, Time: 0.76 seconds\n",
            "Batch 104/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 104/480, Loss: 0.2145, Time: 0.76 seconds\n",
            "Batch 105/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 105/480, Loss: 0.3252, Time: 0.77 seconds\n",
            "Batch 106/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 106/480, Loss: 0.7694, Time: 0.77 seconds\n",
            "Batch 107/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 107/480, Loss: 0.1484, Time: 0.76 seconds\n",
            "Batch 108/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 108/480, Loss: 0.4238, Time: 0.77 seconds\n",
            "Batch 109/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 109/480, Loss: 0.5000, Time: 0.76 seconds\n",
            "Batch 110/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 110/480, Loss: 0.0844, Time: 0.76 seconds\n",
            "Batch 111/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 111/480, Loss: 0.4806, Time: 0.76 seconds\n",
            "Batch 112/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 112/480, Loss: 0.1927, Time: 0.76 seconds\n",
            "Batch 113/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 113/480, Loss: 0.2705, Time: 0.75 seconds\n",
            "Batch 114/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 114/480, Loss: 0.6958, Time: 0.76 seconds\n",
            "Batch 115/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 115/480, Loss: 0.1173, Time: 0.76 seconds\n",
            "Batch 116/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 116/480, Loss: 0.1832, Time: 0.77 seconds\n",
            "Batch 117/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 117/480, Loss: 0.6111, Time: 0.76 seconds\n",
            "Batch 118/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 118/480, Loss: 0.2828, Time: 0.76 seconds\n",
            "Batch 119/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 119/480, Loss: 0.3664, Time: 0.76 seconds\n",
            "Batch 120/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 2/3, Batch 120/480, Loss: 0.6066, Time: 0.77 seconds\n",
            "Batch 121/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 121/480, Loss: 0.1153, Time: 0.77 seconds\n",
            "Batch 122/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 122/480, Loss: 0.4941, Time: 0.76 seconds\n",
            "Batch 123/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 123/480, Loss: 0.0720, Time: 0.76 seconds\n",
            "Batch 124/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 124/480, Loss: 0.4490, Time: 0.77 seconds\n",
            "Batch 125/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 125/480, Loss: 0.1636, Time: 0.76 seconds\n",
            "Batch 126/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 126/480, Loss: 0.2118, Time: 0.77 seconds\n",
            "Batch 127/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 127/480, Loss: 0.2248, Time: 0.76 seconds\n",
            "Batch 128/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 128/480, Loss: 0.0940, Time: 0.76 seconds\n",
            "Batch 129/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 129/480, Loss: 0.2756, Time: 0.77 seconds\n",
            "Batch 130/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 130/480, Loss: 0.3837, Time: 0.76 seconds\n",
            "Batch 131/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 131/480, Loss: 0.5924, Time: 0.76 seconds\n",
            "Batch 132/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 132/480, Loss: 0.9124, Time: 0.76 seconds\n",
            "Batch 133/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 133/480, Loss: 0.1453, Time: 0.76 seconds\n",
            "Batch 134/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 134/480, Loss: 0.2860, Time: 0.76 seconds\n",
            "Batch 135/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 135/480, Loss: 0.3566, Time: 0.74 seconds\n",
            "Batch 136/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 136/480, Loss: 0.1576, Time: 0.77 seconds\n",
            "Batch 137/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 137/480, Loss: 0.0847, Time: 0.75 seconds\n",
            "Batch 138/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 138/480, Loss: 0.5482, Time: 0.75 seconds\n",
            "Batch 139/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 139/480, Loss: 0.4233, Time: 0.75 seconds\n",
            "Batch 140/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 140/480, Loss: 0.5909, Time: 0.76 seconds\n",
            "Batch 141/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 141/480, Loss: 0.3290, Time: 0.77 seconds\n",
            "Batch 142/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 142/480, Loss: 0.1165, Time: 0.76 seconds\n",
            "Batch 143/480, Label Counts: {0: 2, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 143/480, Loss: 0.5535, Time: 0.76 seconds\n",
            "Batch 144/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 144/480, Loss: 0.1955, Time: 0.78 seconds\n",
            "Batch 145/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 145/480, Loss: 0.0641, Time: 0.76 seconds\n",
            "Batch 146/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 146/480, Loss: 0.1516, Time: 0.76 seconds\n",
            "Batch 147/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 147/480, Loss: 0.2902, Time: 0.77 seconds\n",
            "Batch 148/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 148/480, Loss: 0.1036, Time: 0.75 seconds\n",
            "Batch 149/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 149/480, Loss: 0.3260, Time: 0.77 seconds\n",
            "Batch 150/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 150/480, Loss: 0.4161, Time: 0.76 seconds\n",
            "Batch 151/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 151/480, Loss: 0.1229, Time: 0.76 seconds\n",
            "Batch 152/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 152/480, Loss: 0.9741, Time: 0.77 seconds\n",
            "Batch 153/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 153/480, Loss: 0.5884, Time: 0.77 seconds\n",
            "Batch 154/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 154/480, Loss: 0.1031, Time: 0.77 seconds\n",
            "Batch 155/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 155/480, Loss: 0.2680, Time: 0.77 seconds\n",
            "Batch 156/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 156/480, Loss: 0.5327, Time: 0.77 seconds\n",
            "Batch 157/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 157/480, Loss: 0.5396, Time: 0.76 seconds\n",
            "Batch 158/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 158/480, Loss: 0.3004, Time: 0.77 seconds\n",
            "Batch 159/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 159/480, Loss: 0.3426, Time: 0.76 seconds\n",
            "Batch 160/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 160/480, Loss: 0.6332, Time: 0.77 seconds\n",
            "Batch 161/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 161/480, Loss: 0.1116, Time: 0.76 seconds\n",
            "Batch 162/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 162/480, Loss: 0.4506, Time: 0.76 seconds\n",
            "Batch 163/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 163/480, Loss: 0.1506, Time: 0.76 seconds\n",
            "Batch 164/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 164/480, Loss: 0.1853, Time: 0.76 seconds\n",
            "Batch 165/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 165/480, Loss: 0.3531, Time: 0.77 seconds\n",
            "Batch 166/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 166/480, Loss: 0.2057, Time: 0.77 seconds\n",
            "Batch 167/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 167/480, Loss: 0.2827, Time: 0.75 seconds\n",
            "Batch 168/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 168/480, Loss: 0.5432, Time: 0.77 seconds\n",
            "Batch 169/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 169/480, Loss: 0.1277, Time: 0.76 seconds\n",
            "Batch 170/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 170/480, Loss: 0.2270, Time: 0.75 seconds\n",
            "Batch 171/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 171/480, Loss: 1.1092, Time: 0.76 seconds\n",
            "Batch 172/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 172/480, Loss: 0.5161, Time: 0.76 seconds\n",
            "Batch 173/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 173/480, Loss: 0.0612, Time: 0.76 seconds\n",
            "Batch 174/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 174/480, Loss: 0.4734, Time: 0.77 seconds\n",
            "Batch 175/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 175/480, Loss: 0.7634, Time: 0.77 seconds\n",
            "Batch 176/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 176/480, Loss: 0.4080, Time: 0.76 seconds\n",
            "Batch 177/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 177/480, Loss: 0.3511, Time: 0.76 seconds\n",
            "Batch 178/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 178/480, Loss: 0.2562, Time: 0.78 seconds\n",
            "Batch 179/480, Label Counts: {1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 179/480, Loss: 0.1789, Time: 0.76 seconds\n",
            "Batch 180/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 180/480, Loss: 0.2181, Time: 0.76 seconds\n",
            "Batch 181/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 181/480, Loss: 0.2608, Time: 0.77 seconds\n",
            "Batch 182/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 182/480, Loss: 0.1938, Time: 0.77 seconds\n",
            "Batch 183/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 183/480, Loss: 0.0730, Time: 0.76 seconds\n",
            "Batch 184/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 184/480, Loss: 0.2039, Time: 0.75 seconds\n",
            "Batch 185/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 185/480, Loss: 0.5237, Time: 0.77 seconds\n",
            "Batch 186/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 186/480, Loss: 0.3619, Time: 0.76 seconds\n",
            "Batch 187/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 187/480, Loss: 0.1338, Time: 0.75 seconds\n",
            "Batch 188/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 188/480, Loss: 0.1884, Time: 0.77 seconds\n",
            "Batch 189/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 189/480, Loss: 0.1047, Time: 0.75 seconds\n",
            "Batch 190/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 190/480, Loss: 0.9762, Time: 0.77 seconds\n",
            "Batch 191/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 191/480, Loss: 0.5651, Time: 0.77 seconds\n",
            "Batch 192/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 192/480, Loss: 0.1211, Time: 0.77 seconds\n",
            "Batch 193/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 193/480, Loss: 0.0700, Time: 0.76 seconds\n",
            "Batch 194/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 194/480, Loss: 0.3698, Time: 0.76 seconds\n",
            "Batch 195/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 195/480, Loss: 0.1933, Time: 0.76 seconds\n",
            "Batch 196/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 196/480, Loss: 0.1066, Time: 0.75 seconds\n",
            "Batch 197/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 197/480, Loss: 0.2345, Time: 0.75 seconds\n",
            "Batch 198/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 198/480, Loss: 0.2056, Time: 0.77 seconds\n",
            "Batch 199/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 199/480, Loss: 0.4785, Time: 0.77 seconds\n",
            "Batch 200/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 200/480, Loss: 0.3287, Time: 0.75 seconds\n",
            "Batch 201/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 201/480, Loss: 0.3302, Time: 0.77 seconds\n",
            "Batch 202/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 202/480, Loss: 0.7448, Time: 0.77 seconds\n",
            "Batch 203/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 203/480, Loss: 0.0713, Time: 0.76 seconds\n",
            "Batch 204/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 204/480, Loss: 0.2068, Time: 0.77 seconds\n",
            "Batch 205/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 205/480, Loss: 0.5666, Time: 0.77 seconds\n",
            "Batch 206/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 206/480, Loss: 0.1273, Time: 0.76 seconds\n",
            "Batch 207/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 207/480, Loss: 0.1087, Time: 0.77 seconds\n",
            "Batch 208/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 208/480, Loss: 0.5954, Time: 0.78 seconds\n",
            "Batch 209/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 209/480, Loss: 0.0520, Time: 0.76 seconds\n",
            "Batch 210/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 210/480, Loss: 0.0892, Time: 0.77 seconds\n",
            "Batch 211/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 211/480, Loss: 0.2013, Time: 0.76 seconds\n",
            "Batch 212/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 212/480, Loss: 0.1098, Time: 0.76 seconds\n",
            "Batch 213/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 213/480, Loss: 0.3676, Time: 0.75 seconds\n",
            "Batch 214/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 214/480, Loss: 0.2362, Time: 0.75 seconds\n",
            "Batch 215/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 215/480, Loss: 0.2444, Time: 0.76 seconds\n",
            "Batch 216/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 2/3, Batch 216/480, Loss: 0.5486, Time: 0.77 seconds\n",
            "Batch 217/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 217/480, Loss: 0.0147, Time: 0.75 seconds\n",
            "Batch 218/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 218/480, Loss: 0.2203, Time: 0.76 seconds\n",
            "Batch 219/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 219/480, Loss: 0.6200, Time: 0.77 seconds\n",
            "Batch 220/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 220/480, Loss: 0.0887, Time: 0.75 seconds\n",
            "Batch 221/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 221/480, Loss: 0.0883, Time: 0.76 seconds\n",
            "Batch 222/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 222/480, Loss: 0.5934, Time: 0.77 seconds\n",
            "Batch 223/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 223/480, Loss: 0.1602, Time: 0.76 seconds\n",
            "Batch 224/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 224/480, Loss: 0.3368, Time: 0.76 seconds\n",
            "Batch 225/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 225/480, Loss: 0.1104, Time: 0.77 seconds\n",
            "Batch 226/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 226/480, Loss: 0.1381, Time: 0.76 seconds\n",
            "Batch 227/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 227/480, Loss: 0.0738, Time: 0.76 seconds\n",
            "Batch 228/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 228/480, Loss: 0.3893, Time: 0.76 seconds\n",
            "Batch 229/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 229/480, Loss: 0.0906, Time: 0.78 seconds\n",
            "Batch 230/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 230/480, Loss: 0.3751, Time: 0.77 seconds\n",
            "Batch 231/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 231/480, Loss: 0.3177, Time: 0.77 seconds\n",
            "Batch 232/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 232/480, Loss: 0.0858, Time: 0.77 seconds\n",
            "Batch 233/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 233/480, Loss: 0.0824, Time: 0.78 seconds\n",
            "Batch 234/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 234/480, Loss: 0.5184, Time: 0.76 seconds\n",
            "Batch 235/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 235/480, Loss: 0.6180, Time: 0.77 seconds\n",
            "Batch 236/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 236/480, Loss: 1.0552, Time: 0.77 seconds\n",
            "Batch 237/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 237/480, Loss: 0.8454, Time: 0.76 seconds\n",
            "Batch 238/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 2/3, Batch 238/480, Loss: 0.3720, Time: 0.76 seconds\n",
            "Batch 239/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 239/480, Loss: 0.4066, Time: 0.78 seconds\n",
            "Batch 240/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 240/480, Loss: 0.4084, Time: 0.77 seconds\n",
            "Batch 241/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 241/480, Loss: 0.5650, Time: 0.76 seconds\n",
            "Batch 242/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 242/480, Loss: 0.4009, Time: 0.76 seconds\n",
            "Batch 243/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 243/480, Loss: 1.1922, Time: 0.77 seconds\n",
            "Batch 244/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 244/480, Loss: 1.2013, Time: 0.75 seconds\n",
            "Batch 245/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 245/480, Loss: 0.5654, Time: 0.77 seconds\n",
            "Batch 246/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 246/480, Loss: 0.2192, Time: 0.76 seconds\n",
            "Batch 247/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 247/480, Loss: 0.0982, Time: 0.76 seconds\n",
            "Batch 248/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 248/480, Loss: 0.4666, Time: 0.77 seconds\n",
            "Batch 249/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 249/480, Loss: 1.1323, Time: 0.77 seconds\n",
            "Batch 250/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 250/480, Loss: 0.3080, Time: 0.76 seconds\n",
            "Batch 251/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 251/480, Loss: 0.4230, Time: 0.76 seconds\n",
            "Batch 252/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 252/480, Loss: 0.4370, Time: 0.76 seconds\n",
            "Batch 253/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 253/480, Loss: 0.8146, Time: 0.77 seconds\n",
            "Batch 254/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 254/480, Loss: 0.3953, Time: 0.77 seconds\n",
            "Batch 255/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 255/480, Loss: 0.3965, Time: 0.77 seconds\n",
            "Batch 256/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 256/480, Loss: 0.7769, Time: 0.77 seconds\n",
            "Batch 257/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 257/480, Loss: 0.7634, Time: 0.77 seconds\n",
            "Batch 258/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 258/480, Loss: 0.5571, Time: 0.77 seconds\n",
            "Batch 259/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 259/480, Loss: 0.0484, Time: 0.76 seconds\n",
            "Batch 260/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 260/480, Loss: 0.5023, Time: 0.76 seconds\n",
            "Batch 261/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 261/480, Loss: 0.6983, Time: 0.77 seconds\n",
            "Batch 262/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 262/480, Loss: 0.7315, Time: 0.77 seconds\n",
            "Batch 263/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 263/480, Loss: 0.5065, Time: 0.75 seconds\n",
            "Batch 264/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 264/480, Loss: 0.0288, Time: 0.75 seconds\n",
            "Batch 265/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 265/480, Loss: 0.5118, Time: 0.77 seconds\n",
            "Batch 266/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 266/480, Loss: 0.1854, Time: 0.76 seconds\n",
            "Batch 267/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 267/480, Loss: 0.8715, Time: 0.78 seconds\n",
            "Batch 268/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 268/480, Loss: 0.1477, Time: 0.76 seconds\n",
            "Batch 269/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 269/480, Loss: 0.2039, Time: 0.77 seconds\n",
            "Batch 270/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 270/480, Loss: 0.7678, Time: 0.76 seconds\n",
            "Batch 271/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 271/480, Loss: 0.2150, Time: 0.75 seconds\n",
            "Batch 272/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 272/480, Loss: 0.4982, Time: 0.76 seconds\n",
            "Batch 273/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 273/480, Loss: 0.0988, Time: 0.75 seconds\n",
            "Batch 274/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 274/480, Loss: 0.6487, Time: 0.76 seconds\n",
            "Batch 275/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 275/480, Loss: 0.5355, Time: 0.77 seconds\n",
            "Batch 276/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 276/480, Loss: 0.2813, Time: 0.76 seconds\n",
            "Batch 277/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 277/480, Loss: 0.4121, Time: 0.77 seconds\n",
            "Batch 278/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 278/480, Loss: 0.4385, Time: 0.75 seconds\n",
            "Batch 279/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 279/480, Loss: 0.3485, Time: 0.76 seconds\n",
            "Batch 280/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 280/480, Loss: 0.1647, Time: 0.76 seconds\n",
            "Batch 281/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 281/480, Loss: 0.1599, Time: 0.77 seconds\n",
            "Batch 282/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 282/480, Loss: 0.4351, Time: 0.76 seconds\n",
            "Batch 283/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 283/480, Loss: 0.0760, Time: 0.77 seconds\n",
            "Batch 284/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 284/480, Loss: 0.3927, Time: 0.76 seconds\n",
            "Batch 285/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 285/480, Loss: 0.1494, Time: 0.77 seconds\n",
            "Batch 286/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 286/480, Loss: 0.7632, Time: 0.77 seconds\n",
            "Batch 287/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 287/480, Loss: 0.1541, Time: 0.76 seconds\n",
            "Batch 288/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 288/480, Loss: 0.1769, Time: 0.78 seconds\n",
            "Batch 289/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 289/480, Loss: 0.0865, Time: 0.76 seconds\n",
            "Batch 290/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 290/480, Loss: 0.2975, Time: 0.77 seconds\n",
            "Batch 291/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 291/480, Loss: 0.1635, Time: 0.77 seconds\n",
            "Batch 292/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 292/480, Loss: 0.1348, Time: 0.77 seconds\n",
            "Batch 293/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 293/480, Loss: 0.4085, Time: 0.76 seconds\n",
            "Batch 294/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 294/480, Loss: 0.0157, Time: 0.76 seconds\n",
            "Batch 295/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 295/480, Loss: 0.1072, Time: 0.76 seconds\n",
            "Batch 296/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 296/480, Loss: 0.7297, Time: 0.77 seconds\n",
            "Batch 297/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 297/480, Loss: 0.0134, Time: 0.76 seconds\n",
            "Batch 298/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 298/480, Loss: 0.0888, Time: 0.76 seconds\n",
            "Batch 299/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 299/480, Loss: 0.0454, Time: 0.76 seconds\n",
            "Batch 300/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 300/480, Loss: 0.6853, Time: 0.76 seconds\n",
            "Batch 301/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 301/480, Loss: 0.4038, Time: 0.77 seconds\n",
            "Batch 302/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 302/480, Loss: 0.0891, Time: 0.77 seconds\n",
            "Batch 303/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 303/480, Loss: 0.0456, Time: 0.76 seconds\n",
            "Batch 304/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 304/480, Loss: 0.3478, Time: 0.77 seconds\n",
            "Batch 305/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 305/480, Loss: 0.5688, Time: 0.75 seconds\n",
            "Batch 306/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 306/480, Loss: 0.0516, Time: 0.77 seconds\n",
            "Batch 307/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 307/480, Loss: 0.7110, Time: 0.77 seconds\n",
            "Batch 308/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 308/480, Loss: 0.0668, Time: 0.77 seconds\n",
            "Batch 309/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 309/480, Loss: 0.3806, Time: 0.76 seconds\n",
            "Batch 310/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 310/480, Loss: 0.2915, Time: 0.77 seconds\n",
            "Batch 311/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 311/480, Loss: 0.7799, Time: 0.77 seconds\n",
            "Batch 312/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 312/480, Loss: 0.5317, Time: 0.76 seconds\n",
            "Batch 313/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 313/480, Loss: 0.0940, Time: 0.76 seconds\n",
            "Batch 314/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 314/480, Loss: 0.3434, Time: 0.77 seconds\n",
            "Batch 315/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 315/480, Loss: 0.0694, Time: 0.77 seconds\n",
            "Batch 316/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 316/480, Loss: 0.7948, Time: 0.77 seconds\n",
            "Batch 317/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 317/480, Loss: 0.3454, Time: 0.76 seconds\n",
            "Batch 318/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 318/480, Loss: 0.2836, Time: 0.76 seconds\n",
            "Batch 319/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 319/480, Loss: 0.3967, Time: 0.77 seconds\n",
            "Batch 320/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 320/480, Loss: 0.0275, Time: 0.77 seconds\n",
            "Batch 321/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 321/480, Loss: 0.1284, Time: 0.76 seconds\n",
            "Batch 322/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 322/480, Loss: 0.2734, Time: 0.75 seconds\n",
            "Batch 323/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 323/480, Loss: 0.5870, Time: 0.76 seconds\n",
            "Batch 324/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 324/480, Loss: 0.2851, Time: 0.77 seconds\n",
            "Batch 325/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 325/480, Loss: 0.2607, Time: 0.75 seconds\n",
            "Batch 326/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 326/480, Loss: 0.1490, Time: 0.77 seconds\n",
            "Batch 327/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 327/480, Loss: 0.3663, Time: 0.76 seconds\n",
            "Batch 328/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 328/480, Loss: 0.3211, Time: 0.76 seconds\n",
            "Batch 329/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 329/480, Loss: 0.2924, Time: 0.77 seconds\n",
            "Batch 330/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 330/480, Loss: 0.1058, Time: 0.77 seconds\n",
            "Batch 331/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 331/480, Loss: 0.1288, Time: 0.75 seconds\n",
            "Batch 332/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 332/480, Loss: 0.1384, Time: 0.77 seconds\n",
            "Batch 333/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 333/480, Loss: 0.6630, Time: 0.77 seconds\n",
            "Batch 334/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 334/480, Loss: 0.4610, Time: 0.77 seconds\n",
            "Batch 335/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 335/480, Loss: 0.4547, Time: 0.76 seconds\n",
            "Batch 336/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 336/480, Loss: 0.4279, Time: 0.76 seconds\n",
            "Batch 337/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 337/480, Loss: 0.6641, Time: 0.76 seconds\n",
            "Batch 338/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 338/480, Loss: 0.3845, Time: 0.76 seconds\n",
            "Batch 339/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 339/480, Loss: 0.6632, Time: 0.76 seconds\n",
            "Batch 340/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 340/480, Loss: 0.0900, Time: 0.76 seconds\n",
            "Batch 341/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 341/480, Loss: 0.3806, Time: 0.76 seconds\n",
            "Batch 342/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 342/480, Loss: 0.7832, Time: 0.77 seconds\n",
            "Batch 343/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 343/480, Loss: 0.3767, Time: 0.75 seconds\n",
            "Batch 344/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 344/480, Loss: 0.0634, Time: 0.76 seconds\n",
            "Batch 345/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 345/480, Loss: 0.7323, Time: 0.76 seconds\n",
            "Batch 346/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 346/480, Loss: 0.6051, Time: 0.77 seconds\n",
            "Batch 347/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 347/480, Loss: 0.1691, Time: 0.77 seconds\n",
            "Batch 348/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 348/480, Loss: 0.3227, Time: 0.76 seconds\n",
            "Batch 349/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 349/480, Loss: 0.3197, Time: 0.77 seconds\n",
            "Batch 350/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 350/480, Loss: 0.3746, Time: 0.77 seconds\n",
            "Batch 351/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 351/480, Loss: 0.4599, Time: 0.77 seconds\n",
            "Batch 352/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 352/480, Loss: 0.1508, Time: 0.76 seconds\n",
            "Batch 353/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 353/480, Loss: 0.1390, Time: 0.76 seconds\n",
            "Batch 354/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 354/480, Loss: 0.0452, Time: 0.77 seconds\n",
            "Batch 355/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 355/480, Loss: 0.1712, Time: 0.76 seconds\n",
            "Batch 356/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 356/480, Loss: 0.7857, Time: 0.76 seconds\n",
            "Batch 357/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 357/480, Loss: 0.3002, Time: 0.77 seconds\n",
            "Batch 358/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 358/480, Loss: 0.1731, Time: 0.76 seconds\n",
            "Batch 359/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 359/480, Loss: 0.4683, Time: 0.77 seconds\n",
            "Batch 360/480, Label Counts: {0: 2, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 360/480, Loss: 0.3989, Time: 0.77 seconds\n",
            "Batch 361/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 361/480, Loss: 0.3859, Time: 0.76 seconds\n",
            "Batch 362/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 362/480, Loss: 0.0742, Time: 0.76 seconds\n",
            "Batch 363/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 363/480, Loss: 0.1115, Time: 0.77 seconds\n",
            "Batch 364/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 364/480, Loss: 0.1075, Time: 0.77 seconds\n",
            "Batch 365/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 365/480, Loss: 0.1640, Time: 0.76 seconds\n",
            "Batch 366/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 366/480, Loss: 0.4455, Time: 0.76 seconds\n",
            "Batch 367/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 367/480, Loss: 0.3049, Time: 0.77 seconds\n",
            "Batch 368/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 368/480, Loss: 0.6425, Time: 0.76 seconds\n",
            "Batch 369/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 369/480, Loss: 0.2573, Time: 0.77 seconds\n",
            "Batch 370/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 370/480, Loss: 0.3875, Time: 0.77 seconds\n",
            "Batch 371/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 371/480, Loss: 0.2106, Time: 0.77 seconds\n",
            "Batch 372/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 372/480, Loss: 0.1296, Time: 0.76 seconds\n",
            "Batch 373/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 373/480, Loss: 0.5133, Time: 0.77 seconds\n",
            "Batch 374/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 374/480, Loss: 0.1531, Time: 0.77 seconds\n",
            "Batch 375/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 375/480, Loss: 0.2716, Time: 0.77 seconds\n",
            "Batch 376/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 376/480, Loss: 0.5882, Time: 0.77 seconds\n",
            "Batch 377/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 377/480, Loss: 0.3243, Time: 0.76 seconds\n",
            "Batch 378/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 378/480, Loss: 0.6483, Time: 0.78 seconds\n",
            "Batch 379/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 379/480, Loss: 0.0614, Time: 0.76 seconds\n",
            "Batch 380/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 380/480, Loss: 0.8207, Time: 0.77 seconds\n",
            "Batch 381/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 381/480, Loss: 0.0774, Time: 0.75 seconds\n",
            "Batch 382/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 382/480, Loss: 0.2123, Time: 0.76 seconds\n",
            "Batch 383/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 383/480, Loss: 0.3126, Time: 0.76 seconds\n",
            "Batch 384/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 384/480, Loss: 0.4529, Time: 0.77 seconds\n",
            "Batch 385/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 385/480, Loss: 0.5986, Time: 0.77 seconds\n",
            "Batch 386/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 386/480, Loss: 0.1246, Time: 0.77 seconds\n",
            "Batch 387/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 387/480, Loss: 0.1075, Time: 0.76 seconds\n",
            "Batch 388/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 388/480, Loss: 0.5129, Time: 0.75 seconds\n",
            "Batch 389/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 389/480, Loss: 0.7983, Time: 0.76 seconds\n",
            "Batch 390/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 390/480, Loss: 0.2631, Time: 0.76 seconds\n",
            "Batch 391/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 391/480, Loss: 0.3965, Time: 0.77 seconds\n",
            "Batch 392/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 392/480, Loss: 0.6345, Time: 0.77 seconds\n",
            "Batch 393/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 393/480, Loss: 0.3710, Time: 0.76 seconds\n",
            "Batch 394/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 394/480, Loss: 0.3028, Time: 0.77 seconds\n",
            "Batch 395/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 395/480, Loss: 0.1847, Time: 0.75 seconds\n",
            "Batch 396/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 396/480, Loss: 0.3168, Time: 0.77 seconds\n",
            "Batch 397/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 397/480, Loss: 0.1788, Time: 0.77 seconds\n",
            "Batch 398/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 398/480, Loss: 0.3400, Time: 0.76 seconds\n",
            "Batch 399/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 399/480, Loss: 0.2675, Time: 0.77 seconds\n",
            "Batch 400/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 400/480, Loss: 0.1975, Time: 0.77 seconds\n",
            "Batch 401/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 401/480, Loss: 0.7922, Time: 0.76 seconds\n",
            "Batch 402/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 402/480, Loss: 0.0542, Time: 0.77 seconds\n",
            "Batch 403/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 403/480, Loss: 0.3196, Time: 0.75 seconds\n",
            "Batch 404/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 404/480, Loss: 0.0497, Time: 0.77 seconds\n",
            "Batch 405/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 405/480, Loss: 0.3921, Time: 0.77 seconds\n",
            "Batch 406/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 406/480, Loss: 0.1288, Time: 0.77 seconds\n",
            "Batch 407/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 407/480, Loss: 0.0063, Time: 0.77 seconds\n",
            "Batch 408/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 408/480, Loss: 0.2910, Time: 0.76 seconds\n",
            "Batch 409/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 409/480, Loss: 0.2971, Time: 0.77 seconds\n",
            "Batch 410/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 410/480, Loss: 0.2912, Time: 0.77 seconds\n",
            "Batch 411/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 411/480, Loss: 0.1670, Time: 0.76 seconds\n",
            "Batch 412/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 412/480, Loss: 0.2936, Time: 0.77 seconds\n",
            "Batch 413/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 413/480, Loss: 0.4496, Time: 0.77 seconds\n",
            "Batch 414/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 414/480, Loss: 0.4516, Time: 0.76 seconds\n",
            "Batch 415/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 415/480, Loss: 0.4337, Time: 0.76 seconds\n",
            "Batch 416/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 416/480, Loss: 0.6177, Time: 0.77 seconds\n",
            "Batch 417/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 417/480, Loss: 0.0119, Time: 0.76 seconds\n",
            "Batch 418/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 418/480, Loss: 0.1452, Time: 0.77 seconds\n",
            "Batch 419/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 419/480, Loss: 0.6609, Time: 0.76 seconds\n",
            "Batch 420/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 420/480, Loss: 0.7213, Time: 0.76 seconds\n",
            "Batch 421/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 421/480, Loss: 0.0632, Time: 0.76 seconds\n",
            "Batch 422/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 422/480, Loss: 0.7312, Time: 0.75 seconds\n",
            "Batch 423/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 423/480, Loss: 0.1583, Time: 0.76 seconds\n",
            "Batch 424/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 424/480, Loss: 0.3055, Time: 0.75 seconds\n",
            "Batch 425/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 425/480, Loss: 0.3437, Time: 0.76 seconds\n",
            "Batch 426/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 426/480, Loss: 0.7623, Time: 0.76 seconds\n",
            "Batch 427/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 427/480, Loss: 0.3518, Time: 0.77 seconds\n",
            "Batch 428/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 428/480, Loss: 0.0493, Time: 0.77 seconds\n",
            "Batch 429/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 429/480, Loss: 0.0526, Time: 0.76 seconds\n",
            "Batch 430/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 430/480, Loss: 0.7849, Time: 0.78 seconds\n",
            "Batch 431/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 2/3, Batch 431/480, Loss: 0.1466, Time: 0.77 seconds\n",
            "Batch 432/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 432/480, Loss: 0.0975, Time: 0.76 seconds\n",
            "Batch 433/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 433/480, Loss: 0.0763, Time: 0.76 seconds\n",
            "Batch 434/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 434/480, Loss: 0.5543, Time: 0.76 seconds\n",
            "Batch 435/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 435/480, Loss: 0.2558, Time: 0.75 seconds\n",
            "Batch 436/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 436/480, Loss: 0.1319, Time: 0.76 seconds\n",
            "Batch 437/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 437/480, Loss: 0.3982, Time: 0.77 seconds\n",
            "Batch 438/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 438/480, Loss: 0.2573, Time: 0.76 seconds\n",
            "Batch 439/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 439/480, Loss: 0.4208, Time: 0.77 seconds\n",
            "Batch 440/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 440/480, Loss: 0.4418, Time: 0.77 seconds\n",
            "Batch 441/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 441/480, Loss: 0.1871, Time: 0.77 seconds\n",
            "Batch 442/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 442/480, Loss: 0.1433, Time: 0.77 seconds\n",
            "Batch 443/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 443/480, Loss: 0.2821, Time: 0.77 seconds\n",
            "Batch 444/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 444/480, Loss: 0.2937, Time: 0.77 seconds\n",
            "Batch 445/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 2/3, Batch 445/480, Loss: 0.8786, Time: 0.76 seconds\n",
            "Batch 446/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 446/480, Loss: 0.1231, Time: 0.77 seconds\n",
            "Batch 447/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 447/480, Loss: 0.3910, Time: 0.77 seconds\n",
            "Batch 448/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 448/480, Loss: 0.4754, Time: 0.76 seconds\n",
            "Batch 449/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 449/480, Loss: 0.5798, Time: 0.77 seconds\n",
            "Batch 450/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 450/480, Loss: 0.5615, Time: 0.76 seconds\n",
            "Batch 451/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 451/480, Loss: 0.3585, Time: 0.77 seconds\n",
            "Batch 452/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 452/480, Loss: 0.4272, Time: 0.76 seconds\n",
            "Batch 453/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 453/480, Loss: 0.4097, Time: 0.76 seconds\n",
            "Batch 454/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 454/480, Loss: 0.0077, Time: 0.77 seconds\n",
            "Batch 455/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 455/480, Loss: 0.3492, Time: 0.77 seconds\n",
            "Batch 456/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 456/480, Loss: 0.1102, Time: 0.77 seconds\n",
            "Batch 457/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 457/480, Loss: 0.3153, Time: 0.77 seconds\n",
            "Batch 458/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 458/480, Loss: 0.1171, Time: 0.76 seconds\n",
            "Batch 459/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 459/480, Loss: 0.0910, Time: 0.77 seconds\n",
            "Batch 460/480, Label Counts: {0: 8}\n",
            "Epoch 2/3, Batch 460/480, Loss: 0.4742, Time: 0.76 seconds\n",
            "Batch 461/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 461/480, Loss: 0.5558, Time: 0.76 seconds\n",
            "Batch 462/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 462/480, Loss: 0.1930, Time: 0.76 seconds\n",
            "Batch 463/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 463/480, Loss: 0.0812, Time: 0.76 seconds\n",
            "Batch 464/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 464/480, Loss: 0.3661, Time: 0.75 seconds\n",
            "Batch 465/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 465/480, Loss: 0.1998, Time: 0.76 seconds\n",
            "Batch 466/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 466/480, Loss: 0.3074, Time: 0.76 seconds\n",
            "Batch 467/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 467/480, Loss: 0.2690, Time: 0.78 seconds\n",
            "Batch 468/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 468/480, Loss: 0.4233, Time: 0.75 seconds\n",
            "Batch 469/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 469/480, Loss: 0.3375, Time: 0.77 seconds\n",
            "Batch 470/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 470/480, Loss: 0.0999, Time: 0.77 seconds\n",
            "Batch 471/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 471/480, Loss: 0.5230, Time: 0.76 seconds\n",
            "Batch 472/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 2/3, Batch 472/480, Loss: 0.4474, Time: 0.76 seconds\n",
            "Batch 473/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 473/480, Loss: 0.1673, Time: 0.76 seconds\n",
            "Batch 474/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 474/480, Loss: 0.6170, Time: 0.77 seconds\n",
            "Batch 475/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 2/3, Batch 475/480, Loss: 0.3379, Time: 0.76 seconds\n",
            "Batch 476/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 476/480, Loss: 0.1884, Time: 0.76 seconds\n",
            "Batch 477/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 477/480, Loss: 0.2669, Time: 0.75 seconds\n",
            "Batch 478/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 2/3, Batch 478/480, Loss: 0.1296, Time: 0.77 seconds\n",
            "Batch 479/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 2/3, Batch 479/480, Loss: 0.5725, Time: 0.77 seconds\n",
            "Batch 480/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 480/480, Loss: 0.3069, Time: 0.76 seconds\n",
            "Epoch 2/3, Training Loss: 0.3430, Time: 367.31 seconds\n",
            "Validation Loss: 0.3809, Accuracy: 0.8458\n",
            "Batch 1/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 1/480, Loss: 0.1010, Time: 0.77 seconds\n",
            "Batch 2/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 2/480, Loss: 0.1147, Time: 0.76 seconds\n",
            "Batch 3/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 3/480, Loss: 0.0857, Time: 0.77 seconds\n",
            "Batch 4/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 4/480, Loss: 0.0902, Time: 0.77 seconds\n",
            "Batch 5/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 5/480, Loss: 0.2808, Time: 0.75 seconds\n",
            "Batch 6/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 6/480, Loss: 0.5879, Time: 0.76 seconds\n",
            "Batch 7/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 7/480, Loss: 0.0207, Time: 0.76 seconds\n",
            "Batch 8/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 8/480, Loss: 0.0371, Time: 0.76 seconds\n",
            "Batch 9/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 9/480, Loss: 0.1149, Time: 0.76 seconds\n",
            "Batch 10/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 10/480, Loss: 0.3470, Time: 0.76 seconds\n",
            "Batch 11/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 11/480, Loss: 0.1052, Time: 0.76 seconds\n",
            "Batch 12/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 12/480, Loss: 1.1571, Time: 0.75 seconds\n",
            "Batch 13/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 13/480, Loss: 0.2799, Time: 0.76 seconds\n",
            "Batch 14/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 14/480, Loss: 0.2045, Time: 0.75 seconds\n",
            "Batch 15/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 15/480, Loss: 0.6125, Time: 0.77 seconds\n",
            "Batch 16/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 16/480, Loss: 0.0822, Time: 0.77 seconds\n",
            "Batch 17/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 17/480, Loss: 0.0538, Time: 0.77 seconds\n",
            "Batch 18/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 18/480, Loss: 0.3631, Time: 0.78 seconds\n",
            "Batch 19/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 19/480, Loss: 0.7360, Time: 0.76 seconds\n",
            "Batch 20/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 20/480, Loss: 0.3258, Time: 0.77 seconds\n",
            "Batch 21/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 21/480, Loss: 0.1117, Time: 0.75 seconds\n",
            "Batch 22/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 22/480, Loss: 0.3180, Time: 0.76 seconds\n",
            "Batch 23/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 23/480, Loss: 0.3523, Time: 0.76 seconds\n",
            "Batch 24/480, Label Counts: {0: 2, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 24/480, Loss: 0.2953, Time: 0.76 seconds\n",
            "Batch 25/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 25/480, Loss: 0.8742, Time: 0.77 seconds\n",
            "Batch 26/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 26/480, Loss: 0.3193, Time: 0.76 seconds\n",
            "Batch 27/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 27/480, Loss: 0.5664, Time: 0.77 seconds\n",
            "Batch 28/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 28/480, Loss: 0.5104, Time: 0.75 seconds\n",
            "Batch 29/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 29/480, Loss: 0.2667, Time: 0.75 seconds\n",
            "Batch 30/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 30/480, Loss: 0.0846, Time: 0.77 seconds\n",
            "Batch 31/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 31/480, Loss: 1.1775, Time: 0.76 seconds\n",
            "Batch 32/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 32/480, Loss: 0.1336, Time: 0.76 seconds\n",
            "Batch 33/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 33/480, Loss: 0.2454, Time: 0.76 seconds\n",
            "Batch 34/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 34/480, Loss: 0.5926, Time: 0.77 seconds\n",
            "Batch 35/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 35/480, Loss: 0.3448, Time: 0.77 seconds\n",
            "Batch 36/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 36/480, Loss: 0.2166, Time: 0.77 seconds\n",
            "Batch 37/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 37/480, Loss: 0.3547, Time: 0.77 seconds\n",
            "Batch 38/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 38/480, Loss: 0.3075, Time: 0.76 seconds\n",
            "Batch 39/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 39/480, Loss: 0.4032, Time: 0.76 seconds\n",
            "Batch 40/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 40/480, Loss: 0.2936, Time: 0.77 seconds\n",
            "Batch 41/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 41/480, Loss: 0.1188, Time: 0.75 seconds\n",
            "Batch 42/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 42/480, Loss: 0.4870, Time: 0.76 seconds\n",
            "Batch 43/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 43/480, Loss: 0.2583, Time: 0.76 seconds\n",
            "Batch 44/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 44/480, Loss: 0.2676, Time: 0.76 seconds\n",
            "Batch 45/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 45/480, Loss: 0.1676, Time: 0.76 seconds\n",
            "Batch 46/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 46/480, Loss: 0.1144, Time: 0.76 seconds\n",
            "Batch 47/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 47/480, Loss: 0.6743, Time: 0.77 seconds\n",
            "Batch 48/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 48/480, Loss: 0.3035, Time: 0.76 seconds\n",
            "Batch 49/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 49/480, Loss: 0.2745, Time: 0.76 seconds\n",
            "Batch 50/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 50/480, Loss: 0.3154, Time: 0.76 seconds\n",
            "Batch 51/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 51/480, Loss: 0.2701, Time: 0.77 seconds\n",
            "Batch 52/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 52/480, Loss: 0.3327, Time: 0.77 seconds\n",
            "Batch 53/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 53/480, Loss: 0.2382, Time: 0.78 seconds\n",
            "Batch 54/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 54/480, Loss: 0.1717, Time: 0.76 seconds\n",
            "Batch 55/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 55/480, Loss: 0.3195, Time: 0.76 seconds\n",
            "Batch 56/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 56/480, Loss: 0.6119, Time: 0.77 seconds\n",
            "Batch 57/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 57/480, Loss: 0.0222, Time: 0.75 seconds\n",
            "Batch 58/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 58/480, Loss: 0.3604, Time: 0.76 seconds\n",
            "Batch 59/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 59/480, Loss: 0.2763, Time: 0.76 seconds\n",
            "Batch 60/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 60/480, Loss: 0.6763, Time: 0.77 seconds\n",
            "Batch 61/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 61/480, Loss: 0.2047, Time: 0.75 seconds\n",
            "Batch 62/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 62/480, Loss: 0.4691, Time: 0.77 seconds\n",
            "Batch 63/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 63/480, Loss: 0.1627, Time: 0.75 seconds\n",
            "Batch 64/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 64/480, Loss: 0.5421, Time: 0.76 seconds\n",
            "Batch 65/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 65/480, Loss: 0.2708, Time: 0.77 seconds\n",
            "Batch 66/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 66/480, Loss: 0.4019, Time: 0.77 seconds\n",
            "Batch 67/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 67/480, Loss: 0.5931, Time: 0.76 seconds\n",
            "Batch 68/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 68/480, Loss: 0.0661, Time: 0.76 seconds\n",
            "Batch 69/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 69/480, Loss: 0.1345, Time: 0.77 seconds\n",
            "Batch 70/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 70/480, Loss: 0.3389, Time: 0.76 seconds\n",
            "Batch 71/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 71/480, Loss: 0.7986, Time: 0.76 seconds\n",
            "Batch 72/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 72/480, Loss: 0.1197, Time: 0.75 seconds\n",
            "Batch 73/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 73/480, Loss: 0.2113, Time: 0.76 seconds\n",
            "Batch 74/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 74/480, Loss: 0.5825, Time: 0.77 seconds\n",
            "Batch 75/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 75/480, Loss: 0.3403, Time: 0.77 seconds\n",
            "Batch 76/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 76/480, Loss: 0.1689, Time: 0.76 seconds\n",
            "Batch 77/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 77/480, Loss: 0.7343, Time: 0.77 seconds\n",
            "Batch 78/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 78/480, Loss: 0.0624, Time: 0.77 seconds\n",
            "Batch 79/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 79/480, Loss: 0.4262, Time: 0.76 seconds\n",
            "Batch 80/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 80/480, Loss: 0.2792, Time: 0.77 seconds\n",
            "Batch 81/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 81/480, Loss: 0.4798, Time: 0.77 seconds\n",
            "Batch 82/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 82/480, Loss: 0.4622, Time: 0.76 seconds\n",
            "Batch 83/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 83/480, Loss: 0.1066, Time: 0.77 seconds\n",
            "Batch 84/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 84/480, Loss: 0.0807, Time: 0.76 seconds\n",
            "Batch 85/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 85/480, Loss: 0.5114, Time: 0.76 seconds\n",
            "Batch 86/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 86/480, Loss: 0.8256, Time: 0.77 seconds\n",
            "Batch 87/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 87/480, Loss: 0.1841, Time: 0.76 seconds\n",
            "Batch 88/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 88/480, Loss: 0.7858, Time: 0.77 seconds\n",
            "Batch 89/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 89/480, Loss: 0.3760, Time: 0.77 seconds\n",
            "Batch 90/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 90/480, Loss: 0.0070, Time: 0.76 seconds\n",
            "Batch 91/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 91/480, Loss: 0.1694, Time: 0.77 seconds\n",
            "Batch 92/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 92/480, Loss: 0.7726, Time: 0.77 seconds\n",
            "Batch 93/480, Label Counts: {0: 2, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 93/480, Loss: 0.1262, Time: 0.76 seconds\n",
            "Batch 94/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 94/480, Loss: 0.2451, Time: 0.77 seconds\n",
            "Batch 95/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 95/480, Loss: 0.2836, Time: 0.75 seconds\n",
            "Batch 96/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 96/480, Loss: 0.1502, Time: 0.76 seconds\n",
            "Batch 97/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 97/480, Loss: 0.1766, Time: 0.76 seconds\n",
            "Batch 98/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 98/480, Loss: 0.6667, Time: 0.76 seconds\n",
            "Batch 99/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 99/480, Loss: 0.5941, Time: 0.76 seconds\n",
            "Batch 100/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 100/480, Loss: 0.2405, Time: 0.76 seconds\n",
            "Batch 101/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 101/480, Loss: 0.0593, Time: 0.78 seconds\n",
            "Batch 102/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 102/480, Loss: 0.2436, Time: 0.75 seconds\n",
            "Batch 103/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 103/480, Loss: 0.4955, Time: 0.76 seconds\n",
            "Batch 104/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 104/480, Loss: 0.0295, Time: 0.77 seconds\n",
            "Batch 105/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 105/480, Loss: 0.4745, Time: 0.75 seconds\n",
            "Batch 106/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 106/480, Loss: 0.1349, Time: 0.76 seconds\n",
            "Batch 107/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 107/480, Loss: 0.3235, Time: 0.77 seconds\n",
            "Batch 108/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 108/480, Loss: 0.1857, Time: 0.74 seconds\n",
            "Batch 109/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 109/480, Loss: 0.2486, Time: 0.76 seconds\n",
            "Batch 110/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 110/480, Loss: 0.2775, Time: 0.76 seconds\n",
            "Batch 111/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 111/480, Loss: 0.3514, Time: 0.77 seconds\n",
            "Batch 112/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 112/480, Loss: 0.4218, Time: 0.77 seconds\n",
            "Batch 113/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 113/480, Loss: 0.5026, Time: 0.77 seconds\n",
            "Batch 114/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 114/480, Loss: 0.4039, Time: 0.77 seconds\n",
            "Batch 115/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 115/480, Loss: 0.1265, Time: 0.76 seconds\n",
            "Batch 116/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 116/480, Loss: 0.3579, Time: 0.76 seconds\n",
            "Batch 117/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 117/480, Loss: 0.3478, Time: 0.76 seconds\n",
            "Batch 118/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 118/480, Loss: 0.3955, Time: 0.77 seconds\n",
            "Batch 119/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 119/480, Loss: 0.1016, Time: 0.75 seconds\n",
            "Batch 120/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 120/480, Loss: 0.1233, Time: 0.77 seconds\n",
            "Batch 121/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 121/480, Loss: 0.1169, Time: 0.76 seconds\n",
            "Batch 122/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 122/480, Loss: 0.5126, Time: 0.77 seconds\n",
            "Batch 123/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 123/480, Loss: 0.8388, Time: 0.76 seconds\n",
            "Batch 124/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 124/480, Loss: 0.7762, Time: 0.75 seconds\n",
            "Batch 125/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 125/480, Loss: 0.0679, Time: 0.75 seconds\n",
            "Batch 126/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 126/480, Loss: 0.3454, Time: 0.76 seconds\n",
            "Batch 127/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 127/480, Loss: 0.3366, Time: 0.76 seconds\n",
            "Batch 128/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 128/480, Loss: 0.3825, Time: 0.76 seconds\n",
            "Batch 129/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 129/480, Loss: 0.1778, Time: 0.77 seconds\n",
            "Batch 130/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 130/480, Loss: 0.2334, Time: 0.77 seconds\n",
            "Batch 131/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 131/480, Loss: 0.3565, Time: 0.76 seconds\n",
            "Batch 132/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 132/480, Loss: 0.3299, Time: 0.76 seconds\n",
            "Batch 133/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 133/480, Loss: 0.4731, Time: 0.77 seconds\n",
            "Batch 134/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 134/480, Loss: 0.3206, Time: 0.76 seconds\n",
            "Batch 135/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 135/480, Loss: 0.3591, Time: 0.75 seconds\n",
            "Batch 136/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 136/480, Loss: 0.0644, Time: 0.76 seconds\n",
            "Batch 137/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 137/480, Loss: 0.3193, Time: 0.77 seconds\n",
            "Batch 138/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 138/480, Loss: 0.3278, Time: 0.76 seconds\n",
            "Batch 139/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 139/480, Loss: 0.0763, Time: 0.77 seconds\n",
            "Batch 140/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 140/480, Loss: 0.2192, Time: 0.77 seconds\n",
            "Batch 141/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 141/480, Loss: 0.3698, Time: 0.76 seconds\n",
            "Batch 142/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 142/480, Loss: 0.0951, Time: 0.76 seconds\n",
            "Batch 143/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 143/480, Loss: 0.1182, Time: 0.75 seconds\n",
            "Batch 144/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 144/480, Loss: 0.1732, Time: 0.76 seconds\n",
            "Batch 145/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 145/480, Loss: 0.1159, Time: 0.76 seconds\n",
            "Batch 146/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 146/480, Loss: 0.4516, Time: 0.77 seconds\n",
            "Batch 147/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 147/480, Loss: 0.3399, Time: 0.75 seconds\n",
            "Batch 148/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 148/480, Loss: 0.3757, Time: 0.76 seconds\n",
            "Batch 149/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 149/480, Loss: 0.4150, Time: 0.76 seconds\n",
            "Batch 150/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 150/480, Loss: 0.4660, Time: 0.77 seconds\n",
            "Batch 151/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 151/480, Loss: 0.7087, Time: 0.75 seconds\n",
            "Batch 152/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 152/480, Loss: 0.3001, Time: 0.77 seconds\n",
            "Batch 153/480, Label Counts: {0: 4, 2: 4}\n",
            "Epoch 3/3, Batch 153/480, Loss: 0.3827, Time: 0.77 seconds\n",
            "Batch 154/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 154/480, Loss: 0.3615, Time: 0.76 seconds\n",
            "Batch 155/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 155/480, Loss: 0.2997, Time: 0.77 seconds\n",
            "Batch 156/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 156/480, Loss: 0.0893, Time: 0.76 seconds\n",
            "Batch 157/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 157/480, Loss: 0.0706, Time: 0.77 seconds\n",
            "Batch 158/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 158/480, Loss: 0.0103, Time: 0.76 seconds\n",
            "Batch 159/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 159/480, Loss: 0.3519, Time: 0.77 seconds\n",
            "Batch 160/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 160/480, Loss: 0.1672, Time: 0.76 seconds\n",
            "Batch 161/480, Label Counts: {0: 2, 1: 1, 2: 5}\n",
            "Epoch 3/3, Batch 161/480, Loss: 1.0470, Time: 0.77 seconds\n",
            "Batch 162/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 162/480, Loss: 0.0218, Time: 0.76 seconds\n",
            "Batch 163/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 163/480, Loss: 0.3648, Time: 0.77 seconds\n",
            "Batch 164/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 164/480, Loss: 0.3189, Time: 0.75 seconds\n",
            "Batch 165/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 165/480, Loss: 1.1726, Time: 0.77 seconds\n",
            "Batch 166/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 166/480, Loss: 0.0957, Time: 0.76 seconds\n",
            "Batch 167/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 167/480, Loss: 0.0171, Time: 0.75 seconds\n",
            "Batch 168/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 168/480, Loss: 0.2728, Time: 0.76 seconds\n",
            "Batch 169/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 169/480, Loss: 0.1490, Time: 0.77 seconds\n",
            "Batch 170/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 170/480, Loss: 0.2920, Time: 0.76 seconds\n",
            "Batch 171/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 171/480, Loss: 0.1389, Time: 0.76 seconds\n",
            "Batch 172/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 172/480, Loss: 0.1822, Time: 0.76 seconds\n",
            "Batch 173/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 173/480, Loss: 0.0830, Time: 0.76 seconds\n",
            "Batch 174/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 174/480, Loss: 0.2706, Time: 0.77 seconds\n",
            "Batch 175/480, Label Counts: {0: 3, 2: 5}\n",
            "Epoch 3/3, Batch 175/480, Loss: 0.2565, Time: 0.77 seconds\n",
            "Batch 176/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 176/480, Loss: 0.2589, Time: 0.76 seconds\n",
            "Batch 177/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 177/480, Loss: 0.3632, Time: 0.76 seconds\n",
            "Batch 178/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 178/480, Loss: 0.5025, Time: 0.77 seconds\n",
            "Batch 179/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 179/480, Loss: 0.5525, Time: 0.75 seconds\n",
            "Batch 180/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 180/480, Loss: 0.0082, Time: 0.76 seconds\n",
            "Batch 181/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 181/480, Loss: 0.2564, Time: 0.77 seconds\n",
            "Batch 182/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 182/480, Loss: 0.1338, Time: 0.77 seconds\n",
            "Batch 183/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 183/480, Loss: 1.0131, Time: 0.75 seconds\n",
            "Batch 184/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 184/480, Loss: 0.1072, Time: 0.77 seconds\n",
            "Batch 185/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 185/480, Loss: 0.5118, Time: 0.74 seconds\n",
            "Batch 186/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 186/480, Loss: 0.5767, Time: 0.76 seconds\n",
            "Batch 187/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 187/480, Loss: 0.9746, Time: 0.76 seconds\n",
            "Batch 188/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 188/480, Loss: 0.2393, Time: 0.75 seconds\n",
            "Batch 189/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 189/480, Loss: 0.3121, Time: 0.78 seconds\n",
            "Batch 190/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 190/480, Loss: 0.4560, Time: 0.76 seconds\n",
            "Batch 191/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 191/480, Loss: 0.2488, Time: 0.76 seconds\n",
            "Batch 192/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 192/480, Loss: 0.2455, Time: 0.77 seconds\n",
            "Batch 193/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 193/480, Loss: 0.0810, Time: 0.76 seconds\n",
            "Batch 194/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 194/480, Loss: 0.0559, Time: 0.76 seconds\n",
            "Batch 195/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 195/480, Loss: 0.4478, Time: 0.75 seconds\n",
            "Batch 196/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 196/480, Loss: 0.3585, Time: 0.76 seconds\n",
            "Batch 197/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 197/480, Loss: 0.4324, Time: 0.77 seconds\n",
            "Batch 198/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 198/480, Loss: 0.7082, Time: 0.76 seconds\n",
            "Batch 199/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 199/480, Loss: 0.6195, Time: 0.77 seconds\n",
            "Batch 200/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 200/480, Loss: 0.4228, Time: 0.76 seconds\n",
            "Batch 201/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 201/480, Loss: 0.0688, Time: 0.75 seconds\n",
            "Batch 202/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 202/480, Loss: 0.5310, Time: 0.77 seconds\n",
            "Batch 203/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 203/480, Loss: 0.3585, Time: 0.76 seconds\n",
            "Batch 204/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 204/480, Loss: 0.0799, Time: 0.75 seconds\n",
            "Batch 205/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 205/480, Loss: 0.5889, Time: 0.76 seconds\n",
            "Batch 206/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 206/480, Loss: 0.0921, Time: 0.75 seconds\n",
            "Batch 207/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 207/480, Loss: 0.0758, Time: 0.74 seconds\n",
            "Batch 208/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 208/480, Loss: 0.3745, Time: 0.76 seconds\n",
            "Batch 209/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 209/480, Loss: 0.0406, Time: 0.77 seconds\n",
            "Batch 210/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 210/480, Loss: 0.0049, Time: 0.76 seconds\n",
            "Batch 211/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 211/480, Loss: 0.3548, Time: 0.76 seconds\n",
            "Batch 212/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 212/480, Loss: 0.0427, Time: 0.75 seconds\n",
            "Batch 213/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 213/480, Loss: 0.6383, Time: 0.77 seconds\n",
            "Batch 214/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 214/480, Loss: 0.1555, Time: 0.76 seconds\n",
            "Batch 215/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 215/480, Loss: 0.4501, Time: 0.76 seconds\n",
            "Batch 216/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 216/480, Loss: 0.1872, Time: 0.76 seconds\n",
            "Batch 217/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 217/480, Loss: 0.1459, Time: 0.77 seconds\n",
            "Batch 218/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 218/480, Loss: 0.9007, Time: 0.77 seconds\n",
            "Batch 219/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 219/480, Loss: 0.0125, Time: 0.76 seconds\n",
            "Batch 220/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 220/480, Loss: 0.2790, Time: 0.76 seconds\n",
            "Batch 221/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 221/480, Loss: 0.6256, Time: 0.76 seconds\n",
            "Batch 222/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 222/480, Loss: 0.3272, Time: 0.76 seconds\n",
            "Batch 223/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 223/480, Loss: 0.0134, Time: 0.76 seconds\n",
            "Batch 224/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 224/480, Loss: 0.3241, Time: 0.77 seconds\n",
            "Batch 225/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 225/480, Loss: 0.0011, Time: 0.76 seconds\n",
            "Batch 226/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 226/480, Loss: 0.0572, Time: 0.75 seconds\n",
            "Batch 227/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 227/480, Loss: 0.1014, Time: 0.76 seconds\n",
            "Batch 228/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 228/480, Loss: 0.1423, Time: 0.75 seconds\n",
            "Batch 229/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 229/480, Loss: 0.2780, Time: 0.77 seconds\n",
            "Batch 230/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 230/480, Loss: 0.2565, Time: 0.76 seconds\n",
            "Batch 231/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 231/480, Loss: 0.2726, Time: 0.76 seconds\n",
            "Batch 232/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 232/480, Loss: 0.9753, Time: 0.76 seconds\n",
            "Batch 233/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 233/480, Loss: 0.3177, Time: 0.76 seconds\n",
            "Batch 234/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 234/480, Loss: 0.3749, Time: 0.76 seconds\n",
            "Batch 235/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 235/480, Loss: 0.8288, Time: 0.76 seconds\n",
            "Batch 236/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 236/480, Loss: 0.1257, Time: 0.76 seconds\n",
            "Batch 237/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 237/480, Loss: 0.0515, Time: 0.75 seconds\n",
            "Batch 238/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 238/480, Loss: 0.4145, Time: 0.76 seconds\n",
            "Batch 239/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 239/480, Loss: 0.6866, Time: 0.76 seconds\n",
            "Batch 240/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 240/480, Loss: 0.3788, Time: 0.76 seconds\n",
            "Batch 241/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 241/480, Loss: 0.0666, Time: 0.76 seconds\n",
            "Batch 242/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 242/480, Loss: 0.2706, Time: 0.77 seconds\n",
            "Batch 243/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 243/480, Loss: 0.5432, Time: 0.77 seconds\n",
            "Batch 244/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 244/480, Loss: 0.3798, Time: 0.76 seconds\n",
            "Batch 245/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 245/480, Loss: 0.5544, Time: 0.76 seconds\n",
            "Batch 246/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 246/480, Loss: 0.3957, Time: 0.76 seconds\n",
            "Batch 247/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 247/480, Loss: 0.1157, Time: 0.76 seconds\n",
            "Batch 248/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 248/480, Loss: 0.1015, Time: 0.77 seconds\n",
            "Batch 249/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 249/480, Loss: 0.3116, Time: 0.76 seconds\n",
            "Batch 250/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 250/480, Loss: 0.1910, Time: 0.76 seconds\n",
            "Batch 251/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 251/480, Loss: 0.1929, Time: 0.76 seconds\n",
            "Batch 252/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 252/480, Loss: 0.2981, Time: 0.76 seconds\n",
            "Batch 253/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 253/480, Loss: 0.4844, Time: 0.76 seconds\n",
            "Batch 254/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 254/480, Loss: 0.3243, Time: 0.76 seconds\n",
            "Batch 255/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 255/480, Loss: 0.4312, Time: 0.76 seconds\n",
            "Batch 256/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 256/480, Loss: 0.8275, Time: 0.76 seconds\n",
            "Batch 257/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 257/480, Loss: 0.3067, Time: 0.76 seconds\n",
            "Batch 258/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 258/480, Loss: 0.9931, Time: 0.76 seconds\n",
            "Batch 259/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 259/480, Loss: 0.0080, Time: 0.76 seconds\n",
            "Batch 260/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 260/480, Loss: 0.1811, Time: 0.76 seconds\n",
            "Batch 261/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 261/480, Loss: 1.1151, Time: 0.75 seconds\n",
            "Batch 262/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 262/480, Loss: 0.2502, Time: 0.77 seconds\n",
            "Batch 263/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 263/480, Loss: 0.3856, Time: 0.76 seconds\n",
            "Batch 264/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 264/480, Loss: 0.4520, Time: 0.77 seconds\n",
            "Batch 265/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 265/480, Loss: 0.0709, Time: 0.75 seconds\n",
            "Batch 266/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 266/480, Loss: 0.0029, Time: 0.77 seconds\n",
            "Batch 267/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 267/480, Loss: 0.5326, Time: 0.77 seconds\n",
            "Batch 268/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 268/480, Loss: 0.0872, Time: 0.76 seconds\n",
            "Batch 269/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 269/480, Loss: 0.1409, Time: 0.74 seconds\n",
            "Batch 270/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 270/480, Loss: 0.2791, Time: 0.75 seconds\n",
            "Batch 271/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 271/480, Loss: 0.0473, Time: 0.75 seconds\n",
            "Batch 272/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 272/480, Loss: 0.1129, Time: 0.77 seconds\n",
            "Batch 273/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 273/480, Loss: 0.7875, Time: 0.76 seconds\n",
            "Batch 274/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 274/480, Loss: 0.2859, Time: 0.77 seconds\n",
            "Batch 275/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 275/480, Loss: 0.6369, Time: 0.74 seconds\n",
            "Batch 276/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 276/480, Loss: 0.2850, Time: 0.76 seconds\n",
            "Batch 277/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 277/480, Loss: 0.3169, Time: 0.76 seconds\n",
            "Batch 278/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 278/480, Loss: 0.6463, Time: 0.77 seconds\n",
            "Batch 279/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 279/480, Loss: 0.5571, Time: 0.76 seconds\n",
            "Batch 280/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 280/480, Loss: 0.0837, Time: 0.76 seconds\n",
            "Batch 281/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 281/480, Loss: 0.3730, Time: 0.76 seconds\n",
            "Batch 282/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 282/480, Loss: 0.2723, Time: 0.75 seconds\n",
            "Batch 283/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 283/480, Loss: 0.4460, Time: 0.75 seconds\n",
            "Batch 284/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 284/480, Loss: 0.1101, Time: 0.76 seconds\n",
            "Batch 285/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 285/480, Loss: 0.3511, Time: 0.76 seconds\n",
            "Batch 286/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 286/480, Loss: 0.2490, Time: 0.77 seconds\n",
            "Batch 287/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 287/480, Loss: 0.9139, Time: 0.76 seconds\n",
            "Batch 288/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 288/480, Loss: 0.2486, Time: 0.76 seconds\n",
            "Batch 289/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 289/480, Loss: 0.3108, Time: 0.76 seconds\n",
            "Batch 290/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 290/480, Loss: 0.1005, Time: 0.75 seconds\n",
            "Batch 291/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 291/480, Loss: 0.1757, Time: 0.74 seconds\n",
            "Batch 292/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 292/480, Loss: 0.1774, Time: 0.76 seconds\n",
            "Batch 293/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 293/480, Loss: 0.3828, Time: 0.76 seconds\n",
            "Batch 294/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 294/480, Loss: 0.2952, Time: 0.77 seconds\n",
            "Batch 295/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 295/480, Loss: 0.0188, Time: 0.76 seconds\n",
            "Batch 296/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 296/480, Loss: 0.1151, Time: 0.76 seconds\n",
            "Batch 297/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 297/480, Loss: 0.1178, Time: 0.76 seconds\n",
            "Batch 298/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 298/480, Loss: 0.3046, Time: 0.75 seconds\n",
            "Batch 299/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 299/480, Loss: 0.3534, Time: 0.77 seconds\n",
            "Batch 300/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 300/480, Loss: 0.1518, Time: 0.76 seconds\n",
            "Batch 301/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 301/480, Loss: 0.4148, Time: 0.77 seconds\n",
            "Batch 302/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 302/480, Loss: 0.2529, Time: 0.76 seconds\n",
            "Batch 303/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 303/480, Loss: 0.1721, Time: 0.75 seconds\n",
            "Batch 304/480, Label Counts: {0: 3, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 304/480, Loss: 0.3066, Time: 0.76 seconds\n",
            "Batch 305/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 305/480, Loss: 0.1401, Time: 0.76 seconds\n",
            "Batch 306/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 306/480, Loss: 0.0140, Time: 0.76 seconds\n",
            "Batch 307/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 307/480, Loss: 0.4497, Time: 0.77 seconds\n",
            "Batch 308/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 308/480, Loss: 0.3672, Time: 0.76 seconds\n",
            "Batch 309/480, Label Counts: {0: 3, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 309/480, Loss: 0.6304, Time: 0.77 seconds\n",
            "Batch 310/480, Label Counts: {0: 4, 2: 4}\n",
            "Epoch 3/3, Batch 310/480, Loss: 0.8678, Time: 0.78 seconds\n",
            "Batch 311/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 311/480, Loss: 0.0517, Time: 0.76 seconds\n",
            "Batch 312/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 312/480, Loss: 0.3430, Time: 0.76 seconds\n",
            "Batch 313/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 313/480, Loss: 0.0528, Time: 0.76 seconds\n",
            "Batch 314/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 314/480, Loss: 0.0569, Time: 0.76 seconds\n",
            "Batch 315/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 315/480, Loss: 0.4189, Time: 0.75 seconds\n",
            "Batch 316/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 316/480, Loss: 0.3894, Time: 0.76 seconds\n",
            "Batch 317/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 317/480, Loss: 0.5240, Time: 0.76 seconds\n",
            "Batch 318/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 318/480, Loss: 0.3505, Time: 0.76 seconds\n",
            "Batch 319/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 319/480, Loss: 0.5556, Time: 0.77 seconds\n",
            "Batch 320/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 320/480, Loss: 0.2800, Time: 0.76 seconds\n",
            "Batch 321/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 321/480, Loss: 0.0330, Time: 0.76 seconds\n",
            "Batch 322/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 322/480, Loss: 0.4979, Time: 0.76 seconds\n",
            "Batch 323/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 323/480, Loss: 0.2657, Time: 0.76 seconds\n",
            "Batch 324/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 324/480, Loss: 0.1623, Time: 0.78 seconds\n",
            "Batch 325/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 325/480, Loss: 0.0631, Time: 0.76 seconds\n",
            "Batch 326/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 326/480, Loss: 0.3316, Time: 0.76 seconds\n",
            "Batch 327/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 327/480, Loss: 0.4981, Time: 0.77 seconds\n",
            "Batch 328/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 328/480, Loss: 0.5457, Time: 0.76 seconds\n",
            "Batch 329/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 329/480, Loss: 0.1830, Time: 0.76 seconds\n",
            "Batch 330/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 330/480, Loss: 0.3737, Time: 0.76 seconds\n",
            "Batch 331/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 331/480, Loss: 0.1246, Time: 0.77 seconds\n",
            "Batch 332/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 332/480, Loss: 0.3423, Time: 0.76 seconds\n",
            "Batch 333/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 333/480, Loss: 0.3754, Time: 0.76 seconds\n",
            "Batch 334/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 334/480, Loss: 0.7613, Time: 0.77 seconds\n",
            "Batch 335/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 335/480, Loss: 0.2901, Time: 0.75 seconds\n",
            "Batch 336/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 336/480, Loss: 0.2630, Time: 0.75 seconds\n",
            "Batch 337/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 337/480, Loss: 0.3022, Time: 0.76 seconds\n",
            "Batch 338/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 338/480, Loss: 0.3797, Time: 0.78 seconds\n",
            "Batch 339/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 339/480, Loss: 0.1579, Time: 0.75 seconds\n",
            "Batch 340/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 340/480, Loss: 0.2468, Time: 0.77 seconds\n",
            "Batch 341/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 341/480, Loss: 1.1916, Time: 0.75 seconds\n",
            "Batch 342/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 342/480, Loss: 0.0727, Time: 0.76 seconds\n",
            "Batch 343/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 343/480, Loss: 0.0747, Time: 0.75 seconds\n",
            "Batch 344/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 344/480, Loss: 0.5057, Time: 0.75 seconds\n",
            "Batch 345/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 345/480, Loss: 0.8517, Time: 0.76 seconds\n",
            "Batch 346/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 346/480, Loss: 0.0649, Time: 0.75 seconds\n",
            "Batch 347/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 347/480, Loss: 0.4909, Time: 0.77 seconds\n",
            "Batch 348/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 348/480, Loss: 0.2564, Time: 0.78 seconds\n",
            "Batch 349/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 349/480, Loss: 0.3289, Time: 0.77 seconds\n",
            "Batch 350/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 350/480, Loss: 0.3745, Time: 0.77 seconds\n",
            "Batch 351/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 351/480, Loss: 0.2067, Time: 0.77 seconds\n",
            "Batch 352/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 352/480, Loss: 0.1365, Time: 0.77 seconds\n",
            "Batch 353/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 353/480, Loss: 0.5517, Time: 0.77 seconds\n",
            "Batch 354/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 354/480, Loss: 0.8415, Time: 0.76 seconds\n",
            "Batch 355/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 355/480, Loss: 0.1284, Time: 0.75 seconds\n",
            "Batch 356/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 356/480, Loss: 0.0989, Time: 0.76 seconds\n",
            "Batch 357/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 357/480, Loss: 0.5715, Time: 0.77 seconds\n",
            "Batch 358/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 358/480, Loss: 0.0980, Time: 0.76 seconds\n",
            "Batch 359/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 359/480, Loss: 0.4092, Time: 0.76 seconds\n",
            "Batch 360/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 360/480, Loss: 0.3605, Time: 0.75 seconds\n",
            "Batch 361/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 361/480, Loss: 0.3415, Time: 0.77 seconds\n",
            "Batch 362/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 362/480, Loss: 0.3576, Time: 0.76 seconds\n",
            "Batch 363/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 363/480, Loss: 0.5194, Time: 0.75 seconds\n",
            "Batch 364/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 364/480, Loss: 0.2800, Time: 0.76 seconds\n",
            "Batch 365/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 365/480, Loss: 0.1279, Time: 0.75 seconds\n",
            "Batch 366/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 366/480, Loss: 0.1722, Time: 0.77 seconds\n",
            "Batch 367/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 367/480, Loss: 0.0845, Time: 0.76 seconds\n",
            "Batch 368/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 368/480, Loss: 0.3369, Time: 0.75 seconds\n",
            "Batch 369/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 369/480, Loss: 0.6102, Time: 0.76 seconds\n",
            "Batch 370/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 370/480, Loss: 0.5351, Time: 0.75 seconds\n",
            "Batch 371/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 371/480, Loss: 0.3648, Time: 0.76 seconds\n",
            "Batch 372/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 372/480, Loss: 0.3981, Time: 0.76 seconds\n",
            "Batch 373/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 373/480, Loss: 0.0331, Time: 0.75 seconds\n",
            "Batch 374/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 374/480, Loss: 0.2487, Time: 0.76 seconds\n",
            "Batch 375/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 375/480, Loss: 0.5684, Time: 0.75 seconds\n",
            "Batch 376/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 376/480, Loss: 0.3704, Time: 0.76 seconds\n",
            "Batch 377/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 377/480, Loss: 0.4891, Time: 0.77 seconds\n",
            "Batch 378/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 378/480, Loss: 0.6675, Time: 0.76 seconds\n",
            "Batch 379/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 379/480, Loss: 0.2322, Time: 0.77 seconds\n",
            "Batch 380/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 380/480, Loss: 0.4970, Time: 0.76 seconds\n",
            "Batch 381/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 381/480, Loss: 0.5317, Time: 0.77 seconds\n",
            "Batch 382/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 382/480, Loss: 0.2175, Time: 0.76 seconds\n",
            "Batch 383/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 383/480, Loss: 0.2509, Time: 0.76 seconds\n",
            "Batch 384/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 384/480, Loss: 0.3025, Time: 0.78 seconds\n",
            "Batch 385/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 385/480, Loss: 0.1019, Time: 0.76 seconds\n",
            "Batch 386/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 386/480, Loss: 0.1184, Time: 0.76 seconds\n",
            "Batch 387/480, Label Counts: {0: 3, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 387/480, Loss: 0.3308, Time: 0.77 seconds\n",
            "Batch 388/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 388/480, Loss: 0.1437, Time: 0.77 seconds\n",
            "Batch 389/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 389/480, Loss: 0.3794, Time: 0.77 seconds\n",
            "Batch 390/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 390/480, Loss: 0.4731, Time: 0.76 seconds\n",
            "Batch 391/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 391/480, Loss: 0.3717, Time: 0.75 seconds\n",
            "Batch 392/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 392/480, Loss: 0.2988, Time: 0.75 seconds\n",
            "Batch 393/480, Label Counts: {0: 5, 1: 3}\n",
            "Epoch 3/3, Batch 393/480, Loss: 0.4168, Time: 0.76 seconds\n",
            "Batch 394/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 394/480, Loss: 0.2058, Time: 0.76 seconds\n",
            "Batch 395/480, Label Counts: {0: 3, 1: 5}\n",
            "Epoch 3/3, Batch 395/480, Loss: 0.6255, Time: 0.77 seconds\n",
            "Batch 396/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 396/480, Loss: 0.3772, Time: 0.75 seconds\n",
            "Batch 397/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 397/480, Loss: 0.2110, Time: 0.77 seconds\n",
            "Batch 398/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 398/480, Loss: 0.0878, Time: 0.75 seconds\n",
            "Batch 399/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 399/480, Loss: 0.6988, Time: 0.76 seconds\n",
            "Batch 400/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 400/480, Loss: 0.2110, Time: 0.76 seconds\n",
            "Batch 401/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 401/480, Loss: 0.4620, Time: 0.77 seconds\n",
            "Batch 402/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 402/480, Loss: 0.1604, Time: 0.75 seconds\n",
            "Batch 403/480, Label Counts: {0: 2, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 403/480, Loss: 0.3804, Time: 0.76 seconds\n",
            "Batch 404/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 404/480, Loss: 0.0958, Time: 0.75 seconds\n",
            "Batch 405/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 405/480, Loss: 0.4055, Time: 0.77 seconds\n",
            "Batch 406/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 406/480, Loss: 0.5749, Time: 0.77 seconds\n",
            "Batch 407/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 407/480, Loss: 0.5471, Time: 0.75 seconds\n",
            "Batch 408/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 408/480, Loss: 0.3507, Time: 0.76 seconds\n",
            "Batch 409/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 409/480, Loss: 0.4443, Time: 0.77 seconds\n",
            "Batch 410/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 410/480, Loss: 0.1427, Time: 0.77 seconds\n",
            "Batch 411/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 411/480, Loss: 0.1944, Time: 0.76 seconds\n",
            "Batch 412/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 412/480, Loss: 0.3111, Time: 0.77 seconds\n",
            "Batch 413/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 413/480, Loss: 0.4607, Time: 0.76 seconds\n",
            "Batch 414/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 414/480, Loss: 0.0867, Time: 0.76 seconds\n",
            "Batch 415/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 415/480, Loss: 0.3256, Time: 0.75 seconds\n",
            "Batch 416/480, Label Counts: {0: 4, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 416/480, Loss: 0.0161, Time: 0.76 seconds\n",
            "Batch 417/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 417/480, Loss: 0.1899, Time: 0.74 seconds\n",
            "Batch 418/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 418/480, Loss: 0.9395, Time: 0.77 seconds\n",
            "Batch 419/480, Label Counts: {0: 4, 1: 4}\n",
            "Epoch 3/3, Batch 419/480, Loss: 0.1187, Time: 0.76 seconds\n",
            "Batch 420/480, Label Counts: {0: 2, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 420/480, Loss: 0.8396, Time: 0.76 seconds\n",
            "Batch 421/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 421/480, Loss: 0.4488, Time: 0.77 seconds\n",
            "Batch 422/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 422/480, Loss: 0.6780, Time: 0.76 seconds\n",
            "Batch 423/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 423/480, Loss: 0.1179, Time: 0.76 seconds\n",
            "Batch 424/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 424/480, Loss: 0.5846, Time: 0.76 seconds\n",
            "Batch 425/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 425/480, Loss: 0.0637, Time: 0.76 seconds\n",
            "Batch 426/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 426/480, Loss: 0.2991, Time: 0.75 seconds\n",
            "Batch 427/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 427/480, Loss: 0.3391, Time: 0.77 seconds\n",
            "Batch 428/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 428/480, Loss: 0.6066, Time: 0.75 seconds\n",
            "Batch 429/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 429/480, Loss: 0.1925, Time: 0.75 seconds\n",
            "Batch 430/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 430/480, Loss: 0.0486, Time: 0.76 seconds\n",
            "Batch 431/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 431/480, Loss: 0.4724, Time: 0.77 seconds\n",
            "Batch 432/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 432/480, Loss: 0.4487, Time: 0.76 seconds\n",
            "Batch 433/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 433/480, Loss: 0.0160, Time: 0.76 seconds\n",
            "Batch 434/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 434/480, Loss: 0.1954, Time: 0.76 seconds\n",
            "Batch 435/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 435/480, Loss: 0.1844, Time: 0.76 seconds\n",
            "Batch 436/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 436/480, Loss: 0.0924, Time: 0.75 seconds\n",
            "Batch 437/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 437/480, Loss: 0.0918, Time: 0.76 seconds\n",
            "Batch 438/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 438/480, Loss: 0.1886, Time: 0.77 seconds\n",
            "Batch 439/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 439/480, Loss: 0.3221, Time: 0.76 seconds\n",
            "Batch 440/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 440/480, Loss: 0.3062, Time: 0.76 seconds\n",
            "Batch 441/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 441/480, Loss: 0.0660, Time: 0.76 seconds\n",
            "Batch 442/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 442/480, Loss: 0.3174, Time: 0.76 seconds\n",
            "Batch 443/480, Label Counts: {0: 3, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 443/480, Loss: 0.8537, Time: 0.77 seconds\n",
            "Batch 444/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 444/480, Loss: 0.3801, Time: 0.77 seconds\n",
            "Batch 445/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 445/480, Loss: 0.2860, Time: 0.75 seconds\n",
            "Batch 446/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 446/480, Loss: 0.0155, Time: 0.75 seconds\n",
            "Batch 447/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 447/480, Loss: 0.3089, Time: 0.76 seconds\n",
            "Batch 448/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 448/480, Loss: 0.3732, Time: 0.77 seconds\n",
            "Batch 449/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 449/480, Loss: 0.2693, Time: 0.75 seconds\n",
            "Batch 450/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 450/480, Loss: 0.3623, Time: 0.76 seconds\n",
            "Batch 451/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 451/480, Loss: 0.3870, Time: 0.76 seconds\n",
            "Batch 452/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 452/480, Loss: 0.2224, Time: 0.75 seconds\n",
            "Batch 453/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 453/480, Loss: 0.3337, Time: 0.76 seconds\n",
            "Batch 454/480, Label Counts: {0: 5, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 454/480, Loss: 0.3510, Time: 0.76 seconds\n",
            "Batch 455/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 455/480, Loss: 0.1192, Time: 0.76 seconds\n",
            "Batch 456/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 456/480, Loss: 0.3912, Time: 0.76 seconds\n",
            "Batch 457/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 457/480, Loss: 0.3393, Time: 0.77 seconds\n",
            "Batch 458/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 458/480, Loss: 0.3995, Time: 0.76 seconds\n",
            "Batch 459/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 459/480, Loss: 0.4081, Time: 0.76 seconds\n",
            "Batch 460/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 460/480, Loss: 0.4260, Time: 0.77 seconds\n",
            "Batch 461/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 461/480, Loss: 0.6112, Time: 0.76 seconds\n",
            "Batch 462/480, Label Counts: {0: 7, 2: 1}\n",
            "Epoch 3/3, Batch 462/480, Loss: 0.0897, Time: 0.76 seconds\n",
            "Batch 463/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 463/480, Loss: 0.2826, Time: 0.76 seconds\n",
            "Batch 464/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 464/480, Loss: 0.2862, Time: 0.77 seconds\n",
            "Batch 465/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 465/480, Loss: 0.1165, Time: 0.75 seconds\n",
            "Batch 466/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 466/480, Loss: 0.1681, Time: 0.77 seconds\n",
            "Batch 467/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 467/480, Loss: 0.1184, Time: 0.76 seconds\n",
            "Batch 468/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 468/480, Loss: 0.0550, Time: 0.75 seconds\n",
            "Batch 469/480, Label Counts: {0: 4, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 469/480, Loss: 0.6515, Time: 0.76 seconds\n",
            "Batch 470/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 470/480, Loss: 0.0995, Time: 0.75 seconds\n",
            "Batch 471/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 471/480, Loss: 0.0483, Time: 0.76 seconds\n",
            "Batch 472/480, Label Counts: {0: 8}\n",
            "Epoch 3/3, Batch 472/480, Loss: 0.3256, Time: 0.76 seconds\n",
            "Batch 473/480, Label Counts: {0: 5, 2: 3}\n",
            "Epoch 3/3, Batch 473/480, Loss: 0.7311, Time: 0.76 seconds\n",
            "Batch 474/480, Label Counts: {0: 6, 1: 2}\n",
            "Epoch 3/3, Batch 474/480, Loss: 0.0903, Time: 0.75 seconds\n",
            "Batch 475/480, Label Counts: {0: 6, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 475/480, Loss: 0.1423, Time: 0.76 seconds\n",
            "Batch 476/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 476/480, Loss: 0.1017, Time: 0.75 seconds\n",
            "Batch 477/480, Label Counts: {0: 4, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 477/480, Loss: 1.3697, Time: 0.76 seconds\n",
            "Batch 478/480, Label Counts: {0: 6, 2: 2}\n",
            "Epoch 3/3, Batch 478/480, Loss: 0.4050, Time: 0.77 seconds\n",
            "Batch 479/480, Label Counts: {0: 5, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 479/480, Loss: 0.3291, Time: 0.77 seconds\n",
            "Batch 480/480, Label Counts: {0: 7, 1: 1}\n",
            "Epoch 3/3, Batch 480/480, Loss: 0.3694, Time: 0.76 seconds\n",
            "Epoch 3/3, Training Loss: 0.3283, Time: 366.51 seconds\n",
            "Validation Loss: 0.3715, Accuracy: 0.8510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/semi_supervised_new/semi_new_1\")"
      ],
      "metadata": {
        "id": "7ecoTQUgBCN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation**"
      ],
      "metadata": {
        "id": "4rlVgTfTFdP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = pd.read_csv('evaluation.csv')\n",
        "del eval['Unnamed: 0']\n",
        "del eval['labels']\n",
        "eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_TyWTJQGBPSV",
        "outputId": "9541b247-360b-46b5-b9b5-3dd0610c2d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "1       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "2       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "3       metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "4       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "..                                                 ...                   ...\n",
              "127     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "128     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "129     metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "130     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "131     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "\n",
              "[132 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06a32370-35e7-4fef-9925-45edb0f6d765\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06a32370-35e7-4fef-9925-45edb0f6d765')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06a32370-35e7-4fef-9925-45edb0f6d765 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06a32370-35e7-4fef-9925-45edb0f6d765');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86fbe0e0-13f7-4eb2-a0aa-1eee70e96ff9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86fbe0e0-13f7-4eb2-a0aa-1eee70e96ff9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86fbe0e0-13f7-4eb2-a0aa-1eee70e96ff9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7f05f747-30b2-40d0-a9cc-749fccecb570\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7f05f747-30b2-40d0-a9cc-749fccecb570 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "\n",
        "# Set the 'labels' column based on the mapping\n",
        "eval['labels'] = eval['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BwojrHCxHFdy",
        "outputId": "0d24046f-92ed-494a-d938-8c51a104878f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "..                                                 ...                   ...   \n",
              "127     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "128     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "129     metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "130     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "131     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         2  \n",
              "4         1  \n",
              "..      ...  \n",
              "127       0  \n",
              "128       0  \n",
              "129       2  \n",
              "130       0  \n",
              "131       0  \n",
              "\n",
              "[132 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27efd3b0-f96c-4552-b3be-a97d224b0e94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27efd3b0-f96c-4552-b3be-a97d224b0e94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27efd3b0-f96c-4552-b3be-a97d224b0e94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27efd3b0-f96c-4552-b3be-a97d224b0e94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-684be050-e408-438c-b2c5-9f5076317474\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-684be050-e408-438c-b2c5-9f5076317474')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-684be050-e408-438c-b2c5-9f5076317474 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f4f08d5f-7228-41d2-9878-532e38643491\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f4f08d5f-7228-41d2-9878-532e38643491 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_dataset = CustomDataset(texts=list(eval['LogContent']), labels=eval['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader for eval dataset\n",
        "evaluation_dataloader = DataLoader(evaluation_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "uxbxpwdyFc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "c90c703d-dec1-4a0a-d3c0-9da73c0b80f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "CustomDataset.__init__() missing 1 required positional argument: 'related_ids'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-e868b38067e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogContent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create DataLoader for eval dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluation_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: CustomDataset.__init__() missing 1 required positional argument: 'related_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_model.eval()\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in evaluation_dataloader:\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # outputs = loaded_model(input_ids, attention_mask=attention_mask)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))\n"
      ],
      "metadata": {
        "id": "NrKTGnahGRF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0bycia8GjbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking"
      ],
      "metadata": {
        "id": "cy_65BqqxIHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text_with_overlap(text, tokenizer, chunk_size=512, overlap_percentage=30):\n",
        "    # Tokenize the input text\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "    # Exclude [CLS] and [SEP] tokens\n",
        "    tokens = [token for token in tokens if token not in ['[CLS]', '[SEP]']]\n",
        "\n",
        "    # Calculate the overlap in tokens\n",
        "    overlap_tokens = int(chunk_size * overlap_percentage / 100)\n",
        "\n",
        "    # Chunk the tokens with overlap\n",
        "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size - overlap_tokens)]\n",
        "\n",
        "    # Convert token chunks back to text chunks\n",
        "    text_chunks = [tokenizer.decode(tokenizer.convert_tokens_to_ids(chunk)) for chunk in chunks]\n",
        "\n",
        "    return text_chunks"
      ],
      "metadata": {
        "id": "ZCGk47mdxLhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_text = \"Hello it's a large text for example\"\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Chunking based on tokens with 20% overlap\n",
        "chunks = chunk_text_with_overlap(large_text, tokenizer, chunk_size=2, overlap_percentage=50)\n",
        "\n",
        "# Print tokenized chunks\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"Chunk {i}:\", chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCNdtc1bxpRi",
        "outputId": "aa7069cb-b111-4e4c-b61b-d8ea4e3a0f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: hello it\n",
            "Chunk 2: it '\n",
            "Chunk 3: ' s\n",
            "Chunk 4: s a\n",
            "Chunk 5: a large\n",
            "Chunk 6: large text\n",
            "Chunk 7: text for\n",
            "Chunk 8: for example\n",
            "Chunk 9: example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new chunking\n",
        "# df_1 = pd.read_csv('dataset.csv')\n",
        "# df_2 = pd.read_csv('largerLogs.csv')\n",
        "# data_process = pd.concat([df_1, df_2], ignore_index=True)\n",
        "\n",
        "data_process = pd.read_csv('dataset.csv')\n",
        "del data_process['Unnamed: 0']\n",
        "data_process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IrHfhnMKxrdj",
        "outputId": "83ee7884-c811-42e7-e039-0b672247495a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "1       metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "2       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "3       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "..                                                 ...                   ...\n",
              "601     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "602     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "603     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "604     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "605     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "\n",
              "[606 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50f448df-4493-4621-a502-2f5d254a51a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>606 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50f448df-4493-4621-a502-2f5d254a51a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50f448df-4493-4621-a502-2f5d254a51a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50f448df-4493-4621-a502-2f5d254a51a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e8bc140-979d-4a75-bb43-d6e54ad52f45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e8bc140-979d-4a75-bb43-d6e54ad52f45')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e8bc140-979d-4a75-bb43-d6e54ad52f45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d2509541-5692-4cac-a2e6-e0a2a42c30ab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_process')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d2509541-5692-4cac-a2e6-e0a2a42c30ab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_process');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "data_process['TextChunks'] = data_process['LogContent'].apply(lambda x: chunk_text_with_overlap(x, tokenizer, chunk_size=508, overlap_percentage=30))"
      ],
      "metadata": {
        "id": "kxNoqsHNyjsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781e5f08-2c7a-4bfa-ecd5-aadd0437c6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs = pd.DataFrame(columns=['LogContent', 'RootCause'])\n",
        "tmp = []\n",
        "for index, row in data_process.iterrows():\n",
        "    root_cause = row['RootCause']\n",
        "    log_chunks = row['TextChunks']\n",
        "\n",
        "    # Create a DataFrame for the current row\n",
        "    df = pd.DataFrame({'LogContent': log_chunks, 'RootCause': [root_cause] * len(log_chunks)})\n",
        "\n",
        "    # Append to the list\n",
        "    tmp.append(df)\n",
        "\n",
        "# Concatenate the list of DataFrames into a single DataFrame\n",
        "chunked_logs = pd.concat(tmp, ignore_index=True)\n",
        "\n",
        "# Reorder the columns\n",
        "chunked_logs = chunked_logs[['LogContent', 'RootCause']]"
      ],
      "metadata": {
        "id": "Pzn_zMIWzPks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply tokenizer.convert_ids_to_tokens and calculate the length of tokens\n",
        "chunked_logs['token_numbers'] = chunked_logs['LogContent'].apply(lambda x: len(tokenizer.convert_ids_to_tokens(tokenizer.encode(x))))"
      ],
      "metadata": {
        "id": "x5GdorJbzXp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "G4-Hy2-l0Zx7",
        "outputId": "16a0a688-d528-4838-b56f-3ebe1ed0c1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  \\\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown   \n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown   \n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown   \n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown   \n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown   \n",
              "...                                                 ...          ...   \n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown   \n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown   \n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown   \n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown   \n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown   \n",
              "\n",
              "      token_numbers  \n",
              "0               510  \n",
              "1               510  \n",
              "2               512  \n",
              "3               510  \n",
              "4               421  \n",
              "...             ...  \n",
              "4369            510  \n",
              "4370            510  \n",
              "4371            512  \n",
              "4372            512  \n",
              "4373            232  \n",
              "\n",
              "[4374 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21d40c68-152e-4987-8b01-37aec8fefaa6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>token_numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21d40c68-152e-4987-8b01-37aec8fefaa6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21d40c68-152e-4987-8b01-37aec8fefaa6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21d40c68-152e-4987-8b01-37aec8fefaa6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b09468ff-7309-4565-b48f-9017f9da54f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b09468ff-7309-4565-b48f-9017f9da54f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b09468ff-7309-4565-b48f-9017f9da54f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c0f80cef-4d73-4829-abc6-1a6c354ff756\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('chunked_logs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c0f80cef-4d73-4829-abc6-1a6c354ff756 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('chunked_logs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunked_logs[chunked_logs['token_numbers']<100].count()\n",
        "chunked_logs['token_numbers'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM8tOMIx0VUX",
        "outputId": "778c025e-23f9-4ca7-b2c9-0982ff937be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "513"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del chunked_logs['token_numbers']\n",
        "chunked_logs.to_csv('chunked_new.csv')"
      ],
      "metadata": {
        "id": "ayzeum4R1clN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **training**"
      ],
      "metadata": {
        "id": "Qgo0vLQo1Ttl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs = pd.read_csv('chunked_new.csv')\n",
        "del chunked_logs['Unnamed: 0']\n",
        "chunked_logs"
      ],
      "metadata": {
        "id": "bm6sAI2i2w-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "01d5c575-e9fc-46f0-a05d-8574d743e150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown\n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown\n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown\n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown\n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown\n",
              "...                                                 ...          ...\n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown\n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown\n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown\n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown\n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown\n",
              "\n",
              "[4374 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37009656-21ed-47e7-98a2-6cc6af2e0bcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37009656-21ed-47e7-98a2-6cc6af2e0bcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37009656-21ed-47e7-98a2-6cc6af2e0bcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37009656-21ed-47e7-98a2-6cc6af2e0bcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-832c2642-cb08-422f-a56b-c6fe7b758385\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-832c2642-cb08-422f-a56b-c6fe7b758385')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-832c2642-cb08-422f-a56b-c6fe7b758385 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS= 3\n",
        "\n",
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "\n",
        "# Set the 'labels' column based on the mapping\n",
        "chunked_logs['labels'] = chunked_logs['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jvz755bb1b4a",
        "outputId": "0b638370-fc82-4069-c387-4e6c457b1b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  labels\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown       0\n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown       0\n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown       0\n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown       0\n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown       0\n",
              "...                                                 ...          ...     ...\n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown       0\n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown       0\n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown       0\n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown       0\n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown       0\n",
              "\n",
              "[4374 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ef9d17a-fda1-4a44-9a5f-f11f9fff3ffd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ef9d17a-fda1-4a44-9a5f-f11f9fff3ffd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ef9d17a-fda1-4a44-9a5f-f11f9fff3ffd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ef9d17a-fda1-4a44-9a5f-f11f9fff3ffd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8eb7ca91-60f4-4a77-81cf-f30b2f9b5d70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8eb7ca91-60f4-4a77-81cf-f30b2f9b5d70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8eb7ca91-60f4-4a77-81cf-f30b2f9b5d70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VanYrkZM2B1G",
        "outputId": "a513de7e-3afd-44d3-f409-d693fe5c7cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2975\n",
              "1     755\n",
              "2     644\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "5vPlYLtQ2H50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation datasets (80-20 split)\n",
        "train, val = train_test_split(chunked_logs, test_size=0.2, random_state=45, shuffle=True)\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nEucLyQJ0a93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDataset(texts=list(train['LogContent']), labels=train['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDataset(texts=list(val['LogContent']), labels=val['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "LJpmwMAD22N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV9fp-JI3z_V",
        "outputId": "bc47027c-8e3a-4c70-a7ab-35fd045fb925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Training loop without early stopping\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6872dW4V26Jj",
        "outputId": "95682447-c40c-4427-dd9f-68f5ce2d5d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-ef9e455f6b36>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 1/219, Loss: 1.2964, Time: 1.56 seconds\n",
            "Batch 2/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 2/219, Loss: 0.9985, Time: 1.53 seconds\n",
            "Batch 3/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 1/3, Batch 3/219, Loss: 0.9229, Time: 1.53 seconds\n",
            "Batch 4/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 4/219, Loss: 0.7902, Time: 1.55 seconds\n",
            "Batch 5/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 5/219, Loss: 0.9526, Time: 1.57 seconds\n",
            "Batch 6/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 6/219, Loss: 0.8320, Time: 1.58 seconds\n",
            "Batch 7/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 7/219, Loss: 0.6708, Time: 1.58 seconds\n",
            "Batch 8/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 8/219, Loss: 0.5837, Time: 1.57 seconds\n",
            "Batch 9/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 9/219, Loss: 0.9917, Time: 1.61 seconds\n",
            "Batch 10/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 10/219, Loss: 0.7410, Time: 1.62 seconds\n",
            "Batch 11/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 11/219, Loss: 0.9475, Time: 1.62 seconds\n",
            "Batch 12/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 12/219, Loss: 0.8406, Time: 1.63 seconds\n",
            "Batch 13/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 13/219, Loss: 1.0892, Time: 1.61 seconds\n",
            "Batch 14/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 14/219, Loss: 0.9248, Time: 1.66 seconds\n",
            "Batch 15/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 15/219, Loss: 1.0287, Time: 1.65 seconds\n",
            "Batch 16/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 16/219, Loss: 0.8815, Time: 1.64 seconds\n",
            "Batch 17/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 17/219, Loss: 0.8479, Time: 1.70 seconds\n",
            "Batch 18/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 18/219, Loss: 0.6676, Time: 1.69 seconds\n",
            "Batch 19/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 19/219, Loss: 0.7738, Time: 1.69 seconds\n",
            "Batch 20/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 20/219, Loss: 0.8571, Time: 1.64 seconds\n",
            "Batch 21/219, Label Counts: {0: 7, 1: 8, 2: 1}\n",
            "Epoch 1/3, Batch 21/219, Loss: 1.3355, Time: 1.71 seconds\n",
            "Batch 22/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 22/219, Loss: 0.9143, Time: 1.64 seconds\n",
            "Batch 23/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 23/219, Loss: 0.6098, Time: 1.71 seconds\n",
            "Batch 24/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 24/219, Loss: 1.0221, Time: 1.67 seconds\n",
            "Batch 25/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 25/219, Loss: 0.8191, Time: 1.66 seconds\n",
            "Batch 26/219, Label Counts: {0: 15, 2: 1}\n",
            "Epoch 1/3, Batch 26/219, Loss: 0.4993, Time: 1.63 seconds\n",
            "Batch 27/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 1/3, Batch 27/219, Loss: 0.5938, Time: 1.61 seconds\n",
            "Batch 28/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 28/219, Loss: 0.8034, Time: 1.62 seconds\n",
            "Batch 29/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 29/219, Loss: 0.8232, Time: 1.64 seconds\n",
            "Batch 30/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 30/219, Loss: 0.8313, Time: 1.63 seconds\n",
            "Batch 31/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 31/219, Loss: 0.6538, Time: 1.61 seconds\n",
            "Batch 32/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 32/219, Loss: 0.9811, Time: 1.59 seconds\n",
            "Batch 33/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 33/219, Loss: 0.7227, Time: 1.60 seconds\n",
            "Batch 34/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 34/219, Loss: 0.7374, Time: 1.59 seconds\n",
            "Batch 35/219, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 1/3, Batch 35/219, Loss: 0.7836, Time: 1.59 seconds\n",
            "Batch 36/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 36/219, Loss: 0.8542, Time: 1.60 seconds\n",
            "Batch 37/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 37/219, Loss: 1.1316, Time: 1.60 seconds\n",
            "Batch 38/219, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 38/219, Loss: 1.3557, Time: 1.59 seconds\n",
            "Batch 39/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 39/219, Loss: 1.0032, Time: 1.57 seconds\n",
            "Batch 40/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 40/219, Loss: 0.6392, Time: 1.58 seconds\n",
            "Batch 41/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 41/219, Loss: 1.0102, Time: 1.57 seconds\n",
            "Batch 42/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 42/219, Loss: 0.6517, Time: 1.58 seconds\n",
            "Batch 43/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 43/219, Loss: 0.7360, Time: 1.55 seconds\n",
            "Batch 44/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 44/219, Loss: 0.7926, Time: 1.56 seconds\n",
            "Batch 45/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 45/219, Loss: 0.6466, Time: 1.58 seconds\n",
            "Batch 46/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 46/219, Loss: 0.9379, Time: 1.58 seconds\n",
            "Batch 47/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 47/219, Loss: 0.7955, Time: 1.58 seconds\n",
            "Batch 48/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 1/3, Batch 48/219, Loss: 0.4308, Time: 1.57 seconds\n",
            "Batch 49/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 49/219, Loss: 0.9320, Time: 1.57 seconds\n",
            "Batch 50/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 50/219, Loss: 0.6933, Time: 1.57 seconds\n",
            "Batch 51/219, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 51/219, Loss: 1.4021, Time: 1.58 seconds\n",
            "Batch 52/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 52/219, Loss: 0.9135, Time: 1.57 seconds\n",
            "Batch 53/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 53/219, Loss: 1.2377, Time: 1.57 seconds\n",
            "Batch 54/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 1/3, Batch 54/219, Loss: 0.7225, Time: 1.58 seconds\n",
            "Batch 55/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 55/219, Loss: 0.8802, Time: 1.58 seconds\n",
            "Batch 56/219, Label Counts: {0: 10, 1: 6}\n",
            "Epoch 1/3, Batch 56/219, Loss: 0.7243, Time: 1.60 seconds\n",
            "Batch 57/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 57/219, Loss: 0.9073, Time: 1.59 seconds\n",
            "Batch 58/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 58/219, Loss: 0.9167, Time: 1.59 seconds\n",
            "Batch 59/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 1/3, Batch 59/219, Loss: 1.0865, Time: 1.60 seconds\n",
            "Batch 60/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 60/219, Loss: 0.7768, Time: 1.59 seconds\n",
            "Batch 61/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 61/219, Loss: 0.8582, Time: 1.60 seconds\n",
            "Batch 62/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 62/219, Loss: 0.7715, Time: 1.60 seconds\n",
            "Batch 63/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 63/219, Loss: 0.6639, Time: 1.60 seconds\n",
            "Batch 64/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 64/219, Loss: 1.0066, Time: 1.60 seconds\n",
            "Batch 65/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 65/219, Loss: 0.5361, Time: 1.60 seconds\n",
            "Batch 66/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 1/3, Batch 66/219, Loss: 0.8070, Time: 1.60 seconds\n",
            "Batch 67/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 67/219, Loss: 0.5143, Time: 1.63 seconds\n",
            "Batch 68/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 68/219, Loss: 1.1066, Time: 1.62 seconds\n",
            "Batch 69/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 69/219, Loss: 0.8175, Time: 1.63 seconds\n",
            "Batch 70/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 1/3, Batch 70/219, Loss: 0.4164, Time: 1.62 seconds\n",
            "Batch 71/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 71/219, Loss: 0.8651, Time: 1.65 seconds\n",
            "Batch 72/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 72/219, Loss: 0.5805, Time: 1.64 seconds\n",
            "Batch 73/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 73/219, Loss: 0.6182, Time: 1.62 seconds\n",
            "Batch 74/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 1/3, Batch 74/219, Loss: 0.4983, Time: 1.66 seconds\n",
            "Batch 75/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 75/219, Loss: 1.0209, Time: 1.62 seconds\n",
            "Batch 76/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 76/219, Loss: 1.0184, Time: 1.61 seconds\n",
            "Batch 77/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 77/219, Loss: 0.5752, Time: 1.62 seconds\n",
            "Batch 78/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 78/219, Loss: 0.6003, Time: 1.63 seconds\n",
            "Batch 79/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 79/219, Loss: 0.7427, Time: 1.60 seconds\n",
            "Batch 80/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 80/219, Loss: 1.1321, Time: 1.63 seconds\n",
            "Batch 81/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 81/219, Loss: 0.6224, Time: 1.62 seconds\n",
            "Batch 82/219, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 1/3, Batch 82/219, Loss: 0.8709, Time: 1.60 seconds\n",
            "Batch 83/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 83/219, Loss: 0.6707, Time: 1.61 seconds\n",
            "Batch 84/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 84/219, Loss: 0.8551, Time: 1.60 seconds\n",
            "Batch 85/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 1/3, Batch 85/219, Loss: 0.5679, Time: 1.62 seconds\n",
            "Batch 86/219, Label Counts: {0: 15, 2: 1}\n",
            "Epoch 1/3, Batch 86/219, Loss: 0.4493, Time: 1.59 seconds\n",
            "Batch 87/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 87/219, Loss: 0.6706, Time: 1.59 seconds\n",
            "Batch 88/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 88/219, Loss: 0.9122, Time: 1.60 seconds\n",
            "Batch 89/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 89/219, Loss: 0.6163, Time: 1.57 seconds\n",
            "Batch 90/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 90/219, Loss: 0.7433, Time: 1.60 seconds\n",
            "Batch 91/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 91/219, Loss: 1.0997, Time: 1.60 seconds\n",
            "Batch 92/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 92/219, Loss: 0.8246, Time: 1.59 seconds\n",
            "Batch 93/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 1/3, Batch 93/219, Loss: 0.6178, Time: 1.57 seconds\n",
            "Batch 94/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 1/3, Batch 94/219, Loss: 0.6819, Time: 1.58 seconds\n",
            "Batch 95/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 95/219, Loss: 0.9559, Time: 1.60 seconds\n",
            "Batch 96/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 96/219, Loss: 0.7974, Time: 1.59 seconds\n",
            "Batch 97/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 97/219, Loss: 1.1124, Time: 1.59 seconds\n",
            "Batch 98/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 98/219, Loss: 0.8092, Time: 1.58 seconds\n",
            "Batch 99/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 99/219, Loss: 0.6025, Time: 1.58 seconds\n",
            "Batch 100/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 100/219, Loss: 0.6804, Time: 1.56 seconds\n",
            "Batch 101/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 101/219, Loss: 0.7966, Time: 1.59 seconds\n",
            "Batch 102/219, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 102/219, Loss: 0.9977, Time: 1.59 seconds\n",
            "Batch 103/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 103/219, Loss: 0.6785, Time: 1.60 seconds\n",
            "Batch 104/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 1/3, Batch 104/219, Loss: 0.6593, Time: 1.59 seconds\n",
            "Batch 105/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 105/219, Loss: 0.9812, Time: 1.59 seconds\n",
            "Batch 106/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 1/3, Batch 106/219, Loss: 0.6704, Time: 1.59 seconds\n",
            "Batch 107/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 107/219, Loss: 1.0432, Time: 1.59 seconds\n",
            "Batch 108/219, Label Counts: {0: 12, 2: 4}\n",
            "Epoch 1/3, Batch 108/219, Loss: 0.7565, Time: 1.60 seconds\n",
            "Batch 109/219, Label Counts: {0: 9, 2: 7}\n",
            "Epoch 1/3, Batch 109/219, Loss: 1.0662, Time: 1.59 seconds\n",
            "Batch 110/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 1/3, Batch 110/219, Loss: 0.5443, Time: 1.61 seconds\n",
            "Batch 111/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 111/219, Loss: 0.7648, Time: 1.61 seconds\n",
            "Batch 112/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 112/219, Loss: 0.9003, Time: 1.59 seconds\n",
            "Batch 113/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 113/219, Loss: 0.6295, Time: 1.60 seconds\n",
            "Batch 114/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 114/219, Loss: 0.4731, Time: 1.60 seconds\n",
            "Batch 115/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 115/219, Loss: 0.5070, Time: 1.59 seconds\n",
            "Batch 116/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 116/219, Loss: 1.0687, Time: 1.62 seconds\n",
            "Batch 117/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 117/219, Loss: 0.8752, Time: 1.59 seconds\n",
            "Batch 118/219, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 118/219, Loss: 1.2110, Time: 1.60 seconds\n",
            "Batch 119/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 119/219, Loss: 1.0483, Time: 1.59 seconds\n",
            "Batch 120/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 120/219, Loss: 1.0085, Time: 1.62 seconds\n",
            "Batch 121/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 121/219, Loss: 0.7334, Time: 1.62 seconds\n",
            "Batch 122/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 122/219, Loss: 0.8580, Time: 1.61 seconds\n",
            "Batch 123/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 123/219, Loss: 0.9320, Time: 1.61 seconds\n",
            "Batch 124/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 1/3, Batch 124/219, Loss: 0.6493, Time: 1.62 seconds\n",
            "Batch 125/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 125/219, Loss: 0.8652, Time: 1.62 seconds\n",
            "Batch 126/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 126/219, Loss: 0.8414, Time: 1.61 seconds\n",
            "Batch 127/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 127/219, Loss: 0.9040, Time: 1.60 seconds\n",
            "Batch 128/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 128/219, Loss: 0.8513, Time: 1.63 seconds\n",
            "Batch 129/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 129/219, Loss: 0.8529, Time: 1.60 seconds\n",
            "Batch 130/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 130/219, Loss: 0.8210, Time: 1.60 seconds\n",
            "Batch 131/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 1/3, Batch 131/219, Loss: 0.7266, Time: 1.61 seconds\n",
            "Batch 132/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 132/219, Loss: 0.9344, Time: 1.59 seconds\n",
            "Batch 133/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 133/219, Loss: 1.0362, Time: 1.60 seconds\n",
            "Batch 134/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 134/219, Loss: 0.7518, Time: 1.60 seconds\n",
            "Batch 135/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 135/219, Loss: 0.7674, Time: 1.59 seconds\n",
            "Batch 136/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 136/219, Loss: 0.7439, Time: 1.61 seconds\n",
            "Batch 137/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 137/219, Loss: 0.7968, Time: 1.60 seconds\n",
            "Batch 138/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 138/219, Loss: 0.8198, Time: 1.62 seconds\n",
            "Batch 139/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 139/219, Loss: 1.0562, Time: 1.60 seconds\n",
            "Batch 140/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 140/219, Loss: 0.7950, Time: 1.59 seconds\n",
            "Batch 141/219, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 141/219, Loss: 1.2490, Time: 1.60 seconds\n",
            "Batch 142/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 142/219, Loss: 0.8228, Time: 1.60 seconds\n",
            "Batch 143/219, Label Counts: {0: 10, 1: 6}\n",
            "Epoch 1/3, Batch 143/219, Loss: 0.9166, Time: 1.60 seconds\n",
            "Batch 144/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 144/219, Loss: 0.9223, Time: 1.60 seconds\n",
            "Batch 145/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 145/219, Loss: 0.7644, Time: 1.59 seconds\n",
            "Batch 146/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 1/3, Batch 146/219, Loss: 0.9031, Time: 1.58 seconds\n",
            "Batch 147/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 147/219, Loss: 0.9614, Time: 1.60 seconds\n",
            "Batch 148/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 148/219, Loss: 0.9660, Time: 1.60 seconds\n",
            "Batch 149/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 149/219, Loss: 0.8089, Time: 1.59 seconds\n",
            "Batch 150/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 150/219, Loss: 0.8702, Time: 1.60 seconds\n",
            "Batch 151/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 1/3, Batch 151/219, Loss: 0.4840, Time: 1.59 seconds\n",
            "Batch 152/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 152/219, Loss: 0.7103, Time: 1.60 seconds\n",
            "Batch 153/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 1/3, Batch 153/219, Loss: 0.4012, Time: 1.59 seconds\n",
            "Batch 154/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 154/219, Loss: 1.1371, Time: 1.60 seconds\n",
            "Batch 155/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 1/3, Batch 155/219, Loss: 0.3669, Time: 1.60 seconds\n",
            "Batch 156/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 156/219, Loss: 0.8041, Time: 1.60 seconds\n",
            "Batch 157/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 1/3, Batch 157/219, Loss: 1.0976, Time: 1.59 seconds\n",
            "Batch 158/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 158/219, Loss: 0.8164, Time: 1.60 seconds\n",
            "Batch 159/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 159/219, Loss: 1.1079, Time: 1.59 seconds\n",
            "Batch 160/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 160/219, Loss: 0.7301, Time: 1.57 seconds\n",
            "Batch 161/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 161/219, Loss: 0.7770, Time: 1.60 seconds\n",
            "Batch 162/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 1/3, Batch 162/219, Loss: 0.7493, Time: 1.59 seconds\n",
            "Batch 163/219, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 163/219, Loss: 1.0946, Time: 1.60 seconds\n",
            "Batch 164/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 164/219, Loss: 0.7467, Time: 1.59 seconds\n",
            "Batch 165/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 165/219, Loss: 0.7898, Time: 1.58 seconds\n",
            "Batch 166/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 166/219, Loss: 0.8522, Time: 1.60 seconds\n",
            "Batch 167/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 167/219, Loss: 1.2399, Time: 1.59 seconds\n",
            "Batch 168/219, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 1/3, Batch 168/219, Loss: 1.1438, Time: 1.60 seconds\n",
            "Batch 169/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 169/219, Loss: 0.7971, Time: 1.59 seconds\n",
            "Batch 170/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 170/219, Loss: 0.7536, Time: 1.60 seconds\n",
            "Batch 171/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 171/219, Loss: 0.9408, Time: 1.60 seconds\n",
            "Batch 172/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 172/219, Loss: 0.8779, Time: 1.59 seconds\n",
            "Batch 173/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 173/219, Loss: 0.5443, Time: 1.60 seconds\n",
            "Batch 174/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 174/219, Loss: 1.0572, Time: 1.60 seconds\n",
            "Batch 175/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 175/219, Loss: 0.9342, Time: 1.60 seconds\n",
            "Batch 176/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 176/219, Loss: 0.9045, Time: 1.59 seconds\n",
            "Batch 177/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 177/219, Loss: 0.8467, Time: 1.59 seconds\n",
            "Batch 178/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 178/219, Loss: 1.0441, Time: 1.59 seconds\n",
            "Batch 179/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 179/219, Loss: 0.7728, Time: 1.59 seconds\n",
            "Batch 180/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 180/219, Loss: 0.5925, Time: 1.60 seconds\n",
            "Batch 181/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 181/219, Loss: 0.8389, Time: 1.60 seconds\n",
            "Batch 182/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 182/219, Loss: 0.9594, Time: 1.60 seconds\n",
            "Batch 183/219, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 1/3, Batch 183/219, Loss: 0.8686, Time: 1.60 seconds\n",
            "Batch 184/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 184/219, Loss: 0.8578, Time: 1.57 seconds\n",
            "Batch 185/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 1/3, Batch 185/219, Loss: 0.7633, Time: 1.60 seconds\n",
            "Batch 186/219, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 186/219, Loss: 1.1111, Time: 1.57 seconds\n",
            "Batch 187/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 187/219, Loss: 0.8295, Time: 1.58 seconds\n",
            "Batch 188/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 1/3, Batch 188/219, Loss: 0.8082, Time: 1.60 seconds\n",
            "Batch 189/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 189/219, Loss: 0.8053, Time: 1.60 seconds\n",
            "Batch 190/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 1/3, Batch 190/219, Loss: 0.6492, Time: 1.59 seconds\n",
            "Batch 191/219, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 1/3, Batch 191/219, Loss: 0.8584, Time: 1.60 seconds\n",
            "Batch 192/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 192/219, Loss: 0.9613, Time: 1.58 seconds\n",
            "Batch 193/219, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 1/3, Batch 193/219, Loss: 0.9630, Time: 1.60 seconds\n",
            "Batch 194/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 194/219, Loss: 0.9986, Time: 1.60 seconds\n",
            "Batch 195/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 1/3, Batch 195/219, Loss: 0.7790, Time: 1.60 seconds\n",
            "Batch 196/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 1/3, Batch 196/219, Loss: 0.6673, Time: 1.59 seconds\n",
            "Batch 197/219, Label Counts: {0: 10, 2: 6}\n",
            "Epoch 1/3, Batch 197/219, Loss: 0.9005, Time: 1.60 seconds\n",
            "Batch 198/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 198/219, Loss: 0.9385, Time: 1.57 seconds\n",
            "Batch 199/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 199/219, Loss: 0.7284, Time: 1.60 seconds\n",
            "Batch 200/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 1/3, Batch 200/219, Loss: 0.7243, Time: 1.59 seconds\n",
            "Batch 201/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 201/219, Loss: 1.0280, Time: 1.58 seconds\n",
            "Batch 202/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 202/219, Loss: 0.9629, Time: 1.60 seconds\n",
            "Batch 203/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 203/219, Loss: 0.8979, Time: 1.59 seconds\n",
            "Batch 204/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 204/219, Loss: 1.1483, Time: 1.58 seconds\n",
            "Batch 205/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 1/3, Batch 205/219, Loss: 0.7835, Time: 1.58 seconds\n",
            "Batch 206/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 206/219, Loss: 0.8693, Time: 1.55 seconds\n",
            "Batch 207/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 207/219, Loss: 1.0096, Time: 1.58 seconds\n",
            "Batch 208/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 208/219, Loss: 0.7504, Time: 1.58 seconds\n",
            "Batch 209/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 1/3, Batch 209/219, Loss: 0.8666, Time: 1.60 seconds\n",
            "Batch 210/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 210/219, Loss: 0.8625, Time: 1.59 seconds\n",
            "Batch 211/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 211/219, Loss: 0.9662, Time: 1.60 seconds\n",
            "Batch 212/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 1/3, Batch 212/219, Loss: 0.6565, Time: 1.59 seconds\n",
            "Batch 213/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 213/219, Loss: 0.9247, Time: 1.60 seconds\n",
            "Batch 214/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 214/219, Loss: 0.8593, Time: 1.59 seconds\n",
            "Batch 215/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 1/3, Batch 215/219, Loss: 1.0240, Time: 1.59 seconds\n",
            "Batch 216/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 1/3, Batch 216/219, Loss: 0.6091, Time: 1.59 seconds\n",
            "Batch 217/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 1/3, Batch 217/219, Loss: 0.7602, Time: 1.62 seconds\n",
            "Batch 218/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 1/3, Batch 218/219, Loss: 0.5814, Time: 1.59 seconds\n",
            "Batch 219/219, Label Counts: {0: 8, 2: 3}\n",
            "Epoch 1/3, Batch 219/219, Loss: 0.8507, Time: 1.13 seconds\n",
            "Epoch 1/3, Training Loss: 0.8374, Time: 350.44 seconds\n",
            "Validation Loss: 0.8185, Accuracy: 0.6891\n",
            "Batch 1/219, Label Counts: {0: 15, 2: 1}\n",
            "Epoch 2/3, Batch 1/219, Loss: 0.4301, Time: 1.56 seconds\n",
            "Batch 2/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 2/219, Loss: 1.0096, Time: 1.61 seconds\n",
            "Batch 3/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 3/219, Loss: 0.7459, Time: 1.59 seconds\n",
            "Batch 4/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 2/3, Batch 4/219, Loss: 1.0379, Time: 1.60 seconds\n",
            "Batch 5/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 5/219, Loss: 0.6506, Time: 1.60 seconds\n",
            "Batch 6/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 6/219, Loss: 0.6236, Time: 1.60 seconds\n",
            "Batch 7/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 7/219, Loss: 1.0167, Time: 1.60 seconds\n",
            "Batch 8/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 8/219, Loss: 0.9871, Time: 1.59 seconds\n",
            "Batch 9/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 9/219, Loss: 0.8993, Time: 1.59 seconds\n",
            "Batch 10/219, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 2/3, Batch 10/219, Loss: 1.0211, Time: 1.60 seconds\n",
            "Batch 11/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 11/219, Loss: 0.6790, Time: 1.60 seconds\n",
            "Batch 12/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 12/219, Loss: 0.8761, Time: 1.59 seconds\n",
            "Batch 13/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 2/3, Batch 13/219, Loss: 0.7565, Time: 1.60 seconds\n",
            "Batch 14/219, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 14/219, Loss: 1.1669, Time: 1.59 seconds\n",
            "Batch 15/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 15/219, Loss: 0.9351, Time: 1.57 seconds\n",
            "Batch 16/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 16/219, Loss: 0.6971, Time: 1.60 seconds\n",
            "Batch 17/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 17/219, Loss: 0.7833, Time: 1.59 seconds\n",
            "Batch 18/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 18/219, Loss: 0.8932, Time: 1.60 seconds\n",
            "Batch 19/219, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 19/219, Loss: 0.8487, Time: 1.60 seconds\n",
            "Batch 20/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 20/219, Loss: 0.6478, Time: 1.60 seconds\n",
            "Batch 21/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 21/219, Loss: 0.7518, Time: 1.60 seconds\n",
            "Batch 22/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 22/219, Loss: 0.6035, Time: 1.59 seconds\n",
            "Batch 23/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 23/219, Loss: 0.7338, Time: 1.60 seconds\n",
            "Batch 24/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 24/219, Loss: 0.8776, Time: 1.62 seconds\n",
            "Batch 25/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 25/219, Loss: 0.8295, Time: 1.60 seconds\n",
            "Batch 26/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 26/219, Loss: 1.1879, Time: 1.59 seconds\n",
            "Batch 27/219, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 27/219, Loss: 1.1833, Time: 1.59 seconds\n",
            "Batch 28/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 28/219, Loss: 0.7562, Time: 1.59 seconds\n",
            "Batch 29/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 29/219, Loss: 0.9167, Time: 1.60 seconds\n",
            "Batch 30/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 2/3, Batch 30/219, Loss: 0.7222, Time: 1.60 seconds\n",
            "Batch 31/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 31/219, Loss: 0.7475, Time: 1.60 seconds\n",
            "Batch 32/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 32/219, Loss: 0.7858, Time: 1.61 seconds\n",
            "Batch 33/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 33/219, Loss: 0.6285, Time: 1.60 seconds\n",
            "Batch 34/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 34/219, Loss: 0.8991, Time: 1.60 seconds\n",
            "Batch 35/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 2/3, Batch 35/219, Loss: 0.9727, Time: 1.59 seconds\n",
            "Batch 36/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 36/219, Loss: 0.8172, Time: 1.60 seconds\n",
            "Batch 37/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 37/219, Loss: 0.6664, Time: 1.59 seconds\n",
            "Batch 38/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 38/219, Loss: 0.8617, Time: 1.60 seconds\n",
            "Batch 39/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 39/219, Loss: 0.9039, Time: 1.60 seconds\n",
            "Batch 40/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 40/219, Loss: 0.6564, Time: 1.59 seconds\n",
            "Batch 41/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 41/219, Loss: 1.1015, Time: 1.60 seconds\n",
            "Batch 42/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 42/219, Loss: 0.8877, Time: 1.62 seconds\n",
            "Batch 43/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 43/219, Loss: 0.7958, Time: 1.59 seconds\n",
            "Batch 44/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 44/219, Loss: 0.7264, Time: 1.62 seconds\n",
            "Batch 45/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 2/3, Batch 45/219, Loss: 0.6720, Time: 1.62 seconds\n",
            "Batch 46/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 46/219, Loss: 0.5939, Time: 1.61 seconds\n",
            "Batch 47/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 47/219, Loss: 0.7482, Time: 1.59 seconds\n",
            "Batch 48/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 48/219, Loss: 0.8727, Time: 1.59 seconds\n",
            "Batch 49/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 49/219, Loss: 0.7163, Time: 1.60 seconds\n",
            "Batch 50/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 50/219, Loss: 0.6596, Time: 1.59 seconds\n",
            "Batch 51/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 51/219, Loss: 0.5558, Time: 1.60 seconds\n",
            "Batch 52/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 52/219, Loss: 0.5634, Time: 1.60 seconds\n",
            "Batch 53/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 53/219, Loss: 0.8621, Time: 1.60 seconds\n",
            "Batch 54/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 54/219, Loss: 0.8174, Time: 1.62 seconds\n",
            "Batch 55/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 55/219, Loss: 0.5664, Time: 1.60 seconds\n",
            "Batch 56/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 56/219, Loss: 0.7961, Time: 1.59 seconds\n",
            "Batch 57/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 57/219, Loss: 0.8922, Time: 1.60 seconds\n",
            "Batch 58/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 58/219, Loss: 0.8270, Time: 1.59 seconds\n",
            "Batch 59/219, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 59/219, Loss: 1.1221, Time: 1.60 seconds\n",
            "Batch 60/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 2/3, Batch 60/219, Loss: 0.5844, Time: 1.59 seconds\n",
            "Batch 61/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 61/219, Loss: 0.7273, Time: 1.60 seconds\n",
            "Batch 62/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 62/219, Loss: 0.7884, Time: 1.61 seconds\n",
            "Batch 63/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 2/3, Batch 63/219, Loss: 0.6395, Time: 1.60 seconds\n",
            "Batch 64/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 64/219, Loss: 0.7598, Time: 1.60 seconds\n",
            "Batch 65/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 65/219, Loss: 0.6865, Time: 1.62 seconds\n",
            "Batch 66/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 66/219, Loss: 0.6452, Time: 1.62 seconds\n",
            "Batch 67/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 67/219, Loss: 0.8377, Time: 1.59 seconds\n",
            "Batch 68/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 68/219, Loss: 0.8841, Time: 1.60 seconds\n",
            "Batch 69/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 2/3, Batch 69/219, Loss: 0.7933, Time: 1.59 seconds\n",
            "Batch 70/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 70/219, Loss: 0.6914, Time: 1.59 seconds\n",
            "Batch 71/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 2/3, Batch 71/219, Loss: 0.5331, Time: 1.60 seconds\n",
            "Batch 72/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 2/3, Batch 72/219, Loss: 0.9559, Time: 1.55 seconds\n",
            "Batch 73/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 73/219, Loss: 1.1805, Time: 1.60 seconds\n",
            "Batch 74/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 74/219, Loss: 0.8456, Time: 1.59 seconds\n",
            "Batch 75/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 2/3, Batch 75/219, Loss: 1.1607, Time: 1.60 seconds\n",
            "Batch 76/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 76/219, Loss: 0.5236, Time: 1.60 seconds\n",
            "Batch 77/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 2/3, Batch 77/219, Loss: 0.4324, Time: 1.60 seconds\n",
            "Batch 78/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 78/219, Loss: 0.5824, Time: 1.59 seconds\n",
            "Batch 79/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 79/219, Loss: 0.7109, Time: 1.60 seconds\n",
            "Batch 80/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 80/219, Loss: 0.9009, Time: 1.60 seconds\n",
            "Batch 81/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 81/219, Loss: 0.6426, Time: 1.59 seconds\n",
            "Batch 82/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 82/219, Loss: 0.7416, Time: 1.59 seconds\n",
            "Batch 83/219, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 2/3, Batch 83/219, Loss: 0.9815, Time: 1.60 seconds\n",
            "Batch 84/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 84/219, Loss: 0.6389, Time: 1.60 seconds\n",
            "Batch 85/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 85/219, Loss: 0.6849, Time: 1.60 seconds\n",
            "Batch 86/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 86/219, Loss: 0.6174, Time: 1.60 seconds\n",
            "Batch 87/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 2/3, Batch 87/219, Loss: 0.6197, Time: 1.59 seconds\n",
            "Batch 88/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 88/219, Loss: 0.7906, Time: 1.60 seconds\n",
            "Batch 89/219, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 89/219, Loss: 1.1066, Time: 1.61 seconds\n",
            "Batch 90/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 90/219, Loss: 0.8142, Time: 1.61 seconds\n",
            "Batch 91/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 91/219, Loss: 0.6151, Time: 1.59 seconds\n",
            "Batch 92/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 92/219, Loss: 0.3818, Time: 1.59 seconds\n",
            "Batch 93/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 93/219, Loss: 0.8904, Time: 1.62 seconds\n",
            "Batch 94/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 94/219, Loss: 1.0234, Time: 1.59 seconds\n",
            "Batch 95/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 95/219, Loss: 0.9703, Time: 1.60 seconds\n",
            "Batch 96/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 96/219, Loss: 0.8425, Time: 1.59 seconds\n",
            "Batch 97/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 2/3, Batch 97/219, Loss: 0.5824, Time: 1.60 seconds\n",
            "Batch 98/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 98/219, Loss: 1.0619, Time: 1.61 seconds\n",
            "Batch 99/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 99/219, Loss: 0.8028, Time: 1.60 seconds\n",
            "Batch 100/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 100/219, Loss: 0.7170, Time: 1.60 seconds\n",
            "Batch 101/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 101/219, Loss: 0.8901, Time: 1.60 seconds\n",
            "Batch 102/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 2/3, Batch 102/219, Loss: 0.7360, Time: 1.59 seconds\n",
            "Batch 103/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 103/219, Loss: 0.7297, Time: 1.60 seconds\n",
            "Batch 104/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 104/219, Loss: 0.8040, Time: 1.59 seconds\n",
            "Batch 105/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 105/219, Loss: 0.8827, Time: 1.60 seconds\n",
            "Batch 106/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 106/219, Loss: 0.6380, Time: 1.59 seconds\n",
            "Batch 107/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 107/219, Loss: 0.6880, Time: 1.59 seconds\n",
            "Batch 108/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 108/219, Loss: 0.8148, Time: 1.60 seconds\n",
            "Batch 109/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 109/219, Loss: 0.6452, Time: 1.60 seconds\n",
            "Batch 110/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 110/219, Loss: 0.6385, Time: 1.59 seconds\n",
            "Batch 111/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 2/3, Batch 111/219, Loss: 1.0356, Time: 1.60 seconds\n",
            "Batch 112/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 112/219, Loss: 0.5693, Time: 1.60 seconds\n",
            "Batch 113/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 113/219, Loss: 0.6011, Time: 1.60 seconds\n",
            "Batch 114/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 114/219, Loss: 0.8611, Time: 1.60 seconds\n",
            "Batch 115/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 115/219, Loss: 0.7822, Time: 1.59 seconds\n",
            "Batch 116/219, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 116/219, Loss: 1.0093, Time: 1.60 seconds\n",
            "Batch 117/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 117/219, Loss: 0.8282, Time: 1.59 seconds\n",
            "Batch 118/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 118/219, Loss: 0.8476, Time: 1.61 seconds\n",
            "Batch 119/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 119/219, Loss: 0.7392, Time: 1.60 seconds\n",
            "Batch 120/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 120/219, Loss: 0.6954, Time: 1.59 seconds\n",
            "Batch 121/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 121/219, Loss: 0.5881, Time: 1.59 seconds\n",
            "Batch 122/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 122/219, Loss: 0.5044, Time: 1.57 seconds\n",
            "Batch 123/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 123/219, Loss: 0.7578, Time: 1.60 seconds\n",
            "Batch 124/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 124/219, Loss: 0.7612, Time: 1.59 seconds\n",
            "Batch 125/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 125/219, Loss: 1.0137, Time: 1.60 seconds\n",
            "Batch 126/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 126/219, Loss: 0.8614, Time: 1.60 seconds\n",
            "Batch 127/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 127/219, Loss: 1.0324, Time: 1.60 seconds\n",
            "Batch 128/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 2/3, Batch 128/219, Loss: 0.5117, Time: 1.60 seconds\n",
            "Batch 129/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 129/219, Loss: 0.5608, Time: 1.60 seconds\n",
            "Batch 130/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 130/219, Loss: 0.8119, Time: 1.59 seconds\n",
            "Batch 131/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 131/219, Loss: 0.8290, Time: 1.59 seconds\n",
            "Batch 132/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 132/219, Loss: 0.8625, Time: 1.57 seconds\n",
            "Batch 133/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 133/219, Loss: 0.7635, Time: 1.58 seconds\n",
            "Batch 134/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 134/219, Loss: 0.8802, Time: 1.60 seconds\n",
            "Batch 135/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 135/219, Loss: 0.8255, Time: 1.59 seconds\n",
            "Batch 136/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 136/219, Loss: 0.6012, Time: 1.57 seconds\n",
            "Batch 137/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 2/3, Batch 137/219, Loss: 0.8422, Time: 1.59 seconds\n",
            "Batch 138/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 138/219, Loss: 0.6580, Time: 1.57 seconds\n",
            "Batch 139/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 139/219, Loss: 0.6439, Time: 1.60 seconds\n",
            "Batch 140/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 140/219, Loss: 0.6227, Time: 1.60 seconds\n",
            "Batch 141/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 141/219, Loss: 0.9375, Time: 1.59 seconds\n",
            "Batch 142/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 142/219, Loss: 0.7644, Time: 1.60 seconds\n",
            "Batch 143/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 143/219, Loss: 0.5750, Time: 1.57 seconds\n",
            "Batch 144/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 144/219, Loss: 0.7055, Time: 1.58 seconds\n",
            "Batch 145/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 145/219, Loss: 0.8422, Time: 1.60 seconds\n",
            "Batch 146/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 146/219, Loss: 0.8536, Time: 1.59 seconds\n",
            "Batch 147/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 2/3, Batch 147/219, Loss: 1.4381, Time: 1.58 seconds\n",
            "Batch 148/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 148/219, Loss: 0.7732, Time: 1.59 seconds\n",
            "Batch 149/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 149/219, Loss: 0.7239, Time: 1.60 seconds\n",
            "Batch 150/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 150/219, Loss: 0.5622, Time: 1.59 seconds\n",
            "Batch 151/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 151/219, Loss: 0.6463, Time: 1.60 seconds\n",
            "Batch 152/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 152/219, Loss: 0.6537, Time: 1.59 seconds\n",
            "Batch 153/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 2/3, Batch 153/219, Loss: 0.5605, Time: 1.60 seconds\n",
            "Batch 154/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 154/219, Loss: 1.0366, Time: 1.60 seconds\n",
            "Batch 155/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 155/219, Loss: 0.8946, Time: 1.57 seconds\n",
            "Batch 156/219, Label Counts: {0: 12, 2: 4}\n",
            "Epoch 2/3, Batch 156/219, Loss: 0.6045, Time: 1.58 seconds\n",
            "Batch 157/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 157/219, Loss: 0.7036, Time: 1.57 seconds\n",
            "Batch 158/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 158/219, Loss: 0.5063, Time: 1.61 seconds\n",
            "Batch 159/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 159/219, Loss: 0.7937, Time: 1.59 seconds\n",
            "Batch 160/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 2/3, Batch 160/219, Loss: 0.7065, Time: 1.60 seconds\n",
            "Batch 161/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 161/219, Loss: 0.5344, Time: 1.60 seconds\n",
            "Batch 162/219, Label Counts: {0: 15, 2: 1}\n",
            "Epoch 2/3, Batch 162/219, Loss: 0.6626, Time: 1.58 seconds\n",
            "Batch 163/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 163/219, Loss: 0.9066, Time: 1.60 seconds\n",
            "Batch 164/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 164/219, Loss: 0.6617, Time: 1.60 seconds\n",
            "Batch 165/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 165/219, Loss: 0.6808, Time: 1.57 seconds\n",
            "Batch 166/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 166/219, Loss: 0.8349, Time: 1.58 seconds\n",
            "Batch 167/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 167/219, Loss: 0.8009, Time: 1.60 seconds\n",
            "Batch 168/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 168/219, Loss: 0.6747, Time: 1.59 seconds\n",
            "Batch 169/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 169/219, Loss: 0.5490, Time: 1.60 seconds\n",
            "Batch 170/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 170/219, Loss: 0.8430, Time: 1.59 seconds\n",
            "Batch 171/219, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 2/3, Batch 171/219, Loss: 0.6639, Time: 1.58 seconds\n",
            "Batch 172/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 172/219, Loss: 0.8600, Time: 1.59 seconds\n",
            "Batch 173/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 173/219, Loss: 0.6837, Time: 1.58 seconds\n",
            "Batch 174/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 2/3, Batch 174/219, Loss: 0.4860, Time: 1.60 seconds\n",
            "Batch 175/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 175/219, Loss: 0.9035, Time: 1.59 seconds\n",
            "Batch 176/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 176/219, Loss: 0.7725, Time: 1.59 seconds\n",
            "Batch 177/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 177/219, Loss: 0.7304, Time: 1.59 seconds\n",
            "Batch 178/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 178/219, Loss: 0.7427, Time: 1.57 seconds\n",
            "Batch 179/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 179/219, Loss: 0.8890, Time: 1.60 seconds\n",
            "Batch 180/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 180/219, Loss: 0.7793, Time: 1.60 seconds\n",
            "Batch 181/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 181/219, Loss: 0.5978, Time: 1.59 seconds\n",
            "Batch 182/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 2/3, Batch 182/219, Loss: 0.6813, Time: 1.57 seconds\n",
            "Batch 183/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 183/219, Loss: 0.8623, Time: 1.60 seconds\n",
            "Batch 184/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 184/219, Loss: 0.7086, Time: 1.60 seconds\n",
            "Batch 185/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 2/3, Batch 185/219, Loss: 0.6904, Time: 1.59 seconds\n",
            "Batch 186/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 186/219, Loss: 0.7077, Time: 1.60 seconds\n",
            "Batch 187/219, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 2/3, Batch 187/219, Loss: 0.9467, Time: 1.60 seconds\n",
            "Batch 188/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 188/219, Loss: 0.6624, Time: 1.59 seconds\n",
            "Batch 189/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 2/3, Batch 189/219, Loss: 0.6079, Time: 1.59 seconds\n",
            "Batch 190/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 190/219, Loss: 0.3255, Time: 1.60 seconds\n",
            "Batch 191/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 191/219, Loss: 0.3247, Time: 1.59 seconds\n",
            "Batch 192/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 192/219, Loss: 0.3680, Time: 1.60 seconds\n",
            "Batch 193/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 193/219, Loss: 0.6435, Time: 1.59 seconds\n",
            "Batch 194/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 194/219, Loss: 1.0798, Time: 1.59 seconds\n",
            "Batch 195/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 195/219, Loss: 0.7363, Time: 1.60 seconds\n",
            "Batch 196/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 196/219, Loss: 0.9967, Time: 1.58 seconds\n",
            "Batch 197/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 2/3, Batch 197/219, Loss: 0.6828, Time: 1.60 seconds\n",
            "Batch 198/219, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 198/219, Loss: 1.1477, Time: 1.59 seconds\n",
            "Batch 199/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 199/219, Loss: 0.7468, Time: 1.58 seconds\n",
            "Batch 200/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 200/219, Loss: 0.8303, Time: 1.59 seconds\n",
            "Batch 201/219, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 201/219, Loss: 1.0257, Time: 1.60 seconds\n",
            "Batch 202/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 202/219, Loss: 0.7703, Time: 1.62 seconds\n",
            "Batch 203/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 203/219, Loss: 0.8963, Time: 1.59 seconds\n",
            "Batch 204/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 2/3, Batch 204/219, Loss: 0.7925, Time: 1.60 seconds\n",
            "Batch 205/219, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 205/219, Loss: 1.0871, Time: 1.60 seconds\n",
            "Batch 206/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 206/219, Loss: 0.7682, Time: 1.57 seconds\n",
            "Batch 207/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 207/219, Loss: 0.8102, Time: 1.60 seconds\n",
            "Batch 208/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 2/3, Batch 208/219, Loss: 0.7042, Time: 1.59 seconds\n",
            "Batch 209/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 209/219, Loss: 0.7437, Time: 1.60 seconds\n",
            "Batch 210/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 2/3, Batch 210/219, Loss: 0.5304, Time: 1.60 seconds\n",
            "Batch 211/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 211/219, Loss: 0.7754, Time: 1.59 seconds\n",
            "Batch 212/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 212/219, Loss: 0.8188, Time: 1.58 seconds\n",
            "Batch 213/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 2/3, Batch 213/219, Loss: 0.7185, Time: 1.58 seconds\n",
            "Batch 214/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 2/3, Batch 214/219, Loss: 0.8916, Time: 1.60 seconds\n",
            "Batch 215/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 2/3, Batch 215/219, Loss: 0.7358, Time: 1.57 seconds\n",
            "Batch 216/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 216/219, Loss: 1.0256, Time: 1.58 seconds\n",
            "Batch 217/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 217/219, Loss: 0.9870, Time: 1.59 seconds\n",
            "Batch 218/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 2/3, Batch 218/219, Loss: 0.5746, Time: 1.60 seconds\n",
            "Batch 219/219, Label Counts: {0: 6, 1: 2, 2: 3}\n",
            "Epoch 2/3, Batch 219/219, Loss: 0.9812, Time: 1.12 seconds\n",
            "Epoch 2/3, Training Loss: 0.7747, Time: 349.25 seconds\n",
            "Validation Loss: 0.8066, Accuracy: 0.6720\n",
            "Batch 1/219, Label Counts: {0: 9, 1: 1, 2: 6}\n",
            "Epoch 3/3, Batch 1/219, Loss: 0.9313, Time: 1.60 seconds\n",
            "Batch 2/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 2/219, Loss: 0.7136, Time: 1.59 seconds\n",
            "Batch 3/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 3/3, Batch 3/219, Loss: 0.5396, Time: 1.59 seconds\n",
            "Batch 4/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 4/219, Loss: 0.6517, Time: 1.60 seconds\n",
            "Batch 5/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 5/219, Loss: 0.7899, Time: 1.57 seconds\n",
            "Batch 6/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 6/219, Loss: 0.6049, Time: 1.60 seconds\n",
            "Batch 7/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 7/219, Loss: 0.6519, Time: 1.60 seconds\n",
            "Batch 8/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 8/219, Loss: 0.4303, Time: 1.60 seconds\n",
            "Batch 9/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 9/219, Loss: 0.9243, Time: 1.60 seconds\n",
            "Batch 10/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 10/219, Loss: 0.8133, Time: 1.55 seconds\n",
            "Batch 11/219, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 11/219, Loss: 0.9588, Time: 1.61 seconds\n",
            "Batch 12/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 12/219, Loss: 0.7021, Time: 1.57 seconds\n",
            "Batch 13/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 13/219, Loss: 0.7432, Time: 1.58 seconds\n",
            "Batch 14/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 14/219, Loss: 0.9090, Time: 1.54 seconds\n",
            "Batch 15/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 15/219, Loss: 0.5030, Time: 1.60 seconds\n",
            "Batch 16/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 16/219, Loss: 1.1640, Time: 1.60 seconds\n",
            "Batch 17/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 17/219, Loss: 0.6799, Time: 1.59 seconds\n",
            "Batch 18/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 18/219, Loss: 0.8558, Time: 1.59 seconds\n",
            "Batch 19/219, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 19/219, Loss: 1.0858, Time: 1.60 seconds\n",
            "Batch 20/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 20/219, Loss: 0.7171, Time: 1.60 seconds\n",
            "Batch 21/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 21/219, Loss: 0.7671, Time: 1.59 seconds\n",
            "Batch 22/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 22/219, Loss: 1.1648, Time: 1.60 seconds\n",
            "Batch 23/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 23/219, Loss: 0.8770, Time: 1.60 seconds\n",
            "Batch 24/219, Label Counts: {0: 15, 2: 1}\n",
            "Epoch 3/3, Batch 24/219, Loss: 0.4483, Time: 1.59 seconds\n",
            "Batch 25/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 25/219, Loss: 0.5556, Time: 1.60 seconds\n",
            "Batch 26/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 26/219, Loss: 0.7492, Time: 1.59 seconds\n",
            "Batch 27/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 27/219, Loss: 0.6815, Time: 1.60 seconds\n",
            "Batch 28/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 28/219, Loss: 0.7490, Time: 1.59 seconds\n",
            "Batch 29/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 29/219, Loss: 0.7801, Time: 1.60 seconds\n",
            "Batch 30/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 30/219, Loss: 0.6521, Time: 1.59 seconds\n",
            "Batch 31/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 31/219, Loss: 0.5291, Time: 1.55 seconds\n",
            "Batch 32/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 32/219, Loss: 0.4472, Time: 1.58 seconds\n",
            "Batch 33/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 33/219, Loss: 1.0035, Time: 1.60 seconds\n",
            "Batch 34/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 34/219, Loss: 0.7420, Time: 1.59 seconds\n",
            "Batch 35/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 35/219, Loss: 0.7579, Time: 1.58 seconds\n",
            "Batch 36/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 36/219, Loss: 1.1899, Time: 1.60 seconds\n",
            "Batch 37/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 37/219, Loss: 0.6953, Time: 1.59 seconds\n",
            "Batch 38/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 38/219, Loss: 0.5382, Time: 1.59 seconds\n",
            "Batch 39/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 39/219, Loss: 0.8291, Time: 1.58 seconds\n",
            "Batch 40/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 40/219, Loss: 0.8366, Time: 1.60 seconds\n",
            "Batch 41/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 41/219, Loss: 0.8598, Time: 1.60 seconds\n",
            "Batch 42/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 42/219, Loss: 0.7359, Time: 1.60 seconds\n",
            "Batch 43/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 43/219, Loss: 0.8432, Time: 1.60 seconds\n",
            "Batch 44/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 44/219, Loss: 0.8774, Time: 1.59 seconds\n",
            "Batch 45/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 45/219, Loss: 0.8103, Time: 1.60 seconds\n",
            "Batch 46/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 46/219, Loss: 0.4023, Time: 1.59 seconds\n",
            "Batch 47/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 47/219, Loss: 0.8733, Time: 1.60 seconds\n",
            "Batch 48/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 48/219, Loss: 0.9248, Time: 1.60 seconds\n",
            "Batch 49/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 49/219, Loss: 0.8349, Time: 1.60 seconds\n",
            "Batch 50/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 50/219, Loss: 1.0898, Time: 1.57 seconds\n",
            "Batch 51/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 51/219, Loss: 0.8324, Time: 1.58 seconds\n",
            "Batch 52/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 52/219, Loss: 0.7062, Time: 1.60 seconds\n",
            "Batch 53/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 53/219, Loss: 0.5120, Time: 1.60 seconds\n",
            "Batch 54/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 54/219, Loss: 0.7259, Time: 1.59 seconds\n",
            "Batch 55/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 55/219, Loss: 0.7530, Time: 1.60 seconds\n",
            "Batch 56/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 56/219, Loss: 0.7104, Time: 1.60 seconds\n",
            "Batch 57/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 57/219, Loss: 1.0010, Time: 1.59 seconds\n",
            "Batch 58/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 3/3, Batch 58/219, Loss: 0.8671, Time: 1.58 seconds\n",
            "Batch 59/219, Label Counts: {0: 13, 2: 3}\n",
            "Epoch 3/3, Batch 59/219, Loss: 0.6294, Time: 1.58 seconds\n",
            "Batch 60/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 60/219, Loss: 1.0107, Time: 1.58 seconds\n",
            "Batch 61/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 61/219, Loss: 0.6144, Time: 1.60 seconds\n",
            "Batch 62/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 62/219, Loss: 1.0365, Time: 1.60 seconds\n",
            "Batch 63/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 63/219, Loss: 0.6849, Time: 1.57 seconds\n",
            "Batch 64/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 64/219, Loss: 0.8988, Time: 1.57 seconds\n",
            "Batch 65/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 65/219, Loss: 0.7950, Time: 1.60 seconds\n",
            "Batch 66/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 66/219, Loss: 0.6186, Time: 1.60 seconds\n",
            "Batch 67/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 67/219, Loss: 0.7243, Time: 1.57 seconds\n",
            "Batch 68/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 68/219, Loss: 0.7599, Time: 1.58 seconds\n",
            "Batch 69/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 69/219, Loss: 0.7212, Time: 1.60 seconds\n",
            "Batch 70/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 70/219, Loss: 0.6405, Time: 1.60 seconds\n",
            "Batch 71/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 71/219, Loss: 0.7514, Time: 1.57 seconds\n",
            "Batch 72/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 72/219, Loss: 0.8933, Time: 1.58 seconds\n",
            "Batch 73/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 73/219, Loss: 0.7522, Time: 1.60 seconds\n",
            "Batch 74/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 74/219, Loss: 0.6405, Time: 1.59 seconds\n",
            "Batch 75/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 3/3, Batch 75/219, Loss: 0.8075, Time: 1.60 seconds\n",
            "Batch 76/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 76/219, Loss: 0.7166, Time: 1.60 seconds\n",
            "Batch 77/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 77/219, Loss: 0.8835, Time: 1.57 seconds\n",
            "Batch 78/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 3/3, Batch 78/219, Loss: 0.5335, Time: 1.58 seconds\n",
            "Batch 79/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 79/219, Loss: 0.7003, Time: 1.58 seconds\n",
            "Batch 80/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 80/219, Loss: 0.7871, Time: 1.60 seconds\n",
            "Batch 81/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 81/219, Loss: 0.6409, Time: 1.60 seconds\n",
            "Batch 82/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 82/219, Loss: 0.8887, Time: 1.60 seconds\n",
            "Batch 83/219, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 3/3, Batch 83/219, Loss: 0.9340, Time: 1.57 seconds\n",
            "Batch 84/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 84/219, Loss: 0.5966, Time: 1.58 seconds\n",
            "Batch 85/219, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 85/219, Loss: 0.9608, Time: 1.60 seconds\n",
            "Batch 86/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 86/219, Loss: 0.8385, Time: 1.59 seconds\n",
            "Batch 87/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 87/219, Loss: 0.5704, Time: 1.60 seconds\n",
            "Batch 88/219, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 88/219, Loss: 1.1469, Time: 1.57 seconds\n",
            "Batch 89/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 89/219, Loss: 0.7129, Time: 1.60 seconds\n",
            "Batch 90/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 3/3, Batch 90/219, Loss: 0.4236, Time: 1.59 seconds\n",
            "Batch 91/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 91/219, Loss: 0.7741, Time: 1.59 seconds\n",
            "Batch 92/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 92/219, Loss: 0.9087, Time: 1.60 seconds\n",
            "Batch 93/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 93/219, Loss: 0.9018, Time: 1.59 seconds\n",
            "Batch 94/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 94/219, Loss: 0.5039, Time: 1.58 seconds\n",
            "Batch 95/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 95/219, Loss: 0.8535, Time: 1.58 seconds\n",
            "Batch 96/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 96/219, Loss: 1.0214, Time: 1.58 seconds\n",
            "Batch 97/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 97/219, Loss: 0.9036, Time: 1.60 seconds\n",
            "Batch 98/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 98/219, Loss: 0.9857, Time: 1.60 seconds\n",
            "Batch 99/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 99/219, Loss: 0.7047, Time: 1.59 seconds\n",
            "Batch 100/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 100/219, Loss: 1.1193, Time: 1.60 seconds\n",
            "Batch 101/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 3/3, Batch 101/219, Loss: 0.9852, Time: 1.60 seconds\n",
            "Batch 102/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 102/219, Loss: 0.5305, Time: 1.59 seconds\n",
            "Batch 103/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 3/3, Batch 103/219, Loss: 1.0476, Time: 1.60 seconds\n",
            "Batch 104/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 104/219, Loss: 0.6978, Time: 1.59 seconds\n",
            "Batch 105/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 105/219, Loss: 0.5980, Time: 1.58 seconds\n",
            "Batch 106/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 106/219, Loss: 0.8509, Time: 1.59 seconds\n",
            "Batch 107/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 107/219, Loss: 0.8096, Time: 1.59 seconds\n",
            "Batch 108/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 108/219, Loss: 0.6586, Time: 1.59 seconds\n",
            "Batch 109/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 3/3, Batch 109/219, Loss: 0.5037, Time: 1.60 seconds\n",
            "Batch 110/219, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 110/219, Loss: 1.3884, Time: 1.59 seconds\n",
            "Batch 111/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 111/219, Loss: 0.7032, Time: 1.59 seconds\n",
            "Batch 112/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 112/219, Loss: 0.6338, Time: 1.59 seconds\n",
            "Batch 113/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 113/219, Loss: 1.0255, Time: 1.60 seconds\n",
            "Batch 114/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 114/219, Loss: 0.8345, Time: 1.57 seconds\n",
            "Batch 115/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 115/219, Loss: 0.5042, Time: 1.60 seconds\n",
            "Batch 116/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 116/219, Loss: 0.9071, Time: 1.60 seconds\n",
            "Batch 117/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 117/219, Loss: 0.8830, Time: 1.59 seconds\n",
            "Batch 118/219, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 118/219, Loss: 1.2047, Time: 1.60 seconds\n",
            "Batch 119/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 119/219, Loss: 0.5828, Time: 1.59 seconds\n",
            "Batch 120/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 3/3, Batch 120/219, Loss: 0.6455, Time: 1.59 seconds\n",
            "Batch 121/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 121/219, Loss: 0.9617, Time: 1.57 seconds\n",
            "Batch 122/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 122/219, Loss: 0.7075, Time: 1.58 seconds\n",
            "Batch 123/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 123/219, Loss: 1.0132, Time: 1.60 seconds\n",
            "Batch 124/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 124/219, Loss: 0.7702, Time: 1.59 seconds\n",
            "Batch 125/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 125/219, Loss: 0.5940, Time: 1.60 seconds\n",
            "Batch 126/219, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 126/219, Loss: 1.2831, Time: 1.60 seconds\n",
            "Batch 127/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 127/219, Loss: 0.9429, Time: 1.59 seconds\n",
            "Batch 128/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 128/219, Loss: 0.9965, Time: 1.57 seconds\n",
            "Batch 129/219, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 129/219, Loss: 0.9730, Time: 1.58 seconds\n",
            "Batch 130/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 130/219, Loss: 0.8831, Time: 1.60 seconds\n",
            "Batch 131/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 131/219, Loss: 0.6798, Time: 1.59 seconds\n",
            "Batch 132/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 132/219, Loss: 0.6133, Time: 1.59 seconds\n",
            "Batch 133/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 133/219, Loss: 1.0061, Time: 1.60 seconds\n",
            "Batch 134/219, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 3/3, Batch 134/219, Loss: 0.8865, Time: 1.57 seconds\n",
            "Batch 135/219, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 3/3, Batch 135/219, Loss: 1.0973, Time: 1.57 seconds\n",
            "Batch 136/219, Label Counts: {0: 12, 2: 4}\n",
            "Epoch 3/3, Batch 136/219, Loss: 0.7115, Time: 1.58 seconds\n",
            "Batch 137/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 137/219, Loss: 0.8015, Time: 1.60 seconds\n",
            "Batch 138/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 138/219, Loss: 0.8748, Time: 1.59 seconds\n",
            "Batch 139/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 139/219, Loss: 0.8623, Time: 1.59 seconds\n",
            "Batch 140/219, Label Counts: {0: 14, 2: 2}\n",
            "Epoch 3/3, Batch 140/219, Loss: 0.5230, Time: 1.58 seconds\n",
            "Batch 141/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 141/219, Loss: 0.8353, Time: 1.58 seconds\n",
            "Batch 142/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 142/219, Loss: 0.7740, Time: 1.58 seconds\n",
            "Batch 143/219, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 143/219, Loss: 1.1100, Time: 1.58 seconds\n",
            "Batch 144/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 144/219, Loss: 0.7014, Time: 1.60 seconds\n",
            "Batch 145/219, Label Counts: {0: 14, 1: 1, 2: 1}\n",
            "Epoch 3/3, Batch 145/219, Loss: 0.5617, Time: 1.60 seconds\n",
            "Batch 146/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 146/219, Loss: 0.7408, Time: 1.59 seconds\n",
            "Batch 147/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 147/219, Loss: 0.5990, Time: 1.60 seconds\n",
            "Batch 148/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 148/219, Loss: 0.9358, Time: 1.57 seconds\n",
            "Batch 149/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 149/219, Loss: 0.8183, Time: 1.58 seconds\n",
            "Batch 150/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 150/219, Loss: 0.7446, Time: 1.59 seconds\n",
            "Batch 151/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 151/219, Loss: 0.8412, Time: 1.58 seconds\n",
            "Batch 152/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 152/219, Loss: 1.0155, Time: 1.57 seconds\n",
            "Batch 153/219, Label Counts: {0: 12, 2: 4}\n",
            "Epoch 3/3, Batch 153/219, Loss: 0.8011, Time: 1.60 seconds\n",
            "Batch 154/219, Label Counts: {0: 12, 1: 4}\n",
            "Epoch 3/3, Batch 154/219, Loss: 0.7706, Time: 1.57 seconds\n",
            "Batch 155/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 155/219, Loss: 0.8284, Time: 1.58 seconds\n",
            "Batch 156/219, Label Counts: {0: 12, 1: 1, 2: 3}\n",
            "Epoch 3/3, Batch 156/219, Loss: 0.6658, Time: 1.55 seconds\n",
            "Batch 157/219, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 157/219, Loss: 0.9381, Time: 1.58 seconds\n",
            "Batch 158/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 158/219, Loss: 0.7206, Time: 1.60 seconds\n",
            "Batch 159/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 159/219, Loss: 0.8200, Time: 1.59 seconds\n",
            "Batch 160/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 160/219, Loss: 0.6424, Time: 1.60 seconds\n",
            "Batch 161/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 161/219, Loss: 1.0613, Time: 1.60 seconds\n",
            "Batch 162/219, Label Counts: {0: 11, 1: 5}\n",
            "Epoch 3/3, Batch 162/219, Loss: 0.8008, Time: 1.57 seconds\n",
            "Batch 163/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 163/219, Loss: 1.3097, Time: 1.58 seconds\n",
            "Batch 164/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 164/219, Loss: 0.8048, Time: 1.60 seconds\n",
            "Batch 165/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 165/219, Loss: 1.0415, Time: 1.57 seconds\n",
            "Batch 166/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 166/219, Loss: 0.7249, Time: 1.60 seconds\n",
            "Batch 167/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 167/219, Loss: 1.0358, Time: 1.59 seconds\n",
            "Batch 168/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 168/219, Loss: 0.6757, Time: 1.58 seconds\n",
            "Batch 169/219, Label Counts: {0: 12, 1: 2, 2: 2}\n",
            "Epoch 3/3, Batch 169/219, Loss: 0.7919, Time: 1.58 seconds\n",
            "Batch 170/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 170/219, Loss: 0.7813, Time: 1.56 seconds\n",
            "Batch 171/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 171/219, Loss: 0.9757, Time: 1.58 seconds\n",
            "Batch 172/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 172/219, Loss: 0.7739, Time: 1.60 seconds\n",
            "Batch 173/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 173/219, Loss: 0.9052, Time: 1.59 seconds\n",
            "Batch 174/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 174/219, Loss: 0.7294, Time: 1.57 seconds\n",
            "Batch 175/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 175/219, Loss: 0.6864, Time: 1.58 seconds\n",
            "Batch 176/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 176/219, Loss: 0.8610, Time: 1.59 seconds\n",
            "Batch 177/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 177/219, Loss: 0.9595, Time: 1.58 seconds\n",
            "Batch 178/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 3/3, Batch 178/219, Loss: 0.4984, Time: 1.59 seconds\n",
            "Batch 179/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 179/219, Loss: 0.8793, Time: 1.58 seconds\n",
            "Batch 180/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 180/219, Loss: 0.9459, Time: 1.55 seconds\n",
            "Batch 181/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 181/219, Loss: 0.6954, Time: 1.60 seconds\n",
            "Batch 182/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 182/219, Loss: 1.0140, Time: 1.60 seconds\n",
            "Batch 183/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 183/219, Loss: 0.6450, Time: 1.58 seconds\n",
            "Batch 184/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 184/219, Loss: 1.0085, Time: 1.57 seconds\n",
            "Batch 185/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 185/219, Loss: 0.6422, Time: 1.58 seconds\n",
            "Batch 186/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 186/219, Loss: 0.8431, Time: 1.57 seconds\n",
            "Batch 187/219, Label Counts: {0: 13, 1: 3}\n",
            "Epoch 3/3, Batch 187/219, Loss: 0.6113, Time: 1.59 seconds\n",
            "Batch 188/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 3/3, Batch 188/219, Loss: 0.4028, Time: 1.60 seconds\n",
            "Batch 189/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 189/219, Loss: 0.9719, Time: 1.60 seconds\n",
            "Batch 190/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 190/219, Loss: 0.8690, Time: 1.59 seconds\n",
            "Batch 191/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 191/219, Loss: 0.6025, Time: 1.57 seconds\n",
            "Batch 192/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 192/219, Loss: 1.1131, Time: 1.58 seconds\n",
            "Batch 193/219, Label Counts: {0: 14, 1: 2}\n",
            "Epoch 3/3, Batch 193/219, Loss: 0.4994, Time: 1.60 seconds\n",
            "Batch 194/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 194/219, Loss: 1.0724, Time: 1.60 seconds\n",
            "Batch 195/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 195/219, Loss: 0.8301, Time: 1.59 seconds\n",
            "Batch 196/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 196/219, Loss: 0.8362, Time: 1.57 seconds\n",
            "Batch 197/219, Label Counts: {0: 12, 1: 3, 2: 1}\n",
            "Epoch 3/3, Batch 197/219, Loss: 0.7463, Time: 1.58 seconds\n",
            "Batch 198/219, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 198/219, Loss: 0.9088, Time: 1.61 seconds\n",
            "Batch 199/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 199/219, Loss: 1.0162, Time: 1.61 seconds\n",
            "Batch 200/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 200/219, Loss: 0.6924, Time: 1.59 seconds\n",
            "Batch 201/219, Label Counts: {0: 9, 1: 1, 2: 6}\n",
            "Epoch 3/3, Batch 201/219, Loss: 0.9516, Time: 1.60 seconds\n",
            "Batch 202/219, Label Counts: {0: 13, 1: 1, 2: 2}\n",
            "Epoch 3/3, Batch 202/219, Loss: 0.6949, Time: 1.59 seconds\n",
            "Batch 203/219, Label Counts: {0: 13, 1: 2, 2: 1}\n",
            "Epoch 3/3, Batch 203/219, Loss: 0.6936, Time: 1.60 seconds\n",
            "Batch 204/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 204/219, Loss: 0.9163, Time: 1.59 seconds\n",
            "Batch 205/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 205/219, Loss: 0.9450, Time: 1.60 seconds\n",
            "Batch 206/219, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 206/219, Loss: 1.0684, Time: 1.59 seconds\n",
            "Batch 207/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 207/219, Loss: 0.9318, Time: 1.59 seconds\n",
            "Batch 208/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 208/219, Loss: 1.0273, Time: 1.58 seconds\n",
            "Batch 209/219, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 3/3, Batch 209/219, Loss: 0.9451, Time: 1.60 seconds\n",
            "Batch 210/219, Label Counts: {0: 15, 1: 1}\n",
            "Epoch 3/3, Batch 210/219, Loss: 0.4755, Time: 1.59 seconds\n",
            "Batch 211/219, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 3/3, Batch 211/219, Loss: 0.8496, Time: 1.60 seconds\n",
            "Batch 212/219, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 3/3, Batch 212/219, Loss: 0.8632, Time: 1.60 seconds\n",
            "Batch 213/219, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 213/219, Loss: 1.0498, Time: 1.59 seconds\n",
            "Batch 214/219, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 214/219, Loss: 1.0112, Time: 1.60 seconds\n",
            "Batch 215/219, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 3/3, Batch 215/219, Loss: 0.9256, Time: 1.59 seconds\n",
            "Batch 216/219, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 3/3, Batch 216/219, Loss: 1.0524, Time: 1.60 seconds\n",
            "Batch 217/219, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 217/219, Loss: 0.8195, Time: 1.59 seconds\n",
            "Batch 218/219, Label Counts: {0: 11, 1: 4, 2: 1}\n",
            "Epoch 3/3, Batch 218/219, Loss: 0.8407, Time: 1.60 seconds\n",
            "Batch 219/219, Label Counts: {0: 5, 1: 5, 2: 1}\n",
            "Epoch 3/3, Batch 219/219, Loss: 1.1151, Time: 1.12 seconds\n",
            "Epoch 3/3, Training Loss: 0.8091, Time: 348.02 seconds\n",
            "Validation Loss: 0.8494, Accuracy: 0.6720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/new_train_unblanced_chunked.csv\")"
      ],
      "metadata": {
        "id": "I8Eai5ejfabZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation**"
      ],
      "metadata": {
        "id": "ilqll2mD29MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = pd.read_csv('evaluation.csv')\n",
        "report_scores = pd.read_csv('evaluation.csv')\n",
        "\n",
        "del eval['Unnamed: 0']\n",
        "\n",
        "del report_scores['Unnamed: 0']\n",
        "eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nt4kg4bc27q1",
        "outputId": "36ed6e72-2151-4519-a792-cb4801cc3d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull\n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection\n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "..                                                 ...                   ...\n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown\n",
              "\n",
              "[152 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ec07ecf-8f93-47f3-99b1-aa0f90b0fada\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ec07ecf-8f93-47f3-99b1-aa0f90b0fada')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ec07ecf-8f93-47f3-99b1-aa0f90b0fada button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ec07ecf-8f93-47f3-99b1-aa0f90b0fada');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab84e917-0600-471d-bbca-7b9f263ec612\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab84e917-0600-471d-bbca-7b9f263ec612')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab84e917-0600-471d-bbca-7b9f263ec612 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "\n",
        "# Set the 'labels' column based on the mapping\n",
        "report_scores['labels'] = report_scores['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "report_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dbdwESeIJ9pl",
        "outputId": "1df7a87c-7144-49c3-8939-f9c63e444dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "..                                                 ...                   ...   \n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  \n",
              "0         2  \n",
              "1         1  \n",
              "2         1  \n",
              "3         0  \n",
              "4         0  \n",
              "..      ...  \n",
              "147       0  \n",
              "148       0  \n",
              "149       0  \n",
              "150       0  \n",
              "151       0  \n",
              "\n",
              "[152 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb91bc3e-5a7c-4a6f-9f53-4db2bc76ea83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb91bc3e-5a7c-4a6f-9f53-4db2bc76ea83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb91bc3e-5a7c-4a6f-9f53-4db2bc76ea83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb91bc3e-5a7c-4a6f-9f53-4db2bc76ea83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa903343-aa26-42bc-bb1c-1faa0e89e250\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa903343-aa26-42bc-bb1c-1faa0e89e250')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa903343-aa26-42bc-bb1c-1faa0e89e250 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chunking the data**"
      ],
      "metadata": {
        "id": "dnzFl-Dprn43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame named eval\n",
        "# eval['Related_ID'] = range(1, len(eval) + 1)\n",
        "report_scores['Related_ID'] = range(1, len(report_scores) + 1)\n",
        "\n",
        "report_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cJfMvL6p2l8B",
        "outputId": "b6cc6b73-11a9-437d-c5b8-f562ac8a2f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "..                                                 ...                   ...   \n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  Related_ID  \n",
              "0         2           1  \n",
              "1         1           2  \n",
              "2         1           3  \n",
              "3         0           4  \n",
              "4         0           5  \n",
              "..      ...         ...  \n",
              "147       0         148  \n",
              "148       0         149  \n",
              "149       0         150  \n",
              "150       0         151  \n",
              "151       0         152  \n",
              "\n",
              "[152 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d15bf8ac-232e-467a-aea9-e5da65c94d82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "      <th>Related_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d15bf8ac-232e-467a-aea9-e5da65c94d82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d15bf8ac-232e-467a-aea9-e5da65c94d82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d15bf8ac-232e-467a-aea9-e5da65c94d82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5e2ac95-df07-4726-8fdc-e96f22d8a034\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5e2ac95-df07-4726-8fdc-e96f22d8a034')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5e2ac95-df07-4726-8fdc-e96f22d8a034 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chunking with Memory**"
      ],
      "metadata": {
        "id": "AUds4UCK2wTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chunk text with overlap and assign the Sample_ID\n",
        "def chunk_text_with_overlap_and_id(row, tokenizer, chunk_size=508, overlap_percentage=30):\n",
        "    # Tokenize the input text\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(row['LogContent'])))\n",
        "\n",
        "    # Exclude [CLS] and [SEP] tokens\n",
        "    tokens = [token for token in tokens if token not in ['[CLS]', '[SEP]']]\n",
        "\n",
        "    # Calculate the overlap in tokens\n",
        "    overlap_tokens = int(chunk_size * overlap_percentage / 100)\n",
        "\n",
        "    # Chunk the tokens with overlap\n",
        "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size - overlap_tokens)]\n",
        "\n",
        "    # Convert token chunks back to text chunks\n",
        "    text_chunks = [tokenizer.decode(tokenizer.convert_tokens_to_ids(chunk)) for chunk in chunks]\n",
        "\n",
        "    # Assign Sample_ID to each chunk\n",
        "    chunk_ids = [row['Related_ID']] * len(chunks)\n",
        "\n",
        "    # Create a DataFrame for the current row\n",
        "    df = pd.DataFrame({'LogContent': text_chunks, 'RootCause': [row['RootCause']] * len(text_chunks), 'labels': [row['labels']] * len(text_chunks), 'Related_ID': chunk_ids})\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the chunking function to each row and concatenate the results\n",
        "chunked_logs = pd.concat([chunk_text_with_overlap_and_id(row, tokenizer) for _, row in report_scores.iterrows()], ignore_index=True)\n",
        "\n",
        "# Reorder the columns\n",
        "chunked_logs = chunked_logs[['LogContent', 'RootCause', 'labels', 'Related_ID']]\n"
      ],
      "metadata": {
        "id": "cxJDAYxH2Tbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9475dd41-7c88-44ac-9034-89f23523fb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UP_g51Ct21W1",
        "outputId": "c8152835-51cb-4e2b-d978-d33afb6a8f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent    RootCause  labels  \\\n",
              "0    metrics2. impl. metricsconfig : loaded propert...     DiskFull       2   \n",
              "1    maptask : ( equator ) 0 kvi 26214396 ( 1048575...     DiskFull       2   \n",
              "2    = 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...     DiskFull       2   \n",
              "3    ##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...     DiskFull       2   \n",
              "4    ##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...     DiskFull       2   \n",
              "..                                                 ...          ...     ...   \n",
              "952  ##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...  MachineDown       0   \n",
              "953  : assigned 1 of 1 to 04dn8iq. fareast. corp. m...  MachineDown       0   \n",
              "954  ##lerimpl : assigned 1 of 1 to minint - fnanli...  MachineDown       0   \n",
              "955  . ondiskmapoutput : read 216999713 bytes from ...  MachineDown       0   \n",
              "956  . output. fileoutputcommitter : saved output o...  MachineDown       0   \n",
              "\n",
              "     Related_ID  \n",
              "0             1  \n",
              "1             1  \n",
              "2             1  \n",
              "3             1  \n",
              "4             1  \n",
              "..          ...  \n",
              "952         152  \n",
              "953         152  \n",
              "954         152  \n",
              "955         152  \n",
              "956         152  \n",
              "\n",
              "[957 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8a06a28-9c65-4a66-b541-6054356dafda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "      <th>Related_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>= 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>: assigned 1 of 1 to 04dn8iq. fareast. corp. m...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>##lerimpl : assigned 1 of 1 to minint - fnanli...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>. ondiskmapoutput : read 216999713 bytes from ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>. output. fileoutputcommitter : saved output o...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>957 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8a06a28-9c65-4a66-b541-6054356dafda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8a06a28-9c65-4a66-b541-6054356dafda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8a06a28-9c65-4a66-b541-6054356dafda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d717dfb1-552c-4786-b417-622756f0b183\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d717dfb1-552c-4786-b417-622756f0b183')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d717dfb1-552c-4786-b417-622756f0b183 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normal Chunking**"
      ],
      "metadata": {
        "id": "sPPh95Jb2rLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text_with_overlap(text, tokenizer, chunk_size=512, overlap_percentage=30):\n",
        "    # Tokenize the input text\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "    # Exclude [CLS] and [SEP] tokens\n",
        "    tokens = [token for token in tokens if token not in ['[CLS]', '[SEP]']]\n",
        "\n",
        "    # Calculate the overlap in tokens\n",
        "    overlap_tokens = int(chunk_size * overlap_percentage / 100)\n",
        "\n",
        "    # Chunk the tokens with overlap\n",
        "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size - overlap_tokens)]\n",
        "\n",
        "    # Convert token chunks back to text chunks\n",
        "    text_chunks = [tokenizer.decode(tokenizer.convert_tokens_to_ids(chunk)) for chunk in chunks]\n",
        "\n",
        "    return text_chunks"
      ],
      "metadata": {
        "id": "-1aEdx_LbUNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval['TextChunks'] = eval['LogContent'].apply(lambda x: chunk_text_with_overlap(x, tokenizer, chunk_size=508, overlap_percentage=30))"
      ],
      "metadata": {
        "id": "OxC4O9kernrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs_no_id = pd.DataFrame(columns=['LogContent', 'RootCause'])\n",
        "tmp = []\n",
        "for index, row in eval.iterrows():\n",
        "    root_cause = row['RootCause']\n",
        "    log_chunks = row['TextChunks']\n",
        "\n",
        "    # Create a DataFrame for the current row\n",
        "    df = pd.DataFrame({'LogContent': log_chunks, 'RootCause': [root_cause] * len(log_chunks)})\n",
        "\n",
        "    # Append to the list\n",
        "    tmp.append(df)\n",
        "\n",
        "# Concatenate the list of DataFrames into a single DataFrame\n",
        "chunked_logs_no_id = pd.concat(tmp, ignore_index=True)\n",
        "\n",
        "# Reorder the columns\n",
        "chunked_logs_no_id = chunked_logs_no_id[['LogContent', 'RootCause']]"
      ],
      "metadata": {
        "id": "_n-38V1UsCtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply tokenizer.convert_ids_to_tokens and calculate the length of tokens\n",
        "chunked_logs['token_numbers'] = chunked_logs['LogContent'].apply(lambda x: len(tokenizer.convert_ids_to_tokens(tokenizer.encode(x))))"
      ],
      "metadata": {
        "id": "2qcxKAGcsC-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs[chunked_logs['token_numbers']<50].count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE7KdLlhK184",
        "outputId": "4bff5362-b553-47e7-ca65-6443e16e196b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogContent       8\n",
              "RootCause        8\n",
              "token_numbers    8\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del chunked_logs['token_numbers']"
      ],
      "metadata": {
        "id": "RiPMvn52tVBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval = chunked_logs_no_id\n",
        "eval"
      ],
      "metadata": {
        "id": "zBiTxtDjuJDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "89101713-d62e-4927-b0de-b83a55aba53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent    RootCause\n",
              "0    metrics2. impl. metricsconfig : loaded propert...     DiskFull\n",
              "1    maptask : ( equator ) 0 kvi 26214396 ( 1048575...     DiskFull\n",
              "2    = 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...     DiskFull\n",
              "3    ##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...     DiskFull\n",
              "4    ##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...     DiskFull\n",
              "..                                                 ...          ...\n",
              "952  ##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...  MachineDown\n",
              "953  : assigned 1 of 1 to 04dn8iq. fareast. corp. m...  MachineDown\n",
              "954  ##lerimpl : assigned 1 of 1 to minint - fnanli...  MachineDown\n",
              "955  . ondiskmapoutput : read 216999713 bytes from ...  MachineDown\n",
              "956  . output. fileoutputcommitter : saved output o...  MachineDown\n",
              "\n",
              "[957 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-468fd460-ea6a-4b9e-8570-d9824b150b12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>= 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...</td>\n",
              "      <td>DiskFull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>: assigned 1 of 1 to 04dn8iq. fareast. corp. m...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>##lerimpl : assigned 1 of 1 to minint - fnanli...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>. ondiskmapoutput : read 216999713 bytes from ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>. output. fileoutputcommitter : saved output o...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>957 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-468fd460-ea6a-4b9e-8570-d9824b150b12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-468fd460-ea6a-4b9e-8570-d9824b150b12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-468fd460-ea6a-4b9e-8570-d9824b150b12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bc2ba6c5-d7c1-4255-a47a-a9840d7178be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc2ba6c5-d7c1-4255-a47a-a9840d7178be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bc2ba6c5-d7c1-4255-a47a-a9840d7178be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "\n",
        "# Set the 'labels' column based on the mapping\n",
        "eval['labels'] = eval['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zTtdGtN038Rs",
        "outputId": "60d4d87a-8107-413d-aa89-01ddec63c043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent    RootCause  labels\n",
              "0    metrics2. impl. metricsconfig : loaded propert...     DiskFull       2\n",
              "1    maptask : ( equator ) 0 kvi 26214396 ( 1048575...     DiskFull       2\n",
              "2    = 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...     DiskFull       2\n",
              "3    ##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...     DiskFull       2\n",
              "4    ##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...     DiskFull       2\n",
              "..                                                 ...          ...     ...\n",
              "952  ##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...  MachineDown       0\n",
              "953  : assigned 1 of 1 to 04dn8iq. fareast. corp. m...  MachineDown       0\n",
              "954  ##lerimpl : assigned 1 of 1 to minint - fnanli...  MachineDown       0\n",
              "955  . ondiskmapoutput : read 216999713 bytes from ...  MachineDown       0\n",
              "956  . output. fileoutputcommitter : saved output o...  MachineDown       0\n",
              "\n",
              "[957 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b6cacbf-1c76-4df5-bbe7-7b61688688c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>= 11165556 ( 44662224 ) ; kvend = 24952068 ( 9...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>##80708 ( 29122832 ) ; kvend = 21067396 ( 8426...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##6 ( 13581584 ) ; kvend = 17182048 ( 68728192...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>##3 _ 0003 _ m _ 000002 _ 0 decomp : 216991624...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>: assigned 1 of 1 to 04dn8iq. fareast. corp. m...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>##lerimpl : assigned 1 of 1 to minint - fnanli...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>. ondiskmapoutput : read 216999713 bytes from ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>. output. fileoutputcommitter : saved output o...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>957 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b6cacbf-1c76-4df5-bbe7-7b61688688c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b6cacbf-1c76-4df5-bbe7-7b61688688c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b6cacbf-1c76-4df5-bbe7-7b61688688c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e7f1300-8229-4774-ac41-044c0bad24d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e7f1300-8229-4774-ac41-044c0bad24d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e7f1300-8229-4774-ac41-044c0bad24d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetWithID(Dataset):\n",
        "    def __init__(self, texts, labels, related_ids, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        self.labels = labels\n",
        "        self.related_ids = related_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        item['related_ids'] = torch.tensor(self.related_ids[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "metadata": {
        "id": "y7Lh_OyW3Okk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "tvi-zMmqR2tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BN6eEDZlS6lY",
        "outputId": "2baa9a9c-0f77-4a00-9ad4-c366a31f5125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "..                                                 ...                   ...   \n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  Related_ID  \n",
              "0         2           1  \n",
              "1         1           2  \n",
              "2         1           3  \n",
              "3         0           4  \n",
              "4         0           5  \n",
              "..      ...         ...  \n",
              "147       0         148  \n",
              "148       0         149  \n",
              "149       0         150  \n",
              "150       0         151  \n",
              "151       0         152  \n",
              "\n",
              "[152 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1840000b-7c32-48dc-82a2-82fe9d319288\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "      <th>Related_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1840000b-7c32-48dc-82a2-82fe9d319288')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1840000b-7c32-48dc-82a2-82fe9d319288 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1840000b-7c32-48dc-82a2-82fe9d319288');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a4f5619-6cd5-4a81-bf8a-f9b75b39aafc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a4f5619-6cd5-4a81-bf8a-f9b75b39aafc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a4f5619-6cd5-4a81-bf8a-f9b75b39aafc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_ID_dataset = CustomDatasetWithID(texts=list(chunked_logs['LogContent']), labels=chunked_logs['labels'], related_ids=chunked_logs['Related_ID'], tokenizer=tokenizer)\n",
        "evaluation_dataset = CustomDataset(texts=list(eval['LogContent']), labels=eval['labels'], tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader for eval dataset\n",
        "with_ID_dataloader = DataLoader(with_ID_dataset, batch_size=16, shuffle=False)\n",
        "eval_dataloader = DataLoader(evaluation_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "UtK5oqqv38vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model_path = \"./trained_models/trained_on_chunks\"\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrbXEduercqo",
        "outputId": "3d498afb-6c87-4253-8233-b705e7e83b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_model.eval()\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_confidences = []\n",
        "\n",
        "# Initialize an empty list to store batch-wise results\n",
        "batch_results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in with_ID_dataloader:\n",
        "        input_ids, attention_mask, labels, related_ids = (\n",
        "            batch['input_ids'], batch['attention_mask'], batch['labels'], batch['related_ids']\n",
        "        )\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # outputs = loaded_model(input_ids, attention_mask=attention_mask)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "\n",
        "        # Extend lists with batch-wise results\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_confidences.extend(probabilities.max(dim=1).values.cpu().numpy())\n",
        "\n",
        "        # Store batch-wise results in a DataFrame\n",
        "        batch_results.append(pd.DataFrame({'Related_ID': related_ids, 'Predicted_Label': preds.cpu().numpy(),\n",
        "                                           'Confidence': probabilities.max(dim=1).values.cpu().numpy(),\n",
        "                                           'True_Label': labels.cpu().numpy()}))\n",
        "\n",
        "# Concatenate batch-wise DataFrames into the final DataFrame\n",
        "result_df = pd.concat(batch_results, ignore_index=True)\n",
        "\n",
        "# Generate a single label for each original data based on the predicted labels and confidence levels\n",
        "final_predictions = []\n",
        "for related_id, group in result_df.groupby('Related_ID'):\n",
        "    # Choose the label with the highest confidence\n",
        "    # max_confidence_idx = group['Confidence'].idxmax()\n",
        "    # max_confidence_idx = group['Confidence'].idxmin()\n",
        "    # final_predictions.append({'Related_ID': related_id, 'Final_Predicted_Label': result_df.loc[max_confidence_idx, 'Predicted_Label']})\n",
        "\n",
        "    # Apply the rule to calculate the score for each label\n",
        "    label_stats = group.groupby('Predicted_Label').agg(cnt=('Predicted_Label', 'size'), conf_mean=('Confidence', 'mean'))\n",
        "    label_stats['score'] = label_stats['cnt']**2 * label_stats['conf_mean']\n",
        "\n",
        "    # Find the label with the maximum score\n",
        "    max_score_label = label_stats['score'].idxmax()\n",
        "\n",
        "    final_predictions.append({'Related_ID': related_id, 'Final_Predicted_Label': max_score_label})\n",
        "\n",
        "# Convert the final predictions to a DataFrame\n",
        "final_predictions_df = pd.DataFrame(final_predictions)\n",
        "\n",
        "# Optionally, you can merge the final predictions with the original eval dataset\n",
        "# final_eval_dataset = pd.merge(eval, final_predictions_df, on='Related_ID', how='left')\n",
        "\n",
        "final_predictions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FUMjz0b54k7Q",
        "outputId": "1c94d5d4-e519-4e46-e4b1-272c4f114820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-98-04c5fda46df1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Related_ID  Final_Predicted_Label\n",
              "0             1                      0\n",
              "1             2                      0\n",
              "2             3                      0\n",
              "3             4                      0\n",
              "4             5                      0\n",
              "..          ...                    ...\n",
              "147         148                      0\n",
              "148         149                      0\n",
              "149         150                      0\n",
              "150         151                      0\n",
              "151         152                      0\n",
              "\n",
              "[152 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1c960a1-429a-457b-a37a-34ed368a7c72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Related_ID</th>\n",
              "      <th>Final_Predicted_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c960a1-429a-457b-a37a-34ed368a7c72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1c960a1-429a-457b-a37a-34ed368a7c72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1c960a1-429a-457b-a37a-34ed368a7c72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-083d007b-dba9-4fe3-a837-4c724e5493a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-083d007b-dba9-4fe3-a837-4c724e5493a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-083d007b-dba9-4fe3-a837-4c724e5493a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lr4ZYsaz5SoY",
        "outputId": "18de0c99-98cb-42f5-acf5-8a4c2abaf965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Related_ID  Predicted_Label  Confidence  True_Label\n",
              "0             1                2    0.982983           2\n",
              "1             1                0    0.645117           2\n",
              "2             1                0    0.636173           2\n",
              "3             1                0    0.640284           2\n",
              "4             1                2    0.904477           2\n",
              "..          ...              ...         ...         ...\n",
              "952         152                0    0.961143           0\n",
              "953         152                0    0.973201           0\n",
              "954         152                0    0.986395           0\n",
              "955         152                0    0.959202           0\n",
              "956         152                0    0.986748           0\n",
              "\n",
              "[957 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13d1f6fd-c664-471c-adfd-7917f4101507\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Related_ID</th>\n",
              "      <th>Predicted_Label</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>True_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.982983</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.645117</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.636173</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.640284</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.904477</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.961143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.973201</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.986395</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.959202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.986748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>957 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13d1f6fd-c664-471c-adfd-7917f4101507')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13d1f6fd-c664-471c-adfd-7917f4101507 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13d1f6fd-c664-471c-adfd-7917f4101507');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a322bd5-1c4c-48a5-ba8d-542c70967909\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a322bd5-1c4c-48a5-ba8d-542c70967909')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a322bd5-1c4c-48a5-ba8d-542c70967909 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "y3nrd8PCmKU-",
        "outputId": "cb52afd2-a80a-4294-a66f-b877b32c2307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Related_ID  Final_Predicted_Label\n",
              "0             1                      0\n",
              "1             2                      0\n",
              "2             3                      1\n",
              "3             4                      0\n",
              "4             5                      0\n",
              "..          ...                    ...\n",
              "147         148                      0\n",
              "148         149                      0\n",
              "149         150                      0\n",
              "150         151                      0\n",
              "151         152                      0\n",
              "\n",
              "[152 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16717a5d-3db1-494e-aa3b-16418f10b41d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Related_ID</th>\n",
              "      <th>Final_Predicted_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16717a5d-3db1-494e-aa3b-16418f10b41d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16717a5d-3db1-494e-aa3b-16418f10b41d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16717a5d-3db1-494e-aa3b-16418f10b41d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c20ec9b-c882-4c7e-be6d-ac3de84e6e88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c20ec9b-c882-4c7e-be6d-ac3de84e6e88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c20ec9b-c882-4c7e-be6d-ac3de84e6e88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_eval_dataset = pd.merge(report_scores, final_predictions_df, on='Related_ID', how='left')"
      ],
      "metadata": {
        "id": "jZf4103BdS7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CgZ0TLFRUTnY",
        "outputId": "7257555e-9658-44c5-9b68-2a986a6b5331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "..                                                 ...                   ...   \n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  Related_ID  \n",
              "0         2           1  \n",
              "1         1           2  \n",
              "2         1           3  \n",
              "3         0           4  \n",
              "4         0           5  \n",
              "..      ...         ...  \n",
              "147       0         148  \n",
              "148       0         149  \n",
              "149       0         150  \n",
              "150       0         151  \n",
              "151       0         152  \n",
              "\n",
              "[152 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb3920b7-0dc8-4437-8d95-2038f511a8ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "      <th>Related_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb3920b7-0dc8-4437-8d95-2038f511a8ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb3920b7-0dc8-4437-8d95-2038f511a8ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb3920b7-0dc8-4437-8d95-2038f511a8ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d361f968-285a-4600-bb61-adf784bc453f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d361f968-285a-4600-bb61-adf784bc453f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d361f968-285a-4600-bb61-adf784bc453f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_eval_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7l02tNlWd_Nw",
        "outputId": "e34be6b3-b263-4cbf-e9d1-284a253333df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            LogContent             RootCause  \\\n",
              "0       metrics2.impl.MetricsConfig: loaded propert...              DiskFull   \n",
              "1       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "2       metrics2.impl.MetricsConfig: loaded propert...  NetworkDisconnection   \n",
              "3       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "4       metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "..                                                 ...                   ...   \n",
              "147     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "148     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "149     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "150     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "151     metrics2.impl.MetricsConfig: loaded propert...           MachineDown   \n",
              "\n",
              "     labels  Related_ID  Final_Predicted_Label  \n",
              "0         2           1                      0  \n",
              "1         1           2                      0  \n",
              "2         1           3                      1  \n",
              "3         0           4                      0  \n",
              "4         0           5                      0  \n",
              "..      ...         ...                    ...  \n",
              "147       0         148                      0  \n",
              "148       0         149                      0  \n",
              "149       0         150                      0  \n",
              "150       0         151                      0  \n",
              "151       0         152                      0  \n",
              "\n",
              "[152 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00af688b-4490-4b83-9afa-adf3fc9ec78c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "      <th>Related_ID</th>\n",
              "      <th>Final_Predicted_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>DiskFull</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>NetworkDisconnection</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>metrics2.impl.MetricsConfig: loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>152 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00af688b-4490-4b83-9afa-adf3fc9ec78c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00af688b-4490-4b83-9afa-adf3fc9ec78c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00af688b-4490-4b83-9afa-adf3fc9ec78c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd8f9392-9bde-4f5a-9d43-c704fc4194d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd8f9392-9bde-4f5a-9d43-c704fc4194d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd8f9392-9bde-4f5a-9d43-c704fc4194d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(final_eval_dataset['labels'], final_eval_dataset['Final_Predicted_Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZhXw2A176Jl",
        "outputId": "6a5af2b7-16b0-4dde-8a75-a9aa926197a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.76        94\n",
            "           1       0.00      0.00      0.00        25\n",
            "           2       0.00      0.00      0.00        33\n",
            "\n",
            "    accuracy                           0.62       152\n",
            "   macro avg       0.21      0.33      0.25       152\n",
            "weighted avg       0.38      0.62      0.47       152\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded_model.eval()\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in eval_dataloader:\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # outputs = loaded_model(input_ids, attention_mask=attention_mask)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfNQ_AhI3_jf",
        "outputId": "c90f09ed-a90e-4606-bddc-0d00ecb360b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-99-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.73       548\n",
            "           1       0.00      0.00      0.00       210\n",
            "           2       0.00      0.00      0.00       199\n",
            "\n",
            "    accuracy                           0.57       957\n",
            "   macro avg       0.19      0.33      0.24       957\n",
            "weighted avg       0.33      0.57      0.42       957\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/trained_on_chunks\")"
      ],
      "metadata": {
        "id": "AIaVC5RZ9TlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9T1eRTDDV5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "T_RLsaw19i6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs = pd.read_csv('chunked_new.csv')\n",
        "chunked_logs\n",
        "del chunked_logs['Unnamed: 0']"
      ],
      "metadata": {
        "id": "kS4cA0k3YneR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "NUM_LABELS = 3\n",
        "# Set the 'labels' column based on the mapping\n",
        "chunked_logs['labels'] = chunked_logs['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_eI-3l5NYoPt",
        "outputId": "726506cc-36b7-4200-c9a4-e52248a662ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             LogContent    RootCause  labels\n",
              "0     metrics2. impl. metricsconfig : loaded propert...  MachineDown       0\n",
              "1     . maptask : ( equator ) 0 kvi 26214396 ( 10485...  MachineDown       0\n",
              "2     ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...  MachineDown       0\n",
              "3     : kvstart = 7281300 ( 29125200 ) ; kvend = 210...  MachineDown       0\n",
              "4     ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...  MachineDown       0\n",
              "...                                                 ...          ...     ...\n",
              "4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...  MachineDown       0\n",
              "4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...  MachineDown       0\n",
              "4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...  MachineDown       0\n",
              "4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...  MachineDown       0\n",
              "4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...  MachineDown       0\n",
              "\n",
              "[4374 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6227a923-3e5f-4f14-be31-1ca08e0bd733\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6227a923-3e5f-4f14-be31-1ca08e0bd733')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6227a923-3e5f-4f14-be31-1ca08e0bd733 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6227a923-3e5f-4f14-be31-1ca08e0bd733');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f29d5b18-b47f-4366-a5b5-25be43f0c480\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f29d5b18-b47f-4366-a5b5-25be43f0c480')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f29d5b18-b47f-4366-a5b5-25be43f0c480 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gonH1i6-DsS",
        "outputId": "91dff143-b8e2-4023-b7ea-8bc2489bba29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of folds\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=50)"
      ],
      "metadata": {
        "id": "cPSQ7W269kxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store metrics for each fold without balancing\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_accuracies = []\n",
        "num_epochs = 3\n",
        "# K-fold cross-validation loop\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(chunked_logs)):\n",
        "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
        "\n",
        "     # Reinitialize the model for each fold\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=NUM_LABELS\n",
        "    )\n",
        "    model.to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    # Split the data into train and validation datasets for the current fold\n",
        "    train_fold, val_fold = chunked_logs.iloc[train_idx].reset_index(drop=True), chunked_logs.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    # Create CustomDataset instances for training and validation\n",
        "    train_dataset = CustomDataset(texts=list(train_fold['LogContent']), labels=train_fold['labels'], tokenizer=tokenizer)\n",
        "    val_dataset = CustomDataset(texts=list(val_fold['LogContent']), labels=val_fold['labels'], tokenizer=tokenizer)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    # Training loop for the current fold\n",
        "    train_losses_fold = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Print label counts for the current batch\n",
        "            # label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "            # print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "            # Print training progress for each batch\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "        average_loss = total_loss / len(train_dataloader)\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "        train_losses_fold.append(average_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_preds = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                val_loss += outputs.loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                correct_preds += (preds == labels).sum().item()\n",
        "        average_val_loss = val_loss / len(val_dataloader)\n",
        "        accuracy = correct_preds / len(val_fold)\n",
        "        print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        all_val_losses.append(average_val_loss)\n",
        "        all_accuracies.append(accuracy)\n",
        "\n",
        "    all_train_losses.append(train_losses_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkfAJaT19mxb",
        "outputId": "3c62dde3-eddf-4bca-be73-614fb84f1996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-99-db7b66662265>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Batch 1/219, Loss: 1.4525, Time: 1.55 seconds\n",
            "Epoch 1/3, Batch 2/219, Loss: 0.8376, Time: 1.52 seconds\n",
            "Epoch 1/3, Batch 3/219, Loss: 0.8402, Time: 1.54 seconds\n",
            "Epoch 1/3, Batch 4/219, Loss: 0.7677, Time: 1.55 seconds\n",
            "Epoch 1/3, Batch 5/219, Loss: 0.9576, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 6/219, Loss: 0.9443, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 7/219, Loss: 0.8229, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 8/219, Loss: 0.8353, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 9/219, Loss: 0.8526, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 10/219, Loss: 0.7980, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 11/219, Loss: 0.6415, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 12/219, Loss: 0.7352, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 13/219, Loss: 1.3825, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 14/219, Loss: 0.7935, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 15/219, Loss: 1.0958, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 16/219, Loss: 0.8796, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 17/219, Loss: 0.8249, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 18/219, Loss: 0.8405, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 19/219, Loss: 1.0117, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 20/219, Loss: 1.1627, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 21/219, Loss: 0.8138, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 22/219, Loss: 0.9823, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 23/219, Loss: 0.7806, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 24/219, Loss: 0.6545, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 25/219, Loss: 0.9371, Time: 1.63 seconds\n",
            "Epoch 1/3, Batch 26/219, Loss: 0.9788, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 27/219, Loss: 0.7375, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 28/219, Loss: 0.9536, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 29/219, Loss: 0.6267, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 30/219, Loss: 0.8168, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 31/219, Loss: 0.6836, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 32/219, Loss: 0.7471, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 33/219, Loss: 0.9490, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 34/219, Loss: 1.0334, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 35/219, Loss: 0.7067, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 36/219, Loss: 0.7436, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 37/219, Loss: 0.8642, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 38/219, Loss: 0.8729, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 39/219, Loss: 0.7966, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 40/219, Loss: 0.7491, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 41/219, Loss: 0.8878, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 42/219, Loss: 1.2210, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 43/219, Loss: 0.7838, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 44/219, Loss: 0.6060, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 45/219, Loss: 0.8037, Time: 1.55 seconds\n",
            "Epoch 1/3, Batch 46/219, Loss: 0.7716, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 47/219, Loss: 0.7674, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 48/219, Loss: 1.2509, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 49/219, Loss: 0.6411, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 50/219, Loss: 0.9000, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 51/219, Loss: 1.0070, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 52/219, Loss: 0.6204, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 53/219, Loss: 0.9788, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 54/219, Loss: 0.8082, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 55/219, Loss: 0.7698, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 56/219, Loss: 0.7396, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 57/219, Loss: 0.8558, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 58/219, Loss: 0.7704, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 59/219, Loss: 0.7188, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 60/219, Loss: 0.7563, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 61/219, Loss: 0.8814, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 62/219, Loss: 1.0065, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 63/219, Loss: 0.8185, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 64/219, Loss: 0.7424, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 65/219, Loss: 0.9303, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 66/219, Loss: 0.6233, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 67/219, Loss: 0.7351, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 68/219, Loss: 0.9555, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 69/219, Loss: 0.8002, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 70/219, Loss: 0.8895, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 71/219, Loss: 0.7220, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 72/219, Loss: 1.0157, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 73/219, Loss: 0.6611, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 74/219, Loss: 0.7039, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 75/219, Loss: 0.7415, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 76/219, Loss: 0.9185, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 77/219, Loss: 0.8128, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 78/219, Loss: 0.9289, Time: 1.63 seconds\n",
            "Epoch 1/3, Batch 79/219, Loss: 0.7369, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 80/219, Loss: 0.9753, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 81/219, Loss: 1.0587, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 82/219, Loss: 0.5093, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 83/219, Loss: 0.6434, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 84/219, Loss: 1.0576, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 85/219, Loss: 0.6315, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 86/219, Loss: 0.8619, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 87/219, Loss: 1.1521, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 88/219, Loss: 0.9531, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 89/219, Loss: 0.8683, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 90/219, Loss: 0.9799, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 91/219, Loss: 0.9170, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 92/219, Loss: 0.8109, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 93/219, Loss: 0.8487, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 94/219, Loss: 0.8604, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 95/219, Loss: 0.6778, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 96/219, Loss: 0.6356, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 97/219, Loss: 0.7694, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 98/219, Loss: 0.7047, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 99/219, Loss: 0.6445, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 100/219, Loss: 1.1518, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 101/219, Loss: 1.1945, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 102/219, Loss: 0.7199, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 103/219, Loss: 0.6071, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 104/219, Loss: 0.3447, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 105/219, Loss: 0.9324, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 106/219, Loss: 0.8541, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 107/219, Loss: 0.4694, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 108/219, Loss: 0.7972, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 109/219, Loss: 0.8520, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 110/219, Loss: 1.0213, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 111/219, Loss: 0.8194, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 112/219, Loss: 0.7227, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 113/219, Loss: 0.9688, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 114/219, Loss: 0.8797, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 115/219, Loss: 1.1963, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 116/219, Loss: 0.7150, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 117/219, Loss: 0.6405, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 118/219, Loss: 0.8190, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 119/219, Loss: 1.1443, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 120/219, Loss: 1.1483, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 121/219, Loss: 0.8542, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 122/219, Loss: 1.0893, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 123/219, Loss: 0.7547, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 124/219, Loss: 0.8380, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 125/219, Loss: 0.6738, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 126/219, Loss: 1.0079, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 127/219, Loss: 0.8348, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 128/219, Loss: 0.7300, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 129/219, Loss: 0.8973, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 130/219, Loss: 0.7209, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 131/219, Loss: 1.0780, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 132/219, Loss: 0.7735, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 133/219, Loss: 0.9926, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 134/219, Loss: 0.9457, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 135/219, Loss: 0.8175, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 136/219, Loss: 0.9318, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 137/219, Loss: 0.5770, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 138/219, Loss: 0.9666, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 139/219, Loss: 0.9815, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 140/219, Loss: 0.7983, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 141/219, Loss: 0.6909, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 142/219, Loss: 0.5440, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 143/219, Loss: 0.5448, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 144/219, Loss: 1.2729, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 145/219, Loss: 0.8238, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 146/219, Loss: 0.4954, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 147/219, Loss: 1.2439, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 148/219, Loss: 1.3142, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 149/219, Loss: 0.9749, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 150/219, Loss: 0.9674, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 151/219, Loss: 1.2006, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 152/219, Loss: 1.0644, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 153/219, Loss: 0.8464, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 154/219, Loss: 1.0947, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 155/219, Loss: 1.1636, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 156/219, Loss: 0.9210, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 157/219, Loss: 0.7811, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 158/219, Loss: 0.8789, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 159/219, Loss: 0.9607, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 160/219, Loss: 0.8329, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 161/219, Loss: 0.9494, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 162/219, Loss: 0.8665, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 163/219, Loss: 0.7210, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 164/219, Loss: 0.7543, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 165/219, Loss: 0.8036, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 166/219, Loss: 0.7803, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 167/219, Loss: 0.7255, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 168/219, Loss: 0.8155, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 169/219, Loss: 1.0747, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 170/219, Loss: 0.6343, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 171/219, Loss: 1.0269, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 172/219, Loss: 0.6920, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 173/219, Loss: 0.6358, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 174/219, Loss: 0.8374, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 175/219, Loss: 0.8435, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 176/219, Loss: 0.7719, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 177/219, Loss: 0.5969, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 178/219, Loss: 1.0007, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 179/219, Loss: 0.6745, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 180/219, Loss: 0.4887, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 181/219, Loss: 0.7101, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 182/219, Loss: 0.7755, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 183/219, Loss: 0.7743, Time: 1.58 seconds\n",
            "Epoch 1/3, Batch 184/219, Loss: 0.8148, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 185/219, Loss: 0.6173, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 186/219, Loss: 0.7949, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 187/219, Loss: 0.7365, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 188/219, Loss: 0.4197, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 189/219, Loss: 0.5213, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 190/219, Loss: 0.7686, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 191/219, Loss: 1.2881, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 192/219, Loss: 0.9361, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 193/219, Loss: 1.1715, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 194/219, Loss: 0.7819, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 195/219, Loss: 0.7502, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 196/219, Loss: 0.6432, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 197/219, Loss: 0.8025, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 198/219, Loss: 0.8319, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 199/219, Loss: 1.0372, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 200/219, Loss: 1.2544, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 201/219, Loss: 0.9707, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 202/219, Loss: 1.0310, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 203/219, Loss: 0.7823, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 204/219, Loss: 0.7552, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 205/219, Loss: 0.7515, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 206/219, Loss: 0.7742, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 207/219, Loss: 0.7071, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 208/219, Loss: 0.6719, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 209/219, Loss: 0.9974, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 210/219, Loss: 0.7428, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 211/219, Loss: 0.7140, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 212/219, Loss: 0.6583, Time: 1.61 seconds\n",
            "Epoch 1/3, Batch 213/219, Loss: 0.8651, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 214/219, Loss: 0.5802, Time: 1.59 seconds\n",
            "Epoch 1/3, Batch 215/219, Loss: 0.9093, Time: 1.57 seconds\n",
            "Epoch 1/3, Batch 216/219, Loss: 0.8852, Time: 1.60 seconds\n",
            "Epoch 1/3, Batch 217/219, Loss: 0.7767, Time: 1.62 seconds\n",
            "Epoch 1/3, Batch 218/219, Loss: 0.9015, Time: 1.56 seconds\n",
            "Epoch 1/3, Batch 219/219, Loss: 0.7352, Time: 1.15 seconds\n",
            "Epoch 1/3, Training Loss: 0.8446, Time: 350.24 seconds\n",
            "Validation Loss: 0.7620, Accuracy: 0.7074\n",
            "Epoch 2/3, Batch 1/219, Loss: 0.8819, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 2/219, Loss: 0.7399, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 3/219, Loss: 0.7250, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 4/219, Loss: 0.8979, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 5/219, Loss: 0.4391, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 6/219, Loss: 0.8492, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 7/219, Loss: 0.8389, Time: 1.63 seconds\n",
            "Epoch 2/3, Batch 8/219, Loss: 0.8941, Time: 1.58 seconds\n",
            "Epoch 2/3, Batch 9/219, Loss: 0.6660, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 10/219, Loss: 0.3814, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 11/219, Loss: 0.6134, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 12/219, Loss: 0.6764, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 13/219, Loss: 0.9151, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 14/219, Loss: 0.5287, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 15/219, Loss: 0.6267, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 16/219, Loss: 1.1564, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 17/219, Loss: 0.9768, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 18/219, Loss: 0.8838, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 19/219, Loss: 0.8506, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 20/219, Loss: 0.8475, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 21/219, Loss: 0.7342, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 22/219, Loss: 1.1450, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 23/219, Loss: 0.9239, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 24/219, Loss: 0.9236, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 25/219, Loss: 0.9668, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 26/219, Loss: 0.8285, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 27/219, Loss: 0.6010, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 28/219, Loss: 0.4746, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 29/219, Loss: 0.6504, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 30/219, Loss: 0.9999, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 31/219, Loss: 0.7752, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 32/219, Loss: 0.7629, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 33/219, Loss: 1.0840, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 34/219, Loss: 0.9896, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 35/219, Loss: 0.8410, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 36/219, Loss: 0.7848, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 37/219, Loss: 0.6943, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 38/219, Loss: 0.7017, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 39/219, Loss: 0.9565, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 40/219, Loss: 0.7148, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 41/219, Loss: 0.7811, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 42/219, Loss: 0.6098, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 43/219, Loss: 0.6041, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 44/219, Loss: 0.7399, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 45/219, Loss: 0.7185, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 46/219, Loss: 0.9922, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 47/219, Loss: 0.7561, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 48/219, Loss: 0.6627, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 49/219, Loss: 0.7550, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 50/219, Loss: 0.8427, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 51/219, Loss: 1.0835, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 52/219, Loss: 0.6602, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 53/219, Loss: 0.8471, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 54/219, Loss: 0.5235, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 55/219, Loss: 0.7411, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 56/219, Loss: 0.4238, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 57/219, Loss: 0.6034, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 58/219, Loss: 0.3961, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 59/219, Loss: 0.5897, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 60/219, Loss: 0.7248, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 61/219, Loss: 1.1616, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 62/219, Loss: 0.6944, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 63/219, Loss: 0.9008, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 64/219, Loss: 1.0143, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 65/219, Loss: 0.8305, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 66/219, Loss: 0.5803, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 67/219, Loss: 0.7719, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 68/219, Loss: 0.6526, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 69/219, Loss: 1.1057, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 70/219, Loss: 0.6525, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 71/219, Loss: 0.5465, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 72/219, Loss: 0.5865, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 73/219, Loss: 0.7563, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 74/219, Loss: 1.2076, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 75/219, Loss: 0.8550, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 76/219, Loss: 0.6421, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 77/219, Loss: 0.7346, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 78/219, Loss: 0.7324, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 79/219, Loss: 1.0263, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 80/219, Loss: 0.6646, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 81/219, Loss: 1.0761, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 82/219, Loss: 0.7747, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 83/219, Loss: 0.7428, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 84/219, Loss: 0.9367, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 85/219, Loss: 0.7656, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 86/219, Loss: 0.6668, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 87/219, Loss: 0.7807, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 88/219, Loss: 0.9802, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 89/219, Loss: 0.8834, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 90/219, Loss: 0.3743, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 91/219, Loss: 0.8116, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 92/219, Loss: 0.7481, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 93/219, Loss: 0.5594, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 94/219, Loss: 0.7863, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 95/219, Loss: 0.4553, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 96/219, Loss: 0.6692, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 97/219, Loss: 0.7821, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 98/219, Loss: 0.5981, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 99/219, Loss: 0.6120, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 100/219, Loss: 0.9144, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 101/219, Loss: 0.7733, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 102/219, Loss: 0.6598, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 103/219, Loss: 0.8017, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 104/219, Loss: 0.7078, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 105/219, Loss: 0.8939, Time: 1.57 seconds\n",
            "Epoch 2/3, Batch 106/219, Loss: 0.6345, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 107/219, Loss: 1.0683, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 108/219, Loss: 0.6967, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 109/219, Loss: 0.5715, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 110/219, Loss: 0.9226, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 111/219, Loss: 0.7842, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 112/219, Loss: 0.6758, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 113/219, Loss: 0.9187, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 114/219, Loss: 0.9329, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 115/219, Loss: 1.1230, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 116/219, Loss: 0.7206, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 117/219, Loss: 1.1100, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 118/219, Loss: 0.9496, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 119/219, Loss: 0.8009, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 120/219, Loss: 1.0372, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 121/219, Loss: 0.7628, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 122/219, Loss: 0.9933, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 123/219, Loss: 0.9417, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 124/219, Loss: 0.7909, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 125/219, Loss: 0.9009, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 126/219, Loss: 1.0154, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 127/219, Loss: 0.7459, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 128/219, Loss: 0.7657, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 129/219, Loss: 0.6776, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 130/219, Loss: 0.9193, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 131/219, Loss: 0.6995, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 132/219, Loss: 0.6659, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 133/219, Loss: 0.8319, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 134/219, Loss: 0.9321, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 135/219, Loss: 0.7955, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 136/219, Loss: 0.9500, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 137/219, Loss: 0.6543, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 138/219, Loss: 0.7909, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 139/219, Loss: 0.7391, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 140/219, Loss: 0.6175, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 141/219, Loss: 0.8784, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 142/219, Loss: 1.0173, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 143/219, Loss: 0.4327, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 144/219, Loss: 1.0141, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 145/219, Loss: 0.6696, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 146/219, Loss: 0.8500, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 147/219, Loss: 0.9923, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 148/219, Loss: 0.9177, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 149/219, Loss: 0.7273, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 150/219, Loss: 0.5743, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 151/219, Loss: 0.8423, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 152/219, Loss: 0.8714, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 153/219, Loss: 0.6626, Time: 1.57 seconds\n",
            "Epoch 2/3, Batch 154/219, Loss: 0.5251, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 155/219, Loss: 0.7750, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 156/219, Loss: 0.7642, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 157/219, Loss: 0.4805, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 158/219, Loss: 0.7779, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 159/219, Loss: 0.5941, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 160/219, Loss: 0.6755, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 161/219, Loss: 0.6619, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 162/219, Loss: 0.9649, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 163/219, Loss: 0.6172, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 164/219, Loss: 0.6897, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 165/219, Loss: 0.7831, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 166/219, Loss: 1.2733, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 167/219, Loss: 0.4123, Time: 1.58 seconds\n",
            "Epoch 2/3, Batch 168/219, Loss: 0.8443, Time: 1.61 seconds\n",
            "Epoch 2/3, Batch 169/219, Loss: 1.0375, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 170/219, Loss: 0.6881, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 171/219, Loss: 1.0197, Time: 1.58 seconds\n",
            "Epoch 2/3, Batch 172/219, Loss: 0.8925, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 173/219, Loss: 0.9749, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 174/219, Loss: 0.8041, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 175/219, Loss: 0.9165, Time: 1.57 seconds\n",
            "Epoch 2/3, Batch 176/219, Loss: 0.8204, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 177/219, Loss: 0.6662, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 178/219, Loss: 0.8685, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 179/219, Loss: 0.7949, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 180/219, Loss: 0.6619, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 181/219, Loss: 1.0155, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 182/219, Loss: 0.8734, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 183/219, Loss: 0.6376, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 184/219, Loss: 0.8364, Time: 1.58 seconds\n",
            "Epoch 2/3, Batch 185/219, Loss: 0.6391, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 186/219, Loss: 0.8127, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 187/219, Loss: 0.9071, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 188/219, Loss: 1.0461, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 189/219, Loss: 0.7118, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 190/219, Loss: 0.9091, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 191/219, Loss: 0.6728, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 192/219, Loss: 0.8383, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 193/219, Loss: 0.9043, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 194/219, Loss: 0.8834, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 195/219, Loss: 0.8502, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 196/219, Loss: 0.7716, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 197/219, Loss: 0.7581, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 198/219, Loss: 1.1583, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 199/219, Loss: 0.8177, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 200/219, Loss: 0.6541, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 201/219, Loss: 1.0880, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 202/219, Loss: 1.0007, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 203/219, Loss: 0.6541, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 204/219, Loss: 0.9161, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 205/219, Loss: 0.7289, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 206/219, Loss: 0.8264, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 207/219, Loss: 0.8288, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 208/219, Loss: 0.9397, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 209/219, Loss: 0.9338, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 210/219, Loss: 0.7093, Time: 1.57 seconds\n",
            "Epoch 2/3, Batch 211/219, Loss: 1.0527, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 212/219, Loss: 0.8281, Time: 1.62 seconds\n",
            "Epoch 2/3, Batch 213/219, Loss: 0.7147, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 214/219, Loss: 0.5798, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 215/219, Loss: 1.0128, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 216/219, Loss: 0.6896, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 217/219, Loss: 0.6720, Time: 1.59 seconds\n",
            "Epoch 2/3, Batch 218/219, Loss: 0.6716, Time: 1.60 seconds\n",
            "Epoch 2/3, Batch 219/219, Loss: 0.7539, Time: 1.13 seconds\n",
            "Epoch 2/3, Training Loss: 0.7933, Time: 350.42 seconds\n",
            "Validation Loss: 0.7191, Accuracy: 0.7189\n",
            "Epoch 3/3, Batch 1/219, Loss: 0.6722, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 2/219, Loss: 0.9267, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 3/219, Loss: 0.9301, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 4/219, Loss: 0.5374, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 5/219, Loss: 0.6012, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 6/219, Loss: 0.9463, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 7/219, Loss: 0.5309, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 8/219, Loss: 0.8619, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 9/219, Loss: 0.7212, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 10/219, Loss: 0.7611, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 11/219, Loss: 0.7578, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 12/219, Loss: 0.3805, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 13/219, Loss: 0.9702, Time: 1.56 seconds\n",
            "Epoch 3/3, Batch 14/219, Loss: 0.7295, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 15/219, Loss: 0.6888, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 16/219, Loss: 0.8682, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 17/219, Loss: 0.6220, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 18/219, Loss: 0.7264, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 19/219, Loss: 0.4949, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 20/219, Loss: 0.5495, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 21/219, Loss: 0.7167, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 22/219, Loss: 0.6521, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 23/219, Loss: 0.9580, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 24/219, Loss: 0.8487, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 25/219, Loss: 0.4669, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 26/219, Loss: 0.7561, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 27/219, Loss: 0.6499, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 28/219, Loss: 0.8824, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 29/219, Loss: 1.1195, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 30/219, Loss: 0.5321, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 31/219, Loss: 0.5896, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 32/219, Loss: 0.6010, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 33/219, Loss: 0.8415, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 34/219, Loss: 0.6718, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 35/219, Loss: 0.7748, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 36/219, Loss: 0.5884, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 37/219, Loss: 0.6879, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 38/219, Loss: 0.7819, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 39/219, Loss: 0.7017, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 40/219, Loss: 0.6771, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 41/219, Loss: 0.8650, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 42/219, Loss: 0.6542, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 43/219, Loss: 0.6018, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 44/219, Loss: 0.4784, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 45/219, Loss: 1.3534, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 46/219, Loss: 0.6284, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 47/219, Loss: 0.9907, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 48/219, Loss: 0.9689, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 49/219, Loss: 0.9325, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 50/219, Loss: 0.6415, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 51/219, Loss: 0.6162, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 52/219, Loss: 0.7067, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 53/219, Loss: 0.6967, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 54/219, Loss: 0.5551, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 55/219, Loss: 0.6771, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 56/219, Loss: 0.6596, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 57/219, Loss: 0.5462, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 58/219, Loss: 0.6152, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 59/219, Loss: 0.7610, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 60/219, Loss: 1.0343, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 61/219, Loss: 0.5202, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 62/219, Loss: 0.3569, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 63/219, Loss: 0.6795, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 64/219, Loss: 0.9604, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 65/219, Loss: 0.9338, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 66/219, Loss: 0.6639, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 67/219, Loss: 0.5860, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 68/219, Loss: 0.8658, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 69/219, Loss: 1.2474, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 70/219, Loss: 0.5947, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 71/219, Loss: 0.5945, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 72/219, Loss: 0.7478, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 73/219, Loss: 0.9295, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 74/219, Loss: 0.5694, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 75/219, Loss: 0.7611, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 76/219, Loss: 0.7214, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 77/219, Loss: 0.4761, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 78/219, Loss: 0.9358, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 79/219, Loss: 0.4083, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 80/219, Loss: 0.8408, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 81/219, Loss: 0.5255, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 82/219, Loss: 0.7985, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 83/219, Loss: 0.7231, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 84/219, Loss: 0.7050, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 85/219, Loss: 0.5157, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 86/219, Loss: 1.2865, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 87/219, Loss: 0.6823, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 88/219, Loss: 0.5507, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 89/219, Loss: 0.6580, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 90/219, Loss: 0.7456, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 91/219, Loss: 0.6112, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 92/219, Loss: 0.5449, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 93/219, Loss: 0.7595, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 94/219, Loss: 0.8495, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 95/219, Loss: 1.0115, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 96/219, Loss: 0.9427, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 97/219, Loss: 0.6147, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 98/219, Loss: 0.6469, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 99/219, Loss: 0.6677, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 100/219, Loss: 0.4975, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 101/219, Loss: 0.7135, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 102/219, Loss: 0.6024, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 103/219, Loss: 0.7825, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 104/219, Loss: 0.5571, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 105/219, Loss: 0.6563, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 106/219, Loss: 0.4459, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 107/219, Loss: 0.5337, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 108/219, Loss: 0.8269, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 109/219, Loss: 0.6064, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 110/219, Loss: 0.7270, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 111/219, Loss: 0.7420, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 112/219, Loss: 0.7206, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 113/219, Loss: 0.4358, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 114/219, Loss: 0.4179, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 115/219, Loss: 0.7673, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 116/219, Loss: 0.6702, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 117/219, Loss: 0.6767, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 118/219, Loss: 0.3709, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 119/219, Loss: 0.7914, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 120/219, Loss: 0.5936, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 121/219, Loss: 1.2379, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 122/219, Loss: 0.5613, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 123/219, Loss: 0.7005, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 124/219, Loss: 0.6088, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 125/219, Loss: 0.8197, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 126/219, Loss: 0.7018, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 127/219, Loss: 0.6669, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 128/219, Loss: 0.7251, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 129/219, Loss: 0.7085, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 130/219, Loss: 0.5355, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 131/219, Loss: 0.7479, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 132/219, Loss: 0.3641, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 133/219, Loss: 0.5886, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 134/219, Loss: 0.5400, Time: 1.58 seconds\n",
            "Epoch 3/3, Batch 135/219, Loss: 0.4039, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 136/219, Loss: 0.5164, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 137/219, Loss: 0.6322, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 138/219, Loss: 0.3398, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 139/219, Loss: 1.0371, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 140/219, Loss: 0.5727, Time: 1.55 seconds\n",
            "Epoch 3/3, Batch 141/219, Loss: 0.5692, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 142/219, Loss: 0.6603, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 143/219, Loss: 0.5058, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 144/219, Loss: 0.7192, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 145/219, Loss: 0.5449, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 146/219, Loss: 0.5368, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 147/219, Loss: 0.5668, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 148/219, Loss: 0.6195, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 149/219, Loss: 0.4099, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 150/219, Loss: 0.5980, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 151/219, Loss: 0.4233, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 152/219, Loss: 0.4011, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 153/219, Loss: 0.4271, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 154/219, Loss: 0.6760, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 155/219, Loss: 0.5233, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 156/219, Loss: 0.4956, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 157/219, Loss: 0.6407, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 158/219, Loss: 0.4478, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 159/219, Loss: 0.4262, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 160/219, Loss: 0.5379, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 161/219, Loss: 0.2434, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 162/219, Loss: 0.3848, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 163/219, Loss: 0.5587, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 164/219, Loss: 0.7070, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 165/219, Loss: 0.6609, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 166/219, Loss: 0.6949, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 167/219, Loss: 0.7032, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 168/219, Loss: 0.4774, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 169/219, Loss: 0.4295, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 170/219, Loss: 0.2637, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 171/219, Loss: 0.6756, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 172/219, Loss: 0.6669, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 173/219, Loss: 0.7680, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 174/219, Loss: 0.2846, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 175/219, Loss: 0.3501, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 176/219, Loss: 0.3650, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 177/219, Loss: 0.4744, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 178/219, Loss: 0.6041, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 179/219, Loss: 0.7132, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 180/219, Loss: 0.5950, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 181/219, Loss: 0.3908, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 182/219, Loss: 0.8832, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 183/219, Loss: 0.3382, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 184/219, Loss: 0.3638, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 185/219, Loss: 0.6592, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 186/219, Loss: 0.3968, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 187/219, Loss: 0.1817, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 188/219, Loss: 0.2908, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 189/219, Loss: 0.6721, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 190/219, Loss: 0.4979, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 191/219, Loss: 0.3643, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 192/219, Loss: 0.4353, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 193/219, Loss: 0.6933, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 194/219, Loss: 0.4767, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 195/219, Loss: 0.2668, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 196/219, Loss: 0.6806, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 197/219, Loss: 0.5152, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 198/219, Loss: 0.4996, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 199/219, Loss: 0.6240, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 200/219, Loss: 0.0783, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 201/219, Loss: 0.7479, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 202/219, Loss: 0.7375, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 203/219, Loss: 0.3668, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 204/219, Loss: 0.5799, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 205/219, Loss: 0.6065, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 206/219, Loss: 0.7657, Time: 1.57 seconds\n",
            "Epoch 3/3, Batch 207/219, Loss: 0.5411, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 208/219, Loss: 0.3065, Time: 1.62 seconds\n",
            "Epoch 3/3, Batch 209/219, Loss: 0.3812, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 210/219, Loss: 0.2043, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 211/219, Loss: 0.4643, Time: 1.61 seconds\n",
            "Epoch 3/3, Batch 212/219, Loss: 0.5348, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 213/219, Loss: 0.3792, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 214/219, Loss: 0.6848, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 215/219, Loss: 0.8472, Time: 1.59 seconds\n",
            "Epoch 3/3, Batch 216/219, Loss: 0.6972, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 217/219, Loss: 0.6405, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 218/219, Loss: 0.4917, Time: 1.60 seconds\n",
            "Epoch 3/3, Batch 219/219, Loss: 0.7577, Time: 1.13 seconds\n",
            "Epoch 3/3, Training Loss: 0.6371, Time: 349.93 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "class CustomDatasetForSMOTE(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        # self.labels = labels\n",
        "        self.labels = torch.tensor(labels).clone().detach()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "G0T1TkrUXQ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store metrics for each fold with balancing (using SMOTE)\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_accuracies = []\n",
        "num_epochs = 3\n",
        "# K-fold cross-validation loop\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(chunked_logs)):\n",
        "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
        "\n",
        "     # Reinitialize the model for each fold\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=NUM_LABELS\n",
        "    )\n",
        "    model.to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    # Split the data into train and validation datasets for the current fold\n",
        "    train_fold, val_fold = chunked_logs.iloc[train_idx].reset_index(drop=True), chunked_logs.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    # Create CustomDataset instances for training and validation\n",
        "    train_dataset = CustomDatasetForSMOTE(texts=list(train_fold['LogContent']), labels=train_fold['labels'], tokenizer=tokenizer)\n",
        "    val_dataset = CustomDatasetForSMOTE(texts=list(val_fold['LogContent']), labels=val_fold['labels'], tokenizer=tokenizer)\n",
        "\n",
        "    # Step 1: Extract features and labels\n",
        "    features = torch.cat([train_dataset[i]['input_ids'].reshape(1, -1) for i in range(len(train_dataset))], dim=0)\n",
        "    labels = torch.tensor(train_dataset[:]['labels'])\n",
        "\n",
        "    # Step 2: Apply SMOTE\n",
        "    smote = SMOTE(random_state=40)\n",
        "    features_resampled, labels_resampled = smote.fit_resample(features, labels)\n",
        "\n",
        "    # Step 3: Convert feature vectors back to text\n",
        "    text_data_resampled = [tokenizer.decode(input_ids) for input_ids in features_resampled]\n",
        "\n",
        "    # Step 4: Create a new dataset\n",
        "    train_dataset_resampled = CustomDatasetForSMOTE(text_data_resampled, labels_resampled, tokenizer)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataloader = DataLoader(train_dataset_resampled, batch_size=16, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    # Training loop for the current fold\n",
        "    train_losses_fold = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Print label counts for the current batch\n",
        "            # label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "            # print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            batch_end_time = time.time()\n",
        "            batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "            # Print training progress for each batch\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "        average_loss = total_loss / len(train_dataloader)\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "        train_losses_fold.append(average_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_preds = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                val_loss += outputs.loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                correct_preds += (preds == labels).sum().item()\n",
        "        average_val_loss = val_loss / len(val_dataloader)\n",
        "        accuracy = correct_preds / len(val_fold)\n",
        "        print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        all_val_losses.append(average_val_loss)\n",
        "        all_accuracies.append(accuracy)\n",
        "\n",
        "    all_train_losses.append(train_losses_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q4uKqafXLw4",
        "outputId": "effdaeaf-0973-4405-fe44-7bde10dedf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-13-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n",
            "<ipython-input-14-ba2ef8751743>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(train_dataset[:]['labels'])\n",
            "<ipython-input-13-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Batch 1/448, Loss: 1.2360, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 2/448, Loss: 1.0984, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 3/448, Loss: 1.1273, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 4/448, Loss: 1.1906, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 5/448, Loss: 1.0822, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 6/448, Loss: 1.0543, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 7/448, Loss: 1.0055, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 8/448, Loss: 1.0282, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 9/448, Loss: 1.1811, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 10/448, Loss: 0.9440, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 11/448, Loss: 0.9929, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 12/448, Loss: 1.0767, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 13/448, Loss: 0.9116, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 14/448, Loss: 0.9396, Time: 1.76 seconds\n",
            "Epoch 1/3, Batch 15/448, Loss: 0.9081, Time: 1.76 seconds\n",
            "Epoch 1/3, Batch 16/448, Loss: 0.9754, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 17/448, Loss: 0.9880, Time: 1.79 seconds\n",
            "Epoch 1/3, Batch 18/448, Loss: 0.9430, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 19/448, Loss: 0.8840, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 20/448, Loss: 0.9095, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 21/448, Loss: 0.6826, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 22/448, Loss: 0.9123, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 23/448, Loss: 1.2228, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 24/448, Loss: 0.7768, Time: 1.79 seconds\n",
            "Epoch 1/3, Batch 25/448, Loss: 0.8472, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 26/448, Loss: 1.1452, Time: 1.76 seconds\n",
            "Epoch 1/3, Batch 27/448, Loss: 0.9078, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 28/448, Loss: 0.8572, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 29/448, Loss: 1.0632, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 30/448, Loss: 1.0989, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 31/448, Loss: 0.9571, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 32/448, Loss: 1.0563, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 33/448, Loss: 1.0307, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 34/448, Loss: 1.0361, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 35/448, Loss: 1.0013, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 36/448, Loss: 0.9343, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 37/448, Loss: 0.8543, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 38/448, Loss: 0.8454, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 39/448, Loss: 0.8362, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 40/448, Loss: 1.0738, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 41/448, Loss: 0.9129, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 42/448, Loss: 0.7354, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 43/448, Loss: 0.9194, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 44/448, Loss: 0.9304, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 45/448, Loss: 1.0692, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 46/448, Loss: 0.7315, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 47/448, Loss: 0.6942, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 48/448, Loss: 0.8575, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 49/448, Loss: 0.8160, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 50/448, Loss: 0.8201, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 51/448, Loss: 0.8587, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 52/448, Loss: 0.7480, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 53/448, Loss: 0.9233, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 54/448, Loss: 0.9109, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 55/448, Loss: 0.9277, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 56/448, Loss: 0.6395, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 57/448, Loss: 0.7568, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 58/448, Loss: 1.0009, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 59/448, Loss: 0.7815, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 60/448, Loss: 1.0693, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 61/448, Loss: 0.8430, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 62/448, Loss: 0.7823, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 63/448, Loss: 1.0602, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 64/448, Loss: 0.7868, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 65/448, Loss: 0.8086, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 66/448, Loss: 0.8829, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 67/448, Loss: 1.0274, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 68/448, Loss: 0.6440, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 69/448, Loss: 0.8894, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 70/448, Loss: 0.6415, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 71/448, Loss: 0.6623, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 72/448, Loss: 1.0435, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 73/448, Loss: 0.6495, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 74/448, Loss: 0.6655, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 75/448, Loss: 0.9979, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 76/448, Loss: 0.7811, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 77/448, Loss: 0.7928, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 78/448, Loss: 0.8538, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 79/448, Loss: 0.8388, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 80/448, Loss: 0.8573, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 81/448, Loss: 0.7196, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 82/448, Loss: 0.6047, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 83/448, Loss: 0.8556, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 84/448, Loss: 1.0487, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 85/448, Loss: 0.9146, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 86/448, Loss: 0.8412, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 87/448, Loss: 0.8853, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 88/448, Loss: 0.7446, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 89/448, Loss: 0.5029, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 90/448, Loss: 0.8235, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 91/448, Loss: 1.0195, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 92/448, Loss: 0.8029, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 93/448, Loss: 0.8927, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 94/448, Loss: 1.0987, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 95/448, Loss: 0.8334, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 96/448, Loss: 0.9925, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 97/448, Loss: 0.9248, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 98/448, Loss: 0.7554, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 99/448, Loss: 0.8653, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 100/448, Loss: 0.9395, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 101/448, Loss: 0.9139, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 102/448, Loss: 0.8032, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 103/448, Loss: 0.8173, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 104/448, Loss: 0.9168, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 105/448, Loss: 0.8110, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 106/448, Loss: 0.7574, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 107/448, Loss: 0.7440, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 108/448, Loss: 1.0123, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 109/448, Loss: 0.7137, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 110/448, Loss: 1.0688, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 111/448, Loss: 0.7590, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 112/448, Loss: 0.7523, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 113/448, Loss: 1.0845, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 114/448, Loss: 0.6824, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 115/448, Loss: 0.8420, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 116/448, Loss: 0.6670, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 117/448, Loss: 0.6706, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 118/448, Loss: 0.8066, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 119/448, Loss: 0.8039, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 120/448, Loss: 0.9404, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 121/448, Loss: 0.6946, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 122/448, Loss: 0.8189, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 123/448, Loss: 0.8368, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 124/448, Loss: 0.9063, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 125/448, Loss: 0.7083, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 126/448, Loss: 0.7620, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 127/448, Loss: 0.9448, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 128/448, Loss: 0.7677, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 129/448, Loss: 0.7464, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 130/448, Loss: 0.9379, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 131/448, Loss: 0.7935, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 132/448, Loss: 0.6920, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 133/448, Loss: 0.9143, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 134/448, Loss: 0.7819, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 135/448, Loss: 0.7817, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 136/448, Loss: 1.0940, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 137/448, Loss: 0.8486, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 138/448, Loss: 0.8045, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 139/448, Loss: 0.8267, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 140/448, Loss: 0.6925, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 141/448, Loss: 1.0053, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 142/448, Loss: 0.7552, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 143/448, Loss: 0.8522, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 144/448, Loss: 0.8113, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 145/448, Loss: 0.7894, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 146/448, Loss: 0.8364, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 147/448, Loss: 0.9597, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 148/448, Loss: 0.7766, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 149/448, Loss: 1.0086, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 150/448, Loss: 0.8354, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 151/448, Loss: 0.8222, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 152/448, Loss: 0.8486, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 153/448, Loss: 0.8060, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 154/448, Loss: 0.9175, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 155/448, Loss: 0.7764, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 156/448, Loss: 0.8880, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 157/448, Loss: 0.5751, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 158/448, Loss: 0.7873, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 159/448, Loss: 0.8214, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 160/448, Loss: 0.8650, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 161/448, Loss: 1.0124, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 162/448, Loss: 0.8303, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 163/448, Loss: 0.8205, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 164/448, Loss: 0.9241, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 165/448, Loss: 0.8850, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 166/448, Loss: 0.8309, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 167/448, Loss: 0.8722, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 168/448, Loss: 0.7861, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 169/448, Loss: 0.6052, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 170/448, Loss: 0.7910, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 171/448, Loss: 1.0374, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 172/448, Loss: 0.8461, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 173/448, Loss: 0.7645, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 174/448, Loss: 0.6788, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 175/448, Loss: 1.0243, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 176/448, Loss: 0.9238, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 177/448, Loss: 0.9052, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 178/448, Loss: 0.9285, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 179/448, Loss: 0.7602, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 180/448, Loss: 0.8905, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 181/448, Loss: 0.8136, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 182/448, Loss: 0.8412, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 183/448, Loss: 0.9161, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 184/448, Loss: 0.6969, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 185/448, Loss: 0.7178, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 186/448, Loss: 0.7513, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 187/448, Loss: 0.7786, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 188/448, Loss: 0.7967, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 189/448, Loss: 0.8898, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 190/448, Loss: 0.6385, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 191/448, Loss: 0.8905, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 192/448, Loss: 1.1911, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 193/448, Loss: 1.0262, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 194/448, Loss: 0.8704, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 195/448, Loss: 0.5495, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 196/448, Loss: 0.6265, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 197/448, Loss: 0.8244, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 198/448, Loss: 0.7626, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 199/448, Loss: 0.8604, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 200/448, Loss: 0.9249, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 201/448, Loss: 0.9004, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 202/448, Loss: 0.9408, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 203/448, Loss: 0.9237, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 204/448, Loss: 0.7465, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 205/448, Loss: 0.7549, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 206/448, Loss: 0.7798, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 207/448, Loss: 1.0488, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 208/448, Loss: 0.8173, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 209/448, Loss: 0.8005, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 210/448, Loss: 0.6691, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 211/448, Loss: 0.6566, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 212/448, Loss: 0.6294, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 213/448, Loss: 0.7386, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 214/448, Loss: 0.8612, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 215/448, Loss: 0.5999, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 216/448, Loss: 0.7835, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 217/448, Loss: 0.8057, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 218/448, Loss: 0.6124, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 219/448, Loss: 0.7856, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 220/448, Loss: 0.9936, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 221/448, Loss: 1.1404, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 222/448, Loss: 0.7599, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 223/448, Loss: 0.9682, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 224/448, Loss: 0.7506, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 225/448, Loss: 0.7275, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 226/448, Loss: 0.6654, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 227/448, Loss: 0.6727, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 228/448, Loss: 0.7754, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 229/448, Loss: 1.0031, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 230/448, Loss: 0.9219, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 231/448, Loss: 0.5858, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 232/448, Loss: 0.8036, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 233/448, Loss: 0.8889, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 234/448, Loss: 0.7563, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 235/448, Loss: 0.8159, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 236/448, Loss: 1.1058, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 237/448, Loss: 0.7448, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 238/448, Loss: 0.9090, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 239/448, Loss: 0.9873, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 240/448, Loss: 0.7311, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 241/448, Loss: 0.6901, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 242/448, Loss: 0.6831, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 243/448, Loss: 0.6880, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 244/448, Loss: 0.8083, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 245/448, Loss: 1.1455, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 246/448, Loss: 0.7656, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 247/448, Loss: 1.0381, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 248/448, Loss: 0.9159, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 249/448, Loss: 0.7575, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 250/448, Loss: 0.7658, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 251/448, Loss: 0.8417, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 252/448, Loss: 0.8948, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 253/448, Loss: 0.8275, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 254/448, Loss: 0.7011, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 255/448, Loss: 0.8161, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 256/448, Loss: 0.7815, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 257/448, Loss: 0.8221, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 258/448, Loss: 0.7670, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 259/448, Loss: 0.8864, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 260/448, Loss: 0.9812, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 261/448, Loss: 0.7363, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 262/448, Loss: 0.7807, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 263/448, Loss: 0.8831, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 264/448, Loss: 0.6880, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 265/448, Loss: 0.6386, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 266/448, Loss: 0.7634, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 267/448, Loss: 0.9230, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 268/448, Loss: 0.5715, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 269/448, Loss: 0.7646, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 270/448, Loss: 0.6582, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 271/448, Loss: 0.7013, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 272/448, Loss: 0.8484, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 273/448, Loss: 0.8346, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 274/448, Loss: 0.6388, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 275/448, Loss: 0.6093, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 276/448, Loss: 0.9168, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 277/448, Loss: 0.4672, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 278/448, Loss: 0.7257, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 279/448, Loss: 0.7205, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 280/448, Loss: 0.4985, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 281/448, Loss: 0.5857, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 282/448, Loss: 0.8260, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 283/448, Loss: 0.5619, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 284/448, Loss: 0.4574, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 285/448, Loss: 0.6412, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 286/448, Loss: 0.6705, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 287/448, Loss: 0.7119, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 288/448, Loss: 0.7268, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 289/448, Loss: 0.6362, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 290/448, Loss: 0.6394, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 291/448, Loss: 0.9090, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 292/448, Loss: 0.7016, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 293/448, Loss: 0.6846, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 294/448, Loss: 0.9105, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 295/448, Loss: 0.6193, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 296/448, Loss: 0.8192, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 297/448, Loss: 0.7639, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 298/448, Loss: 0.8367, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 299/448, Loss: 0.5738, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 300/448, Loss: 0.5398, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 301/448, Loss: 0.7654, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 302/448, Loss: 0.7470, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 303/448, Loss: 0.7369, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 304/448, Loss: 0.3882, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 305/448, Loss: 0.6797, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 306/448, Loss: 0.6530, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 307/448, Loss: 0.5545, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 308/448, Loss: 0.9260, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 309/448, Loss: 0.7353, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 310/448, Loss: 0.5428, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 311/448, Loss: 0.7305, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 312/448, Loss: 0.5689, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 313/448, Loss: 0.4890, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 314/448, Loss: 0.7233, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 315/448, Loss: 0.4840, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 316/448, Loss: 0.4525, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 317/448, Loss: 0.5738, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 318/448, Loss: 0.4491, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 319/448, Loss: 1.0219, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 320/448, Loss: 0.7709, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 321/448, Loss: 0.5044, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 322/448, Loss: 0.2841, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 323/448, Loss: 0.7153, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 324/448, Loss: 0.8201, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 325/448, Loss: 0.8862, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 326/448, Loss: 0.7386, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 327/448, Loss: 0.5104, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 328/448, Loss: 0.8532, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 329/448, Loss: 0.4504, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 330/448, Loss: 0.7525, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 331/448, Loss: 0.4833, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 332/448, Loss: 0.6675, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 333/448, Loss: 0.4757, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 334/448, Loss: 0.7446, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 335/448, Loss: 0.7803, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 336/448, Loss: 0.6286, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 337/448, Loss: 0.7467, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 338/448, Loss: 0.4991, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 339/448, Loss: 0.9502, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 340/448, Loss: 0.5478, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 341/448, Loss: 0.6717, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 342/448, Loss: 0.7186, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 343/448, Loss: 0.7118, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 344/448, Loss: 0.5571, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 345/448, Loss: 0.6721, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 346/448, Loss: 0.5902, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 347/448, Loss: 0.9102, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 348/448, Loss: 0.5111, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 349/448, Loss: 0.5935, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 350/448, Loss: 0.4027, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 351/448, Loss: 0.6731, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 352/448, Loss: 0.6915, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 353/448, Loss: 0.5074, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 354/448, Loss: 0.7633, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 355/448, Loss: 0.3794, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 356/448, Loss: 0.4898, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 357/448, Loss: 0.4380, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 358/448, Loss: 0.6566, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 359/448, Loss: 0.6337, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 360/448, Loss: 0.9280, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 361/448, Loss: 1.0354, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 362/448, Loss: 0.2567, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 363/448, Loss: 0.5286, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 364/448, Loss: 0.9732, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 365/448, Loss: 0.6517, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 366/448, Loss: 0.4891, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 367/448, Loss: 0.5434, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 368/448, Loss: 0.5806, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 369/448, Loss: 0.7335, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 370/448, Loss: 0.5655, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 371/448, Loss: 0.6307, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 372/448, Loss: 0.4949, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 373/448, Loss: 0.2793, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 374/448, Loss: 0.9017, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 375/448, Loss: 0.7585, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 376/448, Loss: 1.0625, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 377/448, Loss: 0.5414, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 378/448, Loss: 0.7492, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 379/448, Loss: 0.6306, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 380/448, Loss: 0.9246, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 381/448, Loss: 0.6094, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 382/448, Loss: 0.8446, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 383/448, Loss: 0.5470, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 384/448, Loss: 0.5904, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 385/448, Loss: 0.7413, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 386/448, Loss: 0.7475, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 387/448, Loss: 0.6908, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 388/448, Loss: 0.8507, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 389/448, Loss: 0.8312, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 390/448, Loss: 0.5518, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 391/448, Loss: 0.6109, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 392/448, Loss: 0.5987, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 393/448, Loss: 0.6159, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 394/448, Loss: 0.5579, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 395/448, Loss: 0.5122, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 396/448, Loss: 0.8163, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 397/448, Loss: 0.4731, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 398/448, Loss: 0.5516, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 399/448, Loss: 0.5103, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 400/448, Loss: 0.5917, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 401/448, Loss: 0.5488, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 402/448, Loss: 0.7591, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 403/448, Loss: 0.6997, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 404/448, Loss: 0.8129, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 405/448, Loss: 0.6886, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 406/448, Loss: 0.4359, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 407/448, Loss: 0.7353, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 408/448, Loss: 0.3953, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 409/448, Loss: 0.7091, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 410/448, Loss: 0.9019, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 411/448, Loss: 0.7969, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 412/448, Loss: 0.7821, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 413/448, Loss: 0.8492, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 414/448, Loss: 0.5898, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 415/448, Loss: 0.5207, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 416/448, Loss: 0.6984, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 417/448, Loss: 0.6366, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 418/448, Loss: 0.5307, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 419/448, Loss: 0.6195, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 420/448, Loss: 0.6241, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 421/448, Loss: 0.6911, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 422/448, Loss: 0.4688, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 423/448, Loss: 0.6468, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 424/448, Loss: 1.0342, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 425/448, Loss: 0.6060, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 426/448, Loss: 0.4620, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 427/448, Loss: 0.5243, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 428/448, Loss: 0.7157, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 429/448, Loss: 0.6415, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 430/448, Loss: 0.4747, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 431/448, Loss: 0.7078, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 432/448, Loss: 0.7478, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 433/448, Loss: 0.5744, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 434/448, Loss: 0.5040, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 435/448, Loss: 0.9345, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 436/448, Loss: 0.4001, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 437/448, Loss: 0.5417, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 438/448, Loss: 0.6421, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 439/448, Loss: 0.4148, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 440/448, Loss: 0.4538, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 441/448, Loss: 0.7044, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 442/448, Loss: 0.9113, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 443/448, Loss: 0.4930, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 444/448, Loss: 0.9984, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 445/448, Loss: 0.6079, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 446/448, Loss: 0.7343, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 447/448, Loss: 0.6271, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 448/448, Loss: 0.7884, Time: 0.98 seconds\n",
            "Epoch 1/3, Training Loss: 0.7742, Time: 766.27 seconds\n",
            "Validation Loss: 0.7133, Accuracy: 0.7051\n",
            "Epoch 2/3, Batch 1/448, Loss: 0.6688, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 2/448, Loss: 0.7841, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 3/448, Loss: 0.5053, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 4/448, Loss: 0.3497, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 5/448, Loss: 1.0794, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 6/448, Loss: 0.4397, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 7/448, Loss: 0.7024, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 8/448, Loss: 0.6340, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 9/448, Loss: 0.6574, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 10/448, Loss: 0.6762, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 11/448, Loss: 0.6577, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 12/448, Loss: 0.9908, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 13/448, Loss: 0.6235, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 14/448, Loss: 0.3208, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 15/448, Loss: 0.6355, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 16/448, Loss: 0.8286, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 17/448, Loss: 0.7037, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 18/448, Loss: 0.9359, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 19/448, Loss: 0.5002, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 20/448, Loss: 0.8383, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 21/448, Loss: 0.7648, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 22/448, Loss: 0.6185, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 23/448, Loss: 0.6460, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 24/448, Loss: 0.3323, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 25/448, Loss: 0.6022, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 26/448, Loss: 0.7511, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 27/448, Loss: 0.7000, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 28/448, Loss: 0.5261, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 29/448, Loss: 0.5761, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 30/448, Loss: 0.6233, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 31/448, Loss: 0.6175, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 32/448, Loss: 0.7596, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 33/448, Loss: 0.8498, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 34/448, Loss: 0.7440, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 35/448, Loss: 0.6245, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 36/448, Loss: 0.6444, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 37/448, Loss: 0.4304, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 38/448, Loss: 0.8158, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 39/448, Loss: 0.6821, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 40/448, Loss: 0.6724, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 41/448, Loss: 0.6162, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 42/448, Loss: 0.3725, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 43/448, Loss: 0.7341, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 44/448, Loss: 0.4634, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 45/448, Loss: 0.5146, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 46/448, Loss: 0.7224, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 47/448, Loss: 0.5108, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 48/448, Loss: 0.7952, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 49/448, Loss: 0.5018, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 50/448, Loss: 0.5535, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 51/448, Loss: 0.5945, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 52/448, Loss: 0.5430, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 53/448, Loss: 0.7777, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 54/448, Loss: 0.5147, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 55/448, Loss: 0.9510, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 56/448, Loss: 0.4580, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 57/448, Loss: 0.4559, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 58/448, Loss: 0.6818, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 59/448, Loss: 0.7381, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 60/448, Loss: 0.5043, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 61/448, Loss: 0.6205, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 62/448, Loss: 0.5501, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 63/448, Loss: 0.7342, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 64/448, Loss: 0.5650, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 65/448, Loss: 0.5410, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 66/448, Loss: 0.5802, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 67/448, Loss: 0.6033, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 68/448, Loss: 0.3279, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 69/448, Loss: 0.6889, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 70/448, Loss: 0.7648, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 71/448, Loss: 0.6286, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 72/448, Loss: 0.8783, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 73/448, Loss: 0.6150, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 74/448, Loss: 0.5744, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 75/448, Loss: 0.5215, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 76/448, Loss: 0.4366, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 77/448, Loss: 0.8614, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 78/448, Loss: 0.5547, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 79/448, Loss: 0.5558, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 80/448, Loss: 0.7669, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 81/448, Loss: 0.6767, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 82/448, Loss: 0.7562, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 83/448, Loss: 0.7926, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 84/448, Loss: 0.1199, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 85/448, Loss: 0.5543, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 86/448, Loss: 0.4538, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 87/448, Loss: 0.5194, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 88/448, Loss: 0.3814, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 89/448, Loss: 0.6087, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 90/448, Loss: 0.3302, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 91/448, Loss: 0.6933, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 92/448, Loss: 0.6233, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 93/448, Loss: 0.5350, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 94/448, Loss: 0.5257, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 95/448, Loss: 0.5926, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 96/448, Loss: 0.6796, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 97/448, Loss: 0.3765, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 98/448, Loss: 0.5390, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 99/448, Loss: 0.3236, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 100/448, Loss: 0.3076, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 101/448, Loss: 0.5110, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 102/448, Loss: 0.9530, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 103/448, Loss: 0.5731, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 104/448, Loss: 0.8736, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 105/448, Loss: 0.7591, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 106/448, Loss: 0.4569, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 107/448, Loss: 0.4120, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 108/448, Loss: 0.6339, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 109/448, Loss: 0.4069, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 110/448, Loss: 0.7813, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 111/448, Loss: 0.5875, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 112/448, Loss: 0.6175, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 113/448, Loss: 0.5140, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 114/448, Loss: 0.5258, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 115/448, Loss: 0.4835, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 116/448, Loss: 0.7478, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 117/448, Loss: 0.5602, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 118/448, Loss: 0.3599, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 119/448, Loss: 0.4324, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 120/448, Loss: 0.3909, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 121/448, Loss: 0.5005, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 122/448, Loss: 0.6513, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 123/448, Loss: 0.5442, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 124/448, Loss: 0.6650, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 125/448, Loss: 0.5257, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 126/448, Loss: 0.3633, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 127/448, Loss: 0.6987, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 128/448, Loss: 0.6405, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 129/448, Loss: 0.5521, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 130/448, Loss: 0.3046, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 131/448, Loss: 0.5493, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 132/448, Loss: 0.4958, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 133/448, Loss: 0.7525, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 134/448, Loss: 0.4528, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 135/448, Loss: 0.4202, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 136/448, Loss: 0.5286, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 137/448, Loss: 0.6999, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 138/448, Loss: 0.4561, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 139/448, Loss: 0.6949, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 140/448, Loss: 0.8017, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 141/448, Loss: 0.1975, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 142/448, Loss: 0.5347, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 143/448, Loss: 0.4322, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 144/448, Loss: 0.6151, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 145/448, Loss: 0.5936, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 146/448, Loss: 0.4859, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 147/448, Loss: 0.4735, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 148/448, Loss: 0.8918, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 149/448, Loss: 0.5732, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 150/448, Loss: 0.4453, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 151/448, Loss: 0.9308, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 152/448, Loss: 0.6266, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 153/448, Loss: 0.5092, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 154/448, Loss: 0.8764, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 155/448, Loss: 1.0542, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 156/448, Loss: 0.6952, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 157/448, Loss: 0.6564, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 158/448, Loss: 0.9290, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 159/448, Loss: 0.6873, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 160/448, Loss: 0.6716, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 161/448, Loss: 0.5631, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 162/448, Loss: 0.5269, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 163/448, Loss: 0.4694, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 164/448, Loss: 0.5536, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 165/448, Loss: 0.6686, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 166/448, Loss: 0.6170, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 167/448, Loss: 0.7876, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 168/448, Loss: 0.9211, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 169/448, Loss: 0.5363, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 170/448, Loss: 0.6206, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 171/448, Loss: 0.7918, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 172/448, Loss: 0.5515, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 173/448, Loss: 0.6518, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 174/448, Loss: 0.5336, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 175/448, Loss: 0.6326, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 176/448, Loss: 1.0602, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 177/448, Loss: 0.5958, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 178/448, Loss: 0.5836, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 179/448, Loss: 0.7397, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 180/448, Loss: 0.7808, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 181/448, Loss: 0.8653, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 182/448, Loss: 0.3891, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 183/448, Loss: 0.5347, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 184/448, Loss: 0.4753, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 185/448, Loss: 0.6109, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 186/448, Loss: 0.8694, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 187/448, Loss: 0.6559, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 188/448, Loss: 0.6317, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 189/448, Loss: 0.4866, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 190/448, Loss: 0.7826, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 191/448, Loss: 0.4843, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 192/448, Loss: 0.6460, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 193/448, Loss: 0.5942, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 194/448, Loss: 0.7665, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 195/448, Loss: 0.8403, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 196/448, Loss: 0.3876, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 197/448, Loss: 0.9273, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 198/448, Loss: 0.3700, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 199/448, Loss: 1.2434, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 200/448, Loss: 0.8129, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 201/448, Loss: 0.5741, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 202/448, Loss: 0.4040, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 203/448, Loss: 0.4772, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 204/448, Loss: 0.8222, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 205/448, Loss: 0.8068, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 206/448, Loss: 0.6867, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 207/448, Loss: 0.7660, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 208/448, Loss: 0.5592, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 209/448, Loss: 0.5229, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 210/448, Loss: 0.7937, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 211/448, Loss: 0.7454, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 212/448, Loss: 0.4803, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 213/448, Loss: 0.6156, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 214/448, Loss: 1.0304, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 215/448, Loss: 0.4309, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 216/448, Loss: 0.4171, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 217/448, Loss: 0.7948, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 218/448, Loss: 0.6696, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 219/448, Loss: 0.6976, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 220/448, Loss: 0.5100, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 221/448, Loss: 0.2969, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 222/448, Loss: 0.6715, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 223/448, Loss: 0.6108, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 224/448, Loss: 0.5386, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 225/448, Loss: 0.6154, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 226/448, Loss: 0.5864, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 227/448, Loss: 0.4188, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 228/448, Loss: 0.3883, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 229/448, Loss: 0.5685, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 230/448, Loss: 0.6141, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 231/448, Loss: 0.6128, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 232/448, Loss: 0.5916, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 233/448, Loss: 0.7195, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 234/448, Loss: 0.6359, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 235/448, Loss: 0.5669, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 236/448, Loss: 0.4124, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 237/448, Loss: 0.7282, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 238/448, Loss: 0.9215, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 239/448, Loss: 0.5357, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 240/448, Loss: 0.4475, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 241/448, Loss: 0.5887, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 242/448, Loss: 0.6544, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 243/448, Loss: 0.5900, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 244/448, Loss: 0.5429, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 245/448, Loss: 0.5994, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 246/448, Loss: 0.7567, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 247/448, Loss: 0.5636, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 248/448, Loss: 0.7081, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 249/448, Loss: 0.4168, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 250/448, Loss: 0.4514, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 251/448, Loss: 0.4807, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 252/448, Loss: 0.5844, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 253/448, Loss: 0.9565, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 254/448, Loss: 0.6412, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 255/448, Loss: 0.7063, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 256/448, Loss: 0.3331, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 257/448, Loss: 0.5809, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 258/448, Loss: 0.5601, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 259/448, Loss: 0.2055, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 260/448, Loss: 0.4716, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 261/448, Loss: 0.3927, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 262/448, Loss: 0.6075, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 263/448, Loss: 0.6153, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 264/448, Loss: 0.5089, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 265/448, Loss: 0.7030, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 266/448, Loss: 0.7426, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 267/448, Loss: 0.5973, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 268/448, Loss: 0.7406, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 269/448, Loss: 0.4193, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 270/448, Loss: 0.5103, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 271/448, Loss: 0.4543, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 272/448, Loss: 0.7149, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 273/448, Loss: 0.7778, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 274/448, Loss: 0.5904, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 275/448, Loss: 0.7008, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 276/448, Loss: 0.5165, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 277/448, Loss: 0.5989, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 278/448, Loss: 0.6812, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 279/448, Loss: 0.7513, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 280/448, Loss: 0.7502, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 281/448, Loss: 0.9143, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 282/448, Loss: 0.4860, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 283/448, Loss: 0.5073, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 284/448, Loss: 0.5817, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 285/448, Loss: 0.4907, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 286/448, Loss: 0.4781, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 287/448, Loss: 0.4651, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 288/448, Loss: 0.5690, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 289/448, Loss: 0.4217, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 290/448, Loss: 0.5977, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 291/448, Loss: 0.6310, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 292/448, Loss: 0.3356, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 293/448, Loss: 0.7049, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 294/448, Loss: 0.4576, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 295/448, Loss: 0.5854, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 296/448, Loss: 0.6641, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 297/448, Loss: 0.3975, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 298/448, Loss: 0.5516, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 299/448, Loss: 0.8182, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 300/448, Loss: 0.7034, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 301/448, Loss: 0.8028, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 302/448, Loss: 0.6025, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 303/448, Loss: 0.6681, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 304/448, Loss: 0.7199, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 305/448, Loss: 0.4026, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 306/448, Loss: 0.3844, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 307/448, Loss: 0.5601, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 308/448, Loss: 0.6757, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 309/448, Loss: 0.4490, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 310/448, Loss: 0.2903, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 311/448, Loss: 0.4856, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 312/448, Loss: 0.7183, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 313/448, Loss: 0.3169, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 314/448, Loss: 0.5887, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 315/448, Loss: 0.4910, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 316/448, Loss: 0.5480, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 317/448, Loss: 0.4881, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 318/448, Loss: 0.5567, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 319/448, Loss: 0.6192, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 320/448, Loss: 0.3287, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 321/448, Loss: 0.5122, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 322/448, Loss: 0.5204, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 323/448, Loss: 0.5252, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 324/448, Loss: 0.8139, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 325/448, Loss: 0.4539, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 326/448, Loss: 0.4197, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 327/448, Loss: 0.7407, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 328/448, Loss: 0.8275, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 329/448, Loss: 0.4525, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 330/448, Loss: 0.8250, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 331/448, Loss: 0.6530, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 332/448, Loss: 0.3475, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 333/448, Loss: 0.4815, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 334/448, Loss: 0.3542, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 335/448, Loss: 0.4682, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 336/448, Loss: 0.6091, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 337/448, Loss: 0.4900, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 338/448, Loss: 0.5180, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 339/448, Loss: 0.3762, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 340/448, Loss: 0.6440, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 341/448, Loss: 0.3523, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 342/448, Loss: 0.5473, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 343/448, Loss: 0.7192, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 344/448, Loss: 0.4507, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 345/448, Loss: 0.3816, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 346/448, Loss: 0.6067, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 347/448, Loss: 0.6244, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 348/448, Loss: 0.3714, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 349/448, Loss: 0.6000, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 350/448, Loss: 0.5215, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 351/448, Loss: 0.9193, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 352/448, Loss: 0.4036, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 353/448, Loss: 0.6800, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 354/448, Loss: 0.8089, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 355/448, Loss: 0.7311, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 356/448, Loss: 0.4888, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 357/448, Loss: 0.5881, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 358/448, Loss: 0.5186, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 359/448, Loss: 0.3665, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 360/448, Loss: 0.5292, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 361/448, Loss: 0.4898, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 362/448, Loss: 0.5471, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 363/448, Loss: 0.3181, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 364/448, Loss: 0.3632, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 365/448, Loss: 0.9409, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 366/448, Loss: 0.4304, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 367/448, Loss: 0.6976, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 368/448, Loss: 0.4610, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 369/448, Loss: 0.6769, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 370/448, Loss: 0.5727, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 371/448, Loss: 0.4169, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 372/448, Loss: 0.3711, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 373/448, Loss: 0.8365, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 374/448, Loss: 0.3604, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 375/448, Loss: 0.5998, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 376/448, Loss: 0.5492, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 377/448, Loss: 0.5085, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 378/448, Loss: 0.3498, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 379/448, Loss: 0.5411, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 380/448, Loss: 0.2126, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 381/448, Loss: 0.7591, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 382/448, Loss: 0.5999, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 383/448, Loss: 0.1424, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 384/448, Loss: 0.7170, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 385/448, Loss: 0.7334, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 386/448, Loss: 0.6071, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 387/448, Loss: 0.7104, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 388/448, Loss: 0.4650, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 389/448, Loss: 0.3960, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 390/448, Loss: 0.8818, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 391/448, Loss: 0.7321, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 392/448, Loss: 0.4027, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 393/448, Loss: 0.7130, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 394/448, Loss: 0.8301, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 395/448, Loss: 0.3785, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 396/448, Loss: 0.7450, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 397/448, Loss: 0.4244, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 398/448, Loss: 0.4879, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 399/448, Loss: 0.4994, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 400/448, Loss: 0.3612, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 401/448, Loss: 0.4132, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 402/448, Loss: 0.3935, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 403/448, Loss: 0.2958, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 404/448, Loss: 0.2863, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 405/448, Loss: 0.5718, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 406/448, Loss: 0.6616, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 407/448, Loss: 0.2485, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 408/448, Loss: 0.5225, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 409/448, Loss: 0.4701, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 410/448, Loss: 0.4160, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 411/448, Loss: 0.6495, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 412/448, Loss: 0.7864, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 413/448, Loss: 0.4482, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 414/448, Loss: 0.3101, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 415/448, Loss: 0.5264, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 416/448, Loss: 0.2731, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 417/448, Loss: 0.6994, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 418/448, Loss: 0.6375, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 419/448, Loss: 0.3741, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 420/448, Loss: 0.3418, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 421/448, Loss: 0.7259, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 422/448, Loss: 0.2893, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 423/448, Loss: 0.5772, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 424/448, Loss: 0.4264, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 425/448, Loss: 0.3399, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 426/448, Loss: 0.3228, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 427/448, Loss: 0.6880, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 428/448, Loss: 0.3881, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 429/448, Loss: 0.5405, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 430/448, Loss: 0.4809, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 431/448, Loss: 0.6168, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 432/448, Loss: 0.2278, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 433/448, Loss: 0.5713, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 434/448, Loss: 0.7470, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 435/448, Loss: 0.3317, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 436/448, Loss: 0.5694, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 437/448, Loss: 0.4245, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 438/448, Loss: 0.4235, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 439/448, Loss: 0.5599, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 440/448, Loss: 0.3934, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 441/448, Loss: 0.3918, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 442/448, Loss: 0.9220, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 443/448, Loss: 0.3512, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 444/448, Loss: 0.7192, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 445/448, Loss: 0.8787, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 446/448, Loss: 0.4535, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 447/448, Loss: 0.6835, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 448/448, Loss: 0.3673, Time: 0.98 seconds\n",
            "Epoch 2/3, Training Loss: 0.5837, Time: 766.29 seconds\n",
            "Validation Loss: 0.5788, Accuracy: 0.7634\n",
            "Epoch 3/3, Batch 1/448, Loss: 0.5705, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 2/448, Loss: 0.3432, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 3/448, Loss: 0.5534, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 4/448, Loss: 0.5468, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 5/448, Loss: 0.6088, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 6/448, Loss: 0.4484, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 7/448, Loss: 0.3764, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 8/448, Loss: 0.3598, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 9/448, Loss: 0.7271, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 10/448, Loss: 0.4861, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 11/448, Loss: 0.2908, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 12/448, Loss: 0.5112, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 13/448, Loss: 0.4438, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 14/448, Loss: 0.5603, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 15/448, Loss: 0.5958, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 16/448, Loss: 0.4735, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 17/448, Loss: 0.6417, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 18/448, Loss: 0.2926, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 19/448, Loss: 0.5402, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 20/448, Loss: 0.6676, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 21/448, Loss: 0.5293, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 22/448, Loss: 0.4391, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 23/448, Loss: 0.8395, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 24/448, Loss: 0.4099, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 25/448, Loss: 0.7297, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 26/448, Loss: 0.5022, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 27/448, Loss: 0.3774, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 28/448, Loss: 0.3168, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 29/448, Loss: 0.3679, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 30/448, Loss: 0.3934, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 31/448, Loss: 0.6624, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 32/448, Loss: 0.3189, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 33/448, Loss: 0.2194, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 34/448, Loss: 0.5090, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 35/448, Loss: 0.4862, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 36/448, Loss: 0.6334, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 37/448, Loss: 0.4604, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 38/448, Loss: 0.6293, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 39/448, Loss: 0.5225, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 40/448, Loss: 0.5300, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 41/448, Loss: 0.5534, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 42/448, Loss: 0.6227, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 43/448, Loss: 0.3593, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 44/448, Loss: 0.1501, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 45/448, Loss: 0.4275, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 46/448, Loss: 0.5988, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 47/448, Loss: 0.2590, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 48/448, Loss: 0.5997, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 49/448, Loss: 0.4053, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 50/448, Loss: 0.5380, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 51/448, Loss: 0.4115, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 52/448, Loss: 0.4261, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 53/448, Loss: 0.6296, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 54/448, Loss: 0.3614, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 55/448, Loss: 0.7836, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 56/448, Loss: 0.6504, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 57/448, Loss: 0.3668, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 58/448, Loss: 0.4096, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 59/448, Loss: 0.3614, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 60/448, Loss: 0.5709, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 61/448, Loss: 0.6542, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 62/448, Loss: 0.4822, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 63/448, Loss: 0.5243, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 64/448, Loss: 0.2774, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 65/448, Loss: 0.3435, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 66/448, Loss: 0.2705, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 67/448, Loss: 0.4697, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 68/448, Loss: 0.6127, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 69/448, Loss: 0.4159, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 70/448, Loss: 0.2738, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 71/448, Loss: 0.4274, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 72/448, Loss: 0.3760, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 73/448, Loss: 0.2248, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 74/448, Loss: 0.5581, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 75/448, Loss: 0.3656, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 76/448, Loss: 0.4674, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 77/448, Loss: 0.3339, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 78/448, Loss: 0.5383, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 79/448, Loss: 0.8718, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 80/448, Loss: 0.0979, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 81/448, Loss: 0.4316, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 82/448, Loss: 0.9487, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 83/448, Loss: 0.6738, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 84/448, Loss: 0.6424, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 85/448, Loss: 0.3572, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 86/448, Loss: 0.4117, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 87/448, Loss: 0.2494, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 88/448, Loss: 0.4426, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 89/448, Loss: 0.6087, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 90/448, Loss: 0.4260, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 91/448, Loss: 0.3952, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 92/448, Loss: 0.3895, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 93/448, Loss: 0.5752, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 94/448, Loss: 0.2863, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 95/448, Loss: 0.2360, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 96/448, Loss: 0.3395, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 97/448, Loss: 0.2810, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 98/448, Loss: 0.2928, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 99/448, Loss: 0.4738, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 100/448, Loss: 0.3375, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 101/448, Loss: 0.5092, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 102/448, Loss: 0.8806, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 103/448, Loss: 0.6468, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 104/448, Loss: 0.3649, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 105/448, Loss: 0.4716, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 106/448, Loss: 0.2866, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 107/448, Loss: 0.2800, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 108/448, Loss: 0.3856, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 109/448, Loss: 0.4160, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 110/448, Loss: 0.3154, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 111/448, Loss: 0.6737, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 112/448, Loss: 0.3226, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 113/448, Loss: 0.5144, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 114/448, Loss: 0.6046, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 115/448, Loss: 0.2794, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 116/448, Loss: 0.5520, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 117/448, Loss: 0.3108, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 118/448, Loss: 0.8081, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 119/448, Loss: 0.6642, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 120/448, Loss: 0.5698, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 121/448, Loss: 0.4769, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 122/448, Loss: 0.9698, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 123/448, Loss: 0.5946, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 124/448, Loss: 0.5531, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 125/448, Loss: 0.6899, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 126/448, Loss: 0.9004, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 127/448, Loss: 0.6293, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 128/448, Loss: 0.7517, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 129/448, Loss: 0.4901, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 130/448, Loss: 0.4962, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 131/448, Loss: 0.5793, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 132/448, Loss: 0.4221, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 133/448, Loss: 0.5843, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 134/448, Loss: 0.5765, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 135/448, Loss: 0.4272, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 136/448, Loss: 0.6205, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 137/448, Loss: 0.4391, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 138/448, Loss: 0.4674, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 139/448, Loss: 0.6373, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 140/448, Loss: 0.3122, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 141/448, Loss: 0.3116, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 142/448, Loss: 0.4097, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 143/448, Loss: 0.4633, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 144/448, Loss: 0.3129, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 145/448, Loss: 0.4971, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 146/448, Loss: 0.3254, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 147/448, Loss: 0.4320, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 148/448, Loss: 0.2514, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 149/448, Loss: 0.5713, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 150/448, Loss: 0.2590, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 151/448, Loss: 0.3526, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 152/448, Loss: 0.2149, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 153/448, Loss: 0.5553, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 154/448, Loss: 0.5170, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 155/448, Loss: 0.5731, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 156/448, Loss: 0.5934, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 157/448, Loss: 0.3028, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 158/448, Loss: 0.1678, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 159/448, Loss: 0.3252, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 160/448, Loss: 0.2790, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 161/448, Loss: 0.6371, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 162/448, Loss: 0.4426, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 163/448, Loss: 0.3731, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 164/448, Loss: 0.5186, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 165/448, Loss: 0.4533, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 166/448, Loss: 0.8441, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 167/448, Loss: 0.4078, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 168/448, Loss: 0.4487, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 169/448, Loss: 0.3641, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 170/448, Loss: 0.5275, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 171/448, Loss: 0.4572, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 172/448, Loss: 0.4451, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 173/448, Loss: 0.4781, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 174/448, Loss: 0.4598, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 175/448, Loss: 0.5551, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 176/448, Loss: 0.4419, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 177/448, Loss: 0.2576, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 178/448, Loss: 0.4201, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 179/448, Loss: 0.2176, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 180/448, Loss: 0.5224, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 181/448, Loss: 0.8270, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 182/448, Loss: 0.6847, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 183/448, Loss: 0.2554, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 184/448, Loss: 0.6085, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 185/448, Loss: 0.3971, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 186/448, Loss: 0.7675, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 187/448, Loss: 0.4198, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 188/448, Loss: 0.3623, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 189/448, Loss: 0.5571, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 190/448, Loss: 0.5750, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 191/448, Loss: 0.4875, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 192/448, Loss: 0.3518, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 193/448, Loss: 0.2980, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 194/448, Loss: 0.5488, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 195/448, Loss: 0.4573, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 196/448, Loss: 0.5508, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 197/448, Loss: 0.5959, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 198/448, Loss: 0.4070, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 199/448, Loss: 0.4053, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 200/448, Loss: 0.3580, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 201/448, Loss: 0.3812, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 202/448, Loss: 0.2518, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 203/448, Loss: 0.3332, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 204/448, Loss: 0.3246, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 205/448, Loss: 0.3199, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 206/448, Loss: 0.7168, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 207/448, Loss: 0.5094, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 208/448, Loss: 0.6970, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 209/448, Loss: 0.4267, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 210/448, Loss: 0.4644, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 211/448, Loss: 0.3284, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 212/448, Loss: 0.6395, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 213/448, Loss: 0.3504, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 214/448, Loss: 0.3606, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 215/448, Loss: 0.6989, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 216/448, Loss: 0.2654, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 217/448, Loss: 0.4559, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 218/448, Loss: 0.5359, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 219/448, Loss: 0.4455, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 220/448, Loss: 0.3398, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 221/448, Loss: 0.2339, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 222/448, Loss: 0.1948, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 223/448, Loss: 0.5116, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 224/448, Loss: 0.6609, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 225/448, Loss: 0.2516, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 226/448, Loss: 0.2792, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 227/448, Loss: 0.1878, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 228/448, Loss: 0.3409, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 229/448, Loss: 0.2393, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 230/448, Loss: 0.1823, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 231/448, Loss: 0.2890, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 232/448, Loss: 0.3910, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 233/448, Loss: 0.5711, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 234/448, Loss: 0.6642, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 235/448, Loss: 0.4711, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 236/448, Loss: 0.5639, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 237/448, Loss: 0.2805, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 238/448, Loss: 0.5117, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 239/448, Loss: 0.3485, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 240/448, Loss: 0.6417, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 241/448, Loss: 0.2028, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 242/448, Loss: 0.5208, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 243/448, Loss: 0.4081, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 244/448, Loss: 0.2822, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 245/448, Loss: 0.5127, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 246/448, Loss: 0.6050, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 247/448, Loss: 0.5571, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 248/448, Loss: 0.4463, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 249/448, Loss: 0.4465, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 250/448, Loss: 0.5374, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 251/448, Loss: 0.5207, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 252/448, Loss: 0.3142, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 253/448, Loss: 0.2832, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 254/448, Loss: 0.2800, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 255/448, Loss: 0.3189, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 256/448, Loss: 0.5534, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 257/448, Loss: 0.2897, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 258/448, Loss: 0.4892, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 259/448, Loss: 0.1357, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 260/448, Loss: 0.3807, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 261/448, Loss: 0.5070, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 262/448, Loss: 0.3007, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 263/448, Loss: 1.0398, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 264/448, Loss: 1.3753, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 265/448, Loss: 0.8849, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 266/448, Loss: 1.4855, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 267/448, Loss: 0.8886, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 268/448, Loss: 0.6369, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 269/448, Loss: 0.5565, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 270/448, Loss: 0.6175, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 271/448, Loss: 0.5599, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 272/448, Loss: 0.5533, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 273/448, Loss: 0.7201, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 274/448, Loss: 0.3035, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 275/448, Loss: 0.4562, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 276/448, Loss: 0.5885, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 277/448, Loss: 0.5490, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 278/448, Loss: 0.3560, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 279/448, Loss: 0.6654, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 280/448, Loss: 0.3732, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 281/448, Loss: 0.4408, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 282/448, Loss: 0.2766, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 283/448, Loss: 0.4396, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 284/448, Loss: 0.5917, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 285/448, Loss: 0.7099, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 286/448, Loss: 0.6432, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 287/448, Loss: 0.5573, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 288/448, Loss: 0.3749, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 289/448, Loss: 0.3952, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 290/448, Loss: 0.7243, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 291/448, Loss: 0.1436, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 292/448, Loss: 0.8906, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 293/448, Loss: 0.4207, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 294/448, Loss: 0.7994, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 295/448, Loss: 0.3479, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 296/448, Loss: 0.4870, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 297/448, Loss: 0.3006, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 298/448, Loss: 0.5435, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 299/448, Loss: 0.3912, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 300/448, Loss: 0.4285, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 301/448, Loss: 0.5097, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 302/448, Loss: 0.4869, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 303/448, Loss: 0.5641, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 304/448, Loss: 0.6035, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 305/448, Loss: 0.5045, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 306/448, Loss: 0.5997, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 307/448, Loss: 0.3488, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 308/448, Loss: 0.5141, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 309/448, Loss: 0.4376, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 310/448, Loss: 0.4507, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 311/448, Loss: 0.5930, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 312/448, Loss: 0.3913, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 313/448, Loss: 0.4367, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 314/448, Loss: 0.4485, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 315/448, Loss: 0.1937, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 316/448, Loss: 0.5168, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 317/448, Loss: 0.3175, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 318/448, Loss: 0.2609, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 319/448, Loss: 0.2752, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 320/448, Loss: 0.3087, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 321/448, Loss: 0.2889, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 322/448, Loss: 0.5150, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 323/448, Loss: 0.3113, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 324/448, Loss: 0.4027, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 325/448, Loss: 0.3395, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 326/448, Loss: 0.5686, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 327/448, Loss: 0.2003, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 328/448, Loss: 0.2685, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 329/448, Loss: 0.3764, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 330/448, Loss: 0.7692, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 331/448, Loss: 0.5825, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 332/448, Loss: 0.2527, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 333/448, Loss: 0.2177, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 334/448, Loss: 0.4509, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 335/448, Loss: 0.7508, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 336/448, Loss: 0.6025, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 337/448, Loss: 0.4758, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 338/448, Loss: 0.3430, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 339/448, Loss: 0.1430, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 340/448, Loss: 0.6979, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 341/448, Loss: 0.2636, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 342/448, Loss: 0.3135, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 343/448, Loss: 0.4215, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 344/448, Loss: 0.4456, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 345/448, Loss: 0.5408, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 346/448, Loss: 0.3770, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 347/448, Loss: 0.2856, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 348/448, Loss: 0.3584, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 349/448, Loss: 0.3165, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 350/448, Loss: 0.5174, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 351/448, Loss: 0.3143, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 352/448, Loss: 0.4385, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 353/448, Loss: 0.4172, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 354/448, Loss: 0.3820, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 355/448, Loss: 0.2256, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 356/448, Loss: 0.5500, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 357/448, Loss: 0.2162, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 358/448, Loss: 0.1659, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 359/448, Loss: 0.2555, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 360/448, Loss: 0.2717, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 361/448, Loss: 0.2348, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 362/448, Loss: 0.2978, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 363/448, Loss: 0.2324, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 364/448, Loss: 0.5135, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 365/448, Loss: 0.6545, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 366/448, Loss: 0.4033, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 367/448, Loss: 0.3878, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 368/448, Loss: 0.3386, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 369/448, Loss: 0.5839, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 370/448, Loss: 0.5931, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 371/448, Loss: 0.2447, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 372/448, Loss: 0.6643, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 373/448, Loss: 0.3930, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 374/448, Loss: 0.3608, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 375/448, Loss: 0.3342, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 376/448, Loss: 0.1697, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 377/448, Loss: 0.2199, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 378/448, Loss: 0.5675, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 379/448, Loss: 0.3800, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 380/448, Loss: 0.1855, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 381/448, Loss: 0.5979, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 382/448, Loss: 0.2754, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 383/448, Loss: 0.1673, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 384/448, Loss: 0.4073, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 385/448, Loss: 0.2223, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 386/448, Loss: 0.8297, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 387/448, Loss: 0.3824, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 388/448, Loss: 0.2104, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 389/448, Loss: 0.6254, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 390/448, Loss: 0.3888, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 391/448, Loss: 0.5135, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 392/448, Loss: 0.2687, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 393/448, Loss: 0.3822, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 394/448, Loss: 0.4073, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 395/448, Loss: 0.3413, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 396/448, Loss: 0.5499, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 397/448, Loss: 0.2087, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 398/448, Loss: 0.3674, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 399/448, Loss: 0.3333, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 400/448, Loss: 0.6721, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 401/448, Loss: 0.4433, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 402/448, Loss: 0.3563, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 403/448, Loss: 0.3229, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 404/448, Loss: 0.4023, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 405/448, Loss: 0.2302, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 406/448, Loss: 0.3176, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 407/448, Loss: 0.5732, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 408/448, Loss: 0.6588, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 409/448, Loss: 0.6970, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 410/448, Loss: 0.2395, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 411/448, Loss: 0.6157, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 412/448, Loss: 0.2689, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 413/448, Loss: 0.4598, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 414/448, Loss: 0.3839, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 415/448, Loss: 0.3086, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 416/448, Loss: 0.4878, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 417/448, Loss: 0.2918, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 418/448, Loss: 0.4833, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 419/448, Loss: 0.3466, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 420/448, Loss: 0.4874, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 421/448, Loss: 0.4122, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 422/448, Loss: 0.3570, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 423/448, Loss: 0.7232, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 424/448, Loss: 0.3159, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 425/448, Loss: 0.4336, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 426/448, Loss: 0.2652, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 427/448, Loss: 0.2275, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 428/448, Loss: 0.2468, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 429/448, Loss: 0.4461, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 430/448, Loss: 0.3218, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 431/448, Loss: 0.2585, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 432/448, Loss: 0.5974, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 433/448, Loss: 0.3052, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 434/448, Loss: 0.4645, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 435/448, Loss: 0.5542, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 436/448, Loss: 0.4076, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 437/448, Loss: 0.4114, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 438/448, Loss: 0.3410, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 439/448, Loss: 0.4709, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 440/448, Loss: 0.3559, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 441/448, Loss: 0.8924, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 442/448, Loss: 0.1394, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 443/448, Loss: 0.6337, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 444/448, Loss: 0.1734, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 445/448, Loss: 0.3771, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 446/448, Loss: 0.2857, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 447/448, Loss: 0.5595, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 448/448, Loss: 0.4358, Time: 0.97 seconds\n",
            "Epoch 3/3, Training Loss: 0.4538, Time: 766.41 seconds\n",
            "Validation Loss: 0.5390, Accuracy: 0.7851\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-14-ba2ef8751743>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(train_dataset[:]['labels'])\n",
            "<ipython-input-13-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Batch 1/447, Loss: 1.2547, Time: 1.65 seconds\n",
            "Epoch 1/3, Batch 2/447, Loss: 1.2984, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 3/447, Loss: 0.9978, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 4/447, Loss: 1.1840, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 5/447, Loss: 1.0817, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 6/447, Loss: 1.0352, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 7/447, Loss: 0.9546, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 8/447, Loss: 0.9682, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 9/447, Loss: 0.9378, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 10/447, Loss: 1.0785, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 11/447, Loss: 1.0574, Time: 1.76 seconds\n",
            "Epoch 1/3, Batch 12/447, Loss: 1.0554, Time: 1.77 seconds\n",
            "Epoch 1/3, Batch 13/447, Loss: 1.0053, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 14/447, Loss: 0.8946, Time: 1.79 seconds\n",
            "Epoch 1/3, Batch 15/447, Loss: 0.9067, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 16/447, Loss: 0.8215, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 17/447, Loss: 1.1692, Time: 1.82 seconds\n",
            "Epoch 1/3, Batch 18/447, Loss: 0.8907, Time: 1.83 seconds\n",
            "Epoch 1/3, Batch 19/447, Loss: 0.9744, Time: 1.82 seconds\n",
            "Epoch 1/3, Batch 20/447, Loss: 0.9774, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 21/447, Loss: 0.9063, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 22/447, Loss: 0.9262, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 23/447, Loss: 0.9779, Time: 1.77 seconds\n",
            "Epoch 1/3, Batch 24/447, Loss: 0.9242, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 25/447, Loss: 0.7517, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 26/447, Loss: 1.2022, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 27/447, Loss: 1.0709, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 28/447, Loss: 0.8948, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 29/447, Loss: 1.2460, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 30/447, Loss: 1.0341, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 31/447, Loss: 1.0844, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 32/447, Loss: 0.8690, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 33/447, Loss: 0.8994, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 34/447, Loss: 0.8085, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 35/447, Loss: 1.0692, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 36/447, Loss: 0.8170, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 37/447, Loss: 0.9041, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 38/447, Loss: 0.9280, Time: 1.65 seconds\n",
            "Epoch 1/3, Batch 39/447, Loss: 0.9036, Time: 1.65 seconds\n",
            "Epoch 1/3, Batch 40/447, Loss: 0.8842, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 41/447, Loss: 0.9006, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 42/447, Loss: 0.8246, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 43/447, Loss: 0.8948, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 44/447, Loss: 0.9328, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 45/447, Loss: 0.8073, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 46/447, Loss: 0.8193, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 47/447, Loss: 0.7720, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 48/447, Loss: 0.8930, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 49/447, Loss: 0.9093, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 50/447, Loss: 1.0197, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 51/447, Loss: 0.9751, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 52/447, Loss: 0.9941, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 53/447, Loss: 0.9432, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 54/447, Loss: 0.7766, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 55/447, Loss: 0.7758, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 56/447, Loss: 0.8637, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 57/447, Loss: 0.9320, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 58/447, Loss: 0.7850, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 59/447, Loss: 0.9849, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 60/447, Loss: 0.8415, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 61/447, Loss: 0.8381, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 62/447, Loss: 0.8366, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 63/447, Loss: 0.9270, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 64/447, Loss: 0.7241, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 65/447, Loss: 0.7847, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 66/447, Loss: 0.6700, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 67/447, Loss: 0.9023, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 68/447, Loss: 0.8885, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 69/447, Loss: 0.7536, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 70/447, Loss: 1.0222, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 71/447, Loss: 0.7677, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 72/447, Loss: 0.8778, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 73/447, Loss: 0.8103, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 74/447, Loss: 0.7450, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 75/447, Loss: 0.8595, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 76/447, Loss: 0.8130, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 77/447, Loss: 0.9290, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 78/447, Loss: 0.7697, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 79/447, Loss: 0.7945, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 80/447, Loss: 0.8089, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 81/447, Loss: 0.8635, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 82/447, Loss: 0.8148, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 83/447, Loss: 0.7119, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 84/447, Loss: 0.9408, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 85/447, Loss: 0.5428, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 86/447, Loss: 0.6843, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 87/447, Loss: 0.7010, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 88/447, Loss: 0.7708, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 89/447, Loss: 0.5978, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 90/447, Loss: 0.7988, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 91/447, Loss: 0.8590, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 92/447, Loss: 0.7066, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 93/447, Loss: 0.7108, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 94/447, Loss: 0.5621, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 95/447, Loss: 0.7170, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 96/447, Loss: 0.7491, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 97/447, Loss: 0.9345, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 98/447, Loss: 0.8496, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 99/447, Loss: 1.0046, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 100/447, Loss: 0.8507, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 101/447, Loss: 0.8454, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 102/447, Loss: 0.6438, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 103/447, Loss: 0.8290, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 104/447, Loss: 0.7306, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 105/447, Loss: 0.7770, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 106/447, Loss: 0.7755, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 107/447, Loss: 0.7381, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 108/447, Loss: 0.6426, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 109/447, Loss: 0.7010, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 110/447, Loss: 0.6942, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 111/447, Loss: 1.0775, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 112/447, Loss: 1.0052, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 113/447, Loss: 0.6625, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 114/447, Loss: 1.0813, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 115/447, Loss: 0.8563, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 116/447, Loss: 1.0882, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 117/447, Loss: 0.9107, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 118/447, Loss: 0.9528, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 119/447, Loss: 0.8015, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 120/447, Loss: 0.8411, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 121/447, Loss: 0.8963, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 122/447, Loss: 0.8482, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 123/447, Loss: 0.8747, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 124/447, Loss: 0.6451, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 125/447, Loss: 0.7239, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 126/447, Loss: 0.7579, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 127/447, Loss: 0.7655, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 128/447, Loss: 0.8956, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 129/447, Loss: 0.9535, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 130/447, Loss: 0.7259, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 131/447, Loss: 0.6609, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 132/447, Loss: 0.7122, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 133/447, Loss: 0.8097, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 134/447, Loss: 0.9457, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 135/447, Loss: 0.7115, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 136/447, Loss: 0.7960, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 137/447, Loss: 0.8518, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 138/447, Loss: 1.0203, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 139/447, Loss: 0.7753, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 140/447, Loss: 0.8385, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 141/447, Loss: 0.8640, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 142/447, Loss: 0.8739, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 143/447, Loss: 0.6424, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 144/447, Loss: 0.9757, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 145/447, Loss: 0.7487, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 146/447, Loss: 0.7017, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 147/447, Loss: 0.7463, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 148/447, Loss: 0.6828, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 149/447, Loss: 0.7025, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 150/447, Loss: 0.5779, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 151/447, Loss: 0.8197, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 152/447, Loss: 0.6589, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 153/447, Loss: 0.7367, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 154/447, Loss: 0.7264, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 155/447, Loss: 0.3872, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 156/447, Loss: 0.7465, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 157/447, Loss: 0.7512, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 158/447, Loss: 1.1460, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 159/447, Loss: 0.7537, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 160/447, Loss: 0.7400, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 161/447, Loss: 0.7526, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 162/447, Loss: 0.6506, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 163/447, Loss: 0.7365, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 164/447, Loss: 0.6344, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 165/447, Loss: 0.8072, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 166/447, Loss: 0.6730, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 167/447, Loss: 0.8980, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 168/447, Loss: 0.7348, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 169/447, Loss: 0.6634, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 170/447, Loss: 0.7690, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 171/447, Loss: 1.0339, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 172/447, Loss: 0.7404, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 173/447, Loss: 0.6732, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 174/447, Loss: 0.5910, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 175/447, Loss: 0.8020, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 176/447, Loss: 0.8249, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 177/447, Loss: 0.7177, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 178/447, Loss: 1.0617, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 179/447, Loss: 0.7518, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 180/447, Loss: 0.6380, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 181/447, Loss: 0.9088, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 182/447, Loss: 0.9779, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 183/447, Loss: 1.0603, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 184/447, Loss: 0.7008, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 185/447, Loss: 0.6654, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 186/447, Loss: 0.7106, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 187/447, Loss: 0.7562, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 188/447, Loss: 0.5564, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 189/447, Loss: 0.8101, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 190/447, Loss: 0.7142, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 191/447, Loss: 0.6894, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 192/447, Loss: 0.6074, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 193/447, Loss: 0.8600, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 194/447, Loss: 0.7692, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 195/447, Loss: 0.8072, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 196/447, Loss: 0.6205, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 197/447, Loss: 0.7761, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 198/447, Loss: 0.8458, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 199/447, Loss: 0.8846, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 200/447, Loss: 0.7254, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 201/447, Loss: 0.5730, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 202/447, Loss: 0.8309, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 203/447, Loss: 0.6181, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 204/447, Loss: 0.6315, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 205/447, Loss: 0.6859, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 206/447, Loss: 0.9126, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 207/447, Loss: 0.5674, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 208/447, Loss: 1.0641, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 209/447, Loss: 0.7364, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 210/447, Loss: 0.6650, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 211/447, Loss: 0.4124, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 212/447, Loss: 0.4542, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 213/447, Loss: 0.6136, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 214/447, Loss: 0.7558, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 215/447, Loss: 0.5267, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 216/447, Loss: 0.5416, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 217/447, Loss: 0.7330, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 218/447, Loss: 0.9518, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 219/447, Loss: 0.8461, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 220/447, Loss: 0.8741, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 221/447, Loss: 0.8523, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 222/447, Loss: 0.7912, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 223/447, Loss: 0.9003, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 224/447, Loss: 0.8750, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 225/447, Loss: 0.6845, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 226/447, Loss: 1.1541, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 227/447, Loss: 0.8569, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 228/447, Loss: 0.9389, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 229/447, Loss: 0.5093, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 230/447, Loss: 0.7140, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 231/447, Loss: 0.6583, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 232/447, Loss: 0.5879, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 233/447, Loss: 0.7657, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 234/447, Loss: 0.6645, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 235/447, Loss: 0.7193, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 236/447, Loss: 0.6631, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 237/447, Loss: 0.9259, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 238/447, Loss: 0.6462, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 239/447, Loss: 0.7286, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 240/447, Loss: 1.2755, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 241/447, Loss: 0.7796, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 242/447, Loss: 0.9208, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 243/447, Loss: 0.7912, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 244/447, Loss: 0.6472, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 245/447, Loss: 0.7568, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 246/447, Loss: 0.8381, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 247/447, Loss: 0.6554, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 248/447, Loss: 0.6757, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 249/447, Loss: 0.7833, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 250/447, Loss: 0.8552, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 251/447, Loss: 0.6895, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 252/447, Loss: 0.8297, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 253/447, Loss: 0.9389, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 254/447, Loss: 0.9062, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 255/447, Loss: 0.6441, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 256/447, Loss: 0.6801, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 257/447, Loss: 0.7086, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 258/447, Loss: 0.8464, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 259/447, Loss: 0.9658, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 260/447, Loss: 1.0184, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 261/447, Loss: 0.9340, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 262/447, Loss: 0.8842, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 263/447, Loss: 0.8253, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 264/447, Loss: 0.6573, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 265/447, Loss: 0.8930, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 266/447, Loss: 0.7104, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 267/447, Loss: 0.6648, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 268/447, Loss: 0.6460, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 269/447, Loss: 0.6790, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 270/447, Loss: 0.6705, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 271/447, Loss: 0.6526, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 272/447, Loss: 0.6293, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 273/447, Loss: 0.7740, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 274/447, Loss: 0.9977, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 275/447, Loss: 0.6000, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 276/447, Loss: 0.6873, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 277/447, Loss: 0.2797, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 278/447, Loss: 0.5740, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 279/447, Loss: 0.6985, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 280/447, Loss: 0.6871, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 281/447, Loss: 0.8265, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 282/447, Loss: 0.5875, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 283/447, Loss: 0.6823, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 284/447, Loss: 0.7887, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 285/447, Loss: 0.9629, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 286/447, Loss: 0.9300, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 287/447, Loss: 0.9059, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 288/447, Loss: 0.9785, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 289/447, Loss: 0.6329, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 290/447, Loss: 0.5680, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 291/447, Loss: 0.7694, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 292/447, Loss: 0.7042, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 293/447, Loss: 0.7256, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 294/447, Loss: 0.7949, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 295/447, Loss: 0.7440, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 296/447, Loss: 0.8980, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 297/447, Loss: 0.5715, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 298/447, Loss: 0.5888, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 299/447, Loss: 0.6325, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 300/447, Loss: 0.5828, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 301/447, Loss: 0.7683, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 302/447, Loss: 0.7759, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 303/447, Loss: 0.6942, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 304/447, Loss: 0.8756, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 305/447, Loss: 0.5093, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 306/447, Loss: 0.5018, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 307/447, Loss: 0.7891, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 308/447, Loss: 0.7951, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 309/447, Loss: 0.5832, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 310/447, Loss: 0.6088, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 311/447, Loss: 0.6518, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 312/447, Loss: 0.5959, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 313/447, Loss: 0.9118, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 314/447, Loss: 0.6003, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 315/447, Loss: 0.8419, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 316/447, Loss: 0.8152, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 317/447, Loss: 0.5729, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 318/447, Loss: 0.7556, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 319/447, Loss: 0.9653, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 320/447, Loss: 0.6215, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 321/447, Loss: 0.6040, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 322/447, Loss: 0.8586, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 323/447, Loss: 0.7322, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 324/447, Loss: 0.8755, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 325/447, Loss: 0.8412, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 326/447, Loss: 0.8683, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 327/447, Loss: 0.5503, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 328/447, Loss: 0.9260, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 329/447, Loss: 0.6894, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 330/447, Loss: 0.7024, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 331/447, Loss: 0.7925, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 332/447, Loss: 0.8199, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 333/447, Loss: 0.7414, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 334/447, Loss: 0.5135, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 335/447, Loss: 0.8065, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 336/447, Loss: 0.8221, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 337/447, Loss: 0.7462, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 338/447, Loss: 0.6123, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 339/447, Loss: 0.9416, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 340/447, Loss: 0.7120, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 341/447, Loss: 0.6920, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 342/447, Loss: 1.0283, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 343/447, Loss: 0.8290, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 344/447, Loss: 0.7962, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 345/447, Loss: 0.5976, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 346/447, Loss: 0.5002, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 347/447, Loss: 0.6922, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 348/447, Loss: 0.8864, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 349/447, Loss: 0.5280, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 350/447, Loss: 0.6595, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 351/447, Loss: 0.7570, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 352/447, Loss: 0.4691, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 353/447, Loss: 0.7227, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 354/447, Loss: 0.5899, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 355/447, Loss: 0.7550, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 356/447, Loss: 0.8771, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 357/447, Loss: 0.6150, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 358/447, Loss: 0.7387, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 359/447, Loss: 0.4721, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 360/447, Loss: 0.7292, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 361/447, Loss: 0.5677, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 362/447, Loss: 0.8105, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 363/447, Loss: 0.6476, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 364/447, Loss: 0.7565, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 365/447, Loss: 0.8515, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 366/447, Loss: 0.5382, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 367/447, Loss: 0.7122, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 368/447, Loss: 0.8162, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 369/447, Loss: 0.7116, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 370/447, Loss: 0.4232, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 371/447, Loss: 0.4786, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 372/447, Loss: 0.6043, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 373/447, Loss: 0.5634, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 374/447, Loss: 0.4629, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 375/447, Loss: 1.1468, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 376/447, Loss: 1.1567, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 377/447, Loss: 0.6657, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 378/447, Loss: 0.7213, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 379/447, Loss: 1.0702, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 380/447, Loss: 0.5078, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 381/447, Loss: 1.1775, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 382/447, Loss: 0.7351, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 383/447, Loss: 0.6850, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 384/447, Loss: 0.6829, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 385/447, Loss: 0.6881, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 386/447, Loss: 0.8945, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 387/447, Loss: 0.9661, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 388/447, Loss: 0.6888, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 389/447, Loss: 0.7646, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 390/447, Loss: 0.7362, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 391/447, Loss: 0.8324, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 392/447, Loss: 0.8446, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 393/447, Loss: 1.1039, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 394/447, Loss: 0.7423, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 395/447, Loss: 0.8610, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 396/447, Loss: 0.7877, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 397/447, Loss: 1.3453, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 398/447, Loss: 0.7566, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 399/447, Loss: 0.9464, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 400/447, Loss: 0.8200, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 401/447, Loss: 0.8249, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 402/447, Loss: 0.5141, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 403/447, Loss: 1.0823, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 404/447, Loss: 0.7465, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 405/447, Loss: 0.7239, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 406/447, Loss: 1.2240, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 407/447, Loss: 0.6420, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 408/447, Loss: 0.9786, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 409/447, Loss: 0.7193, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 410/447, Loss: 0.7000, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 411/447, Loss: 0.8566, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 412/447, Loss: 0.3902, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 413/447, Loss: 0.8776, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 414/447, Loss: 0.8693, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 415/447, Loss: 1.0977, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 416/447, Loss: 0.9501, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 417/447, Loss: 0.7561, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 418/447, Loss: 0.7977, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 419/447, Loss: 0.7518, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 420/447, Loss: 0.8384, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 421/447, Loss: 0.8130, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 422/447, Loss: 0.6864, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 423/447, Loss: 0.6832, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 424/447, Loss: 0.7131, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 425/447, Loss: 0.6650, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 426/447, Loss: 0.4482, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 427/447, Loss: 0.8695, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 428/447, Loss: 0.7574, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 429/447, Loss: 0.4264, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 430/447, Loss: 0.9891, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 431/447, Loss: 0.8266, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 432/447, Loss: 1.2141, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 433/447, Loss: 1.1976, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 434/447, Loss: 0.8644, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 435/447, Loss: 0.4830, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 436/447, Loss: 1.0154, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 437/447, Loss: 0.6245, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 438/447, Loss: 1.3196, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 439/447, Loss: 0.8703, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 440/447, Loss: 1.2213, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 441/447, Loss: 1.1588, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 442/447, Loss: 1.3003, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 443/447, Loss: 1.5280, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 444/447, Loss: 1.2967, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 445/447, Loss: 1.2214, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 446/447, Loss: 1.0667, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 447/447, Loss: 1.9543, Time: 0.16 seconds\n",
            "Epoch 1/3, Training Loss: 0.8046, Time: 764.15 seconds\n",
            "Validation Loss: 1.1513, Accuracy: 0.3623\n",
            "Epoch 2/3, Batch 1/447, Loss: 1.1465, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 2/447, Loss: 0.9128, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 3/447, Loss: 0.9160, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 4/447, Loss: 0.9870, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 5/447, Loss: 0.9841, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 6/447, Loss: 1.2950, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 7/447, Loss: 1.1223, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 8/447, Loss: 0.9909, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 9/447, Loss: 0.9414, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 10/447, Loss: 0.9892, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 11/447, Loss: 1.0748, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 12/447, Loss: 1.1596, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 13/447, Loss: 1.0787, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 14/447, Loss: 0.8994, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 15/447, Loss: 1.0464, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 16/447, Loss: 0.9754, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 17/447, Loss: 1.0931, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 18/447, Loss: 0.9635, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 19/447, Loss: 1.0129, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 20/447, Loss: 0.9475, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 21/447, Loss: 0.9664, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 22/447, Loss: 0.8829, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 23/447, Loss: 1.1215, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 24/447, Loss: 0.9803, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 25/447, Loss: 0.8214, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 26/447, Loss: 0.9751, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 27/447, Loss: 0.9984, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 28/447, Loss: 1.0236, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 29/447, Loss: 0.9080, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 30/447, Loss: 0.8730, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 31/447, Loss: 0.9873, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 32/447, Loss: 0.9040, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 33/447, Loss: 0.7360, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 34/447, Loss: 0.8792, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 35/447, Loss: 0.9305, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 36/447, Loss: 0.9665, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 37/447, Loss: 0.8117, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 38/447, Loss: 0.7109, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 39/447, Loss: 0.9573, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 40/447, Loss: 0.8602, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 41/447, Loss: 0.6838, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 42/447, Loss: 1.0228, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 43/447, Loss: 0.8027, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 44/447, Loss: 0.8188, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 45/447, Loss: 0.7733, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 46/447, Loss: 0.7949, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 47/447, Loss: 0.9056, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 48/447, Loss: 1.5864, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 49/447, Loss: 0.8657, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 50/447, Loss: 0.8734, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 51/447, Loss: 0.8300, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 52/447, Loss: 0.9157, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 53/447, Loss: 0.7264, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 54/447, Loss: 0.7657, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 55/447, Loss: 0.5812, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 56/447, Loss: 0.8367, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 57/447, Loss: 0.5688, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 58/447, Loss: 0.8749, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 59/447, Loss: 0.5468, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 60/447, Loss: 1.0038, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 61/447, Loss: 0.7163, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 62/447, Loss: 0.8379, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 63/447, Loss: 0.7492, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 64/447, Loss: 0.9415, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 65/447, Loss: 0.8722, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 66/447, Loss: 1.1667, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 67/447, Loss: 0.8068, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 68/447, Loss: 0.8257, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 69/447, Loss: 0.6260, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 70/447, Loss: 0.7071, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 71/447, Loss: 0.8742, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 72/447, Loss: 0.8459, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 73/447, Loss: 0.7561, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 74/447, Loss: 0.8529, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 75/447, Loss: 0.7745, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 76/447, Loss: 0.7784, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 77/447, Loss: 0.6857, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 78/447, Loss: 0.7202, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 79/447, Loss: 0.6736, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 80/447, Loss: 0.8087, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 81/447, Loss: 0.9234, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 82/447, Loss: 0.4411, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 83/447, Loss: 0.4717, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 84/447, Loss: 0.6145, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 85/447, Loss: 0.6938, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 86/447, Loss: 1.1062, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 87/447, Loss: 0.8102, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 88/447, Loss: 0.8959, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 89/447, Loss: 0.5891, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 90/447, Loss: 0.7571, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 91/447, Loss: 0.8960, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 92/447, Loss: 0.8255, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 93/447, Loss: 1.0111, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 94/447, Loss: 0.6548, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 95/447, Loss: 0.7540, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 96/447, Loss: 0.9253, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 97/447, Loss: 0.6122, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 98/447, Loss: 0.7034, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 99/447, Loss: 0.5919, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 100/447, Loss: 0.7926, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 101/447, Loss: 0.7849, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 102/447, Loss: 0.7388, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 103/447, Loss: 0.7386, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 104/447, Loss: 0.5830, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 105/447, Loss: 0.5062, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 106/447, Loss: 0.5996, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 107/447, Loss: 0.4830, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 108/447, Loss: 1.0575, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 109/447, Loss: 0.6227, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 110/447, Loss: 0.6694, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 111/447, Loss: 0.7204, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 112/447, Loss: 0.6749, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 113/447, Loss: 0.5395, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 114/447, Loss: 0.6654, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 115/447, Loss: 0.8491, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 116/447, Loss: 0.4826, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 117/447, Loss: 0.8572, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 118/447, Loss: 0.8808, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 119/447, Loss: 0.7287, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 120/447, Loss: 0.6079, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 121/447, Loss: 1.0894, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 122/447, Loss: 0.6632, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 123/447, Loss: 0.7529, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 124/447, Loss: 0.9020, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 125/447, Loss: 0.9587, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 126/447, Loss: 0.8259, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 127/447, Loss: 0.6039, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 128/447, Loss: 1.0122, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 129/447, Loss: 0.7281, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 130/447, Loss: 0.6653, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 131/447, Loss: 0.9742, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 132/447, Loss: 0.7520, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 133/447, Loss: 0.6079, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 134/447, Loss: 0.7347, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 135/447, Loss: 0.7569, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 136/447, Loss: 0.7868, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 137/447, Loss: 0.9270, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 138/447, Loss: 0.8189, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 139/447, Loss: 0.6579, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 140/447, Loss: 0.9013, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 141/447, Loss: 0.5484, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 142/447, Loss: 0.7727, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 143/447, Loss: 0.7945, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 144/447, Loss: 0.9483, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 145/447, Loss: 0.7279, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 146/447, Loss: 0.7914, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 147/447, Loss: 0.5758, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 148/447, Loss: 0.7020, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 149/447, Loss: 0.8328, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 150/447, Loss: 0.7525, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 151/447, Loss: 0.5223, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 152/447, Loss: 0.7608, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 153/447, Loss: 0.6796, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 154/447, Loss: 0.6428, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 155/447, Loss: 0.6694, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 156/447, Loss: 0.8956, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 157/447, Loss: 0.6298, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 158/447, Loss: 0.7189, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 159/447, Loss: 0.7908, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 160/447, Loss: 0.9832, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 161/447, Loss: 0.7120, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 162/447, Loss: 0.6225, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 163/447, Loss: 0.6795, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 164/447, Loss: 0.8584, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 165/447, Loss: 0.6138, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 166/447, Loss: 0.9106, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 167/447, Loss: 0.7724, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 168/447, Loss: 0.7325, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 169/447, Loss: 0.3925, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 170/447, Loss: 0.5806, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 171/447, Loss: 0.4669, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 172/447, Loss: 0.7316, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 173/447, Loss: 0.6338, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 174/447, Loss: 0.7400, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 175/447, Loss: 0.7210, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 176/447, Loss: 0.9171, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 177/447, Loss: 0.5331, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 178/447, Loss: 0.7349, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 179/447, Loss: 0.7622, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 180/447, Loss: 0.7926, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 181/447, Loss: 0.6168, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 182/447, Loss: 0.5184, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 183/447, Loss: 0.9510, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 184/447, Loss: 0.7279, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 185/447, Loss: 0.6195, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 186/447, Loss: 0.9224, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 187/447, Loss: 0.9800, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 188/447, Loss: 0.7139, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 189/447, Loss: 0.7346, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 190/447, Loss: 0.6474, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 191/447, Loss: 0.5826, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 192/447, Loss: 0.4719, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 193/447, Loss: 0.6653, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 194/447, Loss: 0.7065, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 195/447, Loss: 0.7652, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 196/447, Loss: 1.1212, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 197/447, Loss: 0.9951, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 198/447, Loss: 0.5824, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 199/447, Loss: 0.7952, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 200/447, Loss: 0.5383, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 201/447, Loss: 0.6893, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 202/447, Loss: 0.8902, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 203/447, Loss: 0.8062, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 204/447, Loss: 0.9444, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 205/447, Loss: 0.7062, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 206/447, Loss: 0.6888, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 207/447, Loss: 0.8248, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 208/447, Loss: 0.8585, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 209/447, Loss: 0.6512, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 210/447, Loss: 0.6104, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 211/447, Loss: 0.6885, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 212/447, Loss: 0.6097, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 213/447, Loss: 0.7459, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 214/447, Loss: 0.8965, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 215/447, Loss: 0.5209, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 216/447, Loss: 0.6081, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 217/447, Loss: 0.6337, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 218/447, Loss: 0.5591, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 219/447, Loss: 0.6286, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 220/447, Loss: 0.9564, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 221/447, Loss: 0.5706, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 222/447, Loss: 0.8826, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 223/447, Loss: 0.5835, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 224/447, Loss: 0.7711, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 225/447, Loss: 0.6645, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 226/447, Loss: 0.4467, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 227/447, Loss: 0.8498, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 228/447, Loss: 0.4891, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 229/447, Loss: 0.5569, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 230/447, Loss: 0.5934, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 231/447, Loss: 0.5144, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 232/447, Loss: 0.6019, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 233/447, Loss: 0.6688, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 234/447, Loss: 0.7554, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 235/447, Loss: 0.5836, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 236/447, Loss: 0.4983, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 237/447, Loss: 0.4838, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 238/447, Loss: 0.4549, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 239/447, Loss: 0.6541, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 240/447, Loss: 0.5526, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 241/447, Loss: 0.5422, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 242/447, Loss: 0.9408, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 243/447, Loss: 0.6905, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 244/447, Loss: 0.7229, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 245/447, Loss: 1.2987, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 246/447, Loss: 0.7820, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 247/447, Loss: 0.6100, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 248/447, Loss: 0.8605, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 249/447, Loss: 0.6845, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 250/447, Loss: 0.6447, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 251/447, Loss: 0.5616, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 252/447, Loss: 0.5766, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 253/447, Loss: 0.6641, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 254/447, Loss: 0.9173, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 255/447, Loss: 0.9898, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 256/447, Loss: 0.5587, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 257/447, Loss: 0.4732, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 258/447, Loss: 0.5757, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 259/447, Loss: 0.6785, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 260/447, Loss: 0.7385, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 261/447, Loss: 0.7177, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 262/447, Loss: 0.6478, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 263/447, Loss: 0.5636, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 264/447, Loss: 0.4983, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 265/447, Loss: 0.5266, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 266/447, Loss: 0.8075, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 267/447, Loss: 0.6192, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 268/447, Loss: 0.5840, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 269/447, Loss: 0.5920, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 270/447, Loss: 0.5016, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 271/447, Loss: 0.6912, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 272/447, Loss: 0.9652, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 273/447, Loss: 0.5401, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 274/447, Loss: 0.6359, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 275/447, Loss: 0.5917, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 276/447, Loss: 0.3521, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 277/447, Loss: 0.9393, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 278/447, Loss: 0.5273, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 279/447, Loss: 0.4774, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 280/447, Loss: 0.5196, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 281/447, Loss: 0.6191, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 282/447, Loss: 0.6109, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 283/447, Loss: 0.8884, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 284/447, Loss: 0.9819, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 285/447, Loss: 0.5136, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 286/447, Loss: 0.7041, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 287/447, Loss: 0.8275, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 288/447, Loss: 0.7320, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 289/447, Loss: 0.5466, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 290/447, Loss: 0.5709, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 291/447, Loss: 0.4443, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 292/447, Loss: 0.7312, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 293/447, Loss: 0.6106, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 294/447, Loss: 0.7391, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 295/447, Loss: 0.3722, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 296/447, Loss: 0.4499, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 297/447, Loss: 0.8834, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 298/447, Loss: 0.9176, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 299/447, Loss: 0.6837, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 300/447, Loss: 0.3862, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 301/447, Loss: 0.7847, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 302/447, Loss: 0.9553, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 303/447, Loss: 0.5537, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 304/447, Loss: 0.6378, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 305/447, Loss: 1.0450, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 306/447, Loss: 0.8269, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 307/447, Loss: 0.6846, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 308/447, Loss: 0.8127, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 309/447, Loss: 0.4880, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 310/447, Loss: 0.7806, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 311/447, Loss: 0.5034, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 312/447, Loss: 0.5236, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 313/447, Loss: 0.5749, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 314/447, Loss: 0.7875, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 315/447, Loss: 0.5309, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 316/447, Loss: 0.4765, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 317/447, Loss: 0.6432, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 318/447, Loss: 0.6644, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 319/447, Loss: 0.5476, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 320/447, Loss: 0.5847, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 321/447, Loss: 0.8051, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 322/447, Loss: 0.7450, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 323/447, Loss: 0.5898, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 324/447, Loss: 0.6189, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 325/447, Loss: 0.5944, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 326/447, Loss: 0.4313, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 327/447, Loss: 0.6036, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 328/447, Loss: 0.4325, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 329/447, Loss: 0.8781, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 330/447, Loss: 0.6766, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 331/447, Loss: 0.5769, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 332/447, Loss: 0.8032, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 333/447, Loss: 0.8952, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 334/447, Loss: 0.7904, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 335/447, Loss: 0.5798, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 336/447, Loss: 1.0884, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 337/447, Loss: 0.5611, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 338/447, Loss: 0.6123, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 339/447, Loss: 0.5224, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 340/447, Loss: 0.6198, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 341/447, Loss: 0.6980, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 342/447, Loss: 0.4517, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 343/447, Loss: 0.7830, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 344/447, Loss: 0.6866, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 345/447, Loss: 0.6164, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 346/447, Loss: 0.7071, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 347/447, Loss: 0.7659, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 348/447, Loss: 0.5935, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 349/447, Loss: 0.7355, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 350/447, Loss: 0.8586, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 351/447, Loss: 0.7573, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 352/447, Loss: 0.8625, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 353/447, Loss: 0.4127, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 354/447, Loss: 0.8511, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 355/447, Loss: 0.9085, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 356/447, Loss: 0.5181, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 357/447, Loss: 0.6184, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 358/447, Loss: 0.9729, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 359/447, Loss: 0.7754, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 360/447, Loss: 0.5824, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 361/447, Loss: 0.7575, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 362/447, Loss: 0.4930, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 363/447, Loss: 0.7851, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 364/447, Loss: 0.6540, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 365/447, Loss: 0.7038, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 366/447, Loss: 0.7446, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 367/447, Loss: 0.9906, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 368/447, Loss: 1.2073, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 369/447, Loss: 0.5013, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 370/447, Loss: 0.8527, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 371/447, Loss: 0.5848, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 372/447, Loss: 0.6642, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 373/447, Loss: 0.5253, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 374/447, Loss: 0.5891, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 375/447, Loss: 0.4831, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 376/447, Loss: 0.5210, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 377/447, Loss: 0.5416, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 378/447, Loss: 0.5076, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 379/447, Loss: 0.6452, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 380/447, Loss: 0.8406, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 381/447, Loss: 0.6922, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 382/447, Loss: 0.5239, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 383/447, Loss: 0.5102, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 384/447, Loss: 0.7085, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 385/447, Loss: 1.0635, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 386/447, Loss: 0.7767, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 387/447, Loss: 0.4519, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 388/447, Loss: 0.5466, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 389/447, Loss: 0.4373, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 390/447, Loss: 0.5582, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 391/447, Loss: 0.4823, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 392/447, Loss: 0.7959, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 393/447, Loss: 0.6383, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 394/447, Loss: 0.4851, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 395/447, Loss: 0.4926, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 396/447, Loss: 0.6424, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 397/447, Loss: 0.3128, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 398/447, Loss: 0.9123, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 399/447, Loss: 0.2733, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 400/447, Loss: 0.5614, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 401/447, Loss: 0.9522, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 402/447, Loss: 0.2637, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 403/447, Loss: 0.6684, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 404/447, Loss: 0.5714, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 405/447, Loss: 0.6394, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 406/447, Loss: 0.7724, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 407/447, Loss: 0.4557, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 408/447, Loss: 0.4134, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 409/447, Loss: 0.8621, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 410/447, Loss: 0.5038, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 411/447, Loss: 0.4942, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 412/447, Loss: 0.7269, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 413/447, Loss: 0.5460, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 414/447, Loss: 0.6778, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 415/447, Loss: 0.6948, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 416/447, Loss: 0.4569, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 417/447, Loss: 0.3951, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 418/447, Loss: 0.7862, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 419/447, Loss: 0.8826, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 420/447, Loss: 0.6394, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 421/447, Loss: 0.7370, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 422/447, Loss: 0.5688, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 423/447, Loss: 0.6604, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 424/447, Loss: 0.7792, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 425/447, Loss: 0.5246, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 426/447, Loss: 0.4775, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 427/447, Loss: 0.7979, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 428/447, Loss: 0.6307, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 429/447, Loss: 0.8530, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 430/447, Loss: 0.7232, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 431/447, Loss: 0.5306, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 432/447, Loss: 0.4744, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 433/447, Loss: 0.5781, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 434/447, Loss: 0.6728, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 435/447, Loss: 0.6204, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 436/447, Loss: 0.6773, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 437/447, Loss: 0.3672, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 438/447, Loss: 0.6793, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 439/447, Loss: 0.7569, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 440/447, Loss: 0.6070, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 441/447, Loss: 0.5864, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 442/447, Loss: 0.6421, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 443/447, Loss: 0.6744, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 444/447, Loss: 0.6669, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 445/447, Loss: 0.4583, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 446/447, Loss: 0.5518, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 447/447, Loss: 0.6562, Time: 0.14 seconds\n",
            "Epoch 2/3, Training Loss: 0.7213, Time: 762.23 seconds\n",
            "Validation Loss: 0.7152, Accuracy: 0.7223\n",
            "Epoch 3/3, Batch 1/447, Loss: 0.6179, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 2/447, Loss: 0.6726, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 3/447, Loss: 0.8760, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 4/447, Loss: 0.7416, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 5/447, Loss: 0.4848, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 6/447, Loss: 0.8031, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 7/447, Loss: 1.1713, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 8/447, Loss: 0.6088, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 9/447, Loss: 0.5601, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 10/447, Loss: 0.8847, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 11/447, Loss: 1.0297, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 12/447, Loss: 0.6608, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 13/447, Loss: 0.4539, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 14/447, Loss: 1.0053, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 15/447, Loss: 0.9869, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 16/447, Loss: 0.7366, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 17/447, Loss: 0.7152, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 18/447, Loss: 0.6285, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 19/447, Loss: 0.7165, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 20/447, Loss: 0.6993, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 21/447, Loss: 0.5875, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 22/447, Loss: 0.6769, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 23/447, Loss: 0.7514, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 24/447, Loss: 0.5736, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 25/447, Loss: 0.7705, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 26/447, Loss: 0.8064, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 27/447, Loss: 0.5826, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 28/447, Loss: 0.6758, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 29/447, Loss: 0.8291, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 30/447, Loss: 0.6431, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 31/447, Loss: 0.7625, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 32/447, Loss: 0.8466, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 33/447, Loss: 0.4491, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 34/447, Loss: 0.7456, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 35/447, Loss: 0.4475, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 36/447, Loss: 0.8792, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 37/447, Loss: 0.6775, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 38/447, Loss: 0.7512, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 39/447, Loss: 0.7634, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 40/447, Loss: 0.6343, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 41/447, Loss: 0.9062, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 42/447, Loss: 0.7375, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 43/447, Loss: 0.5107, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 44/447, Loss: 0.7976, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 45/447, Loss: 0.5838, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 46/447, Loss: 0.5108, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 47/447, Loss: 0.6689, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 48/447, Loss: 0.3635, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 49/447, Loss: 0.4634, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 50/447, Loss: 0.6250, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 51/447, Loss: 0.6232, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 52/447, Loss: 0.5227, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 53/447, Loss: 0.6614, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 54/447, Loss: 0.5989, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 55/447, Loss: 0.7387, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 56/447, Loss: 0.6417, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 57/447, Loss: 0.5922, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 58/447, Loss: 0.9197, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 59/447, Loss: 0.5105, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 60/447, Loss: 0.5957, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 61/447, Loss: 0.6162, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 62/447, Loss: 0.7355, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 63/447, Loss: 0.5929, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 64/447, Loss: 0.3283, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 65/447, Loss: 0.9203, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 66/447, Loss: 0.6165, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 67/447, Loss: 0.6262, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 68/447, Loss: 0.5964, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 69/447, Loss: 0.6931, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 70/447, Loss: 0.4978, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 71/447, Loss: 0.7890, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 72/447, Loss: 0.9046, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 73/447, Loss: 0.6089, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 74/447, Loss: 0.7418, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 75/447, Loss: 0.6399, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 76/447, Loss: 0.5550, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 77/447, Loss: 0.5785, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 78/447, Loss: 0.5621, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 79/447, Loss: 0.4785, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 80/447, Loss: 0.4832, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 81/447, Loss: 0.6768, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 82/447, Loss: 0.7245, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 83/447, Loss: 0.7123, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 84/447, Loss: 0.7531, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 85/447, Loss: 0.5689, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 86/447, Loss: 0.7429, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 87/447, Loss: 0.7169, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 88/447, Loss: 0.4832, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 89/447, Loss: 0.8138, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 90/447, Loss: 0.8732, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 91/447, Loss: 0.6425, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 92/447, Loss: 0.5211, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 93/447, Loss: 0.5703, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 94/447, Loss: 0.7917, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 95/447, Loss: 0.5330, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 96/447, Loss: 0.7852, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 97/447, Loss: 0.4435, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 98/447, Loss: 0.6063, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 99/447, Loss: 0.5928, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 100/447, Loss: 0.8348, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 101/447, Loss: 0.5111, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 102/447, Loss: 0.5677, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 103/447, Loss: 0.4564, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 104/447, Loss: 0.7088, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 105/447, Loss: 0.4449, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 106/447, Loss: 0.5346, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 107/447, Loss: 0.5553, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 108/447, Loss: 0.9544, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 109/447, Loss: 0.7227, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 110/447, Loss: 0.4004, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 111/447, Loss: 0.5156, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 112/447, Loss: 0.5007, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 113/447, Loss: 0.6621, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 114/447, Loss: 0.6018, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 115/447, Loss: 0.8038, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 116/447, Loss: 0.6342, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 117/447, Loss: 0.5619, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 118/447, Loss: 0.6757, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 119/447, Loss: 0.4967, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 120/447, Loss: 0.7345, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 121/447, Loss: 0.4219, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 122/447, Loss: 0.5511, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 123/447, Loss: 0.5577, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 124/447, Loss: 0.3541, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 125/447, Loss: 0.4852, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 126/447, Loss: 0.3867, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 127/447, Loss: 0.4489, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 128/447, Loss: 0.4768, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 129/447, Loss: 0.7078, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 130/447, Loss: 0.8345, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 131/447, Loss: 0.2962, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 132/447, Loss: 0.5701, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 133/447, Loss: 0.4503, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 134/447, Loss: 0.4865, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 135/447, Loss: 0.5499, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 136/447, Loss: 0.8854, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 137/447, Loss: 0.3436, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 138/447, Loss: 0.9811, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 139/447, Loss: 0.9652, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 140/447, Loss: 0.6869, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 141/447, Loss: 0.4723, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 142/447, Loss: 0.4970, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 143/447, Loss: 0.3818, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 144/447, Loss: 0.3268, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 145/447, Loss: 0.7021, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 146/447, Loss: 0.5671, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 147/447, Loss: 0.9675, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 148/447, Loss: 0.6653, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 149/447, Loss: 0.5501, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 150/447, Loss: 0.3239, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 151/447, Loss: 0.7712, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 152/447, Loss: 0.5406, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 153/447, Loss: 0.2846, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 154/447, Loss: 0.6428, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 155/447, Loss: 0.5948, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 156/447, Loss: 0.6233, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 157/447, Loss: 0.7563, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 158/447, Loss: 0.6617, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 159/447, Loss: 0.4526, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 160/447, Loss: 0.2936, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 161/447, Loss: 0.6541, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 162/447, Loss: 0.3599, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 163/447, Loss: 0.5382, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 164/447, Loss: 0.5021, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 165/447, Loss: 0.8353, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 166/447, Loss: 0.6775, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 167/447, Loss: 0.4028, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 168/447, Loss: 0.7015, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 169/447, Loss: 0.4915, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 170/447, Loss: 0.4751, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 171/447, Loss: 0.7003, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 172/447, Loss: 0.6736, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 173/447, Loss: 0.5463, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 174/447, Loss: 0.3065, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 175/447, Loss: 0.8086, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 176/447, Loss: 0.6073, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 177/447, Loss: 0.3953, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 178/447, Loss: 0.2464, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 179/447, Loss: 0.6715, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 180/447, Loss: 0.2344, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 181/447, Loss: 0.7156, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 182/447, Loss: 0.5541, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 183/447, Loss: 0.4961, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 184/447, Loss: 0.5463, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 185/447, Loss: 0.5578, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 186/447, Loss: 0.9150, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 187/447, Loss: 0.6468, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 188/447, Loss: 0.4451, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 189/447, Loss: 0.5681, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 190/447, Loss: 0.4039, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 191/447, Loss: 0.3826, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 192/447, Loss: 0.5922, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 193/447, Loss: 0.8135, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 194/447, Loss: 0.6256, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 195/447, Loss: 0.4147, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 196/447, Loss: 0.6215, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 197/447, Loss: 0.6506, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 198/447, Loss: 0.2584, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 199/447, Loss: 0.8270, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 200/447, Loss: 0.3586, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 201/447, Loss: 0.9910, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 202/447, Loss: 0.4744, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 203/447, Loss: 0.5850, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 204/447, Loss: 0.8101, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 205/447, Loss: 0.4334, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 206/447, Loss: 0.3899, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 207/447, Loss: 0.7911, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 208/447, Loss: 0.4190, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 209/447, Loss: 0.8485, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 210/447, Loss: 0.4157, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 211/447, Loss: 0.2110, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 212/447, Loss: 0.8008, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 213/447, Loss: 0.8097, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 214/447, Loss: 0.5261, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 215/447, Loss: 0.6676, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 216/447, Loss: 0.3278, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 217/447, Loss: 0.5350, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 218/447, Loss: 0.5216, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 219/447, Loss: 0.4928, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 220/447, Loss: 0.3757, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 221/447, Loss: 0.7592, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 222/447, Loss: 0.4595, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 223/447, Loss: 1.3411, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 224/447, Loss: 0.3699, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 225/447, Loss: 0.5558, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 226/447, Loss: 0.7403, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 227/447, Loss: 0.8936, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 228/447, Loss: 0.7563, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 229/447, Loss: 0.7270, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 230/447, Loss: 0.4446, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 231/447, Loss: 0.6033, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 232/447, Loss: 0.8037, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 233/447, Loss: 0.5430, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 234/447, Loss: 0.4589, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 235/447, Loss: 0.7601, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 236/447, Loss: 0.6140, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 237/447, Loss: 0.6022, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 238/447, Loss: 0.9013, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 239/447, Loss: 0.6017, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 240/447, Loss: 0.5889, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 241/447, Loss: 0.5503, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 242/447, Loss: 0.4824, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 243/447, Loss: 0.4360, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 244/447, Loss: 0.7493, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 245/447, Loss: 0.5381, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 246/447, Loss: 0.5688, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 247/447, Loss: 0.4649, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 248/447, Loss: 0.3633, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 249/447, Loss: 0.5279, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 250/447, Loss: 0.7918, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 251/447, Loss: 0.5326, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 252/447, Loss: 0.6079, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 253/447, Loss: 0.5291, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 254/447, Loss: 0.7152, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 255/447, Loss: 0.6426, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 256/447, Loss: 0.5762, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 257/447, Loss: 0.6207, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 258/447, Loss: 0.4785, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 259/447, Loss: 0.6532, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 260/447, Loss: 0.3613, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 261/447, Loss: 0.7947, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 262/447, Loss: 0.6760, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 263/447, Loss: 0.5296, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 264/447, Loss: 0.4305, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 265/447, Loss: 0.6268, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 266/447, Loss: 0.2498, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 267/447, Loss: 0.8937, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 268/447, Loss: 0.7112, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 269/447, Loss: 0.7894, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 270/447, Loss: 0.7386, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 271/447, Loss: 0.5187, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 272/447, Loss: 0.5093, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 273/447, Loss: 0.3744, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 274/447, Loss: 0.4853, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 275/447, Loss: 0.5709, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 276/447, Loss: 0.7843, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 277/447, Loss: 0.4200, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 278/447, Loss: 0.5247, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 279/447, Loss: 0.5747, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 280/447, Loss: 0.7620, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 281/447, Loss: 0.3441, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 282/447, Loss: 0.4078, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 283/447, Loss: 0.5189, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 284/447, Loss: 0.4315, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 285/447, Loss: 0.4630, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 286/447, Loss: 0.6506, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 287/447, Loss: 0.3428, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 288/447, Loss: 0.6229, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 289/447, Loss: 0.3462, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 290/447, Loss: 0.6302, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 291/447, Loss: 0.8894, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 292/447, Loss: 0.5103, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 293/447, Loss: 0.4313, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 294/447, Loss: 0.7685, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 295/447, Loss: 0.5150, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 296/447, Loss: 0.5225, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 297/447, Loss: 0.4262, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 298/447, Loss: 0.5182, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 299/447, Loss: 1.0303, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 300/447, Loss: 0.6616, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 301/447, Loss: 0.6447, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 302/447, Loss: 0.3907, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 303/447, Loss: 0.5106, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 304/447, Loss: 0.4938, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 305/447, Loss: 0.4130, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 306/447, Loss: 0.6060, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 307/447, Loss: 0.5511, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 308/447, Loss: 0.3414, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 309/447, Loss: 0.5065, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 310/447, Loss: 0.3526, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 311/447, Loss: 0.7463, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 312/447, Loss: 0.3722, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 313/447, Loss: 0.6755, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 314/447, Loss: 0.5899, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 315/447, Loss: 0.6928, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 316/447, Loss: 0.5168, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 317/447, Loss: 0.7543, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 318/447, Loss: 0.4269, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 319/447, Loss: 0.4825, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 320/447, Loss: 0.4049, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 321/447, Loss: 0.6487, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 322/447, Loss: 0.7832, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 323/447, Loss: 0.4293, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 324/447, Loss: 0.3242, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 325/447, Loss: 0.6302, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 326/447, Loss: 0.2276, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 327/447, Loss: 0.5899, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 328/447, Loss: 0.7909, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 329/447, Loss: 0.7204, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 330/447, Loss: 0.6748, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 331/447, Loss: 0.8253, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 332/447, Loss: 0.4965, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 333/447, Loss: 0.6596, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 334/447, Loss: 0.2100, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 335/447, Loss: 0.4090, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 336/447, Loss: 0.3849, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 337/447, Loss: 0.7699, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 338/447, Loss: 0.4581, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 339/447, Loss: 0.5373, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 340/447, Loss: 0.8703, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 341/447, Loss: 0.3292, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 342/447, Loss: 0.3530, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 343/447, Loss: 0.6122, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 344/447, Loss: 0.7450, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 345/447, Loss: 0.4891, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 346/447, Loss: 0.4069, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 347/447, Loss: 0.6691, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 348/447, Loss: 0.7367, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 349/447, Loss: 0.8832, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 350/447, Loss: 0.6396, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 351/447, Loss: 0.5483, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 352/447, Loss: 0.6256, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 353/447, Loss: 0.4996, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 354/447, Loss: 0.4664, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 355/447, Loss: 0.4938, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 356/447, Loss: 0.2921, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 357/447, Loss: 0.8070, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 358/447, Loss: 0.9434, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 359/447, Loss: 0.6019, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 360/447, Loss: 0.7904, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 361/447, Loss: 0.5148, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 362/447, Loss: 0.5687, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 363/447, Loss: 0.3325, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 364/447, Loss: 0.2107, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 365/447, Loss: 0.8095, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 366/447, Loss: 0.4780, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 367/447, Loss: 0.4438, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 368/447, Loss: 0.5483, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 369/447, Loss: 0.3633, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 370/447, Loss: 0.3294, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 371/447, Loss: 0.2761, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 372/447, Loss: 0.5852, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 373/447, Loss: 0.7113, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 374/447, Loss: 0.7305, Time: 1.69 seconds\n",
            "Epoch 3/3, Batch 375/447, Loss: 0.4330, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 376/447, Loss: 0.2390, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 377/447, Loss: 0.5578, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 378/447, Loss: 0.2269, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 379/447, Loss: 0.5159, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 380/447, Loss: 0.4689, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 381/447, Loss: 0.6430, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 382/447, Loss: 0.5689, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 383/447, Loss: 0.4783, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 384/447, Loss: 0.4794, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 385/447, Loss: 1.0164, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 386/447, Loss: 0.6572, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 387/447, Loss: 0.7028, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 388/447, Loss: 0.8216, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 389/447, Loss: 0.3559, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 390/447, Loss: 0.3566, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 391/447, Loss: 0.8249, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 392/447, Loss: 0.5209, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 393/447, Loss: 0.3585, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 394/447, Loss: 0.7671, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 395/447, Loss: 0.4305, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 396/447, Loss: 0.5998, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 397/447, Loss: 0.3591, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 398/447, Loss: 0.8726, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 399/447, Loss: 0.4899, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 400/447, Loss: 0.4958, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 401/447, Loss: 0.9530, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 402/447, Loss: 0.4905, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 403/447, Loss: 0.6119, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 404/447, Loss: 0.4870, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 405/447, Loss: 0.5280, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 406/447, Loss: 0.7772, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 407/447, Loss: 0.4942, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 408/447, Loss: 0.2885, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 409/447, Loss: 0.5098, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 410/447, Loss: 0.8902, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 411/447, Loss: 0.8704, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 412/447, Loss: 0.9829, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 413/447, Loss: 0.5680, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 414/447, Loss: 0.6440, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 415/447, Loss: 0.5753, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 416/447, Loss: 0.6363, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 417/447, Loss: 0.4518, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 418/447, Loss: 0.6616, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 419/447, Loss: 0.5601, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 420/447, Loss: 0.6275, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 421/447, Loss: 0.7377, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 422/447, Loss: 0.6499, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 423/447, Loss: 0.5951, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 424/447, Loss: 0.5656, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 425/447, Loss: 0.4315, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 426/447, Loss: 0.4786, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 427/447, Loss: 0.5437, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 428/447, Loss: 0.6123, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 429/447, Loss: 0.5354, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 430/447, Loss: 0.4416, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 431/447, Loss: 0.3976, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 432/447, Loss: 0.5510, Time: 1.73 seconds\n",
            "Epoch 3/3, Batch 433/447, Loss: 0.5040, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 434/447, Loss: 0.9352, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 435/447, Loss: 0.3086, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 436/447, Loss: 0.6320, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 437/447, Loss: 0.3629, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 438/447, Loss: 0.5717, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 439/447, Loss: 0.7651, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 440/447, Loss: 0.6231, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 441/447, Loss: 0.8491, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 442/447, Loss: 0.4944, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 443/447, Loss: 0.4787, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 444/447, Loss: 0.9939, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 445/447, Loss: 0.6997, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 446/447, Loss: 0.6377, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 447/447, Loss: 0.8209, Time: 0.14 seconds\n",
            "Epoch 3/3, Training Loss: 0.5977, Time: 764.44 seconds\n",
            "Validation Loss: 0.8443, Accuracy: 0.7223\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-14-ba2ef8751743>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(train_dataset[:]['labels'])\n",
            "<ipython-input-13-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Batch 1/448, Loss: 1.1331, Time: 1.65 seconds\n",
            "Epoch 1/3, Batch 2/448, Loss: 1.1015, Time: 1.63 seconds\n",
            "Epoch 1/3, Batch 3/448, Loss: 0.9966, Time: 1.64 seconds\n",
            "Epoch 1/3, Batch 4/448, Loss: 0.9173, Time: 1.66 seconds\n",
            "Epoch 1/3, Batch 5/448, Loss: 1.1090, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 6/448, Loss: 1.2376, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 7/448, Loss: 1.0440, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 8/448, Loss: 1.0115, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 9/448, Loss: 0.8268, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 10/448, Loss: 0.9046, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 11/448, Loss: 0.7123, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 12/448, Loss: 0.8827, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 13/448, Loss: 0.9941, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 14/448, Loss: 0.8919, Time: 1.77 seconds\n",
            "Epoch 1/3, Batch 15/448, Loss: 0.8519, Time: 1.77 seconds\n",
            "Epoch 1/3, Batch 16/448, Loss: 0.8926, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 17/448, Loss: 0.8073, Time: 1.79 seconds\n",
            "Epoch 1/3, Batch 18/448, Loss: 0.7050, Time: 1.79 seconds\n",
            "Epoch 1/3, Batch 19/448, Loss: 0.9028, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 20/448, Loss: 1.1361, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 21/448, Loss: 1.0026, Time: 1.81 seconds\n",
            "Epoch 1/3, Batch 22/448, Loss: 0.9068, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 23/448, Loss: 0.8932, Time: 1.80 seconds\n",
            "Epoch 1/3, Batch 24/448, Loss: 0.9628, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 25/448, Loss: 0.9112, Time: 1.78 seconds\n",
            "Epoch 1/3, Batch 26/448, Loss: 0.9252, Time: 1.76 seconds\n",
            "Epoch 1/3, Batch 27/448, Loss: 0.9211, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 28/448, Loss: 0.9541, Time: 1.75 seconds\n",
            "Epoch 1/3, Batch 29/448, Loss: 0.9191, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 30/448, Loss: 1.0515, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 31/448, Loss: 0.8170, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 32/448, Loss: 0.9856, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 33/448, Loss: 0.9146, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 34/448, Loss: 0.8370, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 35/448, Loss: 0.9678, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 36/448, Loss: 0.8988, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 37/448, Loss: 0.6922, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 38/448, Loss: 0.8927, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 39/448, Loss: 0.8106, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 40/448, Loss: 0.7181, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 41/448, Loss: 1.1673, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 42/448, Loss: 0.7415, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 43/448, Loss: 0.7709, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 44/448, Loss: 0.8693, Time: 1.67 seconds\n",
            "Epoch 1/3, Batch 45/448, Loss: 0.8533, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 46/448, Loss: 0.8567, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 47/448, Loss: 1.0138, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 48/448, Loss: 0.4953, Time: 1.68 seconds\n",
            "Epoch 1/3, Batch 49/448, Loss: 0.9208, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 50/448, Loss: 0.9339, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 51/448, Loss: 0.8787, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 52/448, Loss: 0.8702, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 53/448, Loss: 0.9641, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 54/448, Loss: 0.8702, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 55/448, Loss: 0.8765, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 56/448, Loss: 0.7761, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 57/448, Loss: 1.0765, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 58/448, Loss: 0.9268, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 59/448, Loss: 0.8904, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 60/448, Loss: 0.7934, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 61/448, Loss: 0.9661, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 62/448, Loss: 0.7269, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 63/448, Loss: 0.7639, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 64/448, Loss: 0.6022, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 65/448, Loss: 0.7921, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 66/448, Loss: 0.7112, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 67/448, Loss: 0.8378, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 68/448, Loss: 1.0792, Time: 1.74 seconds\n",
            "Epoch 1/3, Batch 69/448, Loss: 1.0607, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 70/448, Loss: 1.0499, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 71/448, Loss: 0.8141, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 72/448, Loss: 0.8774, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 73/448, Loss: 0.8037, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 74/448, Loss: 0.6518, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 75/448, Loss: 0.7394, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 76/448, Loss: 0.8699, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 77/448, Loss: 0.7365, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 78/448, Loss: 1.0084, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 79/448, Loss: 0.7604, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 80/448, Loss: 0.7572, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 81/448, Loss: 0.8897, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 82/448, Loss: 0.8219, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 83/448, Loss: 0.6976, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 84/448, Loss: 0.9202, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 85/448, Loss: 0.9302, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 86/448, Loss: 0.7214, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 87/448, Loss: 0.8079, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 88/448, Loss: 0.4805, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 89/448, Loss: 0.8222, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 90/448, Loss: 1.0001, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 91/448, Loss: 0.6190, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 92/448, Loss: 0.8626, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 93/448, Loss: 0.9705, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 94/448, Loss: 1.0950, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 95/448, Loss: 0.7169, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 96/448, Loss: 0.7642, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 97/448, Loss: 0.8849, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 98/448, Loss: 0.8296, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 99/448, Loss: 0.7202, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 100/448, Loss: 0.7581, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 101/448, Loss: 0.7995, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 102/448, Loss: 0.7314, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 103/448, Loss: 0.8981, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 104/448, Loss: 0.7242, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 105/448, Loss: 0.7670, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 106/448, Loss: 0.8227, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 107/448, Loss: 0.9129, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 108/448, Loss: 0.6714, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 109/448, Loss: 0.8273, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 110/448, Loss: 1.0904, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 111/448, Loss: 0.9430, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 112/448, Loss: 0.9054, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 113/448, Loss: 1.0212, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 114/448, Loss: 0.9300, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 115/448, Loss: 0.7134, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 116/448, Loss: 0.6555, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 117/448, Loss: 0.8122, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 118/448, Loss: 0.7220, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 119/448, Loss: 0.7857, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 120/448, Loss: 0.8523, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 121/448, Loss: 0.6772, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 122/448, Loss: 0.8425, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 123/448, Loss: 0.5968, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 124/448, Loss: 0.6970, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 125/448, Loss: 0.7140, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 126/448, Loss: 0.7247, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 127/448, Loss: 0.7529, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 128/448, Loss: 0.6569, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 129/448, Loss: 0.9311, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 130/448, Loss: 0.8276, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 131/448, Loss: 0.7577, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 132/448, Loss: 1.0170, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 133/448, Loss: 0.9553, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 134/448, Loss: 0.7100, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 135/448, Loss: 0.8102, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 136/448, Loss: 0.6929, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 137/448, Loss: 0.9942, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 138/448, Loss: 0.8062, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 139/448, Loss: 0.7240, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 140/448, Loss: 0.7991, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 141/448, Loss: 0.8064, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 142/448, Loss: 0.6898, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 143/448, Loss: 0.5893, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 144/448, Loss: 0.7688, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 145/448, Loss: 0.6516, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 146/448, Loss: 0.8935, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 147/448, Loss: 0.7925, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 148/448, Loss: 0.5719, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 149/448, Loss: 0.9209, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 150/448, Loss: 0.9085, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 151/448, Loss: 0.7311, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 152/448, Loss: 0.9098, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 153/448, Loss: 0.8840, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 154/448, Loss: 0.6083, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 155/448, Loss: 0.9315, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 156/448, Loss: 0.6394, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 157/448, Loss: 0.7722, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 158/448, Loss: 0.8027, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 159/448, Loss: 0.8422, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 160/448, Loss: 1.0336, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 161/448, Loss: 0.6790, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 162/448, Loss: 0.8136, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 163/448, Loss: 0.7938, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 164/448, Loss: 0.8990, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 165/448, Loss: 0.7213, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 166/448, Loss: 0.8881, Time: 1.69 seconds\n",
            "Epoch 1/3, Batch 167/448, Loss: 1.0009, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 168/448, Loss: 0.5724, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 169/448, Loss: 0.7208, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 170/448, Loss: 0.8467, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 171/448, Loss: 0.5948, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 172/448, Loss: 1.1768, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 173/448, Loss: 0.5763, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 174/448, Loss: 1.0747, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 175/448, Loss: 0.9911, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 176/448, Loss: 0.7387, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 177/448, Loss: 0.7324, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 178/448, Loss: 0.6899, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 179/448, Loss: 0.6077, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 180/448, Loss: 0.6673, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 181/448, Loss: 0.8827, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 182/448, Loss: 0.6659, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 183/448, Loss: 0.7552, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 184/448, Loss: 0.8611, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 185/448, Loss: 0.7876, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 186/448, Loss: 0.8284, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 187/448, Loss: 0.8376, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 188/448, Loss: 0.8312, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 189/448, Loss: 0.9475, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 190/448, Loss: 0.8568, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 191/448, Loss: 0.9123, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 192/448, Loss: 0.7129, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 193/448, Loss: 0.7204, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 194/448, Loss: 0.7577, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 195/448, Loss: 0.8792, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 196/448, Loss: 0.5870, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 197/448, Loss: 0.5955, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 198/448, Loss: 0.9414, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 199/448, Loss: 1.0638, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 200/448, Loss: 0.8697, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 201/448, Loss: 0.6963, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 202/448, Loss: 0.9826, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 203/448, Loss: 1.2093, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 204/448, Loss: 0.9037, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 205/448, Loss: 1.1090, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 206/448, Loss: 0.8645, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 207/448, Loss: 0.8157, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 208/448, Loss: 0.7739, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 209/448, Loss: 0.6375, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 210/448, Loss: 0.8260, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 211/448, Loss: 0.9492, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 212/448, Loss: 0.7433, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 213/448, Loss: 1.1965, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 214/448, Loss: 0.8900, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 215/448, Loss: 0.7194, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 216/448, Loss: 0.9278, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 217/448, Loss: 0.7397, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 218/448, Loss: 0.9294, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 219/448, Loss: 0.9769, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 220/448, Loss: 0.7106, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 221/448, Loss: 0.8822, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 222/448, Loss: 0.6653, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 223/448, Loss: 0.7063, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 224/448, Loss: 0.5022, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 225/448, Loss: 0.8215, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 226/448, Loss: 0.7532, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 227/448, Loss: 0.9150, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 228/448, Loss: 0.8109, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 229/448, Loss: 0.5188, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 230/448, Loss: 0.7756, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 231/448, Loss: 0.7255, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 232/448, Loss: 0.8396, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 233/448, Loss: 0.6360, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 234/448, Loss: 0.6543, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 235/448, Loss: 0.7160, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 236/448, Loss: 0.9680, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 237/448, Loss: 0.6810, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 238/448, Loss: 0.9702, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 239/448, Loss: 0.7481, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 240/448, Loss: 0.7772, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 241/448, Loss: 0.7964, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 242/448, Loss: 0.6691, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 243/448, Loss: 0.8303, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 244/448, Loss: 0.7693, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 245/448, Loss: 0.6817, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 246/448, Loss: 0.6706, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 247/448, Loss: 0.8226, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 248/448, Loss: 0.7200, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 249/448, Loss: 0.6714, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 250/448, Loss: 0.7427, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 251/448, Loss: 0.8462, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 252/448, Loss: 0.7247, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 253/448, Loss: 0.8620, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 254/448, Loss: 0.8451, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 255/448, Loss: 0.8473, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 256/448, Loss: 0.6282, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 257/448, Loss: 0.7026, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 258/448, Loss: 0.6895, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 259/448, Loss: 0.5933, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 260/448, Loss: 0.8573, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 261/448, Loss: 0.6544, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 262/448, Loss: 0.8427, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 263/448, Loss: 0.8981, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 264/448, Loss: 0.7399, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 265/448, Loss: 0.7054, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 266/448, Loss: 0.6784, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 267/448, Loss: 0.6970, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 268/448, Loss: 0.7305, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 269/448, Loss: 0.7697, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 270/448, Loss: 0.8010, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 271/448, Loss: 0.9042, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 272/448, Loss: 0.8628, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 273/448, Loss: 0.7245, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 274/448, Loss: 0.8150, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 275/448, Loss: 0.9043, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 276/448, Loss: 0.8269, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 277/448, Loss: 0.9007, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 278/448, Loss: 1.1794, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 279/448, Loss: 0.9924, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 280/448, Loss: 0.6855, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 281/448, Loss: 0.7168, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 282/448, Loss: 0.9094, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 283/448, Loss: 1.1165, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 284/448, Loss: 0.7017, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 285/448, Loss: 0.7850, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 286/448, Loss: 0.9550, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 287/448, Loss: 0.7951, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 288/448, Loss: 0.6424, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 289/448, Loss: 0.7762, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 290/448, Loss: 0.6677, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 291/448, Loss: 0.8589, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 292/448, Loss: 1.0796, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 293/448, Loss: 0.8486, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 294/448, Loss: 0.8328, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 295/448, Loss: 0.7302, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 296/448, Loss: 0.7263, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 297/448, Loss: 0.7698, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 298/448, Loss: 0.6419, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 299/448, Loss: 0.5028, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 300/448, Loss: 0.5790, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 301/448, Loss: 0.7901, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 302/448, Loss: 0.5704, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 303/448, Loss: 1.0344, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 304/448, Loss: 0.8134, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 305/448, Loss: 0.8526, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 306/448, Loss: 0.6576, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 307/448, Loss: 0.6178, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 308/448, Loss: 0.7612, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 309/448, Loss: 0.9398, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 310/448, Loss: 0.9056, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 311/448, Loss: 0.6456, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 312/448, Loss: 0.8079, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 313/448, Loss: 0.8740, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 314/448, Loss: 0.7976, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 315/448, Loss: 0.8140, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 316/448, Loss: 0.7436, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 317/448, Loss: 0.7669, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 318/448, Loss: 0.7692, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 319/448, Loss: 0.5870, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 320/448, Loss: 0.8865, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 321/448, Loss: 0.7517, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 322/448, Loss: 0.7329, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 323/448, Loss: 0.9442, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 324/448, Loss: 0.5037, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 325/448, Loss: 0.7468, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 326/448, Loss: 0.6080, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 327/448, Loss: 0.7079, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 328/448, Loss: 0.8553, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 329/448, Loss: 0.6940, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 330/448, Loss: 0.6905, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 331/448, Loss: 0.7180, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 332/448, Loss: 0.6524, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 333/448, Loss: 0.7078, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 334/448, Loss: 0.4971, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 335/448, Loss: 0.4801, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 336/448, Loss: 0.5944, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 337/448, Loss: 0.8316, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 338/448, Loss: 0.7655, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 339/448, Loss: 0.9154, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 340/448, Loss: 0.4756, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 341/448, Loss: 0.5857, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 342/448, Loss: 0.5983, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 343/448, Loss: 1.3040, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 344/448, Loss: 0.7963, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 345/448, Loss: 0.6185, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 346/448, Loss: 0.7310, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 347/448, Loss: 0.4682, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 348/448, Loss: 0.7384, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 349/448, Loss: 0.7292, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 350/448, Loss: 0.6981, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 351/448, Loss: 0.8362, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 352/448, Loss: 0.8237, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 353/448, Loss: 0.6392, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 354/448, Loss: 0.5124, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 355/448, Loss: 0.5309, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 356/448, Loss: 0.8978, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 357/448, Loss: 0.6617, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 358/448, Loss: 0.7614, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 359/448, Loss: 0.6613, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 360/448, Loss: 0.4934, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 361/448, Loss: 0.6728, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 362/448, Loss: 0.9397, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 363/448, Loss: 0.6918, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 364/448, Loss: 0.8309, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 365/448, Loss: 0.6801, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 366/448, Loss: 0.6102, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 367/448, Loss: 0.6850, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 368/448, Loss: 0.5044, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 369/448, Loss: 0.5946, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 370/448, Loss: 0.7304, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 371/448, Loss: 0.9069, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 372/448, Loss: 0.6322, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 373/448, Loss: 0.7922, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 374/448, Loss: 0.4552, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 375/448, Loss: 0.6288, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 376/448, Loss: 0.6743, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 377/448, Loss: 0.5365, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 378/448, Loss: 0.7214, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 379/448, Loss: 0.5105, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 380/448, Loss: 0.4505, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 381/448, Loss: 0.4734, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 382/448, Loss: 0.8360, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 383/448, Loss: 0.4265, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 384/448, Loss: 0.4502, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 385/448, Loss: 0.3970, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 386/448, Loss: 0.7110, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 387/448, Loss: 0.8442, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 388/448, Loss: 0.4305, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 389/448, Loss: 0.7249, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 390/448, Loss: 0.8991, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 391/448, Loss: 0.7620, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 392/448, Loss: 0.6776, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 393/448, Loss: 0.6311, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 394/448, Loss: 0.8231, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 395/448, Loss: 0.9948, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 396/448, Loss: 0.4910, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 397/448, Loss: 0.6597, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 398/448, Loss: 0.5070, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 399/448, Loss: 0.9336, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 400/448, Loss: 0.6409, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 401/448, Loss: 0.7635, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 402/448, Loss: 0.7845, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 403/448, Loss: 0.6094, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 404/448, Loss: 0.6335, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 405/448, Loss: 0.8136, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 406/448, Loss: 0.6604, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 407/448, Loss: 0.7199, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 408/448, Loss: 0.5383, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 409/448, Loss: 0.6504, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 410/448, Loss: 0.8501, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 411/448, Loss: 0.8360, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 412/448, Loss: 0.6483, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 413/448, Loss: 0.4923, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 414/448, Loss: 0.4232, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 415/448, Loss: 0.5763, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 416/448, Loss: 0.5232, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 417/448, Loss: 0.5990, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 418/448, Loss: 0.9179, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 419/448, Loss: 0.5662, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 420/448, Loss: 0.7416, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 421/448, Loss: 0.3621, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 422/448, Loss: 0.6327, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 423/448, Loss: 1.0078, Time: 1.73 seconds\n",
            "Epoch 1/3, Batch 424/448, Loss: 0.9165, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 425/448, Loss: 0.4821, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 426/448, Loss: 0.8934, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 427/448, Loss: 0.3729, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 428/448, Loss: 0.5301, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 429/448, Loss: 0.6082, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 430/448, Loss: 0.4148, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 431/448, Loss: 0.9717, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 432/448, Loss: 0.4509, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 433/448, Loss: 0.8263, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 434/448, Loss: 0.6569, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 435/448, Loss: 0.7260, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 436/448, Loss: 0.3963, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 437/448, Loss: 0.7806, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 438/448, Loss: 0.4316, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 439/448, Loss: 0.4774, Time: 1.72 seconds\n",
            "Epoch 1/3, Batch 440/448, Loss: 1.2366, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 441/448, Loss: 0.8872, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 442/448, Loss: 0.6544, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 443/448, Loss: 0.7020, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 444/448, Loss: 0.7515, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 445/448, Loss: 0.6784, Time: 1.70 seconds\n",
            "Epoch 1/3, Batch 446/448, Loss: 0.4970, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 447/448, Loss: 0.6936, Time: 1.71 seconds\n",
            "Epoch 1/3, Batch 448/448, Loss: 1.1827, Time: 0.35 seconds\n",
            "Epoch 1/3, Training Loss: 0.7811, Time: 766.50 seconds\n",
            "Validation Loss: 0.7227, Accuracy: 0.7063\n",
            "Epoch 2/3, Batch 1/448, Loss: 0.7391, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 2/448, Loss: 0.5357, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 3/448, Loss: 0.4854, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 4/448, Loss: 0.7463, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 5/448, Loss: 0.6376, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 6/448, Loss: 0.5345, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 7/448, Loss: 0.6225, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 8/448, Loss: 0.5761, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 9/448, Loss: 0.8018, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 10/448, Loss: 0.5858, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 11/448, Loss: 0.6936, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 12/448, Loss: 0.3477, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 13/448, Loss: 0.4412, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 14/448, Loss: 0.4576, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 15/448, Loss: 0.8031, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 16/448, Loss: 0.8620, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 17/448, Loss: 0.4814, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 18/448, Loss: 0.6242, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 19/448, Loss: 0.8415, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 20/448, Loss: 0.8080, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 21/448, Loss: 0.6193, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 22/448, Loss: 0.4788, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 23/448, Loss: 0.4841, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 24/448, Loss: 0.8279, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 25/448, Loss: 0.6614, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 26/448, Loss: 0.4022, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 27/448, Loss: 0.5159, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 28/448, Loss: 0.5718, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 29/448, Loss: 0.7627, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 30/448, Loss: 0.5872, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 31/448, Loss: 0.4504, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 32/448, Loss: 0.4237, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 33/448, Loss: 0.6088, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 34/448, Loss: 0.6877, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 35/448, Loss: 0.3194, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 36/448, Loss: 0.4893, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 37/448, Loss: 0.6886, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 38/448, Loss: 0.3427, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 39/448, Loss: 0.6027, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 40/448, Loss: 0.7827, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 41/448, Loss: 0.6584, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 42/448, Loss: 0.6251, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 43/448, Loss: 1.0838, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 44/448, Loss: 0.7567, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 45/448, Loss: 0.8533, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 46/448, Loss: 0.9093, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 47/448, Loss: 0.6263, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 48/448, Loss: 0.5017, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 49/448, Loss: 0.5763, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 50/448, Loss: 0.8652, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 51/448, Loss: 0.8202, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 52/448, Loss: 0.6170, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 53/448, Loss: 0.6456, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 54/448, Loss: 0.7536, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 55/448, Loss: 0.7230, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 56/448, Loss: 0.6307, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 57/448, Loss: 0.5101, Time: 1.69 seconds\n",
            "Epoch 2/3, Batch 58/448, Loss: 0.4721, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 59/448, Loss: 0.4829, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 60/448, Loss: 0.4560, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 61/448, Loss: 0.7760, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 62/448, Loss: 0.5717, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 63/448, Loss: 0.3784, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 64/448, Loss: 0.7447, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 65/448, Loss: 0.6266, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 66/448, Loss: 0.7693, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 67/448, Loss: 0.8643, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 68/448, Loss: 0.5995, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 69/448, Loss: 0.3696, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 70/448, Loss: 0.7364, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 71/448, Loss: 0.4557, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 72/448, Loss: 0.6943, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 73/448, Loss: 0.8350, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 74/448, Loss: 0.4830, Time: 1.73 seconds\n",
            "Epoch 2/3, Batch 75/448, Loss: 0.8427, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 76/448, Loss: 0.8790, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 77/448, Loss: 0.8859, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 78/448, Loss: 0.5820, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 79/448, Loss: 0.7959, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 80/448, Loss: 0.3394, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 81/448, Loss: 0.4683, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 82/448, Loss: 0.6404, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 83/448, Loss: 0.7604, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 84/448, Loss: 0.4956, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 85/448, Loss: 0.3856, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 86/448, Loss: 0.7186, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 87/448, Loss: 0.7182, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 88/448, Loss: 0.5188, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 89/448, Loss: 0.4233, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 90/448, Loss: 0.5338, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 91/448, Loss: 0.5352, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 92/448, Loss: 0.5043, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 93/448, Loss: 0.2965, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 94/448, Loss: 0.4981, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 95/448, Loss: 0.8129, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 96/448, Loss: 0.8865, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 97/448, Loss: 0.6422, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 98/448, Loss: 0.6010, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 99/448, Loss: 0.7117, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 100/448, Loss: 0.3398, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 101/448, Loss: 1.1617, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 102/448, Loss: 0.9104, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 103/448, Loss: 1.0172, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 104/448, Loss: 0.6777, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 105/448, Loss: 0.5672, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 106/448, Loss: 0.4961, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 107/448, Loss: 0.7849, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 108/448, Loss: 0.5416, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 109/448, Loss: 0.5209, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 110/448, Loss: 0.4316, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 111/448, Loss: 0.4795, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 112/448, Loss: 0.4174, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 113/448, Loss: 0.7064, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 114/448, Loss: 0.5182, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 115/448, Loss: 0.7027, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 116/448, Loss: 0.6695, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 117/448, Loss: 0.6636, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 118/448, Loss: 0.6695, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 119/448, Loss: 0.3801, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 120/448, Loss: 0.6760, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 121/448, Loss: 0.7679, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 122/448, Loss: 0.5293, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 123/448, Loss: 0.5611, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 124/448, Loss: 0.4899, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 125/448, Loss: 0.4266, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 126/448, Loss: 0.2386, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 127/448, Loss: 0.5178, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 128/448, Loss: 0.5479, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 129/448, Loss: 0.3979, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 130/448, Loss: 0.6032, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 131/448, Loss: 0.5025, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 132/448, Loss: 0.6254, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 133/448, Loss: 0.4183, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 134/448, Loss: 0.6697, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 135/448, Loss: 0.7608, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 136/448, Loss: 0.6222, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 137/448, Loss: 0.2904, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 138/448, Loss: 0.4598, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 139/448, Loss: 0.6707, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 140/448, Loss: 0.5157, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 141/448, Loss: 0.8032, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 142/448, Loss: 0.8441, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 143/448, Loss: 0.7155, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 144/448, Loss: 0.5532, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 145/448, Loss: 0.5393, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 146/448, Loss: 0.2420, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 147/448, Loss: 0.4025, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 148/448, Loss: 0.7063, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 149/448, Loss: 0.6105, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 150/448, Loss: 0.8446, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 151/448, Loss: 0.5624, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 152/448, Loss: 0.6564, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 153/448, Loss: 0.4977, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 154/448, Loss: 0.5481, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 155/448, Loss: 0.3084, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 156/448, Loss: 0.4197, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 157/448, Loss: 0.4846, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 158/448, Loss: 0.4223, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 159/448, Loss: 0.3887, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 160/448, Loss: 0.9479, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 161/448, Loss: 0.4160, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 162/448, Loss: 0.3112, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 163/448, Loss: 0.3828, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 164/448, Loss: 0.6043, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 165/448, Loss: 0.6503, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 166/448, Loss: 0.4710, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 167/448, Loss: 0.4660, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 168/448, Loss: 0.7995, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 169/448, Loss: 0.9503, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 170/448, Loss: 0.6100, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 171/448, Loss: 0.4777, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 172/448, Loss: 0.6002, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 173/448, Loss: 0.6566, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 174/448, Loss: 0.4941, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 175/448, Loss: 0.6516, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 176/448, Loss: 0.4810, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 177/448, Loss: 0.2809, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 178/448, Loss: 0.4931, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 179/448, Loss: 0.4525, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 180/448, Loss: 0.7129, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 181/448, Loss: 0.7029, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 182/448, Loss: 0.4314, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 183/448, Loss: 0.4448, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 184/448, Loss: 0.4116, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 185/448, Loss: 0.5035, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 186/448, Loss: 0.6208, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 187/448, Loss: 0.7992, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 188/448, Loss: 0.7137, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 189/448, Loss: 0.7342, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 190/448, Loss: 0.6908, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 191/448, Loss: 0.6444, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 192/448, Loss: 0.5026, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 193/448, Loss: 0.6456, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 194/448, Loss: 0.4428, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 195/448, Loss: 0.6438, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 196/448, Loss: 0.7498, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 197/448, Loss: 0.5255, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 198/448, Loss: 0.6557, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 199/448, Loss: 0.5370, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 200/448, Loss: 0.5082, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 201/448, Loss: 0.3916, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 202/448, Loss: 0.6617, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 203/448, Loss: 0.3819, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 204/448, Loss: 0.4618, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 205/448, Loss: 0.2934, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 206/448, Loss: 0.5954, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 207/448, Loss: 0.7678, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 208/448, Loss: 0.3464, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 209/448, Loss: 0.5385, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 210/448, Loss: 0.7012, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 211/448, Loss: 0.4486, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 212/448, Loss: 0.4599, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 213/448, Loss: 0.3339, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 214/448, Loss: 0.4805, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 215/448, Loss: 0.7602, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 216/448, Loss: 0.3262, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 217/448, Loss: 0.4676, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 218/448, Loss: 0.3543, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 219/448, Loss: 0.5227, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 220/448, Loss: 0.4727, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 221/448, Loss: 0.5343, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 222/448, Loss: 0.2652, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 223/448, Loss: 0.5308, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 224/448, Loss: 0.6960, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 225/448, Loss: 0.3551, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 226/448, Loss: 0.4216, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 227/448, Loss: 0.4306, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 228/448, Loss: 0.7233, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 229/448, Loss: 0.4176, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 230/448, Loss: 0.4892, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 231/448, Loss: 0.3434, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 232/448, Loss: 0.5769, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 233/448, Loss: 0.6938, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 234/448, Loss: 0.6976, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 235/448, Loss: 0.4012, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 236/448, Loss: 0.3998, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 237/448, Loss: 0.6338, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 238/448, Loss: 0.6402, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 239/448, Loss: 0.6656, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 240/448, Loss: 0.3996, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 241/448, Loss: 0.5522, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 242/448, Loss: 0.5221, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 243/448, Loss: 0.8182, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 244/448, Loss: 0.8739, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 245/448, Loss: 0.3724, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 246/448, Loss: 0.2950, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 247/448, Loss: 0.1774, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 248/448, Loss: 0.6413, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 249/448, Loss: 0.6006, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 250/448, Loss: 0.6938, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 251/448, Loss: 0.4115, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 252/448, Loss: 0.5923, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 253/448, Loss: 0.5667, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 254/448, Loss: 0.3257, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 255/448, Loss: 1.0114, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 256/448, Loss: 0.2937, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 257/448, Loss: 0.5760, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 258/448, Loss: 0.6732, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 259/448, Loss: 0.5383, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 260/448, Loss: 0.7236, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 261/448, Loss: 0.5449, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 262/448, Loss: 0.5930, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 263/448, Loss: 0.5074, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 264/448, Loss: 0.5348, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 265/448, Loss: 0.6783, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 266/448, Loss: 0.8542, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 267/448, Loss: 0.5098, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 268/448, Loss: 0.6502, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 269/448, Loss: 0.7578, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 270/448, Loss: 0.5449, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 271/448, Loss: 0.7801, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 272/448, Loss: 0.4921, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 273/448, Loss: 0.5001, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 274/448, Loss: 0.5174, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 275/448, Loss: 0.5736, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 276/448, Loss: 0.6407, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 277/448, Loss: 0.3880, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 278/448, Loss: 0.4138, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 279/448, Loss: 0.4083, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 280/448, Loss: 0.7376, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 281/448, Loss: 0.6068, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 282/448, Loss: 0.4328, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 283/448, Loss: 0.7403, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 284/448, Loss: 0.4956, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 285/448, Loss: 0.6037, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 286/448, Loss: 0.4601, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 287/448, Loss: 0.6089, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 288/448, Loss: 0.4747, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 289/448, Loss: 0.4381, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 290/448, Loss: 0.5070, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 291/448, Loss: 0.3663, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 292/448, Loss: 0.4664, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 293/448, Loss: 0.5703, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 294/448, Loss: 0.2328, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 295/448, Loss: 0.4714, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 296/448, Loss: 0.1794, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 297/448, Loss: 0.5087, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 298/448, Loss: 0.5450, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 299/448, Loss: 0.3294, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 300/448, Loss: 0.3727, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 301/448, Loss: 0.8400, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 302/448, Loss: 0.7530, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 303/448, Loss: 0.8446, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 304/448, Loss: 0.9102, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 305/448, Loss: 0.4091, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 306/448, Loss: 0.2824, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 307/448, Loss: 0.6289, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 308/448, Loss: 0.6325, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 309/448, Loss: 0.5403, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 310/448, Loss: 0.9207, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 311/448, Loss: 0.5003, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 312/448, Loss: 0.4655, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 313/448, Loss: 0.5422, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 314/448, Loss: 0.6100, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 315/448, Loss: 0.6856, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 316/448, Loss: 0.5144, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 317/448, Loss: 0.5794, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 318/448, Loss: 0.7527, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 319/448, Loss: 0.4673, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 320/448, Loss: 0.4520, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 321/448, Loss: 0.3057, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 322/448, Loss: 0.8683, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 323/448, Loss: 0.4468, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 324/448, Loss: 0.4925, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 325/448, Loss: 0.6388, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 326/448, Loss: 0.4218, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 327/448, Loss: 0.4126, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 328/448, Loss: 0.8608, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 329/448, Loss: 0.5527, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 330/448, Loss: 0.8559, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 331/448, Loss: 0.9111, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 332/448, Loss: 0.5649, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 333/448, Loss: 0.6036, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 334/448, Loss: 0.7755, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 335/448, Loss: 0.4495, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 336/448, Loss: 0.7552, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 337/448, Loss: 0.6782, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 338/448, Loss: 0.3596, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 339/448, Loss: 0.3493, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 340/448, Loss: 0.4953, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 341/448, Loss: 0.5834, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 342/448, Loss: 0.3086, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 343/448, Loss: 0.7677, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 344/448, Loss: 0.5276, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 345/448, Loss: 0.8206, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 346/448, Loss: 0.4275, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 347/448, Loss: 0.3258, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 348/448, Loss: 0.7317, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 349/448, Loss: 0.3179, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 350/448, Loss: 0.4674, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 351/448, Loss: 0.5975, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 352/448, Loss: 0.5033, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 353/448, Loss: 0.4566, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 354/448, Loss: 0.5085, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 355/448, Loss: 0.7921, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 356/448, Loss: 0.6960, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 357/448, Loss: 0.3073, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 358/448, Loss: 0.5189, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 359/448, Loss: 0.2731, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 360/448, Loss: 0.7721, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 361/448, Loss: 0.3307, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 362/448, Loss: 0.2947, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 363/448, Loss: 0.1928, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 364/448, Loss: 0.6369, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 365/448, Loss: 0.6147, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 366/448, Loss: 0.2978, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 367/448, Loss: 0.5491, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 368/448, Loss: 0.4616, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 369/448, Loss: 0.2585, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 370/448, Loss: 0.4840, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 371/448, Loss: 0.5503, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 372/448, Loss: 0.2888, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 373/448, Loss: 0.4526, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 374/448, Loss: 0.4403, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 375/448, Loss: 0.4773, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 376/448, Loss: 0.5718, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 377/448, Loss: 0.7211, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 378/448, Loss: 0.4750, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 379/448, Loss: 0.4311, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 380/448, Loss: 0.2472, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 381/448, Loss: 0.2983, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 382/448, Loss: 0.2555, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 383/448, Loss: 0.4133, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 384/448, Loss: 0.5034, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 385/448, Loss: 0.4286, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 386/448, Loss: 0.4249, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 387/448, Loss: 0.5335, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 388/448, Loss: 0.4348, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 389/448, Loss: 0.2574, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 390/448, Loss: 1.0115, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 391/448, Loss: 0.9954, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 392/448, Loss: 0.3109, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 393/448, Loss: 0.8117, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 394/448, Loss: 0.6839, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 395/448, Loss: 0.4803, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 396/448, Loss: 0.3859, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 397/448, Loss: 0.3716, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 398/448, Loss: 0.5600, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 399/448, Loss: 0.5160, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 400/448, Loss: 0.6745, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 401/448, Loss: 0.4226, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 402/448, Loss: 0.7253, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 403/448, Loss: 0.4346, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 404/448, Loss: 0.7401, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 405/448, Loss: 0.5280, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 406/448, Loss: 0.7300, Time: 1.72 seconds\n",
            "Epoch 2/3, Batch 407/448, Loss: 0.5693, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 408/448, Loss: 0.3015, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 409/448, Loss: 0.3740, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 410/448, Loss: 0.7177, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 411/448, Loss: 0.5470, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 412/448, Loss: 0.4744, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 413/448, Loss: 0.6039, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 414/448, Loss: 0.4239, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 415/448, Loss: 0.3900, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 416/448, Loss: 0.5813, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 417/448, Loss: 0.7765, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 418/448, Loss: 0.2473, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 419/448, Loss: 0.2281, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 420/448, Loss: 0.2897, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 421/448, Loss: 0.4800, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 422/448, Loss: 0.5057, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 423/448, Loss: 0.2117, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 424/448, Loss: 0.4206, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 425/448, Loss: 0.5354, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 426/448, Loss: 0.2869, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 427/448, Loss: 0.3449, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 428/448, Loss: 0.5581, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 429/448, Loss: 0.2845, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 430/448, Loss: 0.2232, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 431/448, Loss: 0.6804, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 432/448, Loss: 0.5390, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 433/448, Loss: 0.6078, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 434/448, Loss: 0.4401, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 435/448, Loss: 0.5074, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 436/448, Loss: 0.3306, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 437/448, Loss: 0.5082, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 438/448, Loss: 0.7069, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 439/448, Loss: 0.6118, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 440/448, Loss: 0.3442, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 441/448, Loss: 0.6153, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 442/448, Loss: 0.4635, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 443/448, Loss: 0.5583, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 444/448, Loss: 0.4403, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 445/448, Loss: 0.3300, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 446/448, Loss: 0.7758, Time: 1.70 seconds\n",
            "Epoch 2/3, Batch 447/448, Loss: 0.4325, Time: 1.71 seconds\n",
            "Epoch 2/3, Batch 448/448, Loss: 1.6173, Time: 0.35 seconds\n",
            "Epoch 2/3, Training Loss: 0.5603, Time: 766.36 seconds\n",
            "Validation Loss: 0.5714, Accuracy: 0.7897\n",
            "Epoch 3/3, Batch 1/448, Loss: 0.3558, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 2/448, Loss: 0.3860, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 3/448, Loss: 0.3896, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 4/448, Loss: 0.2189, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 5/448, Loss: 0.5955, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 6/448, Loss: 0.5094, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 7/448, Loss: 0.3007, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 8/448, Loss: 0.5547, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 9/448, Loss: 0.3770, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 10/448, Loss: 0.5846, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 11/448, Loss: 0.5197, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 12/448, Loss: 0.3999, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 13/448, Loss: 0.8179, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 14/448, Loss: 0.5800, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 15/448, Loss: 0.4055, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 16/448, Loss: 0.4120, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 17/448, Loss: 0.6552, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 18/448, Loss: 0.4188, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 19/448, Loss: 0.5031, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 20/448, Loss: 0.3549, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 21/448, Loss: 0.4331, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 22/448, Loss: 0.5808, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 23/448, Loss: 0.4384, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 24/448, Loss: 0.3164, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 25/448, Loss: 0.5790, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 26/448, Loss: 0.5053, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 27/448, Loss: 0.4917, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 28/448, Loss: 0.2665, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 29/448, Loss: 0.4385, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 30/448, Loss: 0.3852, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 31/448, Loss: 0.5993, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 32/448, Loss: 0.3500, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 33/448, Loss: 0.3035, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 34/448, Loss: 0.5903, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 35/448, Loss: 0.3054, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 36/448, Loss: 0.2880, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 37/448, Loss: 0.3493, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 38/448, Loss: 0.4567, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 39/448, Loss: 0.5632, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 40/448, Loss: 0.6391, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 41/448, Loss: 0.0877, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 42/448, Loss: 0.6215, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 43/448, Loss: 0.6523, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 44/448, Loss: 0.7689, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 45/448, Loss: 0.1940, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 46/448, Loss: 0.6162, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 47/448, Loss: 0.3824, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 48/448, Loss: 0.8446, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 49/448, Loss: 0.5718, Time: 1.72 seconds\n",
            "Epoch 3/3, Batch 50/448, Loss: 0.4721, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 51/448, Loss: 0.5208, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 52/448, Loss: 0.2756, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 53/448, Loss: 0.3961, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 54/448, Loss: 0.5353, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 55/448, Loss: 0.4185, Time: 1.70 seconds\n",
            "Epoch 3/3, Batch 56/448, Loss: 0.2472, Time: 1.71 seconds\n",
            "Epoch 3/3, Batch 57/448, Loss: 0.4445, Time: 1.71 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate mean accuracy and mean validation loss across all folds\n",
        "mean_accuracy_across_folds = np.mean(all_accuracies)\n",
        "mean_val_loss_across_folds = np.mean(all_val_losses)\n",
        "\n",
        "print(f\"Mean Accuracy Across Folds: {mean_accuracy_across_folds:.4f}\")\n",
        "print(f\"Mean Validation Loss Across Folds: {mean_val_loss_across_folds:.4f}\")\n",
        "\n",
        "# Plot training and validation losses for each fold\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Plot training losses\n",
        "plt.subplot(1, 2, 1)\n",
        "for fold, train_loss_fold in enumerate(all_train_losses, start=1):\n",
        "    plt.plot(range(1, num_epochs + 1), train_loss_fold, label=f\"Fold {fold} - Train Loss\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Across Folds\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation losses for each fold and epoch\n",
        "plt.figure(figsize=(12, 6))\n",
        "for fold in range(num_folds):\n",
        "    fold_val_losses = all_val_losses[fold * num_epochs: (fold + 1) * num_epochs]\n",
        "    plt.plot(range(1, len(fold_val_losses) + 1), fold_val_losses, marker='o', label=f\"Fold {fold + 1}\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.title(\"Validation Loss Across Folds and Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rsINqAFH9u2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "# Number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Plot each fold\n",
        "plt.figure(figsize=(12, 8))\n",
        "for fold in range(num_folds):\n",
        "    start_idx = fold * num_epochs\n",
        "    end_idx = (fold + 1) * num_epochs\n",
        "    accuracies_fold = all_accuracies[start_idx:end_idx]\n",
        "    plt.plot(range(1, num_epochs + 1), accuracies_fold, label=f\"Fold {fold + 1}\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy for Each Fold Across Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IDGu_HS9Yc9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE"
      ],
      "metadata": {
        "id": "z8U6Sy7PMFTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_logs = pd.read_csv('chunked_new.csv')\n",
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vqx5oCjtMt_0",
        "outputId": "58e92eaa-5ce5-40ee-8fab-f80b816534cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                         LogContent  \\\n",
              "0              0  metrics2. impl. metricsconfig : loaded propert...   \n",
              "1              1  . maptask : ( equator ) 0 kvi 26214396 ( 10485...   \n",
              "2              2  ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...   \n",
              "3              3  : kvstart = 7281300 ( 29125200 ) ; kvend = 210...   \n",
              "4              4  ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...   \n",
              "...          ...                                                ...   \n",
              "4369        4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...   \n",
              "4370        4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...   \n",
              "4371        4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...   \n",
              "4372        4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...   \n",
              "4373        4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...   \n",
              "\n",
              "        RootCause  \n",
              "0     MachineDown  \n",
              "1     MachineDown  \n",
              "2     MachineDown  \n",
              "3     MachineDown  \n",
              "4     MachineDown  \n",
              "...           ...  \n",
              "4369  MachineDown  \n",
              "4370  MachineDown  \n",
              "4371  MachineDown  \n",
              "4372  MachineDown  \n",
              "4373  MachineDown  \n",
              "\n",
              "[4374 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95912ddf-ee35-43a1-928d-0ac8f4c3f767\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>4369</td>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>4370</td>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>4371</td>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>4372</td>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>4373</td>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95912ddf-ee35-43a1-928d-0ac8f4c3f767')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95912ddf-ee35-43a1-928d-0ac8f4c3f767 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95912ddf-ee35-43a1-928d-0ac8f4c3f767');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c208279e-07de-467a-97f6-833dc101f0e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c208279e-07de-467a-97f6-833dc101f0e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c208279e-07de-467a-97f6-833dc101f0e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping for label names to numerical IDs\n",
        "label_mapping = {\n",
        "    'MachineDown': 0,\n",
        "    'NetworkDisconnection': 1,\n",
        "    'DiskFull': 2\n",
        "}\n",
        "\n",
        "# Set the 'labels' column based on the mapping\n",
        "chunked_logs['labels'] = chunked_logs['RootCause'].map(lambda x: label_mapping[x.strip()])\n",
        "\n",
        "# Create dictionaries for label mappings\n",
        "id2label = {id: label for label, id in label_mapping.items()}\n",
        "label2id = {label: id for label, id in label_mapping.items()}\n",
        "chunked_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4UrGKkAHNCjN",
        "outputId": "9bcfe707-4086-468e-9754-f85e9364841b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                         LogContent  \\\n",
              "0              0  metrics2. impl. metricsconfig : loaded propert...   \n",
              "1              1  . maptask : ( equator ) 0 kvi 26214396 ( 10485...   \n",
              "2              2  ##k : kvstart = 11165712 ( 44662848 ) ; kvend ...   \n",
              "3              3  : kvstart = 7281300 ( 29125200 ) ; kvend = 210...   \n",
              "4              4  ##388 ( 13585552 ) ; kvend = 17183192 ( 687327...   \n",
              "...          ...                                                ...   \n",
              "4369        4369  maptask : ( equator ) 0 kvi 26214396 ( 1048575...   \n",
              "4370        4370  kvstart = 14330776 ( 57323104 ) ; kvend = 5417...   \n",
              "4371        4371  ##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...   \n",
              "4372        4372  ##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...   \n",
              "4373        4373  ##k : kvstart = 21646124 ( 86584496 ) ; kvend ...   \n",
              "\n",
              "        RootCause  labels  \n",
              "0     MachineDown       0  \n",
              "1     MachineDown       0  \n",
              "2     MachineDown       0  \n",
              "3     MachineDown       0  \n",
              "4     MachineDown       0  \n",
              "...           ...     ...  \n",
              "4369  MachineDown       0  \n",
              "4370  MachineDown       0  \n",
              "4371  MachineDown       0  \n",
              "4372  MachineDown       0  \n",
              "4373  MachineDown       0  \n",
              "\n",
              "[4374 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d65ad033-5a7e-4532-a75e-6bf871f56ed9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>LogContent</th>\n",
              "      <th>RootCause</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>metrics2. impl. metricsconfig : loaded propert...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>. maptask : ( equator ) 0 kvi 26214396 ( 10485...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>##k : kvstart = 11165712 ( 44662848 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>: kvstart = 7281300 ( 29125200 ) ; kvend = 210...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>##388 ( 13585552 ) ; kvend = 17183192 ( 687327...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4369</th>\n",
              "      <td>4369</td>\n",
              "      <td>maptask : ( equator ) 0 kvi 26214396 ( 1048575...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>4370</td>\n",
              "      <td>kvstart = 14330776 ( 57323104 ) ; kvend = 5417...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4371</th>\n",
              "      <td>4371</td>\n",
              "      <td>##t = 16762552 ( 67050208 ) ; kvend = 7853256 ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4372</th>\n",
              "      <td>4372</td>\n",
              "      <td>##4 ( 76802656 ) ; kvend = 10290256 ( 41161024...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>4373</td>\n",
              "      <td>##k : kvstart = 21646124 ( 86584496 ) ; kvend ...</td>\n",
              "      <td>MachineDown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4374 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d65ad033-5a7e-4532-a75e-6bf871f56ed9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d65ad033-5a7e-4532-a75e-6bf871f56ed9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d65ad033-5a7e-4532-a75e-6bf871f56ed9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed0c0cce-a6b9-48a0-8d2c-931764b8080e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed0c0cce-a6b9-48a0-8d2c-931764b8080e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed0c0cce-a6b9-48a0-8d2c-931764b8080e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "class CustomDatasetForSMOTE(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "        # self.labels = labels\n",
        "        self.labels = torch.tensor(labels).clone().detach()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "M4e5pLw5MJZb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "32f347e9f77441d1bbe3ec9826109f43",
            "65109d786baf47dba249f47c276e7315",
            "18a0a802d8404f69b54100a3b1b44e66",
            "6d6b22348b22461f9535e7cc75bc23fa",
            "9cbfd4a7ec814863abb1c5e9b853a307",
            "ffcf1526ad624bdf97f75786577f133b",
            "ccbd124ac89a4aebab059865b5f3a81d",
            "b2fb6618f03b4caaad48f0b5d334e818",
            "353f4b2fa2db4326872716c1c28460a2",
            "89e313f46bcc4da28a57138c10325b9a",
            "3b43e2f9ee954eaca6abb33b90bf191e",
            "96495f49aca749888732726d61600cec",
            "1881e42fce2a4e49a23b6ed34fbe10ed",
            "d3ac646ac8b24f848d2764d3cb042799",
            "5e587af59fe149da8a7809bc946a0d60",
            "bbc27ecfe96047a5addfd938d4790254",
            "c8e94d7544074463bef9784eae5c20df",
            "f0dd291a6203469b988c5ea7a9a39eac",
            "6c1373af0024454289bca3a38df9e966",
            "4c4841b15188464a82a61c2a7bf5a5b2",
            "f00cba2de44844de9bfa4d6e2d93abf4",
            "a683b0e286304609b60728b2d7b207fa",
            "04dd194e15484dcd9a2130fe5334090e",
            "2ea389a310914e30bbf231dbb90f024b",
            "4289cc32fed04628a0a5d9d94000b21a",
            "40fbad3c882a4a5db010f7f208cbf5d0",
            "91008f680abb4446b944a198f64859c3",
            "d28d99749e64401e8d04d9e1363ad8ec",
            "280c2f4589c84701a7e921ecf971a413",
            "eeb11c0ba1024b17a3d1d9c7fec31c6e",
            "46af9f4babf74fa7aa47222474c93f8f",
            "2ae287fed578428ca873e3660cc750e4",
            "e91cb72f7799453885f4a1db11369d5f",
            "743babd3758244e982f8c584bbf6f3ca",
            "77b1e17502824888b6d34e71d2d91f1e",
            "25c0a16ea1de4f83bbd4e84e7a69a609",
            "235bc4cf694d453fbcc575ae71709b7b",
            "eca228d769f84ef1b17f432512c9fba2",
            "ec4dc6f48f0042d2bd81d59d641b6072",
            "36a6e3484e6d4322a88ecac7a897581b",
            "aab297ddcabb40b689303e813dc54147",
            "f1a0eaee3977416390a57af06eb3a28e",
            "7b021b5564de4839b334f5753202b0a2",
            "11486ed1ac7749be8bf7fa9fa844fcba"
          ]
        },
        "outputId": "82fbf2c3-da04-475c-f82f-3fd716e20dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32f347e9f77441d1bbe3ec9826109f43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96495f49aca749888732726d61600cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04dd194e15484dcd9a2130fe5334090e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "743babd3758244e982f8c584bbf6f3ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation datasets (80-20 split)\n",
        "train, val = train_test_split(chunked_logs, test_size=0.2, random_state=45, shuffle=True)\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "42r19K1hMJSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G028w5QSPbYU",
        "outputId": "09d04fc9-801c-413a-e7a6-6935af3517c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2387\n",
              "1     589\n",
              "2     523\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CustomDataset instances for training and validation\n",
        "train_dataset = CustomDatasetForSMOTE(texts=list(train['LogContent']), labels=train['labels'], tokenizer=tokenizer)\n",
        "val_dataset = CustomDatasetForSMOTE(texts=list(val['LogContent']), labels=val['labels'], tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "09Gxpb7tMJKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the encodings of the first sample in the dataset\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeP7xKvXMbaZ",
        "outputId": "9132e466-9f02-4d30-f579-75ba270ddf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.CustomDatasetForSMOTE at 0x7d76a0de9390>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### applying SMOTE"
      ],
      "metadata": {
        "id": "eV0kzRZWOW7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Extract features and labels\n",
        "features = torch.cat([train_dataset[i]['input_ids'].reshape(1, -1) for i in range(len(train_dataset))], dim=0)\n",
        "labels = torch.tensor(train_dataset[:]['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZawXyxAOUnq",
        "outputId": "1d558609-9323-4a06-c09e-de8c46db6a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n",
            "<ipython-input-14-f108629a96d8>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(train_dataset[:]['labels'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFXem7bcPnTh",
        "outputId": "86227ab6-f182-456e-d2c3-7f89650c54b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101, 26640,  1007,  ...,   102,     0,     0],\n",
              "        [  101,  1001,  1001,  ...,  1033,  4949,   102],\n",
              "        [  101,  1001,  1001,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  3535,  1035,  ...,   102,     0,     0],\n",
              "        [  101, 12046,  2015,  ...,   102,     0,     0],\n",
              "        [  101,  1001,  1001,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Apply SMOTE\n",
        "smote = SMOTE(random_state=40)\n",
        "features_resampled, labels_resampled = smote.fit_resample(features, labels)"
      ],
      "metadata": {
        "id": "J9hR8tgDPeCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Convert feature vectors back to text\n",
        "text_data_resampled = [tokenizer.decode(input_ids) for input_ids in features_resampled]"
      ],
      "metadata": {
        "id": "D1FNhjSlQRvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming labels_resampled is your NumPy array\n",
        "unique_values, counts = np.unique(labels_resampled, return_counts=True)\n",
        "\n",
        "# Print unique values and their counts\n",
        "for value, count in zip(unique_values, counts):\n",
        "    print(f\"Label {value}: Count = {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApVWTEnJQmUE",
        "outputId": "0cd6c003-e683-4da9-dcaf-cb544e16962d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0: Count = 2387\n",
            "Label 1: Count = 2387\n",
            "Label 2: Count = 2387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_resampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swDbbx5HRPji",
        "outputId": "28b7becf-566a-4740-ed92-1de9bfe01ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7161"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create a new dataset\n",
        "train_dataset_resampled = CustomDatasetForSMOTE(text_data_resampled, labels_resampled, tokenizer)"
      ],
      "metadata": {
        "id": "tk2dldeERBBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "train_dataloader = DataLoader(train_dataset_resampled, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "aNy1-MjYMbTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_resampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aORftJObRedt",
        "outputId": "11518c77-0a4b-4af9-b179-f93304429c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.CustomDatasetForSMOTE at 0x7e1dac641810>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 3\n",
        "# Initialize the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=NUM_LABELS\n",
        ")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6abb53dd5c2d4e38bca0d91085d32cf4",
            "f035cb1732384538824bc34af0edb5d9",
            "0f636619621540fbb7e7e49272e33bb8",
            "09c938f2924c4575ba3b65653596ac59",
            "0a9f7c626bff4199b22403d03b4b60b2",
            "85af90a113e44d8cbe2dba18f9b2d1d4",
            "3522d92a655d45b4b5b9525b8839f65d",
            "ed70abdaa04e4981b6bbde7bd0d7c377",
            "aa8315e89ebb47b1a5e771fdce05fa14",
            "0994333a514a44a0862b8717f710abb5",
            "9aea601720704c168e64f6541d969c1e"
          ]
        },
        "id": "cQczN1PwRik-",
        "outputId": "8b2ec3aa-4afb-4810-e4f5-958f6284e1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6abb53dd5c2d4e38bca0d91085d32cf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Training loop without early stopping\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over batches in the training DataLoader\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        # Print label counts for the current batch\n",
        "        label_counts = {label: count for label, count in zip(*np.unique(labels.cpu().numpy(), return_counts=True))}\n",
        "        print(f\"Batch {batch_idx + 1}/{len(train_dataloader)}, Label Counts: {label_counts}\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "        # Print training progress for each batch\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_dataloader)}, Loss: {loss.item():.4f}, Time: {batch_time:.2f} seconds\")\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    # Iterate over batches in the validation DataLoader\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    accuracy = correct_preds / len(val_dataset)\n",
        "    print(f\"Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUIbtjAZR6Yk",
        "outputId": "b22dc0df-fb20-4f18-8686-aecf521e0187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3adbf41d52d9>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 1/448, Loss: 1.0042, Time: 2.65 seconds\n",
            "Batch 2/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 2/448, Loss: 0.9106, Time: 1.35 seconds\n",
            "Batch 3/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/3, Batch 3/448, Loss: 1.1417, Time: 1.35 seconds\n",
            "Batch 4/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 4/448, Loss: 0.9712, Time: 1.36 seconds\n",
            "Batch 5/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 5/448, Loss: 1.0177, Time: 1.35 seconds\n",
            "Batch 6/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 6/448, Loss: 0.9191, Time: 1.35 seconds\n",
            "Batch 7/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 7/448, Loss: 0.9517, Time: 1.35 seconds\n",
            "Batch 8/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 8/448, Loss: 0.9210, Time: 1.36 seconds\n",
            "Batch 9/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 9/448, Loss: 1.0019, Time: 1.36 seconds\n",
            "Batch 10/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 10/448, Loss: 0.7694, Time: 1.36 seconds\n",
            "Batch 11/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 11/448, Loss: 0.7183, Time: 1.36 seconds\n",
            "Batch 12/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 12/448, Loss: 1.0203, Time: 1.38 seconds\n",
            "Batch 13/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 13/448, Loss: 0.7967, Time: 1.38 seconds\n",
            "Batch 14/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 14/448, Loss: 0.8176, Time: 1.38 seconds\n",
            "Batch 15/448, Label Counts: {0: 6, 1: 9, 2: 1}\n",
            "Epoch 1/3, Batch 15/448, Loss: 0.9900, Time: 1.37 seconds\n",
            "Batch 16/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 16/448, Loss: 0.9315, Time: 1.38 seconds\n",
            "Batch 17/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 17/448, Loss: 1.0298, Time: 1.39 seconds\n",
            "Batch 18/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 18/448, Loss: 1.1654, Time: 1.39 seconds\n",
            "Batch 19/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 19/448, Loss: 0.9848, Time: 1.39 seconds\n",
            "Batch 20/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 20/448, Loss: 1.0593, Time: 1.40 seconds\n",
            "Batch 21/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 21/448, Loss: 0.8709, Time: 1.39 seconds\n",
            "Batch 22/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 22/448, Loss: 1.1203, Time: 1.38 seconds\n",
            "Batch 23/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 23/448, Loss: 0.7739, Time: 1.39 seconds\n",
            "Batch 24/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 24/448, Loss: 0.9122, Time: 1.40 seconds\n",
            "Batch 25/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 25/448, Loss: 0.9885, Time: 1.40 seconds\n",
            "Batch 26/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 26/448, Loss: 0.9537, Time: 1.41 seconds\n",
            "Batch 27/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/3, Batch 27/448, Loss: 0.9644, Time: 1.41 seconds\n",
            "Batch 28/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 28/448, Loss: 0.9379, Time: 1.42 seconds\n",
            "Batch 29/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 29/448, Loss: 0.6709, Time: 1.42 seconds\n",
            "Batch 30/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 30/448, Loss: 1.0316, Time: 1.42 seconds\n",
            "Batch 31/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 31/448, Loss: 0.9965, Time: 1.42 seconds\n",
            "Batch 32/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 1/3, Batch 32/448, Loss: 0.8516, Time: 1.41 seconds\n",
            "Batch 33/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 33/448, Loss: 0.7062, Time: 1.42 seconds\n",
            "Batch 34/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 34/448, Loss: 0.9220, Time: 1.43 seconds\n",
            "Batch 35/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 35/448, Loss: 0.9860, Time: 1.42 seconds\n",
            "Batch 36/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 36/448, Loss: 0.9709, Time: 1.43 seconds\n",
            "Batch 37/448, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 1/3, Batch 37/448, Loss: 0.9358, Time: 1.43 seconds\n",
            "Batch 38/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 1/3, Batch 38/448, Loss: 1.0076, Time: 1.44 seconds\n",
            "Batch 39/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 39/448, Loss: 0.8758, Time: 1.44 seconds\n",
            "Batch 40/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 40/448, Loss: 0.8968, Time: 1.45 seconds\n",
            "Batch 41/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 41/448, Loss: 0.9561, Time: 1.45 seconds\n",
            "Batch 42/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 42/448, Loss: 0.7112, Time: 1.45 seconds\n",
            "Batch 43/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 43/448, Loss: 0.8278, Time: 1.46 seconds\n",
            "Batch 44/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/3, Batch 44/448, Loss: 0.9862, Time: 1.46 seconds\n",
            "Batch 45/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 45/448, Loss: 0.8161, Time: 1.47 seconds\n",
            "Batch 46/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 46/448, Loss: 0.6736, Time: 1.47 seconds\n",
            "Batch 47/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/3, Batch 47/448, Loss: 1.0112, Time: 1.48 seconds\n",
            "Batch 48/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 48/448, Loss: 0.7354, Time: 1.48 seconds\n",
            "Batch 49/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 49/448, Loss: 0.8554, Time: 1.49 seconds\n",
            "Batch 50/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 50/448, Loss: 0.8768, Time: 1.49 seconds\n",
            "Batch 51/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 51/448, Loss: 0.8557, Time: 1.49 seconds\n",
            "Batch 52/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 52/448, Loss: 0.6869, Time: 1.51 seconds\n",
            "Batch 53/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 53/448, Loss: 0.7308, Time: 1.52 seconds\n",
            "Batch 54/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 54/448, Loss: 0.8133, Time: 1.53 seconds\n",
            "Batch 55/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/3, Batch 55/448, Loss: 0.8773, Time: 1.52 seconds\n",
            "Batch 56/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 56/448, Loss: 0.7361, Time: 1.51 seconds\n",
            "Batch 57/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 57/448, Loss: 0.9330, Time: 1.50 seconds\n",
            "Batch 58/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 58/448, Loss: 0.8341, Time: 1.51 seconds\n",
            "Batch 59/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 59/448, Loss: 0.9942, Time: 1.52 seconds\n",
            "Batch 60/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 60/448, Loss: 0.7442, Time: 1.52 seconds\n",
            "Batch 61/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 1/3, Batch 61/448, Loss: 0.7079, Time: 1.53 seconds\n",
            "Batch 62/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 62/448, Loss: 0.8692, Time: 1.54 seconds\n",
            "Batch 63/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 63/448, Loss: 1.0122, Time: 1.55 seconds\n",
            "Batch 64/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 64/448, Loss: 0.8081, Time: 1.56 seconds\n",
            "Batch 65/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 1/3, Batch 65/448, Loss: 0.8205, Time: 1.56 seconds\n",
            "Batch 66/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 66/448, Loss: 1.0544, Time: 1.56 seconds\n",
            "Batch 67/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 67/448, Loss: 0.9786, Time: 1.56 seconds\n",
            "Batch 68/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 68/448, Loss: 0.9117, Time: 1.56 seconds\n",
            "Batch 69/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 69/448, Loss: 0.7762, Time: 1.58 seconds\n",
            "Batch 70/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 70/448, Loss: 0.7258, Time: 1.58 seconds\n",
            "Batch 71/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 71/448, Loss: 0.8499, Time: 1.58 seconds\n",
            "Batch 72/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 72/448, Loss: 0.8554, Time: 1.58 seconds\n",
            "Batch 73/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 73/448, Loss: 0.8970, Time: 1.60 seconds\n",
            "Batch 74/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 74/448, Loss: 0.8074, Time: 1.60 seconds\n",
            "Batch 75/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 75/448, Loss: 0.6975, Time: 1.60 seconds\n",
            "Batch 76/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 76/448, Loss: 0.8385, Time: 1.60 seconds\n",
            "Batch 77/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/3, Batch 77/448, Loss: 1.1172, Time: 1.60 seconds\n",
            "Batch 78/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 78/448, Loss: 0.7788, Time: 1.63 seconds\n",
            "Batch 79/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 79/448, Loss: 0.5841, Time: 1.62 seconds\n",
            "Batch 80/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 80/448, Loss: 0.6694, Time: 1.64 seconds\n",
            "Batch 81/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 81/448, Loss: 0.8876, Time: 1.65 seconds\n",
            "Batch 82/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/3, Batch 82/448, Loss: 0.7794, Time: 1.66 seconds\n",
            "Batch 83/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 1/3, Batch 83/448, Loss: 1.0671, Time: 1.66 seconds\n",
            "Batch 84/448, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 1/3, Batch 84/448, Loss: 0.7872, Time: 1.67 seconds\n",
            "Batch 85/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 85/448, Loss: 0.6392, Time: 1.68 seconds\n",
            "Batch 86/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 86/448, Loss: 0.7870, Time: 1.68 seconds\n",
            "Batch 87/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 87/448, Loss: 1.0456, Time: 1.68 seconds\n",
            "Batch 88/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 88/448, Loss: 0.8552, Time: 1.68 seconds\n",
            "Batch 89/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 89/448, Loss: 0.7638, Time: 1.68 seconds\n",
            "Batch 90/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 90/448, Loss: 0.7820, Time: 1.68 seconds\n",
            "Batch 91/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 1/3, Batch 91/448, Loss: 0.6987, Time: 1.66 seconds\n",
            "Batch 92/448, Label Counts: {0: 2, 1: 9, 2: 5}\n",
            "Epoch 1/3, Batch 92/448, Loss: 0.8612, Time: 1.66 seconds\n",
            "Batch 93/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 93/448, Loss: 0.8753, Time: 1.64 seconds\n",
            "Batch 94/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 94/448, Loss: 0.8560, Time: 1.64 seconds\n",
            "Batch 95/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 95/448, Loss: 0.5885, Time: 1.63 seconds\n",
            "Batch 96/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 96/448, Loss: 0.9125, Time: 1.62 seconds\n",
            "Batch 97/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 97/448, Loss: 0.7164, Time: 1.61 seconds\n",
            "Batch 98/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 98/448, Loss: 1.0135, Time: 1.62 seconds\n",
            "Batch 99/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 1/3, Batch 99/448, Loss: 0.9778, Time: 1.60 seconds\n",
            "Batch 100/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 100/448, Loss: 0.6872, Time: 1.59 seconds\n",
            "Batch 101/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 101/448, Loss: 0.9180, Time: 1.60 seconds\n",
            "Batch 102/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/3, Batch 102/448, Loss: 1.0217, Time: 1.59 seconds\n",
            "Batch 103/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 103/448, Loss: 0.7906, Time: 1.59 seconds\n",
            "Batch 104/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 104/448, Loss: 0.9345, Time: 1.60 seconds\n",
            "Batch 105/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 105/448, Loss: 0.7878, Time: 1.59 seconds\n",
            "Batch 106/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 106/448, Loss: 0.7582, Time: 1.60 seconds\n",
            "Batch 107/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 107/448, Loss: 0.8905, Time: 1.60 seconds\n",
            "Batch 108/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 108/448, Loss: 0.8109, Time: 1.59 seconds\n",
            "Batch 109/448, Label Counts: {0: 5, 1: 10, 2: 1}\n",
            "Epoch 1/3, Batch 109/448, Loss: 0.9520, Time: 1.60 seconds\n",
            "Batch 110/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 110/448, Loss: 0.7694, Time: 1.59 seconds\n",
            "Batch 111/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 111/448, Loss: 0.9316, Time: 1.59 seconds\n",
            "Batch 112/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 112/448, Loss: 0.8281, Time: 1.58 seconds\n",
            "Batch 113/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 113/448, Loss: 0.8782, Time: 1.58 seconds\n",
            "Batch 114/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 114/448, Loss: 0.6272, Time: 1.60 seconds\n",
            "Batch 115/448, Label Counts: {0: 3, 1: 12, 2: 1}\n",
            "Epoch 1/3, Batch 115/448, Loss: 0.9513, Time: 1.58 seconds\n",
            "Batch 116/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 116/448, Loss: 0.8675, Time: 1.58 seconds\n",
            "Batch 117/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 117/448, Loss: 0.8721, Time: 1.58 seconds\n",
            "Batch 118/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 118/448, Loss: 0.9037, Time: 1.58 seconds\n",
            "Batch 119/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 119/448, Loss: 0.8586, Time: 1.60 seconds\n",
            "Batch 120/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 120/448, Loss: 0.7410, Time: 1.60 seconds\n",
            "Batch 121/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 121/448, Loss: 0.8707, Time: 1.60 seconds\n",
            "Batch 122/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 122/448, Loss: 0.7884, Time: 1.60 seconds\n",
            "Batch 123/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 123/448, Loss: 0.7366, Time: 1.60 seconds\n",
            "Batch 124/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 124/448, Loss: 0.7583, Time: 1.60 seconds\n",
            "Batch 125/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/3, Batch 125/448, Loss: 1.2157, Time: 1.61 seconds\n",
            "Batch 126/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 126/448, Loss: 0.9071, Time: 1.61 seconds\n",
            "Batch 127/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 127/448, Loss: 0.7454, Time: 1.61 seconds\n",
            "Batch 128/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 128/448, Loss: 1.0129, Time: 1.62 seconds\n",
            "Batch 129/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 1/3, Batch 129/448, Loss: 0.9180, Time: 1.62 seconds\n",
            "Batch 130/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 130/448, Loss: 0.7289, Time: 1.61 seconds\n",
            "Batch 131/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 131/448, Loss: 0.8389, Time: 1.64 seconds\n",
            "Batch 132/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 132/448, Loss: 0.6790, Time: 1.62 seconds\n",
            "Batch 133/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 133/448, Loss: 0.8084, Time: 1.63 seconds\n",
            "Batch 134/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 134/448, Loss: 0.8349, Time: 1.64 seconds\n",
            "Batch 135/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 135/448, Loss: 0.7830, Time: 1.63 seconds\n",
            "Batch 136/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 136/448, Loss: 0.6728, Time: 1.64 seconds\n",
            "Batch 137/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 137/448, Loss: 0.8057, Time: 1.63 seconds\n",
            "Batch 138/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/3, Batch 138/448, Loss: 0.7773, Time: 1.64 seconds\n",
            "Batch 139/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 1/3, Batch 139/448, Loss: 0.8917, Time: 1.64 seconds\n",
            "Batch 140/448, Label Counts: {0: 1, 1: 4, 2: 11}\n",
            "Epoch 1/3, Batch 140/448, Loss: 1.0057, Time: 1.64 seconds\n",
            "Batch 141/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 141/448, Loss: 0.8186, Time: 1.63 seconds\n",
            "Batch 142/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 142/448, Loss: 0.8368, Time: 1.63 seconds\n",
            "Batch 143/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 143/448, Loss: 0.8581, Time: 1.63 seconds\n",
            "Batch 144/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 144/448, Loss: 0.8399, Time: 1.63 seconds\n",
            "Batch 145/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 145/448, Loss: 1.1124, Time: 1.63 seconds\n",
            "Batch 146/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 1/3, Batch 146/448, Loss: 0.8113, Time: 1.62 seconds\n",
            "Batch 147/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 147/448, Loss: 0.8364, Time: 1.62 seconds\n",
            "Batch 148/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 148/448, Loss: 0.9772, Time: 1.62 seconds\n",
            "Batch 149/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/3, Batch 149/448, Loss: 0.8173, Time: 1.61 seconds\n",
            "Batch 150/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 150/448, Loss: 0.6795, Time: 1.61 seconds\n",
            "Batch 151/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 151/448, Loss: 0.9300, Time: 1.62 seconds\n",
            "Batch 152/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 152/448, Loss: 0.8641, Time: 1.60 seconds\n",
            "Batch 153/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 153/448, Loss: 0.7800, Time: 1.60 seconds\n",
            "Batch 154/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 1/3, Batch 154/448, Loss: 0.9011, Time: 1.60 seconds\n",
            "Batch 155/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 155/448, Loss: 0.8717, Time: 1.60 seconds\n",
            "Batch 156/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/3, Batch 156/448, Loss: 0.7774, Time: 1.60 seconds\n",
            "Batch 157/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 157/448, Loss: 0.8745, Time: 1.60 seconds\n",
            "Batch 158/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 158/448, Loss: 0.7854, Time: 1.60 seconds\n",
            "Batch 159/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 159/448, Loss: 0.7114, Time: 1.60 seconds\n",
            "Batch 160/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 160/448, Loss: 0.7705, Time: 1.60 seconds\n",
            "Batch 161/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 161/448, Loss: 0.7731, Time: 1.60 seconds\n",
            "Batch 162/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 1/3, Batch 162/448, Loss: 0.8209, Time: 1.60 seconds\n",
            "Batch 163/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 163/448, Loss: 0.8469, Time: 1.60 seconds\n",
            "Batch 164/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 1/3, Batch 164/448, Loss: 0.8004, Time: 1.59 seconds\n",
            "Batch 165/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 165/448, Loss: 0.8203, Time: 1.60 seconds\n",
            "Batch 166/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 166/448, Loss: 0.7971, Time: 1.59 seconds\n",
            "Batch 167/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 167/448, Loss: 0.7818, Time: 1.60 seconds\n",
            "Batch 168/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 168/448, Loss: 1.0060, Time: 1.60 seconds\n",
            "Batch 169/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 169/448, Loss: 0.6221, Time: 1.60 seconds\n",
            "Batch 170/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/3, Batch 170/448, Loss: 0.8338, Time: 1.59 seconds\n",
            "Batch 171/448, Label Counts: {0: 11, 1: 1, 2: 4}\n",
            "Epoch 1/3, Batch 171/448, Loss: 0.8515, Time: 1.60 seconds\n",
            "Batch 172/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 172/448, Loss: 0.8684, Time: 1.60 seconds\n",
            "Batch 173/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 173/448, Loss: 0.7157, Time: 1.60 seconds\n",
            "Batch 174/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 1/3, Batch 174/448, Loss: 0.8387, Time: 1.60 seconds\n",
            "Batch 175/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 175/448, Loss: 0.7818, Time: 1.62 seconds\n",
            "Batch 176/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/3, Batch 176/448, Loss: 0.6824, Time: 1.62 seconds\n",
            "Batch 177/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 177/448, Loss: 0.7820, Time: 1.62 seconds\n",
            "Batch 178/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/3, Batch 178/448, Loss: 1.0480, Time: 1.59 seconds\n",
            "Batch 179/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 179/448, Loss: 0.9938, Time: 1.60 seconds\n",
            "Batch 180/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 180/448, Loss: 0.8295, Time: 1.62 seconds\n",
            "Batch 181/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 181/448, Loss: 0.9160, Time: 1.62 seconds\n",
            "Batch 182/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 1/3, Batch 182/448, Loss: 1.0036, Time: 1.61 seconds\n",
            "Batch 183/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 183/448, Loss: 0.6452, Time: 1.62 seconds\n",
            "Batch 184/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 184/448, Loss: 0.8130, Time: 1.62 seconds\n",
            "Batch 185/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 185/448, Loss: 0.8384, Time: 1.61 seconds\n",
            "Batch 186/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 186/448, Loss: 0.6655, Time: 1.62 seconds\n",
            "Batch 187/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 187/448, Loss: 0.8135, Time: 1.63 seconds\n",
            "Batch 188/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 188/448, Loss: 0.6553, Time: 1.62 seconds\n",
            "Batch 189/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 189/448, Loss: 0.7099, Time: 1.63 seconds\n",
            "Batch 190/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 190/448, Loss: 0.8430, Time: 1.62 seconds\n",
            "Batch 191/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 1/3, Batch 191/448, Loss: 0.8893, Time: 1.62 seconds\n",
            "Batch 192/448, Label Counts: {0: 2, 1: 3, 2: 11}\n",
            "Epoch 1/3, Batch 192/448, Loss: 0.9054, Time: 1.63 seconds\n",
            "Batch 193/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 1/3, Batch 193/448, Loss: 1.1219, Time: 1.63 seconds\n",
            "Batch 194/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 194/448, Loss: 0.7193, Time: 1.62 seconds\n",
            "Batch 195/448, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 1/3, Batch 195/448, Loss: 0.6391, Time: 1.62 seconds\n",
            "Batch 196/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/3, Batch 196/448, Loss: 0.7688, Time: 1.62 seconds\n",
            "Batch 197/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 1/3, Batch 197/448, Loss: 0.5074, Time: 1.63 seconds\n",
            "Batch 198/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 198/448, Loss: 0.8396, Time: 1.62 seconds\n",
            "Batch 199/448, Label Counts: {0: 2, 1: 9, 2: 5}\n",
            "Epoch 1/3, Batch 199/448, Loss: 0.7743, Time: 1.63 seconds\n",
            "Batch 200/448, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 1/3, Batch 200/448, Loss: 0.7745, Time: 1.63 seconds\n",
            "Batch 201/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 201/448, Loss: 0.8416, Time: 1.63 seconds\n",
            "Batch 202/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 202/448, Loss: 0.8021, Time: 1.63 seconds\n",
            "Batch 203/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 1/3, Batch 203/448, Loss: 0.5898, Time: 1.62 seconds\n",
            "Batch 204/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 204/448, Loss: 0.9616, Time: 1.63 seconds\n",
            "Batch 205/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 205/448, Loss: 1.0148, Time: 1.62 seconds\n",
            "Batch 206/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 206/448, Loss: 0.6284, Time: 1.63 seconds\n",
            "Batch 207/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 207/448, Loss: 0.7171, Time: 1.63 seconds\n",
            "Batch 208/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 1/3, Batch 208/448, Loss: 0.7684, Time: 1.62 seconds\n",
            "Batch 209/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 209/448, Loss: 0.8239, Time: 1.63 seconds\n",
            "Batch 210/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 210/448, Loss: 0.5913, Time: 1.62 seconds\n",
            "Batch 211/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 211/448, Loss: 0.9674, Time: 1.63 seconds\n",
            "Batch 212/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 212/448, Loss: 1.0082, Time: 1.62 seconds\n",
            "Batch 213/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 213/448, Loss: 0.6186, Time: 1.62 seconds\n",
            "Batch 214/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 214/448, Loss: 0.6091, Time: 1.62 seconds\n",
            "Batch 215/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 215/448, Loss: 0.9931, Time: 1.62 seconds\n",
            "Batch 216/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 216/448, Loss: 0.8426, Time: 1.63 seconds\n",
            "Batch 217/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 217/448, Loss: 1.1991, Time: 1.62 seconds\n",
            "Batch 218/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 218/448, Loss: 0.6642, Time: 1.62 seconds\n",
            "Batch 219/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 219/448, Loss: 0.8989, Time: 1.62 seconds\n",
            "Batch 220/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 220/448, Loss: 0.9360, Time: 1.61 seconds\n",
            "Batch 221/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 221/448, Loss: 0.8610, Time: 1.62 seconds\n",
            "Batch 222/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 222/448, Loss: 0.7352, Time: 1.63 seconds\n",
            "Batch 223/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 223/448, Loss: 0.7577, Time: 1.62 seconds\n",
            "Batch 224/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 224/448, Loss: 0.8198, Time: 1.62 seconds\n",
            "Batch 225/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 1/3, Batch 225/448, Loss: 0.7693, Time: 1.62 seconds\n",
            "Batch 226/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 1/3, Batch 226/448, Loss: 0.7720, Time: 1.62 seconds\n",
            "Batch 227/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 227/448, Loss: 0.7214, Time: 1.63 seconds\n",
            "Batch 228/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 228/448, Loss: 0.7464, Time: 1.61 seconds\n",
            "Batch 229/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 229/448, Loss: 0.6889, Time: 1.61 seconds\n",
            "Batch 230/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 230/448, Loss: 0.6148, Time: 1.62 seconds\n",
            "Batch 231/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 231/448, Loss: 0.7299, Time: 1.62 seconds\n",
            "Batch 232/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 232/448, Loss: 0.7534, Time: 1.62 seconds\n",
            "Batch 233/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 233/448, Loss: 0.5123, Time: 1.62 seconds\n",
            "Batch 234/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 234/448, Loss: 0.7238, Time: 1.62 seconds\n",
            "Batch 235/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 235/448, Loss: 0.7273, Time: 1.61 seconds\n",
            "Batch 236/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 236/448, Loss: 0.5878, Time: 1.62 seconds\n",
            "Batch 237/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 237/448, Loss: 0.7887, Time: 1.62 seconds\n",
            "Batch 238/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 238/448, Loss: 0.7782, Time: 1.61 seconds\n",
            "Batch 239/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 239/448, Loss: 0.5449, Time: 1.62 seconds\n",
            "Batch 240/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 240/448, Loss: 0.5884, Time: 1.61 seconds\n",
            "Batch 241/448, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 1/3, Batch 241/448, Loss: 0.7949, Time: 1.62 seconds\n",
            "Batch 242/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 1/3, Batch 242/448, Loss: 1.0721, Time: 1.62 seconds\n",
            "Batch 243/448, Label Counts: {0: 5, 1: 9, 2: 2}\n",
            "Epoch 1/3, Batch 243/448, Loss: 0.8027, Time: 1.62 seconds\n",
            "Batch 244/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 1/3, Batch 244/448, Loss: 0.7092, Time: 1.61 seconds\n",
            "Batch 245/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 245/448, Loss: 0.6197, Time: 1.62 seconds\n",
            "Batch 246/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 246/448, Loss: 0.7330, Time: 1.62 seconds\n",
            "Batch 247/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 1/3, Batch 247/448, Loss: 0.9994, Time: 1.62 seconds\n",
            "Batch 248/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 248/448, Loss: 0.5500, Time: 1.61 seconds\n",
            "Batch 249/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 249/448, Loss: 0.7718, Time: 1.62 seconds\n",
            "Batch 250/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 250/448, Loss: 0.7644, Time: 1.61 seconds\n",
            "Batch 251/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 251/448, Loss: 0.5952, Time: 1.62 seconds\n",
            "Batch 252/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 252/448, Loss: 0.5349, Time: 1.61 seconds\n",
            "Batch 253/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/3, Batch 253/448, Loss: 0.6336, Time: 1.62 seconds\n",
            "Batch 254/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 254/448, Loss: 1.0353, Time: 1.62 seconds\n",
            "Batch 255/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 255/448, Loss: 0.7953, Time: 1.62 seconds\n",
            "Batch 256/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 256/448, Loss: 0.9410, Time: 1.62 seconds\n",
            "Batch 257/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 257/448, Loss: 0.7070, Time: 1.61 seconds\n",
            "Batch 258/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 258/448, Loss: 0.6911, Time: 1.62 seconds\n",
            "Batch 259/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 259/448, Loss: 0.8125, Time: 1.61 seconds\n",
            "Batch 260/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 260/448, Loss: 0.8724, Time: 1.61 seconds\n",
            "Batch 261/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/3, Batch 261/448, Loss: 0.8210, Time: 1.62 seconds\n",
            "Batch 262/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 1/3, Batch 262/448, Loss: 0.7073, Time: 1.62 seconds\n",
            "Batch 263/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 263/448, Loss: 0.6972, Time: 1.61 seconds\n",
            "Batch 264/448, Label Counts: {0: 2, 1: 11, 2: 3}\n",
            "Epoch 1/3, Batch 264/448, Loss: 0.9159, Time: 1.62 seconds\n",
            "Batch 265/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 265/448, Loss: 0.7067, Time: 1.62 seconds\n",
            "Batch 266/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 1/3, Batch 266/448, Loss: 0.7338, Time: 1.62 seconds\n",
            "Batch 267/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 267/448, Loss: 0.7474, Time: 1.62 seconds\n",
            "Batch 268/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 268/448, Loss: 0.7723, Time: 1.62 seconds\n",
            "Batch 269/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 269/448, Loss: 0.9453, Time: 1.62 seconds\n",
            "Batch 270/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 270/448, Loss: 1.0547, Time: 1.61 seconds\n",
            "Batch 271/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 1/3, Batch 271/448, Loss: 0.5519, Time: 1.62 seconds\n",
            "Batch 272/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 272/448, Loss: 0.5860, Time: 1.62 seconds\n",
            "Batch 273/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 273/448, Loss: 0.7131, Time: 1.62 seconds\n",
            "Batch 274/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/3, Batch 274/448, Loss: 1.2241, Time: 1.61 seconds\n",
            "Batch 275/448, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 1/3, Batch 275/448, Loss: 0.8262, Time: 1.62 seconds\n",
            "Batch 276/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 276/448, Loss: 0.7184, Time: 1.61 seconds\n",
            "Batch 277/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 277/448, Loss: 0.9016, Time: 1.62 seconds\n",
            "Batch 278/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 278/448, Loss: 0.9213, Time: 1.61 seconds\n",
            "Batch 279/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 279/448, Loss: 0.9050, Time: 1.61 seconds\n",
            "Batch 280/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 280/448, Loss: 0.5816, Time: 1.62 seconds\n",
            "Batch 281/448, Label Counts: {0: 5, 1: 9, 2: 2}\n",
            "Epoch 1/3, Batch 281/448, Loss: 0.9943, Time: 1.61 seconds\n",
            "Batch 282/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 282/448, Loss: 0.7006, Time: 1.60 seconds\n",
            "Batch 283/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 283/448, Loss: 0.7543, Time: 1.62 seconds\n",
            "Batch 284/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/3, Batch 284/448, Loss: 0.9540, Time: 1.60 seconds\n",
            "Batch 285/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 285/448, Loss: 0.6642, Time: 1.61 seconds\n",
            "Batch 286/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 286/448, Loss: 0.6489, Time: 1.61 seconds\n",
            "Batch 287/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 287/448, Loss: 0.6795, Time: 1.62 seconds\n",
            "Batch 288/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 1/3, Batch 288/448, Loss: 0.7860, Time: 1.60 seconds\n",
            "Batch 289/448, Label Counts: {0: 1, 1: 10, 2: 5}\n",
            "Epoch 1/3, Batch 289/448, Loss: 0.8631, Time: 1.60 seconds\n",
            "Batch 290/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 290/448, Loss: 0.6072, Time: 1.61 seconds\n",
            "Batch 291/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 291/448, Loss: 0.7008, Time: 1.62 seconds\n",
            "Batch 292/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 292/448, Loss: 0.8200, Time: 1.62 seconds\n",
            "Batch 293/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 293/448, Loss: 0.8043, Time: 1.62 seconds\n",
            "Batch 294/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 294/448, Loss: 0.8199, Time: 1.62 seconds\n",
            "Batch 295/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 1/3, Batch 295/448, Loss: 0.6987, Time: 1.61 seconds\n",
            "Batch 296/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 296/448, Loss: 0.9212, Time: 1.61 seconds\n",
            "Batch 297/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 297/448, Loss: 0.9072, Time: 1.62 seconds\n",
            "Batch 298/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 298/448, Loss: 0.7366, Time: 1.62 seconds\n",
            "Batch 299/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 299/448, Loss: 1.2123, Time: 1.60 seconds\n",
            "Batch 300/448, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/3, Batch 300/448, Loss: 0.6692, Time: 1.62 seconds\n",
            "Batch 301/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 301/448, Loss: 0.7135, Time: 1.60 seconds\n",
            "Batch 302/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 302/448, Loss: 0.6632, Time: 1.61 seconds\n",
            "Batch 303/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 303/448, Loss: 1.0501, Time: 1.60 seconds\n",
            "Batch 304/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 304/448, Loss: 0.7290, Time: 1.62 seconds\n",
            "Batch 305/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 305/448, Loss: 0.8224, Time: 1.61 seconds\n",
            "Batch 306/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 306/448, Loss: 0.5191, Time: 1.60 seconds\n",
            "Batch 307/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 307/448, Loss: 0.5828, Time: 1.62 seconds\n",
            "Batch 308/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 1/3, Batch 308/448, Loss: 0.8038, Time: 1.61 seconds\n",
            "Batch 309/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 1/3, Batch 309/448, Loss: 0.8307, Time: 1.60 seconds\n",
            "Batch 310/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 310/448, Loss: 0.9954, Time: 1.61 seconds\n",
            "Batch 311/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 311/448, Loss: 0.9923, Time: 1.62 seconds\n",
            "Batch 312/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 312/448, Loss: 0.6536, Time: 1.60 seconds\n",
            "Batch 313/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 1/3, Batch 313/448, Loss: 0.8755, Time: 1.61 seconds\n",
            "Batch 314/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 314/448, Loss: 0.8858, Time: 1.60 seconds\n",
            "Batch 315/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 315/448, Loss: 0.8194, Time: 1.61 seconds\n",
            "Batch 316/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 316/448, Loss: 0.7804, Time: 1.61 seconds\n",
            "Batch 317/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 317/448, Loss: 0.5505, Time: 1.61 seconds\n",
            "Batch 318/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 1/3, Batch 318/448, Loss: 0.7840, Time: 1.62 seconds\n",
            "Batch 319/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 319/448, Loss: 0.6833, Time: 1.62 seconds\n",
            "Batch 320/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 320/448, Loss: 0.6899, Time: 1.61 seconds\n",
            "Batch 321/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 321/448, Loss: 0.6602, Time: 1.61 seconds\n",
            "Batch 322/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 322/448, Loss: 0.7713, Time: 1.61 seconds\n",
            "Batch 323/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 323/448, Loss: 0.5954, Time: 1.60 seconds\n",
            "Batch 324/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 324/448, Loss: 0.8483, Time: 1.62 seconds\n",
            "Batch 325/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 325/448, Loss: 0.7180, Time: 1.62 seconds\n",
            "Batch 326/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 326/448, Loss: 0.6503, Time: 1.59 seconds\n",
            "Batch 327/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 327/448, Loss: 0.9480, Time: 1.61 seconds\n",
            "Batch 328/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 328/448, Loss: 0.9018, Time: 1.61 seconds\n",
            "Batch 329/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 329/448, Loss: 0.8421, Time: 1.60 seconds\n",
            "Batch 330/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 330/448, Loss: 0.8623, Time: 1.61 seconds\n",
            "Batch 331/448, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 1/3, Batch 331/448, Loss: 0.9137, Time: 1.60 seconds\n",
            "Batch 332/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 1/3, Batch 332/448, Loss: 0.6527, Time: 1.61 seconds\n",
            "Batch 333/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 1/3, Batch 333/448, Loss: 0.5983, Time: 1.61 seconds\n",
            "Batch 334/448, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/3, Batch 334/448, Loss: 0.9009, Time: 1.62 seconds\n",
            "Batch 335/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 1/3, Batch 335/448, Loss: 0.6000, Time: 1.61 seconds\n",
            "Batch 336/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 336/448, Loss: 1.4873, Time: 1.62 seconds\n",
            "Batch 337/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 337/448, Loss: 0.8253, Time: 1.60 seconds\n",
            "Batch 338/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 338/448, Loss: 1.0269, Time: 1.62 seconds\n",
            "Batch 339/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 339/448, Loss: 1.1063, Time: 1.60 seconds\n",
            "Batch 340/448, Label Counts: {0: 2, 1: 11, 2: 3}\n",
            "Epoch 1/3, Batch 340/448, Loss: 0.7942, Time: 1.60 seconds\n",
            "Batch 341/448, Label Counts: {0: 4, 1: 10, 2: 2}\n",
            "Epoch 1/3, Batch 341/448, Loss: 0.6450, Time: 1.60 seconds\n",
            "Batch 342/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 342/448, Loss: 0.5517, Time: 1.60 seconds\n",
            "Batch 343/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 343/448, Loss: 0.7889, Time: 1.60 seconds\n",
            "Batch 344/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 344/448, Loss: 0.9561, Time: 1.60 seconds\n",
            "Batch 345/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 345/448, Loss: 0.9309, Time: 1.61 seconds\n",
            "Batch 346/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 1/3, Batch 346/448, Loss: 0.6972, Time: 1.60 seconds\n",
            "Batch 347/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 347/448, Loss: 0.6995, Time: 1.61 seconds\n",
            "Batch 348/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 348/448, Loss: 0.5594, Time: 1.61 seconds\n",
            "Batch 349/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 1/3, Batch 349/448, Loss: 0.8967, Time: 1.61 seconds\n",
            "Batch 350/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 1/3, Batch 350/448, Loss: 0.7023, Time: 1.59 seconds\n",
            "Batch 351/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 351/448, Loss: 0.8293, Time: 1.60 seconds\n",
            "Batch 352/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 352/448, Loss: 0.7002, Time: 1.59 seconds\n",
            "Batch 353/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 353/448, Loss: 1.0103, Time: 1.61 seconds\n",
            "Batch 354/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 354/448, Loss: 0.8198, Time: 1.61 seconds\n",
            "Batch 355/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 355/448, Loss: 0.7496, Time: 1.62 seconds\n",
            "Batch 356/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 356/448, Loss: 0.6348, Time: 1.60 seconds\n",
            "Batch 357/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 357/448, Loss: 0.6724, Time: 1.61 seconds\n",
            "Batch 358/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 358/448, Loss: 0.7748, Time: 1.61 seconds\n",
            "Batch 359/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 359/448, Loss: 1.0445, Time: 1.62 seconds\n",
            "Batch 360/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 360/448, Loss: 0.9382, Time: 1.60 seconds\n",
            "Batch 361/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 1/3, Batch 361/448, Loss: 0.6106, Time: 1.61 seconds\n",
            "Batch 362/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 362/448, Loss: 0.8933, Time: 1.60 seconds\n",
            "Batch 363/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 363/448, Loss: 0.6946, Time: 1.59 seconds\n",
            "Batch 364/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 364/448, Loss: 0.9350, Time: 1.60 seconds\n",
            "Batch 365/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 365/448, Loss: 0.5650, Time: 1.60 seconds\n",
            "Batch 366/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 366/448, Loss: 0.9485, Time: 1.62 seconds\n",
            "Batch 367/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 367/448, Loss: 0.6723, Time: 1.60 seconds\n",
            "Batch 368/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 368/448, Loss: 0.6926, Time: 1.60 seconds\n",
            "Batch 369/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 369/448, Loss: 0.5461, Time: 1.61 seconds\n",
            "Batch 370/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 1/3, Batch 370/448, Loss: 0.9065, Time: 1.62 seconds\n",
            "Batch 371/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 1/3, Batch 371/448, Loss: 0.7418, Time: 1.60 seconds\n",
            "Batch 372/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 372/448, Loss: 0.9255, Time: 1.62 seconds\n",
            "Batch 373/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/3, Batch 373/448, Loss: 0.5928, Time: 1.61 seconds\n",
            "Batch 374/448, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 1/3, Batch 374/448, Loss: 0.7161, Time: 1.60 seconds\n",
            "Batch 375/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 1/3, Batch 375/448, Loss: 0.6624, Time: 1.60 seconds\n",
            "Batch 376/448, Label Counts: {0: 5, 1: 1, 2: 10}\n",
            "Epoch 1/3, Batch 376/448, Loss: 0.7055, Time: 1.62 seconds\n",
            "Batch 377/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 377/448, Loss: 0.7441, Time: 1.60 seconds\n",
            "Batch 378/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 378/448, Loss: 0.6267, Time: 1.62 seconds\n",
            "Batch 379/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 1/3, Batch 379/448, Loss: 1.1805, Time: 1.61 seconds\n",
            "Batch 380/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 380/448, Loss: 1.1199, Time: 1.62 seconds\n",
            "Batch 381/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 381/448, Loss: 0.9436, Time: 1.61 seconds\n",
            "Batch 382/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 382/448, Loss: 0.5100, Time: 1.60 seconds\n",
            "Batch 383/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 383/448, Loss: 0.5877, Time: 1.62 seconds\n",
            "Batch 384/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 384/448, Loss: 0.6159, Time: 1.62 seconds\n",
            "Batch 385/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 385/448, Loss: 0.5251, Time: 1.62 seconds\n",
            "Batch 386/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 386/448, Loss: 0.7178, Time: 1.61 seconds\n",
            "Batch 387/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 387/448, Loss: 0.7488, Time: 1.61 seconds\n",
            "Batch 388/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 388/448, Loss: 0.6153, Time: 1.62 seconds\n",
            "Batch 389/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 389/448, Loss: 0.7712, Time: 1.60 seconds\n",
            "Batch 390/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 1/3, Batch 390/448, Loss: 0.6657, Time: 1.62 seconds\n",
            "Batch 391/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 391/448, Loss: 0.5019, Time: 1.61 seconds\n",
            "Batch 392/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 392/448, Loss: 0.8328, Time: 1.61 seconds\n",
            "Batch 393/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 393/448, Loss: 0.8019, Time: 1.61 seconds\n",
            "Batch 394/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 394/448, Loss: 0.7133, Time: 1.62 seconds\n",
            "Batch 395/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 1/3, Batch 395/448, Loss: 0.5985, Time: 1.62 seconds\n",
            "Batch 396/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 1/3, Batch 396/448, Loss: 0.6831, Time: 1.61 seconds\n",
            "Batch 397/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 397/448, Loss: 0.5994, Time: 1.62 seconds\n",
            "Batch 398/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 1/3, Batch 398/448, Loss: 0.9374, Time: 1.62 seconds\n",
            "Batch 399/448, Label Counts: {0: 4, 1: 10, 2: 2}\n",
            "Epoch 1/3, Batch 399/448, Loss: 0.6146, Time: 1.61 seconds\n",
            "Batch 400/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 400/448, Loss: 0.7375, Time: 1.62 seconds\n",
            "Batch 401/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 401/448, Loss: 0.7766, Time: 1.62 seconds\n",
            "Batch 402/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 402/448, Loss: 0.5322, Time: 1.62 seconds\n",
            "Batch 403/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 403/448, Loss: 0.6062, Time: 1.61 seconds\n",
            "Batch 404/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 404/448, Loss: 0.8347, Time: 1.62 seconds\n",
            "Batch 405/448, Label Counts: {0: 1, 1: 9, 2: 6}\n",
            "Epoch 1/3, Batch 405/448, Loss: 0.7053, Time: 1.62 seconds\n",
            "Batch 406/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 406/448, Loss: 0.5728, Time: 1.63 seconds\n",
            "Batch 407/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 407/448, Loss: 0.6946, Time: 1.62 seconds\n",
            "Batch 408/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 1/3, Batch 408/448, Loss: 0.7649, Time: 1.62 seconds\n",
            "Batch 409/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 1/3, Batch 409/448, Loss: 0.6862, Time: 1.62 seconds\n",
            "Batch 410/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 1/3, Batch 410/448, Loss: 0.7545, Time: 1.62 seconds\n",
            "Batch 411/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 411/448, Loss: 0.6194, Time: 1.61 seconds\n",
            "Batch 412/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 412/448, Loss: 0.8076, Time: 1.62 seconds\n",
            "Batch 413/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 413/448, Loss: 0.6042, Time: 1.61 seconds\n",
            "Batch 414/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 414/448, Loss: 1.0602, Time: 1.62 seconds\n",
            "Batch 415/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 1/3, Batch 415/448, Loss: 0.8208, Time: 1.62 seconds\n",
            "Batch 416/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 416/448, Loss: 0.5244, Time: 1.63 seconds\n",
            "Batch 417/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 417/448, Loss: 0.5283, Time: 1.62 seconds\n",
            "Batch 418/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 418/448, Loss: 0.5578, Time: 1.62 seconds\n",
            "Batch 419/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 1/3, Batch 419/448, Loss: 0.9466, Time: 1.61 seconds\n",
            "Batch 420/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 420/448, Loss: 0.6389, Time: 1.63 seconds\n",
            "Batch 421/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 1/3, Batch 421/448, Loss: 0.7158, Time: 1.62 seconds\n",
            "Batch 422/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 422/448, Loss: 0.7446, Time: 1.61 seconds\n",
            "Batch 423/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 423/448, Loss: 0.7831, Time: 1.62 seconds\n",
            "Batch 424/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 1/3, Batch 424/448, Loss: 0.6294, Time: 1.61 seconds\n",
            "Batch 425/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 425/448, Loss: 0.5229, Time: 1.62 seconds\n",
            "Batch 426/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 1/3, Batch 426/448, Loss: 0.6376, Time: 1.62 seconds\n",
            "Batch 427/448, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 1/3, Batch 427/448, Loss: 0.8997, Time: 1.62 seconds\n",
            "Batch 428/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 428/448, Loss: 0.9972, Time: 1.62 seconds\n",
            "Batch 429/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 429/448, Loss: 0.8519, Time: 1.62 seconds\n",
            "Batch 430/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 1/3, Batch 430/448, Loss: 0.7659, Time: 1.63 seconds\n",
            "Batch 431/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 431/448, Loss: 1.1275, Time: 1.62 seconds\n",
            "Batch 432/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 432/448, Loss: 0.4463, Time: 1.63 seconds\n",
            "Batch 433/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 1/3, Batch 433/448, Loss: 0.5437, Time: 1.62 seconds\n",
            "Batch 434/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 1/3, Batch 434/448, Loss: 0.7065, Time: 1.62 seconds\n",
            "Batch 435/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 1/3, Batch 435/448, Loss: 0.6635, Time: 1.61 seconds\n",
            "Batch 436/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 1/3, Batch 436/448, Loss: 0.9260, Time: 1.63 seconds\n",
            "Batch 437/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 1/3, Batch 437/448, Loss: 0.4909, Time: 1.63 seconds\n",
            "Batch 438/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 1/3, Batch 438/448, Loss: 0.8866, Time: 1.63 seconds\n",
            "Batch 439/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 1/3, Batch 439/448, Loss: 0.5974, Time: 1.62 seconds\n",
            "Batch 440/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 1/3, Batch 440/448, Loss: 0.8202, Time: 1.62 seconds\n",
            "Batch 441/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 1/3, Batch 441/448, Loss: 0.7798, Time: 1.63 seconds\n",
            "Batch 442/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 442/448, Loss: 0.5384, Time: 1.62 seconds\n",
            "Batch 443/448, Label Counts: {0: 1, 1: 7, 2: 8}\n",
            "Epoch 1/3, Batch 443/448, Loss: 0.6164, Time: 1.63 seconds\n",
            "Batch 444/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 1/3, Batch 444/448, Loss: 0.9823, Time: 1.62 seconds\n",
            "Batch 445/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 1/3, Batch 445/448, Loss: 0.8293, Time: 1.62 seconds\n",
            "Batch 446/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 1/3, Batch 446/448, Loss: 0.5303, Time: 1.63 seconds\n",
            "Batch 447/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 1/3, Batch 447/448, Loss: 0.7705, Time: 1.63 seconds\n",
            "Batch 448/448, Label Counts: {0: 3, 2: 6}\n",
            "Epoch 1/3, Batch 448/448, Loss: 0.4872, Time: 0.92 seconds\n",
            "Epoch 1/3, Training Loss: 0.8034, Time: 712.98 seconds\n",
            "Validation Loss: 0.8817, Accuracy: 0.6754\n",
            "Batch 1/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 1/448, Loss: 0.7465, Time: 1.63 seconds\n",
            "Batch 2/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 2/448, Loss: 0.7437, Time: 1.62 seconds\n",
            "Batch 3/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 3/448, Loss: 0.8262, Time: 1.62 seconds\n",
            "Batch 4/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 4/448, Loss: 0.9391, Time: 1.63 seconds\n",
            "Batch 5/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 5/448, Loss: 0.7109, Time: 1.61 seconds\n",
            "Batch 6/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 6/448, Loss: 0.6829, Time: 1.62 seconds\n",
            "Batch 7/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 7/448, Loss: 0.5112, Time: 1.62 seconds\n",
            "Batch 8/448, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 2/3, Batch 8/448, Loss: 0.8132, Time: 1.62 seconds\n",
            "Batch 9/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 2/3, Batch 9/448, Loss: 0.9273, Time: 1.63 seconds\n",
            "Batch 10/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 10/448, Loss: 0.7083, Time: 1.62 seconds\n",
            "Batch 11/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 11/448, Loss: 0.7252, Time: 1.63 seconds\n",
            "Batch 12/448, Label Counts: {0: 6, 1: 9, 2: 1}\n",
            "Epoch 2/3, Batch 12/448, Loss: 0.6501, Time: 1.62 seconds\n",
            "Batch 13/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 13/448, Loss: 0.7438, Time: 1.62 seconds\n",
            "Batch 14/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 14/448, Loss: 0.8063, Time: 1.62 seconds\n",
            "Batch 15/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 15/448, Loss: 0.4992, Time: 1.62 seconds\n",
            "Batch 16/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 16/448, Loss: 0.7070, Time: 1.62 seconds\n",
            "Batch 17/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 17/448, Loss: 0.7139, Time: 1.62 seconds\n",
            "Batch 18/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 18/448, Loss: 0.6949, Time: 1.62 seconds\n",
            "Batch 19/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 19/448, Loss: 0.5798, Time: 1.62 seconds\n",
            "Batch 20/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 20/448, Loss: 0.5997, Time: 1.63 seconds\n",
            "Batch 21/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 21/448, Loss: 0.5165, Time: 1.63 seconds\n",
            "Batch 22/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 22/448, Loss: 0.7413, Time: 1.63 seconds\n",
            "Batch 23/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 23/448, Loss: 0.4932, Time: 1.62 seconds\n",
            "Batch 24/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 24/448, Loss: 0.6354, Time: 1.62 seconds\n",
            "Batch 25/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 25/448, Loss: 0.4104, Time: 1.63 seconds\n",
            "Batch 26/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 26/448, Loss: 0.8006, Time: 1.63 seconds\n",
            "Batch 27/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 27/448, Loss: 0.5085, Time: 1.62 seconds\n",
            "Batch 28/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 28/448, Loss: 0.7822, Time: 1.62 seconds\n",
            "Batch 29/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 29/448, Loss: 0.5900, Time: 1.63 seconds\n",
            "Batch 30/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/3, Batch 30/448, Loss: 0.9357, Time: 1.62 seconds\n",
            "Batch 31/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 31/448, Loss: 0.7537, Time: 1.63 seconds\n",
            "Batch 32/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 32/448, Loss: 0.4735, Time: 1.63 seconds\n",
            "Batch 33/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 33/448, Loss: 0.4754, Time: 1.62 seconds\n",
            "Batch 34/448, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 2/3, Batch 34/448, Loss: 0.5121, Time: 1.63 seconds\n",
            "Batch 35/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 35/448, Loss: 0.4987, Time: 1.62 seconds\n",
            "Batch 36/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 36/448, Loss: 0.5854, Time: 1.62 seconds\n",
            "Batch 37/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 37/448, Loss: 0.7729, Time: 1.63 seconds\n",
            "Batch 38/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 38/448, Loss: 1.1889, Time: 1.62 seconds\n",
            "Batch 39/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 39/448, Loss: 0.7392, Time: 1.62 seconds\n",
            "Batch 40/448, Label Counts: {0: 10, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 40/448, Loss: 0.4438, Time: 1.61 seconds\n",
            "Batch 41/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 41/448, Loss: 0.9050, Time: 1.62 seconds\n",
            "Batch 42/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 42/448, Loss: 0.5963, Time: 1.61 seconds\n",
            "Batch 43/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 43/448, Loss: 0.8287, Time: 1.62 seconds\n",
            "Batch 44/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 44/448, Loss: 0.5219, Time: 1.62 seconds\n",
            "Batch 45/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 2/3, Batch 45/448, Loss: 0.6218, Time: 1.62 seconds\n",
            "Batch 46/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 46/448, Loss: 0.8474, Time: 1.62 seconds\n",
            "Batch 47/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 47/448, Loss: 0.5163, Time: 1.62 seconds\n",
            "Batch 48/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 48/448, Loss: 0.6421, Time: 1.63 seconds\n",
            "Batch 49/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 49/448, Loss: 0.7500, Time: 1.61 seconds\n",
            "Batch 50/448, Label Counts: {0: 2, 1: 11, 2: 3}\n",
            "Epoch 2/3, Batch 50/448, Loss: 0.8144, Time: 1.62 seconds\n",
            "Batch 51/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 51/448, Loss: 0.6546, Time: 1.61 seconds\n",
            "Batch 52/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 52/448, Loss: 0.5295, Time: 1.62 seconds\n",
            "Batch 53/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 53/448, Loss: 0.8341, Time: 1.62 seconds\n",
            "Batch 54/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 54/448, Loss: 0.8169, Time: 1.62 seconds\n",
            "Batch 55/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 55/448, Loss: 0.5232, Time: 1.61 seconds\n",
            "Batch 56/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 56/448, Loss: 0.7967, Time: 1.62 seconds\n",
            "Batch 57/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 2/3, Batch 57/448, Loss: 0.8469, Time: 1.62 seconds\n",
            "Batch 58/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 2/3, Batch 58/448, Loss: 0.6730, Time: 1.61 seconds\n",
            "Batch 59/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 59/448, Loss: 0.4657, Time: 1.62 seconds\n",
            "Batch 60/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 60/448, Loss: 0.7335, Time: 1.62 seconds\n",
            "Batch 61/448, Label Counts: {0: 9, 1: 1, 2: 6}\n",
            "Epoch 2/3, Batch 61/448, Loss: 0.6012, Time: 1.63 seconds\n",
            "Batch 62/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 62/448, Loss: 0.6970, Time: 1.62 seconds\n",
            "Batch 63/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 63/448, Loss: 0.5516, Time: 1.62 seconds\n",
            "Batch 64/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 64/448, Loss: 0.6277, Time: 1.62 seconds\n",
            "Batch 65/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 65/448, Loss: 0.4463, Time: 1.61 seconds\n",
            "Batch 66/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 66/448, Loss: 0.9325, Time: 1.62 seconds\n",
            "Batch 67/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 67/448, Loss: 0.6068, Time: 1.62 seconds\n",
            "Batch 68/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 68/448, Loss: 0.7136, Time: 1.62 seconds\n",
            "Batch 69/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 69/448, Loss: 0.7006, Time: 1.62 seconds\n",
            "Batch 70/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 70/448, Loss: 0.7640, Time: 1.62 seconds\n",
            "Batch 71/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 71/448, Loss: 0.6396, Time: 1.62 seconds\n",
            "Batch 72/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 72/448, Loss: 0.8682, Time: 1.62 seconds\n",
            "Batch 73/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 73/448, Loss: 0.5863, Time: 1.62 seconds\n",
            "Batch 74/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 74/448, Loss: 0.8424, Time: 1.61 seconds\n",
            "Batch 75/448, Label Counts: {0: 1, 1: 8, 2: 7}\n",
            "Epoch 2/3, Batch 75/448, Loss: 0.5401, Time: 1.61 seconds\n",
            "Batch 76/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 76/448, Loss: 0.5309, Time: 1.62 seconds\n",
            "Batch 77/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 2/3, Batch 77/448, Loss: 0.6340, Time: 1.62 seconds\n",
            "Batch 78/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 78/448, Loss: 0.8444, Time: 1.61 seconds\n",
            "Batch 79/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 79/448, Loss: 0.8487, Time: 1.62 seconds\n",
            "Batch 80/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 80/448, Loss: 0.8091, Time: 1.62 seconds\n",
            "Batch 81/448, Label Counts: {0: 10, 2: 6}\n",
            "Epoch 2/3, Batch 81/448, Loss: 0.7139, Time: 1.62 seconds\n",
            "Batch 82/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 82/448, Loss: 0.6687, Time: 1.61 seconds\n",
            "Batch 83/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 83/448, Loss: 0.6251, Time: 1.62 seconds\n",
            "Batch 84/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 84/448, Loss: 0.8837, Time: 1.60 seconds\n",
            "Batch 85/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 85/448, Loss: 0.4498, Time: 1.61 seconds\n",
            "Batch 86/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 86/448, Loss: 0.3835, Time: 1.62 seconds\n",
            "Batch 87/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 87/448, Loss: 0.6062, Time: 1.62 seconds\n",
            "Batch 88/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 88/448, Loss: 0.6446, Time: 1.61 seconds\n",
            "Batch 89/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 89/448, Loss: 0.5738, Time: 1.62 seconds\n",
            "Batch 90/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 90/448, Loss: 0.8105, Time: 1.62 seconds\n",
            "Batch 91/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 91/448, Loss: 0.7317, Time: 1.62 seconds\n",
            "Batch 92/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 92/448, Loss: 0.6440, Time: 1.62 seconds\n",
            "Batch 93/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 93/448, Loss: 0.6586, Time: 1.62 seconds\n",
            "Batch 94/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/3, Batch 94/448, Loss: 0.7828, Time: 1.61 seconds\n",
            "Batch 95/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 95/448, Loss: 0.7156, Time: 1.62 seconds\n",
            "Batch 96/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 96/448, Loss: 0.7654, Time: 1.61 seconds\n",
            "Batch 97/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 97/448, Loss: 0.5665, Time: 1.61 seconds\n",
            "Batch 98/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 98/448, Loss: 0.7143, Time: 1.61 seconds\n",
            "Batch 99/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 99/448, Loss: 0.4930, Time: 1.61 seconds\n",
            "Batch 100/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 2/3, Batch 100/448, Loss: 0.4826, Time: 1.61 seconds\n",
            "Batch 101/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 101/448, Loss: 0.6877, Time: 1.61 seconds\n",
            "Batch 102/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/3, Batch 102/448, Loss: 0.5412, Time: 1.62 seconds\n",
            "Batch 103/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 103/448, Loss: 0.5177, Time: 1.61 seconds\n",
            "Batch 104/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 104/448, Loss: 0.8345, Time: 1.60 seconds\n",
            "Batch 105/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 105/448, Loss: 0.3950, Time: 1.62 seconds\n",
            "Batch 106/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 106/448, Loss: 0.9240, Time: 1.62 seconds\n",
            "Batch 107/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 107/448, Loss: 0.9333, Time: 1.62 seconds\n",
            "Batch 108/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 2/3, Batch 108/448, Loss: 0.8930, Time: 1.61 seconds\n",
            "Batch 109/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 109/448, Loss: 0.5629, Time: 1.61 seconds\n",
            "Batch 110/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 110/448, Loss: 0.2719, Time: 1.61 seconds\n",
            "Batch 111/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 111/448, Loss: 0.6417, Time: 1.61 seconds\n",
            "Batch 112/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 112/448, Loss: 0.3570, Time: 1.61 seconds\n",
            "Batch 113/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 113/448, Loss: 0.6299, Time: 1.61 seconds\n",
            "Batch 114/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 114/448, Loss: 0.8973, Time: 1.62 seconds\n",
            "Batch 115/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 115/448, Loss: 0.7620, Time: 1.62 seconds\n",
            "Batch 116/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 116/448, Loss: 0.7591, Time: 1.61 seconds\n",
            "Batch 117/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 117/448, Loss: 0.5767, Time: 1.62 seconds\n",
            "Batch 118/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 118/448, Loss: 0.9476, Time: 1.62 seconds\n",
            "Batch 119/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 119/448, Loss: 0.4717, Time: 1.59 seconds\n",
            "Batch 120/448, Label Counts: {0: 5, 1: 10, 2: 1}\n",
            "Epoch 2/3, Batch 120/448, Loss: 0.5872, Time: 1.60 seconds\n",
            "Batch 121/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 121/448, Loss: 0.9789, Time: 1.61 seconds\n",
            "Batch 122/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 122/448, Loss: 0.6485, Time: 1.60 seconds\n",
            "Batch 123/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 123/448, Loss: 0.8035, Time: 1.62 seconds\n",
            "Batch 124/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 124/448, Loss: 0.7208, Time: 1.61 seconds\n",
            "Batch 125/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 125/448, Loss: 0.7829, Time: 1.61 seconds\n",
            "Batch 126/448, Label Counts: {0: 2, 1: 9, 2: 5}\n",
            "Epoch 2/3, Batch 126/448, Loss: 0.8351, Time: 1.61 seconds\n",
            "Batch 127/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 127/448, Loss: 0.7758, Time: 1.60 seconds\n",
            "Batch 128/448, Label Counts: {0: 1, 1: 9, 2: 6}\n",
            "Epoch 2/3, Batch 128/448, Loss: 0.6801, Time: 1.61 seconds\n",
            "Batch 129/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 2/3, Batch 129/448, Loss: 0.6115, Time: 1.60 seconds\n",
            "Batch 130/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 130/448, Loss: 0.8555, Time: 1.61 seconds\n",
            "Batch 131/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 131/448, Loss: 0.5627, Time: 1.62 seconds\n",
            "Batch 132/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 132/448, Loss: 0.8658, Time: 1.61 seconds\n",
            "Batch 133/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/3, Batch 133/448, Loss: 1.0284, Time: 1.61 seconds\n",
            "Batch 134/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 134/448, Loss: 0.4074, Time: 1.60 seconds\n",
            "Batch 135/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 2/3, Batch 135/448, Loss: 0.6406, Time: 1.60 seconds\n",
            "Batch 136/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 136/448, Loss: 0.6417, Time: 1.60 seconds\n",
            "Batch 137/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 137/448, Loss: 0.7745, Time: 1.62 seconds\n",
            "Batch 138/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 138/448, Loss: 0.7485, Time: 1.61 seconds\n",
            "Batch 139/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 139/448, Loss: 1.1360, Time: 1.61 seconds\n",
            "Batch 140/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/3, Batch 140/448, Loss: 0.6428, Time: 1.61 seconds\n",
            "Batch 141/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 141/448, Loss: 0.3951, Time: 1.62 seconds\n",
            "Batch 142/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 142/448, Loss: 0.9317, Time: 1.61 seconds\n",
            "Batch 143/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/3, Batch 143/448, Loss: 0.4443, Time: 1.61 seconds\n",
            "Batch 144/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 2/3, Batch 144/448, Loss: 0.9105, Time: 1.61 seconds\n",
            "Batch 145/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 2/3, Batch 145/448, Loss: 0.6275, Time: 1.62 seconds\n",
            "Batch 146/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 146/448, Loss: 0.7208, Time: 1.62 seconds\n",
            "Batch 147/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 147/448, Loss: 0.8630, Time: 1.61 seconds\n",
            "Batch 148/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 148/448, Loss: 0.7198, Time: 1.62 seconds\n",
            "Batch 149/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 149/448, Loss: 0.7509, Time: 1.62 seconds\n",
            "Batch 150/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 150/448, Loss: 0.7774, Time: 1.62 seconds\n",
            "Batch 151/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 151/448, Loss: 0.4982, Time: 1.60 seconds\n",
            "Batch 152/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 152/448, Loss: 0.6322, Time: 1.62 seconds\n",
            "Batch 153/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 153/448, Loss: 0.4693, Time: 1.60 seconds\n",
            "Batch 154/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 154/448, Loss: 0.6332, Time: 1.60 seconds\n",
            "Batch 155/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 155/448, Loss: 1.0700, Time: 1.62 seconds\n",
            "Batch 156/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 156/448, Loss: 0.9436, Time: 1.61 seconds\n",
            "Batch 157/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 157/448, Loss: 0.6314, Time: 1.62 seconds\n",
            "Batch 158/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 158/448, Loss: 0.4172, Time: 1.61 seconds\n",
            "Batch 159/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 159/448, Loss: 0.7312, Time: 1.60 seconds\n",
            "Batch 160/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 160/448, Loss: 0.8643, Time: 1.61 seconds\n",
            "Batch 161/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 161/448, Loss: 0.5688, Time: 1.60 seconds\n",
            "Batch 162/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 162/448, Loss: 0.6671, Time: 1.61 seconds\n",
            "Batch 163/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 163/448, Loss: 0.7659, Time: 1.60 seconds\n",
            "Batch 164/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 2/3, Batch 164/448, Loss: 0.9488, Time: 1.61 seconds\n",
            "Batch 165/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 165/448, Loss: 0.7471, Time: 1.62 seconds\n",
            "Batch 166/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 166/448, Loss: 0.5100, Time: 1.61 seconds\n",
            "Batch 167/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 167/448, Loss: 0.6578, Time: 1.62 seconds\n",
            "Batch 168/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 168/448, Loss: 0.7563, Time: 1.60 seconds\n",
            "Batch 169/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 169/448, Loss: 0.5995, Time: 1.60 seconds\n",
            "Batch 170/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 170/448, Loss: 0.5199, Time: 1.60 seconds\n",
            "Batch 171/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 171/448, Loss: 0.7357, Time: 1.61 seconds\n",
            "Batch 172/448, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 2/3, Batch 172/448, Loss: 0.6559, Time: 1.62 seconds\n",
            "Batch 173/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 173/448, Loss: 0.7243, Time: 1.62 seconds\n",
            "Batch 174/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 174/448, Loss: 0.6961, Time: 1.61 seconds\n",
            "Batch 175/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 175/448, Loss: 0.5954, Time: 1.62 seconds\n",
            "Batch 176/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 176/448, Loss: 0.6196, Time: 1.61 seconds\n",
            "Batch 177/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 177/448, Loss: 0.6790, Time: 1.60 seconds\n",
            "Batch 178/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 178/448, Loss: 0.5949, Time: 1.60 seconds\n",
            "Batch 179/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 179/448, Loss: 0.6201, Time: 1.62 seconds\n",
            "Batch 180/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 180/448, Loss: 0.5232, Time: 1.62 seconds\n",
            "Batch 181/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 181/448, Loss: 0.7896, Time: 1.60 seconds\n",
            "Batch 182/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 182/448, Loss: 0.5489, Time: 1.60 seconds\n",
            "Batch 183/448, Label Counts: {0: 10, 1: 4, 2: 2}\n",
            "Epoch 2/3, Batch 183/448, Loss: 0.3822, Time: 1.60 seconds\n",
            "Batch 184/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 184/448, Loss: 0.5151, Time: 1.60 seconds\n",
            "Batch 185/448, Label Counts: {0: 11, 1: 3, 2: 2}\n",
            "Epoch 2/3, Batch 185/448, Loss: 0.5116, Time: 1.61 seconds\n",
            "Batch 186/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 186/448, Loss: 0.7114, Time: 1.62 seconds\n",
            "Batch 187/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 187/448, Loss: 0.7181, Time: 1.60 seconds\n",
            "Batch 188/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 188/448, Loss: 0.6033, Time: 1.60 seconds\n",
            "Batch 189/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 189/448, Loss: 0.9143, Time: 1.62 seconds\n",
            "Batch 190/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 190/448, Loss: 0.4163, Time: 1.61 seconds\n",
            "Batch 191/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 191/448, Loss: 0.7165, Time: 1.60 seconds\n",
            "Batch 192/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 192/448, Loss: 0.7754, Time: 1.61 seconds\n",
            "Batch 193/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 193/448, Loss: 0.7779, Time: 1.60 seconds\n",
            "Batch 194/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/3, Batch 194/448, Loss: 0.7332, Time: 1.61 seconds\n",
            "Batch 195/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 2/3, Batch 195/448, Loss: 0.8320, Time: 1.60 seconds\n",
            "Batch 196/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 196/448, Loss: 0.5081, Time: 1.62 seconds\n",
            "Batch 197/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 197/448, Loss: 0.6929, Time: 1.62 seconds\n",
            "Batch 198/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 198/448, Loss: 0.5965, Time: 1.60 seconds\n",
            "Batch 199/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 199/448, Loss: 0.4622, Time: 1.61 seconds\n",
            "Batch 200/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 2/3, Batch 200/448, Loss: 0.8465, Time: 1.60 seconds\n",
            "Batch 201/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/3, Batch 201/448, Loss: 0.6217, Time: 1.62 seconds\n",
            "Batch 202/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 202/448, Loss: 0.3460, Time: 1.60 seconds\n",
            "Batch 203/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 2/3, Batch 203/448, Loss: 0.6621, Time: 1.61 seconds\n",
            "Batch 204/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 204/448, Loss: 0.6601, Time: 1.62 seconds\n",
            "Batch 205/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 205/448, Loss: 0.4680, Time: 1.61 seconds\n",
            "Batch 206/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 206/448, Loss: 0.4361, Time: 1.61 seconds\n",
            "Batch 207/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 207/448, Loss: 0.9789, Time: 1.62 seconds\n",
            "Batch 208/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 208/448, Loss: 0.7052, Time: 1.60 seconds\n",
            "Batch 209/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 209/448, Loss: 0.6631, Time: 1.61 seconds\n",
            "Batch 210/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 210/448, Loss: 0.5717, Time: 1.62 seconds\n",
            "Batch 211/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 211/448, Loss: 0.3091, Time: 1.61 seconds\n",
            "Batch 212/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 212/448, Loss: 0.3846, Time: 1.60 seconds\n",
            "Batch 213/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 213/448, Loss: 0.6062, Time: 1.60 seconds\n",
            "Batch 214/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 214/448, Loss: 0.6940, Time: 1.60 seconds\n",
            "Batch 215/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 215/448, Loss: 0.5297, Time: 1.61 seconds\n",
            "Batch 216/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 216/448, Loss: 0.7492, Time: 1.60 seconds\n",
            "Batch 217/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 217/448, Loss: 0.6233, Time: 1.61 seconds\n",
            "Batch 218/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 218/448, Loss: 0.4832, Time: 1.59 seconds\n",
            "Batch 219/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 219/448, Loss: 0.4188, Time: 1.60 seconds\n",
            "Batch 220/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 220/448, Loss: 0.7318, Time: 1.62 seconds\n",
            "Batch 221/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 221/448, Loss: 0.6224, Time: 1.60 seconds\n",
            "Batch 222/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 222/448, Loss: 0.7600, Time: 1.62 seconds\n",
            "Batch 223/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 223/448, Loss: 1.0515, Time: 1.62 seconds\n",
            "Batch 224/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/3, Batch 224/448, Loss: 0.2737, Time: 1.61 seconds\n",
            "Batch 225/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 225/448, Loss: 0.5323, Time: 1.60 seconds\n",
            "Batch 226/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/3, Batch 226/448, Loss: 0.8359, Time: 1.62 seconds\n",
            "Batch 227/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 227/448, Loss: 0.7298, Time: 1.61 seconds\n",
            "Batch 228/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 228/448, Loss: 0.4914, Time: 1.60 seconds\n",
            "Batch 229/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 2/3, Batch 229/448, Loss: 0.6529, Time: 1.62 seconds\n",
            "Batch 230/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 230/448, Loss: 0.9021, Time: 1.60 seconds\n",
            "Batch 231/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 2/3, Batch 231/448, Loss: 0.7212, Time: 1.61 seconds\n",
            "Batch 232/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 232/448, Loss: 0.7388, Time: 1.61 seconds\n",
            "Batch 233/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 2/3, Batch 233/448, Loss: 0.8222, Time: 1.61 seconds\n",
            "Batch 234/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 234/448, Loss: 0.6298, Time: 1.61 seconds\n",
            "Batch 235/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 235/448, Loss: 0.7287, Time: 1.62 seconds\n",
            "Batch 236/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 236/448, Loss: 0.4026, Time: 1.60 seconds\n",
            "Batch 237/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 237/448, Loss: 0.4041, Time: 1.62 seconds\n",
            "Batch 238/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 238/448, Loss: 0.6853, Time: 1.60 seconds\n",
            "Batch 239/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 239/448, Loss: 0.3397, Time: 1.61 seconds\n",
            "Batch 240/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 240/448, Loss: 0.4175, Time: 1.60 seconds\n",
            "Batch 241/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 241/448, Loss: 0.7285, Time: 1.61 seconds\n",
            "Batch 242/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 242/448, Loss: 0.8245, Time: 1.60 seconds\n",
            "Batch 243/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 2/3, Batch 243/448, Loss: 0.6012, Time: 1.60 seconds\n",
            "Batch 244/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 244/448, Loss: 0.9290, Time: 1.62 seconds\n",
            "Batch 245/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 2/3, Batch 245/448, Loss: 1.0104, Time: 1.60 seconds\n",
            "Batch 246/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 246/448, Loss: 0.6934, Time: 1.62 seconds\n",
            "Batch 247/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/3, Batch 247/448, Loss: 0.9012, Time: 1.62 seconds\n",
            "Batch 248/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 2/3, Batch 248/448, Loss: 0.6863, Time: 1.61 seconds\n",
            "Batch 249/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 249/448, Loss: 0.7444, Time: 1.60 seconds\n",
            "Batch 250/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 250/448, Loss: 0.5195, Time: 1.62 seconds\n",
            "Batch 251/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 251/448, Loss: 0.7341, Time: 1.61 seconds\n",
            "Batch 252/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 252/448, Loss: 0.5055, Time: 1.60 seconds\n",
            "Batch 253/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/3, Batch 253/448, Loss: 0.7336, Time: 1.60 seconds\n",
            "Batch 254/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 254/448, Loss: 0.8186, Time: 1.61 seconds\n",
            "Batch 255/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 255/448, Loss: 0.5299, Time: 1.62 seconds\n",
            "Batch 256/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 256/448, Loss: 0.6544, Time: 1.61 seconds\n",
            "Batch 257/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 257/448, Loss: 0.3842, Time: 1.59 seconds\n",
            "Batch 258/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 258/448, Loss: 1.1021, Time: 1.60 seconds\n",
            "Batch 259/448, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 2/3, Batch 259/448, Loss: 0.6220, Time: 1.59 seconds\n",
            "Batch 260/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 260/448, Loss: 0.7320, Time: 1.60 seconds\n",
            "Batch 261/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 261/448, Loss: 0.5366, Time: 1.62 seconds\n",
            "Batch 262/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 262/448, Loss: 0.6519, Time: 1.60 seconds\n",
            "Batch 263/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 263/448, Loss: 0.5568, Time: 1.61 seconds\n",
            "Batch 264/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 264/448, Loss: 0.9599, Time: 1.61 seconds\n",
            "Batch 265/448, Label Counts: {0: 4, 1: 10, 2: 2}\n",
            "Epoch 2/3, Batch 265/448, Loss: 0.8977, Time: 1.62 seconds\n",
            "Batch 266/448, Label Counts: {0: 11, 2: 5}\n",
            "Epoch 2/3, Batch 266/448, Loss: 0.5323, Time: 1.60 seconds\n",
            "Batch 267/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 267/448, Loss: 0.6473, Time: 1.61 seconds\n",
            "Batch 268/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 268/448, Loss: 0.7805, Time: 1.61 seconds\n",
            "Batch 269/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 269/448, Loss: 0.6077, Time: 1.60 seconds\n",
            "Batch 270/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 270/448, Loss: 0.6708, Time: 1.60 seconds\n",
            "Batch 271/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 271/448, Loss: 0.4637, Time: 1.61 seconds\n",
            "Batch 272/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 272/448, Loss: 0.7856, Time: 1.62 seconds\n",
            "Batch 273/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 273/448, Loss: 0.6441, Time: 1.60 seconds\n",
            "Batch 274/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 274/448, Loss: 0.8238, Time: 1.61 seconds\n",
            "Batch 275/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 275/448, Loss: 0.7565, Time: 1.61 seconds\n",
            "Batch 276/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 276/448, Loss: 0.6945, Time: 1.61 seconds\n",
            "Batch 277/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 277/448, Loss: 0.7315, Time: 1.61 seconds\n",
            "Batch 278/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 278/448, Loss: 0.5726, Time: 1.62 seconds\n",
            "Batch 279/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 279/448, Loss: 0.4316, Time: 1.62 seconds\n",
            "Batch 280/448, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 2/3, Batch 280/448, Loss: 0.4780, Time: 1.61 seconds\n",
            "Batch 281/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 281/448, Loss: 0.5821, Time: 1.62 seconds\n",
            "Batch 282/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 282/448, Loss: 0.6798, Time: 1.62 seconds\n",
            "Batch 283/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 283/448, Loss: 0.8106, Time: 1.62 seconds\n",
            "Batch 284/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 284/448, Loss: 0.6411, Time: 1.60 seconds\n",
            "Batch 285/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 285/448, Loss: 0.4256, Time: 1.61 seconds\n",
            "Batch 286/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 2/3, Batch 286/448, Loss: 0.6317, Time: 1.62 seconds\n",
            "Batch 287/448, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 2/3, Batch 287/448, Loss: 0.4054, Time: 1.60 seconds\n",
            "Batch 288/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/3, Batch 288/448, Loss: 0.4057, Time: 1.61 seconds\n",
            "Batch 289/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 289/448, Loss: 0.8638, Time: 1.62 seconds\n",
            "Batch 290/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 290/448, Loss: 0.5369, Time: 1.62 seconds\n",
            "Batch 291/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 291/448, Loss: 0.3888, Time: 1.60 seconds\n",
            "Batch 292/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 292/448, Loss: 0.6865, Time: 1.61 seconds\n",
            "Batch 293/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 293/448, Loss: 0.4419, Time: 1.62 seconds\n",
            "Batch 294/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 294/448, Loss: 0.6358, Time: 1.60 seconds\n",
            "Batch 295/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 295/448, Loss: 0.3952, Time: 1.62 seconds\n",
            "Batch 296/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 296/448, Loss: 0.5474, Time: 1.62 seconds\n",
            "Batch 297/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 297/448, Loss: 0.4701, Time: 1.62 seconds\n",
            "Batch 298/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 2/3, Batch 298/448, Loss: 0.3759, Time: 1.62 seconds\n",
            "Batch 299/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 299/448, Loss: 0.8713, Time: 1.61 seconds\n",
            "Batch 300/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 300/448, Loss: 0.8302, Time: 1.60 seconds\n",
            "Batch 301/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 301/448, Loss: 0.6477, Time: 1.60 seconds\n",
            "Batch 302/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 2/3, Batch 302/448, Loss: 0.5928, Time: 1.61 seconds\n",
            "Batch 303/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 303/448, Loss: 0.6438, Time: 1.61 seconds\n",
            "Batch 304/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 304/448, Loss: 0.7300, Time: 1.61 seconds\n",
            "Batch 305/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 305/448, Loss: 0.7387, Time: 1.61 seconds\n",
            "Batch 306/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 306/448, Loss: 0.4305, Time: 1.61 seconds\n",
            "Batch 307/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 307/448, Loss: 0.4901, Time: 1.61 seconds\n",
            "Batch 308/448, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 2/3, Batch 308/448, Loss: 0.2209, Time: 1.60 seconds\n",
            "Batch 309/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 2/3, Batch 309/448, Loss: 0.3335, Time: 1.59 seconds\n",
            "Batch 310/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 310/448, Loss: 0.5710, Time: 1.62 seconds\n",
            "Batch 311/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 311/448, Loss: 0.3041, Time: 1.60 seconds\n",
            "Batch 312/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 312/448, Loss: 0.5777, Time: 1.60 seconds\n",
            "Batch 313/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 313/448, Loss: 0.9144, Time: 1.60 seconds\n",
            "Batch 314/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 2/3, Batch 314/448, Loss: 0.9644, Time: 1.62 seconds\n",
            "Batch 315/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 315/448, Loss: 0.8370, Time: 1.60 seconds\n",
            "Batch 316/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 316/448, Loss: 0.6752, Time: 1.60 seconds\n",
            "Batch 317/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 317/448, Loss: 0.6467, Time: 1.60 seconds\n",
            "Batch 318/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 318/448, Loss: 0.8167, Time: 1.61 seconds\n",
            "Batch 319/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 319/448, Loss: 0.4104, Time: 1.62 seconds\n",
            "Batch 320/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 320/448, Loss: 0.4704, Time: 1.61 seconds\n",
            "Batch 321/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 321/448, Loss: 0.6791, Time: 1.60 seconds\n",
            "Batch 322/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 322/448, Loss: 0.4926, Time: 1.60 seconds\n",
            "Batch 323/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/3, Batch 323/448, Loss: 0.3384, Time: 1.62 seconds\n",
            "Batch 324/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 324/448, Loss: 0.3454, Time: 1.61 seconds\n",
            "Batch 325/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 325/448, Loss: 0.5664, Time: 1.62 seconds\n",
            "Batch 326/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 326/448, Loss: 0.4101, Time: 1.62 seconds\n",
            "Batch 327/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 327/448, Loss: 0.3806, Time: 1.60 seconds\n",
            "Batch 328/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 328/448, Loss: 0.5243, Time: 1.61 seconds\n",
            "Batch 329/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 329/448, Loss: 0.5034, Time: 1.60 seconds\n",
            "Batch 330/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 330/448, Loss: 0.8293, Time: 1.61 seconds\n",
            "Batch 331/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 331/448, Loss: 0.8891, Time: 1.62 seconds\n",
            "Batch 332/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 332/448, Loss: 0.3655, Time: 1.62 seconds\n",
            "Batch 333/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 333/448, Loss: 0.7989, Time: 1.61 seconds\n",
            "Batch 334/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 334/448, Loss: 0.6050, Time: 1.62 seconds\n",
            "Batch 335/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 335/448, Loss: 0.4888, Time: 1.61 seconds\n",
            "Batch 336/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 2/3, Batch 336/448, Loss: 0.7491, Time: 1.62 seconds\n",
            "Batch 337/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 337/448, Loss: 0.5743, Time: 1.62 seconds\n",
            "Batch 338/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 2/3, Batch 338/448, Loss: 0.4573, Time: 1.61 seconds\n",
            "Batch 339/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 339/448, Loss: 0.6455, Time: 1.60 seconds\n",
            "Batch 340/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 340/448, Loss: 0.2909, Time: 1.61 seconds\n",
            "Batch 341/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 341/448, Loss: 0.5495, Time: 1.62 seconds\n",
            "Batch 342/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 342/448, Loss: 0.7349, Time: 1.62 seconds\n",
            "Batch 343/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 343/448, Loss: 0.1784, Time: 1.60 seconds\n",
            "Batch 344/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 344/448, Loss: 0.4086, Time: 1.61 seconds\n",
            "Batch 345/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 345/448, Loss: 0.7445, Time: 1.62 seconds\n",
            "Batch 346/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 346/448, Loss: 0.7073, Time: 1.61 seconds\n",
            "Batch 347/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 347/448, Loss: 0.5527, Time: 1.61 seconds\n",
            "Batch 348/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 2/3, Batch 348/448, Loss: 0.9876, Time: 1.61 seconds\n",
            "Batch 349/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 349/448, Loss: 0.6774, Time: 1.61 seconds\n",
            "Batch 350/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 2/3, Batch 350/448, Loss: 0.6579, Time: 1.62 seconds\n",
            "Batch 351/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 351/448, Loss: 0.5893, Time: 1.61 seconds\n",
            "Batch 352/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 352/448, Loss: 0.5081, Time: 1.62 seconds\n",
            "Batch 353/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 2/3, Batch 353/448, Loss: 0.9836, Time: 1.62 seconds\n",
            "Batch 354/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 354/448, Loss: 0.2426, Time: 1.61 seconds\n",
            "Batch 355/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 2/3, Batch 355/448, Loss: 0.7079, Time: 1.62 seconds\n",
            "Batch 356/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 356/448, Loss: 0.6367, Time: 1.60 seconds\n",
            "Batch 357/448, Label Counts: {0: 5, 1: 9, 2: 2}\n",
            "Epoch 2/3, Batch 357/448, Loss: 0.5447, Time: 1.60 seconds\n",
            "Batch 358/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 358/448, Loss: 0.6666, Time: 1.62 seconds\n",
            "Batch 359/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 359/448, Loss: 0.3548, Time: 1.62 seconds\n",
            "Batch 360/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 360/448, Loss: 0.4571, Time: 1.62 seconds\n",
            "Batch 361/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 2/3, Batch 361/448, Loss: 0.8939, Time: 1.62 seconds\n",
            "Batch 362/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 362/448, Loss: 0.5674, Time: 1.60 seconds\n",
            "Batch 363/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 363/448, Loss: 0.6986, Time: 1.60 seconds\n",
            "Batch 364/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 364/448, Loss: 0.5140, Time: 1.61 seconds\n",
            "Batch 365/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/3, Batch 365/448, Loss: 0.5061, Time: 1.61 seconds\n",
            "Batch 366/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 366/448, Loss: 0.6977, Time: 1.63 seconds\n",
            "Batch 367/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 367/448, Loss: 0.5330, Time: 1.61 seconds\n",
            "Batch 368/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 368/448, Loss: 0.5839, Time: 1.61 seconds\n",
            "Batch 369/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 369/448, Loss: 0.4439, Time: 1.61 seconds\n",
            "Batch 370/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 370/448, Loss: 0.5886, Time: 1.60 seconds\n",
            "Batch 371/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 371/448, Loss: 0.7579, Time: 1.61 seconds\n",
            "Batch 372/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 372/448, Loss: 0.5793, Time: 1.62 seconds\n",
            "Batch 373/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 373/448, Loss: 0.4081, Time: 1.62 seconds\n",
            "Batch 374/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 374/448, Loss: 0.6399, Time: 1.62 seconds\n",
            "Batch 375/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 2/3, Batch 375/448, Loss: 0.9792, Time: 1.61 seconds\n",
            "Batch 376/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 376/448, Loss: 0.7099, Time: 1.61 seconds\n",
            "Batch 377/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 2/3, Batch 377/448, Loss: 0.5839, Time: 1.60 seconds\n",
            "Batch 378/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 378/448, Loss: 0.7808, Time: 1.60 seconds\n",
            "Batch 379/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 2/3, Batch 379/448, Loss: 0.3497, Time: 1.60 seconds\n",
            "Batch 380/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 2/3, Batch 380/448, Loss: 0.6873, Time: 1.61 seconds\n",
            "Batch 381/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 381/448, Loss: 0.7438, Time: 1.62 seconds\n",
            "Batch 382/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 382/448, Loss: 0.6955, Time: 1.60 seconds\n",
            "Batch 383/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 2/3, Batch 383/448, Loss: 0.4564, Time: 1.62 seconds\n",
            "Batch 384/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 384/448, Loss: 0.6263, Time: 1.61 seconds\n",
            "Batch 385/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 385/448, Loss: 0.5005, Time: 1.62 seconds\n",
            "Batch 386/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 386/448, Loss: 0.5165, Time: 1.61 seconds\n",
            "Batch 387/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 387/448, Loss: 0.7370, Time: 1.61 seconds\n",
            "Batch 388/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 388/448, Loss: 0.9226, Time: 1.61 seconds\n",
            "Batch 389/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 2/3, Batch 389/448, Loss: 0.3805, Time: 1.62 seconds\n",
            "Batch 390/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 390/448, Loss: 0.4063, Time: 1.61 seconds\n",
            "Batch 391/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 391/448, Loss: 0.5161, Time: 1.61 seconds\n",
            "Batch 392/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 392/448, Loss: 0.4987, Time: 1.60 seconds\n",
            "Batch 393/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 2/3, Batch 393/448, Loss: 0.7391, Time: 1.62 seconds\n",
            "Batch 394/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 2/3, Batch 394/448, Loss: 0.6267, Time: 1.62 seconds\n",
            "Batch 395/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 395/448, Loss: 0.4091, Time: 1.61 seconds\n",
            "Batch 396/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 396/448, Loss: 0.4460, Time: 1.59 seconds\n",
            "Batch 397/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 397/448, Loss: 0.4294, Time: 1.62 seconds\n",
            "Batch 398/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 398/448, Loss: 0.8130, Time: 1.62 seconds\n",
            "Batch 399/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 399/448, Loss: 0.3807, Time: 1.61 seconds\n",
            "Batch 400/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 400/448, Loss: 0.3935, Time: 1.61 seconds\n",
            "Batch 401/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 2/3, Batch 401/448, Loss: 0.5626, Time: 1.60 seconds\n",
            "Batch 402/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 2/3, Batch 402/448, Loss: 0.3841, Time: 1.60 seconds\n",
            "Batch 403/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 2/3, Batch 403/448, Loss: 0.3539, Time: 1.60 seconds\n",
            "Batch 404/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 404/448, Loss: 0.4177, Time: 1.60 seconds\n",
            "Batch 405/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 405/448, Loss: 0.4278, Time: 1.60 seconds\n",
            "Batch 406/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 406/448, Loss: 0.4990, Time: 1.62 seconds\n",
            "Batch 407/448, Label Counts: {0: 8, 1: 6, 2: 2}\n",
            "Epoch 2/3, Batch 407/448, Loss: 0.2828, Time: 1.60 seconds\n",
            "Batch 408/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 408/448, Loss: 0.3771, Time: 1.62 seconds\n",
            "Batch 409/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 2/3, Batch 409/448, Loss: 0.4595, Time: 1.62 seconds\n",
            "Batch 410/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 410/448, Loss: 0.5215, Time: 1.62 seconds\n",
            "Batch 411/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 411/448, Loss: 0.5259, Time: 1.61 seconds\n",
            "Batch 412/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 2/3, Batch 412/448, Loss: 0.3709, Time: 1.60 seconds\n",
            "Batch 413/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 413/448, Loss: 0.5615, Time: 1.61 seconds\n",
            "Batch 414/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 414/448, Loss: 0.5700, Time: 1.60 seconds\n",
            "Batch 415/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 2/3, Batch 415/448, Loss: 0.8352, Time: 1.61 seconds\n",
            "Batch 416/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 416/448, Loss: 0.3103, Time: 1.62 seconds\n",
            "Batch 417/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 2/3, Batch 417/448, Loss: 0.2822, Time: 1.60 seconds\n",
            "Batch 418/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 2/3, Batch 418/448, Loss: 0.9203, Time: 1.61 seconds\n",
            "Batch 419/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 419/448, Loss: 0.3849, Time: 1.60 seconds\n",
            "Batch 420/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 2/3, Batch 420/448, Loss: 0.4201, Time: 1.61 seconds\n",
            "Batch 421/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 2/3, Batch 421/448, Loss: 0.5477, Time: 1.61 seconds\n",
            "Batch 422/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 2/3, Batch 422/448, Loss: 0.4900, Time: 1.61 seconds\n",
            "Batch 423/448, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 2/3, Batch 423/448, Loss: 0.4993, Time: 1.60 seconds\n",
            "Batch 424/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 424/448, Loss: 0.3236, Time: 1.59 seconds\n",
            "Batch 425/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 2/3, Batch 425/448, Loss: 0.4441, Time: 1.62 seconds\n",
            "Batch 426/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 2/3, Batch 426/448, Loss: 0.5389, Time: 1.60 seconds\n",
            "Batch 427/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 427/448, Loss: 0.2652, Time: 1.60 seconds\n",
            "Batch 428/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 428/448, Loss: 0.4017, Time: 1.61 seconds\n",
            "Batch 429/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 2/3, Batch 429/448, Loss: 0.4846, Time: 1.62 seconds\n",
            "Batch 430/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 2/3, Batch 430/448, Loss: 0.2916, Time: 1.60 seconds\n",
            "Batch 431/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 2/3, Batch 431/448, Loss: 0.5203, Time: 1.61 seconds\n",
            "Batch 432/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 2/3, Batch 432/448, Loss: 0.5611, Time: 1.60 seconds\n",
            "Batch 433/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 433/448, Loss: 0.7721, Time: 1.62 seconds\n",
            "Batch 434/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 2/3, Batch 434/448, Loss: 0.5168, Time: 1.61 seconds\n",
            "Batch 435/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 2/3, Batch 435/448, Loss: 0.4784, Time: 1.61 seconds\n",
            "Batch 436/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 436/448, Loss: 0.8319, Time: 1.60 seconds\n",
            "Batch 437/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 2/3, Batch 437/448, Loss: 0.2973, Time: 1.60 seconds\n",
            "Batch 438/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 2/3, Batch 438/448, Loss: 0.3552, Time: 1.60 seconds\n",
            "Batch 439/448, Label Counts: {0: 10, 1: 3, 2: 3}\n",
            "Epoch 2/3, Batch 439/448, Loss: 0.7272, Time: 1.60 seconds\n",
            "Batch 440/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 2/3, Batch 440/448, Loss: 0.6887, Time: 1.61 seconds\n",
            "Batch 441/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 2/3, Batch 441/448, Loss: 0.6721, Time: 1.60 seconds\n",
            "Batch 442/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 2/3, Batch 442/448, Loss: 0.4833, Time: 1.60 seconds\n",
            "Batch 443/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 2/3, Batch 443/448, Loss: 0.3897, Time: 1.60 seconds\n",
            "Batch 444/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 2/3, Batch 444/448, Loss: 0.3801, Time: 1.60 seconds\n",
            "Batch 445/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 2/3, Batch 445/448, Loss: 0.7523, Time: 1.60 seconds\n",
            "Batch 446/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 2/3, Batch 446/448, Loss: 0.4137, Time: 1.59 seconds\n",
            "Batch 447/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 2/3, Batch 447/448, Loss: 0.5201, Time: 1.62 seconds\n",
            "Batch 448/448, Label Counts: {0: 3, 1: 5, 2: 1}\n",
            "Epoch 2/3, Batch 448/448, Loss: 0.5939, Time: 0.92 seconds\n",
            "Epoch 2/3, Training Loss: 0.6303, Time: 722.09 seconds\n",
            "Validation Loss: 0.6552, Accuracy: 0.7600\n",
            "Batch 1/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 1/448, Loss: 0.4113, Time: 1.61 seconds\n",
            "Batch 2/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 3/3, Batch 2/448, Loss: 0.5255, Time: 1.60 seconds\n",
            "Batch 3/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 3/448, Loss: 0.5796, Time: 1.61 seconds\n",
            "Batch 4/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 4/448, Loss: 0.2532, Time: 1.61 seconds\n",
            "Batch 5/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 5/448, Loss: 0.5665, Time: 1.62 seconds\n",
            "Batch 6/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 6/448, Loss: 0.6103, Time: 1.62 seconds\n",
            "Batch 7/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 7/448, Loss: 0.8212, Time: 1.61 seconds\n",
            "Batch 8/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 8/448, Loss: 0.3708, Time: 1.62 seconds\n",
            "Batch 9/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 9/448, Loss: 0.5577, Time: 1.62 seconds\n",
            "Batch 10/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 10/448, Loss: 0.8613, Time: 1.62 seconds\n",
            "Batch 11/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 11/448, Loss: 0.9304, Time: 1.61 seconds\n",
            "Batch 12/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 3/3, Batch 12/448, Loss: 0.3303, Time: 1.62 seconds\n",
            "Batch 13/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 13/448, Loss: 0.2206, Time: 1.62 seconds\n",
            "Batch 14/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 14/448, Loss: 0.4019, Time: 1.60 seconds\n",
            "Batch 15/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 15/448, Loss: 0.3208, Time: 1.60 seconds\n",
            "Batch 16/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 16/448, Loss: 0.3501, Time: 1.62 seconds\n",
            "Batch 17/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 17/448, Loss: 0.5451, Time: 1.62 seconds\n",
            "Batch 18/448, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 3/3, Batch 18/448, Loss: 0.5638, Time: 1.62 seconds\n",
            "Batch 19/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 3/3, Batch 19/448, Loss: 0.5328, Time: 1.62 seconds\n",
            "Batch 20/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 20/448, Loss: 0.2854, Time: 1.62 seconds\n",
            "Batch 21/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 21/448, Loss: 0.5896, Time: 1.60 seconds\n",
            "Batch 22/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 22/448, Loss: 0.4993, Time: 1.60 seconds\n",
            "Batch 23/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 23/448, Loss: 0.3537, Time: 1.62 seconds\n",
            "Batch 24/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 24/448, Loss: 0.4167, Time: 1.62 seconds\n",
            "Batch 25/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 25/448, Loss: 0.5119, Time: 1.61 seconds\n",
            "Batch 26/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 26/448, Loss: 1.0456, Time: 1.62 seconds\n",
            "Batch 27/448, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 3/3, Batch 27/448, Loss: 0.4790, Time: 1.61 seconds\n",
            "Batch 28/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 28/448, Loss: 0.8996, Time: 1.62 seconds\n",
            "Batch 29/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 29/448, Loss: 0.6462, Time: 1.62 seconds\n",
            "Batch 30/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 30/448, Loss: 0.5831, Time: 1.61 seconds\n",
            "Batch 31/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 3/3, Batch 31/448, Loss: 0.8369, Time: 1.62 seconds\n",
            "Batch 32/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 32/448, Loss: 0.3715, Time: 1.62 seconds\n",
            "Batch 33/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 33/448, Loss: 0.8550, Time: 1.61 seconds\n",
            "Batch 34/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 34/448, Loss: 0.6606, Time: 1.62 seconds\n",
            "Batch 35/448, Label Counts: {0: 3, 1: 2, 2: 11}\n",
            "Epoch 3/3, Batch 35/448, Loss: 0.5206, Time: 1.61 seconds\n",
            "Batch 36/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 3/3, Batch 36/448, Loss: 0.7146, Time: 1.63 seconds\n",
            "Batch 37/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 3/3, Batch 37/448, Loss: 0.4657, Time: 1.62 seconds\n",
            "Batch 38/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 38/448, Loss: 0.6743, Time: 1.62 seconds\n",
            "Batch 39/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 39/448, Loss: 0.5766, Time: 1.61 seconds\n",
            "Batch 40/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 40/448, Loss: 0.6462, Time: 1.62 seconds\n",
            "Batch 41/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 41/448, Loss: 0.6713, Time: 1.62 seconds\n",
            "Batch 42/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 42/448, Loss: 0.5144, Time: 1.61 seconds\n",
            "Batch 43/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 43/448, Loss: 0.8197, Time: 1.60 seconds\n",
            "Batch 44/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 44/448, Loss: 0.7042, Time: 1.59 seconds\n",
            "Batch 45/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 45/448, Loss: 0.7653, Time: 1.61 seconds\n",
            "Batch 46/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 46/448, Loss: 0.5220, Time: 1.61 seconds\n",
            "Batch 47/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 47/448, Loss: 0.5304, Time: 1.62 seconds\n",
            "Batch 48/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 48/448, Loss: 0.5531, Time: 1.62 seconds\n",
            "Batch 49/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 49/448, Loss: 0.4091, Time: 1.62 seconds\n",
            "Batch 50/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 3/3, Batch 50/448, Loss: 0.5246, Time: 1.61 seconds\n",
            "Batch 51/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 51/448, Loss: 0.4896, Time: 1.62 seconds\n",
            "Batch 52/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 52/448, Loss: 0.5380, Time: 1.62 seconds\n",
            "Batch 53/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 53/448, Loss: 0.4615, Time: 1.61 seconds\n",
            "Batch 54/448, Label Counts: {0: 9, 1: 1, 2: 6}\n",
            "Epoch 3/3, Batch 54/448, Loss: 0.5445, Time: 1.62 seconds\n",
            "Batch 55/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 55/448, Loss: 0.3533, Time: 1.60 seconds\n",
            "Batch 56/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 56/448, Loss: 0.7046, Time: 1.62 seconds\n",
            "Batch 57/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 3/3, Batch 57/448, Loss: 0.6872, Time: 1.62 seconds\n",
            "Batch 58/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 3/3, Batch 58/448, Loss: 0.5088, Time: 1.61 seconds\n",
            "Batch 59/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 59/448, Loss: 0.6772, Time: 1.62 seconds\n",
            "Batch 60/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 60/448, Loss: 0.7290, Time: 1.62 seconds\n",
            "Batch 61/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 61/448, Loss: 0.3973, Time: 1.62 seconds\n",
            "Batch 62/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 62/448, Loss: 0.5513, Time: 1.61 seconds\n",
            "Batch 63/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 63/448, Loss: 0.3180, Time: 1.62 seconds\n",
            "Batch 64/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 64/448, Loss: 0.5210, Time: 1.62 seconds\n",
            "Batch 65/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 65/448, Loss: 0.2231, Time: 1.62 seconds\n",
            "Batch 66/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 3/3, Batch 66/448, Loss: 0.5420, Time: 1.62 seconds\n",
            "Batch 67/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 67/448, Loss: 0.4870, Time: 1.62 seconds\n",
            "Batch 68/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 68/448, Loss: 0.7408, Time: 1.62 seconds\n",
            "Batch 69/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 69/448, Loss: 0.5599, Time: 1.61 seconds\n",
            "Batch 70/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 70/448, Loss: 0.6710, Time: 1.62 seconds\n",
            "Batch 71/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 71/448, Loss: 0.6739, Time: 1.62 seconds\n",
            "Batch 72/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 72/448, Loss: 0.4076, Time: 1.61 seconds\n",
            "Batch 73/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 73/448, Loss: 0.4117, Time: 1.62 seconds\n",
            "Batch 74/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 74/448, Loss: 0.2222, Time: 1.61 seconds\n",
            "Batch 75/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 3/3, Batch 75/448, Loss: 0.7692, Time: 1.62 seconds\n",
            "Batch 76/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 76/448, Loss: 0.7960, Time: 1.61 seconds\n",
            "Batch 77/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 77/448, Loss: 0.6581, Time: 1.62 seconds\n",
            "Batch 78/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 78/448, Loss: 0.5770, Time: 1.62 seconds\n",
            "Batch 79/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 79/448, Loss: 0.6109, Time: 1.63 seconds\n",
            "Batch 80/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 80/448, Loss: 0.6435, Time: 1.62 seconds\n",
            "Batch 81/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 81/448, Loss: 0.2366, Time: 1.62 seconds\n",
            "Batch 82/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 82/448, Loss: 0.6211, Time: 1.61 seconds\n",
            "Batch 83/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 83/448, Loss: 0.3726, Time: 1.62 seconds\n",
            "Batch 84/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 84/448, Loss: 0.2969, Time: 1.62 seconds\n",
            "Batch 85/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 85/448, Loss: 0.6167, Time: 1.62 seconds\n",
            "Batch 86/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 86/448, Loss: 0.3960, Time: 1.62 seconds\n",
            "Batch 87/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 87/448, Loss: 0.7789, Time: 1.63 seconds\n",
            "Batch 88/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 88/448, Loss: 0.6822, Time: 1.62 seconds\n",
            "Batch 89/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 3/3, Batch 89/448, Loss: 0.4580, Time: 1.61 seconds\n",
            "Batch 90/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 90/448, Loss: 0.3045, Time: 1.62 seconds\n",
            "Batch 91/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 91/448, Loss: 0.3925, Time: 1.62 seconds\n",
            "Batch 92/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 92/448, Loss: 0.5805, Time: 1.62 seconds\n",
            "Batch 93/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 93/448, Loss: 0.4528, Time: 1.62 seconds\n",
            "Batch 94/448, Label Counts: {0: 1, 1: 7, 2: 8}\n",
            "Epoch 3/3, Batch 94/448, Loss: 0.4058, Time: 1.63 seconds\n",
            "Batch 95/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 95/448, Loss: 0.3533, Time: 1.62 seconds\n",
            "Batch 96/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 96/448, Loss: 0.5349, Time: 1.61 seconds\n",
            "Batch 97/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 97/448, Loss: 0.4878, Time: 1.61 seconds\n",
            "Batch 98/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 98/448, Loss: 0.3548, Time: 1.62 seconds\n",
            "Batch 99/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 99/448, Loss: 0.8761, Time: 1.62 seconds\n",
            "Batch 100/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 100/448, Loss: 0.4918, Time: 1.62 seconds\n",
            "Batch 101/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 101/448, Loss: 0.6455, Time: 1.62 seconds\n",
            "Batch 102/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 102/448, Loss: 0.8397, Time: 1.62 seconds\n",
            "Batch 103/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 3/3, Batch 103/448, Loss: 0.6722, Time: 1.62 seconds\n",
            "Batch 104/448, Label Counts: {0: 1, 1: 7, 2: 8}\n",
            "Epoch 3/3, Batch 104/448, Loss: 0.5169, Time: 1.62 seconds\n",
            "Batch 105/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 105/448, Loss: 0.7136, Time: 1.63 seconds\n",
            "Batch 106/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 106/448, Loss: 0.5885, Time: 1.62 seconds\n",
            "Batch 107/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 107/448, Loss: 0.4720, Time: 1.62 seconds\n",
            "Batch 108/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 108/448, Loss: 0.5074, Time: 1.62 seconds\n",
            "Batch 109/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 109/448, Loss: 0.3245, Time: 1.62 seconds\n",
            "Batch 110/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 110/448, Loss: 0.6154, Time: 1.62 seconds\n",
            "Batch 111/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 111/448, Loss: 0.5428, Time: 1.62 seconds\n",
            "Batch 112/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 112/448, Loss: 0.4060, Time: 1.63 seconds\n",
            "Batch 113/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 113/448, Loss: 0.4220, Time: 1.62 seconds\n",
            "Batch 114/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 114/448, Loss: 0.4997, Time: 1.62 seconds\n",
            "Batch 115/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 115/448, Loss: 0.4610, Time: 1.63 seconds\n",
            "Batch 116/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 116/448, Loss: 0.4168, Time: 1.62 seconds\n",
            "Batch 117/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 117/448, Loss: 0.3266, Time: 1.62 seconds\n",
            "Batch 118/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 118/448, Loss: 0.8088, Time: 1.62 seconds\n",
            "Batch 119/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 119/448, Loss: 0.5621, Time: 1.61 seconds\n",
            "Batch 120/448, Label Counts: {0: 10, 1: 2, 2: 4}\n",
            "Epoch 3/3, Batch 120/448, Loss: 0.5671, Time: 1.63 seconds\n",
            "Batch 121/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 121/448, Loss: 0.6369, Time: 1.62 seconds\n",
            "Batch 122/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 122/448, Loss: 0.5432, Time: 1.62 seconds\n",
            "Batch 123/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 123/448, Loss: 0.6363, Time: 1.62 seconds\n",
            "Batch 124/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 124/448, Loss: 0.3881, Time: 1.62 seconds\n",
            "Batch 125/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 125/448, Loss: 0.8491, Time: 1.61 seconds\n",
            "Batch 126/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 126/448, Loss: 0.6510, Time: 1.63 seconds\n",
            "Batch 127/448, Label Counts: {0: 9, 1: 6, 2: 1}\n",
            "Epoch 3/3, Batch 127/448, Loss: 0.5436, Time: 1.62 seconds\n",
            "Batch 128/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 128/448, Loss: 0.6495, Time: 1.62 seconds\n",
            "Batch 129/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 129/448, Loss: 0.4605, Time: 1.62 seconds\n",
            "Batch 130/448, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 3/3, Batch 130/448, Loss: 0.5378, Time: 1.62 seconds\n",
            "Batch 131/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 131/448, Loss: 0.1443, Time: 1.63 seconds\n",
            "Batch 132/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 132/448, Loss: 0.2602, Time: 1.62 seconds\n",
            "Batch 133/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 133/448, Loss: 0.4358, Time: 1.62 seconds\n",
            "Batch 134/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 134/448, Loss: 0.3314, Time: 1.63 seconds\n",
            "Batch 135/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 135/448, Loss: 0.5647, Time: 1.62 seconds\n",
            "Batch 136/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 136/448, Loss: 0.4041, Time: 1.62 seconds\n",
            "Batch 137/448, Label Counts: {0: 7, 1: 2, 2: 7}\n",
            "Epoch 3/3, Batch 137/448, Loss: 0.7217, Time: 1.61 seconds\n",
            "Batch 138/448, Label Counts: {0: 3, 1: 10, 2: 3}\n",
            "Epoch 3/3, Batch 138/448, Loss: 0.5954, Time: 1.62 seconds\n",
            "Batch 139/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 139/448, Loss: 0.3596, Time: 1.61 seconds\n",
            "Batch 140/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 140/448, Loss: 0.4897, Time: 1.61 seconds\n",
            "Batch 141/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 141/448, Loss: 0.3375, Time: 1.62 seconds\n",
            "Batch 142/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 142/448, Loss: 0.4432, Time: 1.61 seconds\n",
            "Batch 143/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 143/448, Loss: 0.4568, Time: 1.62 seconds\n",
            "Batch 144/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 3/3, Batch 144/448, Loss: 0.2453, Time: 1.60 seconds\n",
            "Batch 145/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 145/448, Loss: 0.5015, Time: 1.62 seconds\n",
            "Batch 146/448, Label Counts: {0: 2, 1: 9, 2: 5}\n",
            "Epoch 3/3, Batch 146/448, Loss: 0.3338, Time: 1.62 seconds\n",
            "Batch 147/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 3/3, Batch 147/448, Loss: 0.2600, Time: 1.61 seconds\n",
            "Batch 148/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 148/448, Loss: 0.2794, Time: 1.60 seconds\n",
            "Batch 149/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 149/448, Loss: 0.3497, Time: 1.60 seconds\n",
            "Batch 150/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 150/448, Loss: 0.4944, Time: 1.62 seconds\n",
            "Batch 151/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 151/448, Loss: 0.7774, Time: 1.60 seconds\n",
            "Batch 152/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 152/448, Loss: 0.5603, Time: 1.61 seconds\n",
            "Batch 153/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 153/448, Loss: 0.4984, Time: 1.62 seconds\n",
            "Batch 154/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 154/448, Loss: 0.2518, Time: 1.62 seconds\n",
            "Batch 155/448, Label Counts: {0: 5, 1: 9, 2: 2}\n",
            "Epoch 3/3, Batch 155/448, Loss: 0.7408, Time: 1.62 seconds\n",
            "Batch 156/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 156/448, Loss: 0.3788, Time: 1.62 seconds\n",
            "Batch 157/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 3/3, Batch 157/448, Loss: 0.5939, Time: 1.62 seconds\n",
            "Batch 158/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 3/3, Batch 158/448, Loss: 0.5370, Time: 1.62 seconds\n",
            "Batch 159/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 159/448, Loss: 0.3148, Time: 1.61 seconds\n",
            "Batch 160/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 160/448, Loss: 0.3406, Time: 1.62 seconds\n",
            "Batch 161/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 161/448, Loss: 0.2779, Time: 1.60 seconds\n",
            "Batch 162/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 3/3, Batch 162/448, Loss: 0.5379, Time: 1.61 seconds\n",
            "Batch 163/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 163/448, Loss: 0.5562, Time: 1.61 seconds\n",
            "Batch 164/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 164/448, Loss: 0.6102, Time: 1.61 seconds\n",
            "Batch 165/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 165/448, Loss: 0.6639, Time: 1.63 seconds\n",
            "Batch 166/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 166/448, Loss: 0.3735, Time: 1.60 seconds\n",
            "Batch 167/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 167/448, Loss: 0.3275, Time: 1.62 seconds\n",
            "Batch 168/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 168/448, Loss: 0.4690, Time: 1.61 seconds\n",
            "Batch 169/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 169/448, Loss: 0.4813, Time: 1.61 seconds\n",
            "Batch 170/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 170/448, Loss: 0.4055, Time: 1.61 seconds\n",
            "Batch 171/448, Label Counts: {0: 3, 1: 11, 2: 2}\n",
            "Epoch 3/3, Batch 171/448, Loss: 0.2755, Time: 1.60 seconds\n",
            "Batch 172/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 172/448, Loss: 0.9136, Time: 1.61 seconds\n",
            "Batch 173/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 173/448, Loss: 0.3774, Time: 1.61 seconds\n",
            "Batch 174/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 3/3, Batch 174/448, Loss: 0.3212, Time: 1.61 seconds\n",
            "Batch 175/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 175/448, Loss: 0.4332, Time: 1.62 seconds\n",
            "Batch 176/448, Label Counts: {0: 4, 1: 2, 2: 10}\n",
            "Epoch 3/3, Batch 176/448, Loss: 0.4960, Time: 1.62 seconds\n",
            "Batch 177/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 177/448, Loss: 0.3376, Time: 1.62 seconds\n",
            "Batch 178/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 178/448, Loss: 0.3028, Time: 1.61 seconds\n",
            "Batch 179/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 179/448, Loss: 0.5230, Time: 1.61 seconds\n",
            "Batch 180/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 180/448, Loss: 0.3402, Time: 1.60 seconds\n",
            "Batch 181/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 181/448, Loss: 0.9157, Time: 1.59 seconds\n",
            "Batch 182/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 182/448, Loss: 0.4027, Time: 1.60 seconds\n",
            "Batch 183/448, Label Counts: {0: 5, 1: 9, 2: 2}\n",
            "Epoch 3/3, Batch 183/448, Loss: 0.3778, Time: 1.62 seconds\n",
            "Batch 184/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 3/3, Batch 184/448, Loss: 0.5816, Time: 1.61 seconds\n",
            "Batch 185/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 185/448, Loss: 1.0563, Time: 1.62 seconds\n",
            "Batch 186/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 3/3, Batch 186/448, Loss: 0.2978, Time: 1.62 seconds\n",
            "Batch 187/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 187/448, Loss: 0.8764, Time: 1.60 seconds\n",
            "Batch 188/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 188/448, Loss: 0.5865, Time: 1.62 seconds\n",
            "Batch 189/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 189/448, Loss: 0.3632, Time: 1.60 seconds\n",
            "Batch 190/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 190/448, Loss: 0.8815, Time: 1.60 seconds\n",
            "Batch 191/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 191/448, Loss: 0.5493, Time: 1.60 seconds\n",
            "Batch 192/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 192/448, Loss: 0.3127, Time: 1.60 seconds\n",
            "Batch 193/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 193/448, Loss: 0.3302, Time: 1.60 seconds\n",
            "Batch 194/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 194/448, Loss: 0.3406, Time: 1.61 seconds\n",
            "Batch 195/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 195/448, Loss: 0.5336, Time: 1.60 seconds\n",
            "Batch 196/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 3/3, Batch 196/448, Loss: 0.6872, Time: 1.60 seconds\n",
            "Batch 197/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 197/448, Loss: 0.2223, Time: 1.61 seconds\n",
            "Batch 198/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 198/448, Loss: 0.3331, Time: 1.61 seconds\n",
            "Batch 199/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 199/448, Loss: 0.2069, Time: 1.61 seconds\n",
            "Batch 200/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 200/448, Loss: 0.6872, Time: 1.60 seconds\n",
            "Batch 201/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 201/448, Loss: 0.4939, Time: 1.61 seconds\n",
            "Batch 202/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 202/448, Loss: 0.6687, Time: 1.60 seconds\n",
            "Batch 203/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 203/448, Loss: 0.2274, Time: 1.59 seconds\n",
            "Batch 204/448, Label Counts: {0: 1, 1: 6, 2: 9}\n",
            "Epoch 3/3, Batch 204/448, Loss: 0.5875, Time: 1.60 seconds\n",
            "Batch 205/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 3/3, Batch 205/448, Loss: 0.3715, Time: 1.60 seconds\n",
            "Batch 206/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 206/448, Loss: 0.3474, Time: 1.60 seconds\n",
            "Batch 207/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 207/448, Loss: 0.2275, Time: 1.60 seconds\n",
            "Batch 208/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 208/448, Loss: 0.5308, Time: 1.60 seconds\n",
            "Batch 209/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 209/448, Loss: 0.3664, Time: 1.61 seconds\n",
            "Batch 210/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 210/448, Loss: 0.3245, Time: 1.60 seconds\n",
            "Batch 211/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 211/448, Loss: 0.5502, Time: 1.61 seconds\n",
            "Batch 212/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 212/448, Loss: 0.3149, Time: 1.60 seconds\n",
            "Batch 213/448, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 3/3, Batch 213/448, Loss: 0.8116, Time: 1.60 seconds\n",
            "Batch 214/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 214/448, Loss: 0.3813, Time: 1.59 seconds\n",
            "Batch 215/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 215/448, Loss: 0.5486, Time: 1.60 seconds\n",
            "Batch 216/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 216/448, Loss: 0.5781, Time: 1.62 seconds\n",
            "Batch 217/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 217/448, Loss: 0.3865, Time: 1.62 seconds\n",
            "Batch 218/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 218/448, Loss: 0.5355, Time: 1.62 seconds\n",
            "Batch 219/448, Label Counts: {0: 10, 1: 1, 2: 5}\n",
            "Epoch 3/3, Batch 219/448, Loss: 0.2763, Time: 1.60 seconds\n",
            "Batch 220/448, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 3/3, Batch 220/448, Loss: 0.4535, Time: 1.61 seconds\n",
            "Batch 221/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 221/448, Loss: 0.2107, Time: 1.60 seconds\n",
            "Batch 222/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 222/448, Loss: 0.3321, Time: 1.60 seconds\n",
            "Batch 223/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 223/448, Loss: 0.2896, Time: 1.61 seconds\n",
            "Batch 224/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 224/448, Loss: 0.7705, Time: 1.61 seconds\n",
            "Batch 225/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 225/448, Loss: 0.4319, Time: 1.61 seconds\n",
            "Batch 226/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 226/448, Loss: 0.6187, Time: 1.60 seconds\n",
            "Batch 227/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 227/448, Loss: 0.5369, Time: 1.60 seconds\n",
            "Batch 228/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 228/448, Loss: 0.6443, Time: 1.60 seconds\n",
            "Batch 229/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 229/448, Loss: 0.3446, Time: 1.60 seconds\n",
            "Batch 230/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 230/448, Loss: 0.7024, Time: 1.60 seconds\n",
            "Batch 231/448, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 3/3, Batch 231/448, Loss: 0.1701, Time: 1.59 seconds\n",
            "Batch 232/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 232/448, Loss: 0.6506, Time: 1.60 seconds\n",
            "Batch 233/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 233/448, Loss: 0.5501, Time: 1.61 seconds\n",
            "Batch 234/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 234/448, Loss: 0.5270, Time: 1.61 seconds\n",
            "Batch 235/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 235/448, Loss: 0.7757, Time: 1.61 seconds\n",
            "Batch 236/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 236/448, Loss: 0.3230, Time: 1.60 seconds\n",
            "Batch 237/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 237/448, Loss: 0.5462, Time: 1.60 seconds\n",
            "Batch 238/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 238/448, Loss: 0.3923, Time: 1.60 seconds\n",
            "Batch 239/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 239/448, Loss: 0.3386, Time: 1.60 seconds\n",
            "Batch 240/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 240/448, Loss: 0.5032, Time: 1.62 seconds\n",
            "Batch 241/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 241/448, Loss: 0.6063, Time: 1.60 seconds\n",
            "Batch 242/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 242/448, Loss: 0.5996, Time: 1.61 seconds\n",
            "Batch 243/448, Label Counts: {0: 3, 1: 9, 2: 4}\n",
            "Epoch 3/3, Batch 243/448, Loss: 0.6759, Time: 1.60 seconds\n",
            "Batch 244/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 244/448, Loss: 0.5125, Time: 1.60 seconds\n",
            "Batch 245/448, Label Counts: {0: 5, 1: 10, 2: 1}\n",
            "Epoch 3/3, Batch 245/448, Loss: 0.3005, Time: 1.61 seconds\n",
            "Batch 246/448, Label Counts: {0: 2, 1: 4, 2: 10}\n",
            "Epoch 3/3, Batch 246/448, Loss: 0.4228, Time: 1.61 seconds\n",
            "Batch 247/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 247/448, Loss: 0.5333, Time: 1.60 seconds\n",
            "Batch 248/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 248/448, Loss: 0.3947, Time: 1.61 seconds\n",
            "Batch 249/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 249/448, Loss: 0.4573, Time: 1.61 seconds\n",
            "Batch 250/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 250/448, Loss: 0.4536, Time: 1.60 seconds\n",
            "Batch 251/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 3/3, Batch 251/448, Loss: 0.2542, Time: 1.61 seconds\n",
            "Batch 252/448, Label Counts: {0: 2, 1: 10, 2: 4}\n",
            "Epoch 3/3, Batch 252/448, Loss: 0.5389, Time: 1.61 seconds\n",
            "Batch 253/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 253/448, Loss: 0.2137, Time: 1.61 seconds\n",
            "Batch 254/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 254/448, Loss: 0.8260, Time: 1.62 seconds\n",
            "Batch 255/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 255/448, Loss: 0.5637, Time: 1.60 seconds\n",
            "Batch 256/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 256/448, Loss: 0.3566, Time: 1.60 seconds\n",
            "Batch 257/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 257/448, Loss: 0.2860, Time: 1.61 seconds\n",
            "Batch 258/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 258/448, Loss: 0.3952, Time: 1.61 seconds\n",
            "Batch 259/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 259/448, Loss: 0.6458, Time: 1.62 seconds\n",
            "Batch 260/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 260/448, Loss: 0.4588, Time: 1.61 seconds\n",
            "Batch 261/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 261/448, Loss: 0.4421, Time: 1.62 seconds\n",
            "Batch 262/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 262/448, Loss: 0.6319, Time: 1.62 seconds\n",
            "Batch 263/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 263/448, Loss: 0.5591, Time: 1.61 seconds\n",
            "Batch 264/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 264/448, Loss: 0.2763, Time: 1.60 seconds\n",
            "Batch 265/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 265/448, Loss: 0.5536, Time: 1.62 seconds\n",
            "Batch 266/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 266/448, Loss: 0.2785, Time: 1.60 seconds\n",
            "Batch 267/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 267/448, Loss: 0.4447, Time: 1.61 seconds\n",
            "Batch 268/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 268/448, Loss: 0.4643, Time: 1.60 seconds\n",
            "Batch 269/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 269/448, Loss: 0.4070, Time: 1.62 seconds\n",
            "Batch 270/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 270/448, Loss: 0.3083, Time: 1.62 seconds\n",
            "Batch 271/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 271/448, Loss: 0.3954, Time: 1.62 seconds\n",
            "Batch 272/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 3/3, Batch 272/448, Loss: 0.7071, Time: 1.60 seconds\n",
            "Batch 273/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 273/448, Loss: 0.3559, Time: 1.61 seconds\n",
            "Batch 274/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 274/448, Loss: 0.5592, Time: 1.61 seconds\n",
            "Batch 275/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 275/448, Loss: 0.4662, Time: 1.60 seconds\n",
            "Batch 276/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 276/448, Loss: 0.6724, Time: 1.60 seconds\n",
            "Batch 277/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 277/448, Loss: 0.5288, Time: 1.61 seconds\n",
            "Batch 278/448, Label Counts: {0: 8, 1: 2, 2: 6}\n",
            "Epoch 3/3, Batch 278/448, Loss: 0.5767, Time: 1.62 seconds\n",
            "Batch 279/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 279/448, Loss: 0.4579, Time: 1.61 seconds\n",
            "Batch 280/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 280/448, Loss: 0.3019, Time: 1.61 seconds\n",
            "Batch 281/448, Label Counts: {0: 2, 1: 5, 2: 9}\n",
            "Epoch 3/3, Batch 281/448, Loss: 0.5145, Time: 1.62 seconds\n",
            "Batch 282/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 282/448, Loss: 0.2027, Time: 1.62 seconds\n",
            "Batch 283/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 283/448, Loss: 0.4067, Time: 1.62 seconds\n",
            "Batch 284/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 3/3, Batch 284/448, Loss: 0.5151, Time: 1.62 seconds\n",
            "Batch 285/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 285/448, Loss: 0.6084, Time: 1.61 seconds\n",
            "Batch 286/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 286/448, Loss: 0.5192, Time: 1.62 seconds\n",
            "Batch 287/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 3/3, Batch 287/448, Loss: 0.5067, Time: 1.62 seconds\n",
            "Batch 288/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 288/448, Loss: 0.8346, Time: 1.61 seconds\n",
            "Batch 289/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 289/448, Loss: 0.7602, Time: 1.61 seconds\n",
            "Batch 290/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 290/448, Loss: 0.3898, Time: 1.62 seconds\n",
            "Batch 291/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 291/448, Loss: 0.3541, Time: 1.61 seconds\n",
            "Batch 292/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 292/448, Loss: 0.5661, Time: 1.62 seconds\n",
            "Batch 293/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 293/448, Loss: 0.3037, Time: 1.62 seconds\n",
            "Batch 294/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 294/448, Loss: 0.4578, Time: 1.61 seconds\n",
            "Batch 295/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 295/448, Loss: 0.3440, Time: 1.61 seconds\n",
            "Batch 296/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 296/448, Loss: 0.2325, Time: 1.61 seconds\n",
            "Batch 297/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 297/448, Loss: 0.5092, Time: 1.61 seconds\n",
            "Batch 298/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 298/448, Loss: 0.6808, Time: 1.62 seconds\n",
            "Batch 299/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 299/448, Loss: 0.3675, Time: 1.62 seconds\n",
            "Batch 300/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 300/448, Loss: 0.5095, Time: 1.62 seconds\n",
            "Batch 301/448, Label Counts: {0: 1, 1: 10, 2: 5}\n",
            "Epoch 3/3, Batch 301/448, Loss: 0.3323, Time: 1.62 seconds\n",
            "Batch 302/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 302/448, Loss: 0.6089, Time: 1.62 seconds\n",
            "Batch 303/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 303/448, Loss: 0.5039, Time: 1.61 seconds\n",
            "Batch 304/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 304/448, Loss: 0.3647, Time: 1.62 seconds\n",
            "Batch 305/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 305/448, Loss: 0.4266, Time: 1.61 seconds\n",
            "Batch 306/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 306/448, Loss: 0.3859, Time: 1.60 seconds\n",
            "Batch 307/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 307/448, Loss: 0.4341, Time: 1.62 seconds\n",
            "Batch 308/448, Label Counts: {0: 1, 1: 7, 2: 8}\n",
            "Epoch 3/3, Batch 308/448, Loss: 0.6959, Time: 1.62 seconds\n",
            "Batch 309/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 309/448, Loss: 0.6853, Time: 1.61 seconds\n",
            "Batch 310/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 310/448, Loss: 0.5756, Time: 1.62 seconds\n",
            "Batch 311/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 311/448, Loss: 0.5935, Time: 1.62 seconds\n",
            "Batch 312/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 312/448, Loss: 0.4117, Time: 1.62 seconds\n",
            "Batch 313/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 313/448, Loss: 0.5784, Time: 1.62 seconds\n",
            "Batch 314/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 314/448, Loss: 0.4687, Time: 1.62 seconds\n",
            "Batch 315/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 315/448, Loss: 0.2166, Time: 1.62 seconds\n",
            "Batch 316/448, Label Counts: {0: 1, 1: 5, 2: 10}\n",
            "Epoch 3/3, Batch 316/448, Loss: 0.3092, Time: 1.62 seconds\n",
            "Batch 317/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 317/448, Loss: 0.6772, Time: 1.62 seconds\n",
            "Batch 318/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 318/448, Loss: 0.5252, Time: 1.61 seconds\n",
            "Batch 319/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 319/448, Loss: 0.3821, Time: 1.63 seconds\n",
            "Batch 320/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 320/448, Loss: 0.6136, Time: 1.62 seconds\n",
            "Batch 321/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 321/448, Loss: 0.5263, Time: 1.62 seconds\n",
            "Batch 322/448, Label Counts: {0: 3, 1: 8, 2: 5}\n",
            "Epoch 3/3, Batch 322/448, Loss: 0.6678, Time: 1.61 seconds\n",
            "Batch 323/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 323/448, Loss: 0.4022, Time: 1.63 seconds\n",
            "Batch 324/448, Label Counts: {0: 7, 1: 3, 2: 6}\n",
            "Epoch 3/3, Batch 324/448, Loss: 0.5591, Time: 1.62 seconds\n",
            "Batch 325/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 325/448, Loss: 0.3839, Time: 1.62 seconds\n",
            "Batch 326/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 326/448, Loss: 0.4993, Time: 1.62 seconds\n",
            "Batch 327/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 327/448, Loss: 0.6266, Time: 1.62 seconds\n",
            "Batch 328/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 328/448, Loss: 0.5609, Time: 1.62 seconds\n",
            "Batch 329/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 329/448, Loss: 0.5977, Time: 1.63 seconds\n",
            "Batch 330/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 330/448, Loss: 0.5553, Time: 1.62 seconds\n",
            "Batch 331/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 331/448, Loss: 0.3170, Time: 1.62 seconds\n",
            "Batch 332/448, Label Counts: {0: 9, 1: 2, 2: 5}\n",
            "Epoch 3/3, Batch 332/448, Loss: 0.4072, Time: 1.63 seconds\n",
            "Batch 333/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 333/448, Loss: 0.3518, Time: 1.62 seconds\n",
            "Batch 334/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 334/448, Loss: 0.4858, Time: 1.62 seconds\n",
            "Batch 335/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 335/448, Loss: 0.2826, Time: 1.63 seconds\n",
            "Batch 336/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 336/448, Loss: 0.5094, Time: 1.62 seconds\n",
            "Batch 337/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 337/448, Loss: 0.5178, Time: 1.62 seconds\n",
            "Batch 338/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 3/3, Batch 338/448, Loss: 0.3824, Time: 1.62 seconds\n",
            "Batch 339/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 339/448, Loss: 0.5022, Time: 1.62 seconds\n",
            "Batch 340/448, Label Counts: {1: 8, 2: 8}\n",
            "Epoch 3/3, Batch 340/448, Loss: 0.3493, Time: 1.61 seconds\n",
            "Batch 341/448, Label Counts: {0: 8, 1: 7, 2: 1}\n",
            "Epoch 3/3, Batch 341/448, Loss: 0.3121, Time: 1.62 seconds\n",
            "Batch 342/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 342/448, Loss: 0.3620, Time: 1.61 seconds\n",
            "Batch 343/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 343/448, Loss: 0.1972, Time: 1.61 seconds\n",
            "Batch 344/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 344/448, Loss: 0.7460, Time: 1.63 seconds\n",
            "Batch 345/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 345/448, Loss: 0.3378, Time: 1.62 seconds\n",
            "Batch 346/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 346/448, Loss: 0.4425, Time: 1.62 seconds\n",
            "Batch 347/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 347/448, Loss: 0.6499, Time: 1.62 seconds\n",
            "Batch 348/448, Label Counts: {0: 2, 1: 7, 2: 7}\n",
            "Epoch 3/3, Batch 348/448, Loss: 0.3148, Time: 1.62 seconds\n",
            "Batch 349/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 349/448, Loss: 0.2503, Time: 1.61 seconds\n",
            "Batch 350/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 350/448, Loss: 0.2944, Time: 1.62 seconds\n",
            "Batch 351/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 351/448, Loss: 0.5297, Time: 1.61 seconds\n",
            "Batch 352/448, Label Counts: {0: 7, 1: 1, 2: 8}\n",
            "Epoch 3/3, Batch 352/448, Loss: 0.2495, Time: 1.63 seconds\n",
            "Batch 353/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 353/448, Loss: 0.5899, Time: 1.62 seconds\n",
            "Batch 354/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 354/448, Loss: 0.5039, Time: 1.62 seconds\n",
            "Batch 355/448, Label Counts: {0: 3, 1: 3, 2: 10}\n",
            "Epoch 3/3, Batch 355/448, Loss: 0.7850, Time: 1.61 seconds\n",
            "Batch 356/448, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 356/448, Loss: 0.2039, Time: 1.61 seconds\n",
            "Batch 357/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 357/448, Loss: 0.4958, Time: 1.62 seconds\n",
            "Batch 358/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 358/448, Loss: 0.6007, Time: 1.62 seconds\n",
            "Batch 359/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 359/448, Loss: 0.5553, Time: 1.63 seconds\n",
            "Batch 360/448, Label Counts: {0: 4, 1: 3, 2: 9}\n",
            "Epoch 3/3, Batch 360/448, Loss: 0.4849, Time: 1.62 seconds\n",
            "Batch 361/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 361/448, Loss: 0.4758, Time: 1.62 seconds\n",
            "Batch 362/448, Label Counts: {0: 11, 1: 2, 2: 3}\n",
            "Epoch 3/3, Batch 362/448, Loss: 0.3383, Time: 1.62 seconds\n",
            "Batch 363/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 363/448, Loss: 0.2630, Time: 1.63 seconds\n",
            "Batch 364/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 364/448, Loss: 0.3604, Time: 1.62 seconds\n",
            "Batch 365/448, Label Counts: {0: 2, 1: 8, 2: 6}\n",
            "Epoch 3/3, Batch 365/448, Loss: 0.8624, Time: 1.63 seconds\n",
            "Batch 366/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 366/448, Loss: 0.8916, Time: 1.62 seconds\n",
            "Batch 367/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 367/448, Loss: 0.6723, Time: 1.62 seconds\n",
            "Batch 368/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 368/448, Loss: 0.8220, Time: 1.62 seconds\n",
            "Batch 369/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 369/448, Loss: 0.3114, Time: 1.62 seconds\n",
            "Batch 370/448, Label Counts: {0: 7, 1: 6, 2: 3}\n",
            "Epoch 3/3, Batch 370/448, Loss: 0.2908, Time: 1.62 seconds\n",
            "Batch 371/448, Label Counts: {0: 8, 1: 4, 2: 4}\n",
            "Epoch 3/3, Batch 371/448, Loss: 0.5530, Time: 1.63 seconds\n",
            "Batch 372/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 372/448, Loss: 0.3554, Time: 1.63 seconds\n",
            "Batch 373/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 373/448, Loss: 0.2966, Time: 1.62 seconds\n",
            "Batch 374/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 374/448, Loss: 0.4430, Time: 1.61 seconds\n",
            "Batch 375/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 375/448, Loss: 0.3656, Time: 1.63 seconds\n",
            "Batch 376/448, Label Counts: {0: 9, 1: 4, 2: 3}\n",
            "Epoch 3/3, Batch 376/448, Loss: 0.2964, Time: 1.62 seconds\n",
            "Batch 377/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 377/448, Loss: 0.7143, Time: 1.62 seconds\n",
            "Batch 378/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 378/448, Loss: 0.2616, Time: 1.62 seconds\n",
            "Batch 379/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 379/448, Loss: 0.9682, Time: 1.63 seconds\n",
            "Batch 380/448, Label Counts: {0: 3, 1: 5, 2: 8}\n",
            "Epoch 3/3, Batch 380/448, Loss: 0.5308, Time: 1.63 seconds\n",
            "Batch 381/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 381/448, Loss: 0.9363, Time: 1.62 seconds\n",
            "Batch 382/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 382/448, Loss: 0.3896, Time: 1.61 seconds\n",
            "Batch 383/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 383/448, Loss: 0.4003, Time: 1.62 seconds\n",
            "Batch 384/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 384/448, Loss: 0.4684, Time: 1.62 seconds\n",
            "Batch 385/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 385/448, Loss: 0.2624, Time: 1.62 seconds\n",
            "Batch 386/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 386/448, Loss: 0.5352, Time: 1.62 seconds\n",
            "Batch 387/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 387/448, Loss: 0.8854, Time: 1.61 seconds\n",
            "Batch 388/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 388/448, Loss: 0.4758, Time: 1.62 seconds\n",
            "Batch 389/448, Label Counts: {0: 9, 1: 5, 2: 2}\n",
            "Epoch 3/3, Batch 389/448, Loss: 0.3816, Time: 1.61 seconds\n",
            "Batch 390/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 390/448, Loss: 0.3884, Time: 1.62 seconds\n",
            "Batch 391/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 391/448, Loss: 0.3347, Time: 1.61 seconds\n",
            "Batch 392/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 392/448, Loss: 0.7264, Time: 1.62 seconds\n",
            "Batch 393/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 393/448, Loss: 0.3606, Time: 1.62 seconds\n",
            "Batch 394/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 394/448, Loss: 0.6224, Time: 1.62 seconds\n",
            "Batch 395/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 395/448, Loss: 0.2075, Time: 1.62 seconds\n",
            "Batch 396/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 396/448, Loss: 0.5111, Time: 1.62 seconds\n",
            "Batch 397/448, Label Counts: {0: 7, 1: 7, 2: 2}\n",
            "Epoch 3/3, Batch 397/448, Loss: 0.6877, Time: 1.62 seconds\n",
            "Batch 398/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 398/448, Loss: 0.2330, Time: 1.62 seconds\n",
            "Batch 399/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 399/448, Loss: 0.4035, Time: 1.62 seconds\n",
            "Batch 400/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 400/448, Loss: 0.4334, Time: 1.61 seconds\n",
            "Batch 401/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 401/448, Loss: 0.5787, Time: 1.62 seconds\n",
            "Batch 402/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 402/448, Loss: 0.5404, Time: 1.62 seconds\n",
            "Batch 403/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 403/448, Loss: 0.3161, Time: 1.63 seconds\n",
            "Batch 404/448, Label Counts: {0: 4, 1: 9, 2: 3}\n",
            "Epoch 3/3, Batch 404/448, Loss: 0.6232, Time: 1.62 seconds\n",
            "Batch 405/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 405/448, Loss: 0.2809, Time: 1.62 seconds\n",
            "Batch 406/448, Label Counts: {0: 4, 1: 4, 2: 8}\n",
            "Epoch 3/3, Batch 406/448, Loss: 0.3124, Time: 1.62 seconds\n",
            "Batch 407/448, Label Counts: {0: 4, 1: 5, 2: 7}\n",
            "Epoch 3/3, Batch 407/448, Loss: 0.4921, Time: 1.62 seconds\n",
            "Batch 408/448, Label Counts: {0: 4, 1: 6, 2: 6}\n",
            "Epoch 3/3, Batch 408/448, Loss: 0.6094, Time: 1.62 seconds\n",
            "Batch 409/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 409/448, Loss: 0.3730, Time: 1.62 seconds\n",
            "Batch 410/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 410/448, Loss: 0.3724, Time: 1.62 seconds\n",
            "Batch 411/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 411/448, Loss: 0.3190, Time: 1.62 seconds\n",
            "Batch 412/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 412/448, Loss: 0.7308, Time: 1.62 seconds\n",
            "Batch 413/448, Label Counts: {0: 8, 1: 1, 2: 7}\n",
            "Epoch 3/3, Batch 413/448, Loss: 0.5645, Time: 1.62 seconds\n",
            "Batch 414/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 414/448, Loss: 0.1960, Time: 1.61 seconds\n",
            "Batch 415/448, Label Counts: {0: 6, 1: 6, 2: 4}\n",
            "Epoch 3/3, Batch 415/448, Loss: 0.5245, Time: 1.62 seconds\n",
            "Batch 416/448, Label Counts: {0: 6, 1: 7, 2: 3}\n",
            "Epoch 3/3, Batch 416/448, Loss: 0.4704, Time: 1.61 seconds\n",
            "Batch 417/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 417/448, Loss: 0.4179, Time: 1.59 seconds\n",
            "Batch 418/448, Label Counts: {0: 3, 1: 7, 2: 6}\n",
            "Epoch 3/3, Batch 418/448, Loss: 0.2769, Time: 1.62 seconds\n",
            "Batch 419/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 419/448, Loss: 0.3989, Time: 1.61 seconds\n",
            "Batch 420/448, Label Counts: {0: 2, 1: 6, 2: 8}\n",
            "Epoch 3/3, Batch 420/448, Loss: 0.6312, Time: 1.62 seconds\n",
            "Batch 421/448, Label Counts: {0: 7, 1: 5, 2: 4}\n",
            "Epoch 3/3, Batch 421/448, Loss: 0.5895, Time: 1.61 seconds\n",
            "Batch 422/448, Label Counts: {0: 4, 1: 8, 2: 4}\n",
            "Epoch 3/3, Batch 422/448, Loss: 0.3499, Time: 1.61 seconds\n",
            "Batch 423/448, Label Counts: {0: 6, 1: 3, 2: 7}\n",
            "Epoch 3/3, Batch 423/448, Loss: 0.6476, Time: 1.62 seconds\n",
            "Batch 424/448, Label Counts: {0: 5, 1: 8, 2: 3}\n",
            "Epoch 3/3, Batch 424/448, Loss: 0.5114, Time: 1.61 seconds\n",
            "Batch 425/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 425/448, Loss: 0.4866, Time: 1.60 seconds\n",
            "Batch 426/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 426/448, Loss: 0.4628, Time: 1.62 seconds\n",
            "Batch 427/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 427/448, Loss: 0.3047, Time: 1.62 seconds\n",
            "Batch 428/448, Label Counts: {0: 5, 1: 6, 2: 5}\n",
            "Epoch 3/3, Batch 428/448, Loss: 0.3807, Time: 1.61 seconds\n",
            "Batch 429/448, Label Counts: {0: 6, 1: 5, 2: 5}\n",
            "Epoch 3/3, Batch 429/448, Loss: 0.4607, Time: 1.62 seconds\n",
            "Batch 430/448, Label Counts: {0: 5, 1: 5, 2: 6}\n",
            "Epoch 3/3, Batch 430/448, Loss: 0.4612, Time: 1.61 seconds\n",
            "Batch 431/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 431/448, Loss: 0.3012, Time: 1.60 seconds\n",
            "Batch 432/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 432/448, Loss: 0.3601, Time: 1.60 seconds\n",
            "Batch 433/448, Label Counts: {0: 8, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 433/448, Loss: 0.1885, Time: 1.61 seconds\n",
            "Batch 434/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 434/448, Loss: 0.4418, Time: 1.62 seconds\n",
            "Batch 435/448, Label Counts: {0: 8, 1: 5, 2: 3}\n",
            "Epoch 3/3, Batch 435/448, Loss: 0.2231, Time: 1.60 seconds\n",
            "Batch 436/448, Label Counts: {0: 5, 1: 7, 2: 4}\n",
            "Epoch 3/3, Batch 436/448, Loss: 0.4254, Time: 1.62 seconds\n",
            "Batch 437/448, Label Counts: {0: 6, 1: 4, 2: 6}\n",
            "Epoch 3/3, Batch 437/448, Loss: 1.2585, Time: 1.60 seconds\n",
            "Batch 438/448, Label Counts: {0: 6, 1: 2, 2: 8}\n",
            "Epoch 3/3, Batch 438/448, Loss: 1.1580, Time: 1.62 seconds\n",
            "Batch 439/448, Label Counts: {0: 6, 1: 8, 2: 2}\n",
            "Epoch 3/3, Batch 439/448, Loss: 0.3008, Time: 1.60 seconds\n",
            "Batch 440/448, Label Counts: {0: 3, 1: 6, 2: 7}\n",
            "Epoch 3/3, Batch 440/448, Loss: 0.5060, Time: 1.60 seconds\n",
            "Batch 441/448, Label Counts: {0: 9, 1: 3, 2: 4}\n",
            "Epoch 3/3, Batch 441/448, Loss: 0.6170, Time: 1.60 seconds\n",
            "Batch 442/448, Label Counts: {0: 7, 1: 4, 2: 5}\n",
            "Epoch 3/3, Batch 442/448, Loss: 0.4187, Time: 1.62 seconds\n",
            "Batch 443/448, Label Counts: {0: 4, 1: 7, 2: 5}\n",
            "Epoch 3/3, Batch 443/448, Loss: 0.1723, Time: 1.62 seconds\n",
            "Batch 444/448, Label Counts: {0: 5, 1: 4, 2: 7}\n",
            "Epoch 3/3, Batch 444/448, Loss: 0.4136, Time: 1.61 seconds\n",
            "Batch 445/448, Label Counts: {0: 5, 1: 3, 2: 8}\n",
            "Epoch 3/3, Batch 445/448, Loss: 0.4652, Time: 1.60 seconds\n",
            "Batch 446/448, Label Counts: {0: 5, 1: 2, 2: 9}\n",
            "Epoch 3/3, Batch 446/448, Loss: 0.2756, Time: 1.61 seconds\n",
            "Batch 447/448, Label Counts: {0: 3, 1: 4, 2: 9}\n",
            "Epoch 3/3, Batch 447/448, Loss: 0.5423, Time: 1.62 seconds\n",
            "Batch 448/448, Label Counts: {0: 1, 1: 3, 2: 5}\n",
            "Epoch 3/3, Batch 448/448, Loss: 0.7533, Time: 0.93 seconds\n",
            "Epoch 3/3, Training Loss: 0.4943, Time: 723.37 seconds\n",
            "Validation Loss: 0.6908, Accuracy: 0.7589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./trained_models/SMOTE_FINAL_REPORT\")"
      ],
      "metadata": {
        "id": "d-JVHYnjSCV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkGhT2LtLxYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "G4DcAT3AfaWn",
        "bWL0hJN9ibzr",
        "7O_HDcBnbuX9",
        "c_Rsr9qEzGUO",
        "jCYKWMQNKAWO",
        "_3tZ21z4NgxJ",
        "cy-V-2s47_Lc",
        "JZ225ZsEZe59",
        "PvCNJg7ZBNSE",
        "edC2wi3SR00k"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5835f4a7d9d3468ebe0a23d9cf90b24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b10c08db91e34912b6155338b3c2d960",
              "IPY_MODEL_2211e3911de04ef5b5ac00fdc33b2cba",
              "IPY_MODEL_8cc54a2811e443839ed27f6d7a419185"
            ],
            "layout": "IPY_MODEL_6c3dfece449049f781557df694bcaf13"
          }
        },
        "b10c08db91e34912b6155338b3c2d960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972350f425854a1a9208b7a7fdde484d",
            "placeholder": "​",
            "style": "IPY_MODEL_f35386668fc749c1b3337457716623ec",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2211e3911de04ef5b5ac00fdc33b2cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5881c279608a4afdbf0987eb1c903a49",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1379cbe4276c4ab89dfd3a7731a0d190",
            "value": 28
          }
        },
        "8cc54a2811e443839ed27f6d7a419185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1935e4edf4d49ffa6e63d188219c386",
            "placeholder": "​",
            "style": "IPY_MODEL_3b800dc0386b478f8d959d41f48d0d14",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]"
          }
        },
        "6c3dfece449049f781557df694bcaf13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972350f425854a1a9208b7a7fdde484d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35386668fc749c1b3337457716623ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5881c279608a4afdbf0987eb1c903a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1379cbe4276c4ab89dfd3a7731a0d190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1935e4edf4d49ffa6e63d188219c386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b800dc0386b478f8d959d41f48d0d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd575fab1aa4835bec842eacee78334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_025ef785e0e44632a460c7c6378194c4",
              "IPY_MODEL_cea12ba71d4447358c12b74557eeba22",
              "IPY_MODEL_d061cfb0d2714c10b4e94e43e86660fa"
            ],
            "layout": "IPY_MODEL_e6a94f9b541a420688a1707d7b53180e"
          }
        },
        "025ef785e0e44632a460c7c6378194c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16fc1340460641b6a2aed5e46d31c576",
            "placeholder": "​",
            "style": "IPY_MODEL_43f3699cfbde4abc835218a9e9f3f27f",
            "value": "vocab.txt: 100%"
          }
        },
        "cea12ba71d4447358c12b74557eeba22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc865a32fdb247b28729e20a42d76905",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc7ab87384c845e98af5d301ed6bd010",
            "value": 231508
          }
        },
        "d061cfb0d2714c10b4e94e43e86660fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bcf295ccc584ef7afd59bd1556380bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0c77992ab848410fabd7c9b14d2b422b",
            "value": " 232k/232k [00:00&lt;00:00, 4.75MB/s]"
          }
        },
        "e6a94f9b541a420688a1707d7b53180e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16fc1340460641b6a2aed5e46d31c576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f3699cfbde4abc835218a9e9f3f27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc865a32fdb247b28729e20a42d76905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7ab87384c845e98af5d301ed6bd010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bcf295ccc584ef7afd59bd1556380bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c77992ab848410fabd7c9b14d2b422b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a462a79fe924da7bbb2145701052797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aa75dd4b68b456a9f84e21a9f9be8d8",
              "IPY_MODEL_26b7cae120d34413962f8d3d0a2bcd1d",
              "IPY_MODEL_eaba901aa37145669788e686add50b28"
            ],
            "layout": "IPY_MODEL_f4ae8fde7cb04eec81a5644d4d5e1d60"
          }
        },
        "3aa75dd4b68b456a9f84e21a9f9be8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb68d4d36adb43f9bc9bdaaf817d05b8",
            "placeholder": "​",
            "style": "IPY_MODEL_a0062d3167844758accb4b7de17e9ddb",
            "value": "tokenizer.json: 100%"
          }
        },
        "26b7cae120d34413962f8d3d0a2bcd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14921e3b440147d7b150d84533e9250b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_370db093b0eb4e0db8d90c74609eb348",
            "value": 466062
          }
        },
        "eaba901aa37145669788e686add50b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf7c07f06bc4ab0a09a3a60b4b6f4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_55b2da98fa394d5a937f379e8a54c008",
            "value": " 466k/466k [00:00&lt;00:00, 16.3MB/s]"
          }
        },
        "f4ae8fde7cb04eec81a5644d4d5e1d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb68d4d36adb43f9bc9bdaaf817d05b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0062d3167844758accb4b7de17e9ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14921e3b440147d7b150d84533e9250b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370db093b0eb4e0db8d90c74609eb348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bf7c07f06bc4ab0a09a3a60b4b6f4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b2da98fa394d5a937f379e8a54c008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29b1a659c4b4454192ea0275589d9fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5538efd5bd9242d28832235a368793de",
              "IPY_MODEL_2ea1a474636248f5869638ee933be005",
              "IPY_MODEL_a07ab1b37ef745599446e20b8dcbc8c6"
            ],
            "layout": "IPY_MODEL_733b5ac09d3346e485c8f2a94c1efea2"
          }
        },
        "5538efd5bd9242d28832235a368793de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7d9f51081749789ba6eea5e86dccb8",
            "placeholder": "​",
            "style": "IPY_MODEL_cb41004d4bc34b76b2f5ae9abd9f0eee",
            "value": "config.json: 100%"
          }
        },
        "2ea1a474636248f5869638ee933be005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56afec1cc4d54e998f8a6f738cb7a5d8",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_135e893871564eceb039174c9ff2917c",
            "value": 570
          }
        },
        "a07ab1b37ef745599446e20b8dcbc8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408c9ce8995f4b79a5be34ab83380f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_eabf0925d7874fb08b71aedd322ef28e",
            "value": " 570/570 [00:00&lt;00:00, 39.1kB/s]"
          }
        },
        "733b5ac09d3346e485c8f2a94c1efea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7d9f51081749789ba6eea5e86dccb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb41004d4bc34b76b2f5ae9abd9f0eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56afec1cc4d54e998f8a6f738cb7a5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135e893871564eceb039174c9ff2917c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "408c9ce8995f4b79a5be34ab83380f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabf0925d7874fb08b71aedd322ef28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f347e9f77441d1bbe3ec9826109f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65109d786baf47dba249f47c276e7315",
              "IPY_MODEL_18a0a802d8404f69b54100a3b1b44e66",
              "IPY_MODEL_6d6b22348b22461f9535e7cc75bc23fa"
            ],
            "layout": "IPY_MODEL_9cbfd4a7ec814863abb1c5e9b853a307"
          }
        },
        "65109d786baf47dba249f47c276e7315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffcf1526ad624bdf97f75786577f133b",
            "placeholder": "​",
            "style": "IPY_MODEL_ccbd124ac89a4aebab059865b5f3a81d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "18a0a802d8404f69b54100a3b1b44e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2fb6618f03b4caaad48f0b5d334e818",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_353f4b2fa2db4326872716c1c28460a2",
            "value": 28
          }
        },
        "6d6b22348b22461f9535e7cc75bc23fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e313f46bcc4da28a57138c10325b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_3b43e2f9ee954eaca6abb33b90bf191e",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.44kB/s]"
          }
        },
        "9cbfd4a7ec814863abb1c5e9b853a307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcf1526ad624bdf97f75786577f133b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbd124ac89a4aebab059865b5f3a81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2fb6618f03b4caaad48f0b5d334e818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353f4b2fa2db4326872716c1c28460a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89e313f46bcc4da28a57138c10325b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b43e2f9ee954eaca6abb33b90bf191e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96495f49aca749888732726d61600cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1881e42fce2a4e49a23b6ed34fbe10ed",
              "IPY_MODEL_d3ac646ac8b24f848d2764d3cb042799",
              "IPY_MODEL_5e587af59fe149da8a7809bc946a0d60"
            ],
            "layout": "IPY_MODEL_bbc27ecfe96047a5addfd938d4790254"
          }
        },
        "1881e42fce2a4e49a23b6ed34fbe10ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e94d7544074463bef9784eae5c20df",
            "placeholder": "​",
            "style": "IPY_MODEL_f0dd291a6203469b988c5ea7a9a39eac",
            "value": "vocab.txt: 100%"
          }
        },
        "d3ac646ac8b24f848d2764d3cb042799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1373af0024454289bca3a38df9e966",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c4841b15188464a82a61c2a7bf5a5b2",
            "value": 231508
          }
        },
        "5e587af59fe149da8a7809bc946a0d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00cba2de44844de9bfa4d6e2d93abf4",
            "placeholder": "​",
            "style": "IPY_MODEL_a683b0e286304609b60728b2d7b207fa",
            "value": " 232k/232k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "bbc27ecfe96047a5addfd938d4790254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e94d7544074463bef9784eae5c20df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dd291a6203469b988c5ea7a9a39eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c1373af0024454289bca3a38df9e966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4841b15188464a82a61c2a7bf5a5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f00cba2de44844de9bfa4d6e2d93abf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a683b0e286304609b60728b2d7b207fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04dd194e15484dcd9a2130fe5334090e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ea389a310914e30bbf231dbb90f024b",
              "IPY_MODEL_4289cc32fed04628a0a5d9d94000b21a",
              "IPY_MODEL_40fbad3c882a4a5db010f7f208cbf5d0"
            ],
            "layout": "IPY_MODEL_91008f680abb4446b944a198f64859c3"
          }
        },
        "2ea389a310914e30bbf231dbb90f024b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d28d99749e64401e8d04d9e1363ad8ec",
            "placeholder": "​",
            "style": "IPY_MODEL_280c2f4589c84701a7e921ecf971a413",
            "value": "tokenizer.json: 100%"
          }
        },
        "4289cc32fed04628a0a5d9d94000b21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb11c0ba1024b17a3d1d9c7fec31c6e",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46af9f4babf74fa7aa47222474c93f8f",
            "value": 466062
          }
        },
        "40fbad3c882a4a5db010f7f208cbf5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ae287fed578428ca873e3660cc750e4",
            "placeholder": "​",
            "style": "IPY_MODEL_e91cb72f7799453885f4a1db11369d5f",
            "value": " 466k/466k [00:00&lt;00:00, 5.60MB/s]"
          }
        },
        "91008f680abb4446b944a198f64859c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28d99749e64401e8d04d9e1363ad8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280c2f4589c84701a7e921ecf971a413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeb11c0ba1024b17a3d1d9c7fec31c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46af9f4babf74fa7aa47222474c93f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ae287fed578428ca873e3660cc750e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91cb72f7799453885f4a1db11369d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "743babd3758244e982f8c584bbf6f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77b1e17502824888b6d34e71d2d91f1e",
              "IPY_MODEL_25c0a16ea1de4f83bbd4e84e7a69a609",
              "IPY_MODEL_235bc4cf694d453fbcc575ae71709b7b"
            ],
            "layout": "IPY_MODEL_eca228d769f84ef1b17f432512c9fba2"
          }
        },
        "77b1e17502824888b6d34e71d2d91f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec4dc6f48f0042d2bd81d59d641b6072",
            "placeholder": "​",
            "style": "IPY_MODEL_36a6e3484e6d4322a88ecac7a897581b",
            "value": "config.json: 100%"
          }
        },
        "25c0a16ea1de4f83bbd4e84e7a69a609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab297ddcabb40b689303e813dc54147",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1a0eaee3977416390a57af06eb3a28e",
            "value": 570
          }
        },
        "235bc4cf694d453fbcc575ae71709b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b021b5564de4839b334f5753202b0a2",
            "placeholder": "​",
            "style": "IPY_MODEL_11486ed1ac7749be8bf7fa9fa844fcba",
            "value": " 570/570 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "eca228d769f84ef1b17f432512c9fba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4dc6f48f0042d2bd81d59d641b6072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a6e3484e6d4322a88ecac7a897581b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab297ddcabb40b689303e813dc54147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a0eaee3977416390a57af06eb3a28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b021b5564de4839b334f5753202b0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11486ed1ac7749be8bf7fa9fa844fcba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6abb53dd5c2d4e38bca0d91085d32cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f035cb1732384538824bc34af0edb5d9",
              "IPY_MODEL_0f636619621540fbb7e7e49272e33bb8",
              "IPY_MODEL_09c938f2924c4575ba3b65653596ac59"
            ],
            "layout": "IPY_MODEL_0a9f7c626bff4199b22403d03b4b60b2"
          }
        },
        "f035cb1732384538824bc34af0edb5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85af90a113e44d8cbe2dba18f9b2d1d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3522d92a655d45b4b5b9525b8839f65d",
            "value": "model.safetensors: 100%"
          }
        },
        "0f636619621540fbb7e7e49272e33bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed70abdaa04e4981b6bbde7bd0d7c377",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa8315e89ebb47b1a5e771fdce05fa14",
            "value": 440449768
          }
        },
        "09c938f2924c4575ba3b65653596ac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0994333a514a44a0862b8717f710abb5",
            "placeholder": "​",
            "style": "IPY_MODEL_9aea601720704c168e64f6541d969c1e",
            "value": " 440M/440M [00:05&lt;00:00, 115MB/s]"
          }
        },
        "0a9f7c626bff4199b22403d03b4b60b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85af90a113e44d8cbe2dba18f9b2d1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3522d92a655d45b4b5b9525b8839f65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed70abdaa04e4981b6bbde7bd0d7c377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8315e89ebb47b1a5e771fdce05fa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0994333a514a44a0862b8717f710abb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aea601720704c168e64f6541d969c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}